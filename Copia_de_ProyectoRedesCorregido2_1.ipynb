{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ8ca/ImxGxDmek4J2SGjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosQuark/Machine-Learning-Astrophysics/blob/main/Copia_de_ProyectoRedesCorregido2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# PROYECTO DE MACHINE LEARNING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvURBlWmT07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZV03xjlnj-NB"
      },
      "outputs": [],
      "source": [
        "#librerias Comunes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#liberias de PCA\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import eig\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder #Change the class to str for another type the int.\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#librerias de sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#librerias de Keras y Redes Neuronales\n",
        "\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = pd.read_csv(\"star_classification.csv\")\n",
        "data_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "OQ6pTIb2mimr",
        "outputId": "3e10e0a8-8068-4d46-90e8-2ad4d07cc5cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237660e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237660e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237660e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237660e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543780e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176010e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030110e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891860e+18   \n",
              "\n",
              "   redshift  plate    MJD  fiber_ID   class  \n",
              "0  0.634794   5812  56354       171  GALAXY  \n",
              "1  0.779136  10445  58158       427  GALAXY  \n",
              "2  0.644195   4576  55592       299  GALAXY  \n",
              "3  0.932346   9149  58039       775  GALAXY  \n",
              "4  0.116123   6121  56187       842  GALAXY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87b7df07-cb77-443b-aaab-cb63a5948fbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543780e+18</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176010e+19</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030110e+19</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891860e+18</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b7df07-cb77-443b-aaab-cb63a5948fbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87b7df07-cb77-443b-aaab-cb63a5948fbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87b7df07-cb77-443b-aaab-cb63a5948fbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9c19507-52cd-4455-a9af-e69a1a3016bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9c19507-52cd-4455-a9af-e69a1a3016bf')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9c19507-52cd-4455-a9af-e69a1a3016bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nlql6Qz1Znk",
        "outputId": "25c35a38-bed9-4508-8973-246463072e15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 18 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   obj_ID       100000 non-null  float64\n",
            " 1   alpha        100000 non-null  float64\n",
            " 2   delta        100000 non-null  float64\n",
            " 3   u            100000 non-null  float64\n",
            " 4   g            100000 non-null  float64\n",
            " 5   r            100000 non-null  float64\n",
            " 6   i            100000 non-null  float64\n",
            " 7   z            100000 non-null  float64\n",
            " 8   run_ID       100000 non-null  int64  \n",
            " 9   rerun_ID     100000 non-null  int64  \n",
            " 10  cam_col      100000 non-null  int64  \n",
            " 11  field_ID     100000 non-null  int64  \n",
            " 12  spec_obj_ID  100000 non-null  float64\n",
            " 13  redshift     100000 non-null  float64\n",
            " 14  plate        100000 non-null  int64  \n",
            " 15  MJD          100000 non-null  int64  \n",
            " 16  fiber_ID     100000 non-null  int64  \n",
            " 17  class        100000 non-null  object \n",
            "dtypes: float64(10), int64(7), object(1)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enconder = LabelEncoder()\n",
        "\n",
        "data_set[\"class\"] = enconder.fit_transform(data_set[\"class\"])"
      ],
      "metadata": {
        "id": "lVhT4P72weJt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar los datos\n",
        "\n",
        "Y = np.array(data_set[\"class\"])\n",
        "\n",
        "df_new = data_set.drop([\"class\"], axis =1)\n",
        "\n",
        "X = np.array(df_new)\n"
      ],
      "metadata": {
        "id": "5VSRDHJhn75L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components= 17)\n",
        "PCA_objeto.fit(X)"
      ],
      "metadata": {
        "id": "Akeqp3SySWYi",
        "outputId": "7662b86d-f611-4128-cf20-fb6d2592910e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PCA_objeto.explained_variance_)"
      ],
      "metadata": {
        "id": "3jmLTxmoSp0Q",
        "outputId": "8b2452e6-a188-4051-9520-7992f8761636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.10491489e+37 5.34345995e+28 3.63783147e+06 1.90094686e+05\n",
            " 6.89069641e+04 2.22875371e+04 8.93542373e+03 3.01724592e+03\n",
            " 3.23491013e+02 6.79740439e+00 3.42870277e+00 2.46778931e+00\n",
            " 1.93784010e+00 4.09255753e-01 3.26988977e-01 4.66492584e-02\n",
            " 3.72772496e-34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components = 17)\n",
        "Z = PCA_objeto.fit_transform(X)"
      ],
      "metadata": {
        "id": "0dytpcETSr5A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento de los datos\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Z,Y, test_size = 0.2, stratify=Y)"
      ],
      "metadata": {
        "id": "MXeQdyFvxQQ6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estandarizar los datos\n",
        "\n",
        "scaler = MinMaxScaler().fit(xtrain)\n",
        "\n",
        "xtrain_std = scaler.transform(xtrain)\n",
        "\n",
        "xtest_std = scaler.transform(xtest)\n"
      ],
      "metadata": {
        "id": "i6dJHiUQxpVc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Este apartado se utilizar para poder dar inicio el entrenamiento a una red\n",
        "neuronal\n",
        "\n",
        "   Todo esto viene dentro de la página oficial de Keras.\n",
        "\n",
        "   Dense es una capa de neurona que está conectada con todas las anteriores\n",
        "\n",
        "   Sequential es utilizado para crear secuencias en redes neuronales.\n",
        "\n",
        "   Optimizador: Adam.\n",
        "\n",
        "   units es la candtidad de clases que tienes.\n",
        "\n",
        "   activation: \"Qué tipo de función de activación almacenas\".\n",
        "\n",
        "   input_dim = la dimensionalidad.\n",
        "\n",
        "\"\"\"\n",
        "network = Sequential([\n",
        "\n",
        "    Dense(units=3, activation= \"softmax\" , input_dim = 17)\n",
        "])\n",
        "\n",
        "#Que copilador voy a utilizar, Adam, puede hacer eso.\n",
        "\n",
        "Adam(learning_rate=0.0001) #Taza de aprendizaje pequeña\n",
        "\n",
        "network.compile()\n",
        "\n",
        "#Función de perdida que se utilizará en la sala de entrenamient como su métrica.\n",
        "\n",
        "network.compile(loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QbP87Xplx-fX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"La libreria de keras para to_categorical\n",
        "\n",
        "   se utiliza para poder experesar problemas de clasificación de multiclase.\n",
        "   Para convertir nuestras etiquetas númericas en tipo one-hot.\n",
        "\n",
        "   Supongamso que tienes 3 clases (etiqeutas númericas 0,1,2)\n",
        "\n",
        "   En la primera linea convierte la una matriz en one-hot\n",
        "\n",
        "   Cada fila corresponde a un etiqueta, y cada columna, representa una clase.\n",
        "\n",
        "   AQUÍ INICIAMOS LA ETAPA DE ENTRENAMIENTO DE LA RED\n",
        "\n",
        "   El profe explica que es el batch_size, es para reducir el costo\n",
        "   computacional,\n",
        "   crea grupos para filas de hasta 100,000 dimensiones.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#network.fit(xtrain_std, ytrain, epochs=50, batch_size=128 )\n",
        "\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "epoch_accuracy =network.fit(xtrain_std, ytrain, epochs=1000, batch_size=80,\n",
        "                             validation_data=(xtest_std,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMrjFO3yNnb",
        "outputId": "8c66b6a5-351f-4357-81a8-d567263d54c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 0.9428 - accuracy: 0.5842 - val_loss: 0.9140 - val_accuracy: 0.5950\n",
            "Epoch 2/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8957 - accuracy: 0.5966 - val_loss: 0.8825 - val_accuracy: 0.5997\n",
            "Epoch 3/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8681 - accuracy: 0.6037 - val_loss: 0.8583 - val_accuracy: 0.6085\n",
            "Epoch 4/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8463 - accuracy: 0.6119 - val_loss: 0.8386 - val_accuracy: 0.6157\n",
            "Epoch 5/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8277 - accuracy: 0.6188 - val_loss: 0.8211 - val_accuracy: 0.6187\n",
            "Epoch 6/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8112 - accuracy: 0.6260 - val_loss: 0.8054 - val_accuracy: 0.6254\n",
            "Epoch 7/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7961 - accuracy: 0.6345 - val_loss: 0.7908 - val_accuracy: 0.6370\n",
            "Epoch 8/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7825 - accuracy: 0.6455 - val_loss: 0.7774 - val_accuracy: 0.6517\n",
            "Epoch 9/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7695 - accuracy: 0.6565 - val_loss: 0.7644 - val_accuracy: 0.6575\n",
            "Epoch 10/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7573 - accuracy: 0.6680 - val_loss: 0.7527 - val_accuracy: 0.6667\n",
            "Epoch 11/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7461 - accuracy: 0.6787 - val_loss: 0.7419 - val_accuracy: 0.6910\n",
            "Epoch 12/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7358 - accuracy: 0.6887 - val_loss: 0.7317 - val_accuracy: 0.6903\n",
            "Epoch 13/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7261 - accuracy: 0.6980 - val_loss: 0.7219 - val_accuracy: 0.7000\n",
            "Epoch 14/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7169 - accuracy: 0.7078 - val_loss: 0.7132 - val_accuracy: 0.7055\n",
            "Epoch 15/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7085 - accuracy: 0.7162 - val_loss: 0.7049 - val_accuracy: 0.7208\n",
            "Epoch 16/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7006 - accuracy: 0.7253 - val_loss: 0.6970 - val_accuracy: 0.7337\n",
            "Epoch 17/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.7329 - val_loss: 0.6906 - val_accuracy: 0.7209\n",
            "Epoch 18/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6860 - accuracy: 0.7394 - val_loss: 0.6830 - val_accuracy: 0.7523\n",
            "Epoch 19/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.7463 - val_loss: 0.6764 - val_accuracy: 0.7521\n",
            "Epoch 20/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6729 - accuracy: 0.7525 - val_loss: 0.6694 - val_accuracy: 0.7526\n",
            "Epoch 21/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6667 - accuracy: 0.7567 - val_loss: 0.6633 - val_accuracy: 0.7631\n",
            "Epoch 22/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6609 - accuracy: 0.7623 - val_loss: 0.6576 - val_accuracy: 0.7690\n",
            "Epoch 23/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6554 - accuracy: 0.7659 - val_loss: 0.6525 - val_accuracy: 0.7764\n",
            "Epoch 24/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6500 - accuracy: 0.7704 - val_loss: 0.6472 - val_accuracy: 0.7747\n",
            "Epoch 25/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6450 - accuracy: 0.7745 - val_loss: 0.6419 - val_accuracy: 0.7760\n",
            "Epoch 26/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6403 - accuracy: 0.7777 - val_loss: 0.6374 - val_accuracy: 0.7878\n",
            "Epoch 27/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6357 - accuracy: 0.7811 - val_loss: 0.6326 - val_accuracy: 0.7843\n",
            "Epoch 28/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6313 - accuracy: 0.7839 - val_loss: 0.6283 - val_accuracy: 0.7867\n",
            "Epoch 29/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6272 - accuracy: 0.7866 - val_loss: 0.6241 - val_accuracy: 0.7894\n",
            "Epoch 30/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6230 - accuracy: 0.7900 - val_loss: 0.6203 - val_accuracy: 0.7984\n",
            "Epoch 31/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6192 - accuracy: 0.7922 - val_loss: 0.6166 - val_accuracy: 0.8015\n",
            "Epoch 32/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6156 - accuracy: 0.7947 - val_loss: 0.6126 - val_accuracy: 0.7990\n",
            "Epoch 33/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6121 - accuracy: 0.7969 - val_loss: 0.6093 - val_accuracy: 0.7990\n",
            "Epoch 34/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6087 - accuracy: 0.7994 - val_loss: 0.6059 - val_accuracy: 0.8030\n",
            "Epoch 35/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6054 - accuracy: 0.8008 - val_loss: 0.6025 - val_accuracy: 0.8067\n",
            "Epoch 36/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6023 - accuracy: 0.8030 - val_loss: 0.5993 - val_accuracy: 0.8076\n",
            "Epoch 37/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5992 - accuracy: 0.8048 - val_loss: 0.5964 - val_accuracy: 0.8093\n",
            "Epoch 38/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5963 - accuracy: 0.8060 - val_loss: 0.5934 - val_accuracy: 0.8134\n",
            "Epoch 39/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5934 - accuracy: 0.8081 - val_loss: 0.5907 - val_accuracy: 0.8159\n",
            "Epoch 40/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5907 - accuracy: 0.8097 - val_loss: 0.5878 - val_accuracy: 0.8133\n",
            "Epoch 41/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5880 - accuracy: 0.8108 - val_loss: 0.5853 - val_accuracy: 0.8139\n",
            "Epoch 42/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5855 - accuracy: 0.8124 - val_loss: 0.5827 - val_accuracy: 0.8169\n",
            "Epoch 43/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5830 - accuracy: 0.8133 - val_loss: 0.5804 - val_accuracy: 0.8203\n",
            "Epoch 44/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5806 - accuracy: 0.8147 - val_loss: 0.5778 - val_accuracy: 0.8195\n",
            "Epoch 45/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5783 - accuracy: 0.8158 - val_loss: 0.5757 - val_accuracy: 0.8180\n",
            "Epoch 46/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5761 - accuracy: 0.8169 - val_loss: 0.5733 - val_accuracy: 0.8201\n",
            "Epoch 47/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5739 - accuracy: 0.8182 - val_loss: 0.5714 - val_accuracy: 0.8185\n",
            "Epoch 48/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5717 - accuracy: 0.8184 - val_loss: 0.5692 - val_accuracy: 0.8226\n",
            "Epoch 49/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.8199 - val_loss: 0.5669 - val_accuracy: 0.8243\n",
            "Epoch 50/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.8209 - val_loss: 0.5653 - val_accuracy: 0.8280\n",
            "Epoch 51/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5657 - accuracy: 0.8211 - val_loss: 0.5631 - val_accuracy: 0.8278\n",
            "Epoch 52/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5638 - accuracy: 0.8219 - val_loss: 0.5617 - val_accuracy: 0.8300\n",
            "Epoch 53/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5620 - accuracy: 0.8229 - val_loss: 0.5593 - val_accuracy: 0.8276\n",
            "Epoch 54/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5603 - accuracy: 0.8237 - val_loss: 0.5576 - val_accuracy: 0.8281\n",
            "Epoch 55/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5585 - accuracy: 0.8241 - val_loss: 0.5559 - val_accuracy: 0.8295\n",
            "Epoch 56/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5569 - accuracy: 0.8250 - val_loss: 0.5543 - val_accuracy: 0.8300\n",
            "Epoch 57/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5552 - accuracy: 0.8253 - val_loss: 0.5526 - val_accuracy: 0.8303\n",
            "Epoch 58/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5536 - accuracy: 0.8264 - val_loss: 0.5510 - val_accuracy: 0.8303\n",
            "Epoch 59/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5520 - accuracy: 0.8269 - val_loss: 0.5493 - val_accuracy: 0.8324\n",
            "Epoch 60/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.8274 - val_loss: 0.5478 - val_accuracy: 0.8326\n",
            "Epoch 61/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.8280 - val_loss: 0.5466 - val_accuracy: 0.8293\n",
            "Epoch 62/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.8284 - val_loss: 0.5453 - val_accuracy: 0.8344\n",
            "Epoch 63/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.8292 - val_loss: 0.5434 - val_accuracy: 0.8340\n",
            "Epoch 64/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.8295 - val_loss: 0.5421 - val_accuracy: 0.8321\n",
            "Epoch 65/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5430 - accuracy: 0.8298 - val_loss: 0.5411 - val_accuracy: 0.8364\n",
            "Epoch 66/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.8311 - val_loss: 0.5396 - val_accuracy: 0.8309\n",
            "Epoch 67/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.8309 - val_loss: 0.5380 - val_accuracy: 0.8334\n",
            "Epoch 68/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.8314 - val_loss: 0.5365 - val_accuracy: 0.8346\n",
            "Epoch 69/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.8322 - val_loss: 0.5353 - val_accuracy: 0.8347\n",
            "Epoch 70/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.8330 - val_loss: 0.5341 - val_accuracy: 0.8370\n",
            "Epoch 71/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5353 - accuracy: 0.8328 - val_loss: 0.5334 - val_accuracy: 0.8393\n",
            "Epoch 72/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.8336 - val_loss: 0.5321 - val_accuracy: 0.8396\n",
            "Epoch 73/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.8337 - val_loss: 0.5307 - val_accuracy: 0.8383\n",
            "Epoch 74/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.8343 - val_loss: 0.5293 - val_accuracy: 0.8369\n",
            "Epoch 75/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.8349 - val_loss: 0.5281 - val_accuracy: 0.8379\n",
            "Epoch 76/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.8350 - val_loss: 0.5273 - val_accuracy: 0.8362\n",
            "Epoch 77/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5284 - accuracy: 0.8356 - val_loss: 0.5259 - val_accuracy: 0.8395\n",
            "Epoch 78/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5273 - accuracy: 0.8361 - val_loss: 0.5248 - val_accuracy: 0.8384\n",
            "Epoch 79/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5263 - accuracy: 0.8359 - val_loss: 0.5237 - val_accuracy: 0.8393\n",
            "Epoch 80/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5252 - accuracy: 0.8364 - val_loss: 0.5227 - val_accuracy: 0.8401\n",
            "Epoch 81/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5241 - accuracy: 0.8374 - val_loss: 0.5217 - val_accuracy: 0.8403\n",
            "Epoch 82/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5231 - accuracy: 0.8369 - val_loss: 0.5207 - val_accuracy: 0.8400\n",
            "Epoch 83/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5223 - accuracy: 0.8376 - val_loss: 0.5199 - val_accuracy: 0.8426\n",
            "Epoch 84/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5212 - accuracy: 0.8374 - val_loss: 0.5189 - val_accuracy: 0.8429\n",
            "Epoch 85/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5203 - accuracy: 0.8378 - val_loss: 0.5179 - val_accuracy: 0.8406\n",
            "Epoch 86/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5193 - accuracy: 0.8378 - val_loss: 0.5168 - val_accuracy: 0.8418\n",
            "Epoch 87/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5184 - accuracy: 0.8385 - val_loss: 0.5159 - val_accuracy: 0.8415\n",
            "Epoch 88/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5175 - accuracy: 0.8390 - val_loss: 0.5150 - val_accuracy: 0.8429\n",
            "Epoch 89/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5166 - accuracy: 0.8392 - val_loss: 0.5149 - val_accuracy: 0.8382\n",
            "Epoch 90/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5157 - accuracy: 0.8393 - val_loss: 0.5135 - val_accuracy: 0.8413\n",
            "Epoch 91/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5148 - accuracy: 0.8396 - val_loss: 0.5130 - val_accuracy: 0.8449\n",
            "Epoch 92/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5140 - accuracy: 0.8396 - val_loss: 0.5116 - val_accuracy: 0.8449\n",
            "Epoch 93/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5131 - accuracy: 0.8400 - val_loss: 0.5106 - val_accuracy: 0.8432\n",
            "Epoch 94/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5122 - accuracy: 0.8405 - val_loss: 0.5097 - val_accuracy: 0.8440\n",
            "Epoch 95/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5114 - accuracy: 0.8406 - val_loss: 0.5092 - val_accuracy: 0.8419\n",
            "Epoch 96/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5105 - accuracy: 0.8410 - val_loss: 0.5080 - val_accuracy: 0.8444\n",
            "Epoch 97/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5097 - accuracy: 0.8415 - val_loss: 0.5075 - val_accuracy: 0.8429\n",
            "Epoch 98/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5089 - accuracy: 0.8414 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
            "Epoch 99/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5081 - accuracy: 0.8416 - val_loss: 0.5058 - val_accuracy: 0.8450\n",
            "Epoch 100/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5074 - accuracy: 0.8420 - val_loss: 0.5052 - val_accuracy: 0.8464\n",
            "Epoch 101/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5066 - accuracy: 0.8424 - val_loss: 0.5042 - val_accuracy: 0.8449\n",
            "Epoch 102/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5058 - accuracy: 0.8423 - val_loss: 0.5034 - val_accuracy: 0.8454\n",
            "Epoch 103/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5050 - accuracy: 0.8424 - val_loss: 0.5027 - val_accuracy: 0.8466\n",
            "Epoch 104/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5043 - accuracy: 0.8430 - val_loss: 0.5023 - val_accuracy: 0.8433\n",
            "Epoch 105/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5036 - accuracy: 0.8427 - val_loss: 0.5012 - val_accuracy: 0.8464\n",
            "Epoch 106/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5028 - accuracy: 0.8427 - val_loss: 0.5004 - val_accuracy: 0.8468\n",
            "Epoch 107/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5021 - accuracy: 0.8439 - val_loss: 0.4997 - val_accuracy: 0.8468\n",
            "Epoch 108/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5014 - accuracy: 0.8434 - val_loss: 0.4991 - val_accuracy: 0.8465\n",
            "Epoch 109/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5007 - accuracy: 0.8438 - val_loss: 0.4986 - val_accuracy: 0.8486\n",
            "Epoch 110/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5000 - accuracy: 0.8438 - val_loss: 0.4977 - val_accuracy: 0.8484\n",
            "Epoch 111/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4993 - accuracy: 0.8442 - val_loss: 0.4970 - val_accuracy: 0.8472\n",
            "Epoch 112/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4987 - accuracy: 0.8444 - val_loss: 0.4963 - val_accuracy: 0.8485\n",
            "Epoch 113/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4980 - accuracy: 0.8445 - val_loss: 0.4958 - val_accuracy: 0.8485\n",
            "Epoch 114/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.8448 - val_loss: 0.4950 - val_accuracy: 0.8475\n",
            "Epoch 115/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4967 - accuracy: 0.8448 - val_loss: 0.4945 - val_accuracy: 0.8461\n",
            "Epoch 116/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.8449 - val_loss: 0.4943 - val_accuracy: 0.8494\n",
            "Epoch 117/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4954 - accuracy: 0.8450 - val_loss: 0.4930 - val_accuracy: 0.8490\n",
            "Epoch 118/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.8457 - val_loss: 0.4925 - val_accuracy: 0.8476\n",
            "Epoch 119/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4941 - accuracy: 0.8455 - val_loss: 0.4917 - val_accuracy: 0.8493\n",
            "Epoch 120/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4935 - accuracy: 0.8460 - val_loss: 0.4914 - val_accuracy: 0.8484\n",
            "Epoch 121/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4929 - accuracy: 0.8459 - val_loss: 0.4907 - val_accuracy: 0.8478\n",
            "Epoch 122/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4923 - accuracy: 0.8459 - val_loss: 0.4900 - val_accuracy: 0.8482\n",
            "Epoch 123/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4916 - accuracy: 0.8462 - val_loss: 0.4895 - val_accuracy: 0.8499\n",
            "Epoch 124/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4911 - accuracy: 0.8463 - val_loss: 0.4891 - val_accuracy: 0.8466\n",
            "Epoch 125/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4905 - accuracy: 0.8465 - val_loss: 0.4881 - val_accuracy: 0.8495\n",
            "Epoch 126/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4898 - accuracy: 0.8469 - val_loss: 0.4875 - val_accuracy: 0.8501\n",
            "Epoch 127/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4892 - accuracy: 0.8469 - val_loss: 0.4870 - val_accuracy: 0.8493\n",
            "Epoch 128/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4887 - accuracy: 0.8470 - val_loss: 0.4865 - val_accuracy: 0.8502\n",
            "Epoch 129/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4882 - accuracy: 0.8469 - val_loss: 0.4858 - val_accuracy: 0.8503\n",
            "Epoch 130/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4875 - accuracy: 0.8478 - val_loss: 0.4855 - val_accuracy: 0.8474\n",
            "Epoch 131/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4870 - accuracy: 0.8474 - val_loss: 0.4849 - val_accuracy: 0.8505\n",
            "Epoch 132/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4865 - accuracy: 0.8478 - val_loss: 0.4842 - val_accuracy: 0.8508\n",
            "Epoch 133/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4859 - accuracy: 0.8475 - val_loss: 0.4845 - val_accuracy: 0.8513\n",
            "Epoch 134/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4854 - accuracy: 0.8481 - val_loss: 0.4832 - val_accuracy: 0.8512\n",
            "Epoch 135/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.8479 - val_loss: 0.4825 - val_accuracy: 0.8504\n",
            "Epoch 136/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4843 - accuracy: 0.8479 - val_loss: 0.4820 - val_accuracy: 0.8512\n",
            "Epoch 137/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4838 - accuracy: 0.8482 - val_loss: 0.4816 - val_accuracy: 0.8514\n",
            "Epoch 138/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4832 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.8512\n",
            "Epoch 139/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4826 - accuracy: 0.8485 - val_loss: 0.4803 - val_accuracy: 0.8511\n",
            "Epoch 140/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4821 - accuracy: 0.8486 - val_loss: 0.4798 - val_accuracy: 0.8513\n",
            "Epoch 141/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4816 - accuracy: 0.8489 - val_loss: 0.4793 - val_accuracy: 0.8509\n",
            "Epoch 142/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4811 - accuracy: 0.8488 - val_loss: 0.4788 - val_accuracy: 0.8511\n",
            "Epoch 143/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4806 - accuracy: 0.8490 - val_loss: 0.4783 - val_accuracy: 0.8513\n",
            "Epoch 144/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4801 - accuracy: 0.8488 - val_loss: 0.4780 - val_accuracy: 0.8515\n",
            "Epoch 145/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4796 - accuracy: 0.8490 - val_loss: 0.4773 - val_accuracy: 0.8509\n",
            "Epoch 146/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4791 - accuracy: 0.8497 - val_loss: 0.4768 - val_accuracy: 0.8519\n",
            "Epoch 147/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4786 - accuracy: 0.8497 - val_loss: 0.4765 - val_accuracy: 0.8522\n",
            "Epoch 148/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4781 - accuracy: 0.8500 - val_loss: 0.4758 - val_accuracy: 0.8519\n",
            "Epoch 149/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4775 - accuracy: 0.8502 - val_loss: 0.4755 - val_accuracy: 0.8504\n",
            "Epoch 150/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4770 - accuracy: 0.8499 - val_loss: 0.4754 - val_accuracy: 0.8486\n",
            "Epoch 151/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4766 - accuracy: 0.8503 - val_loss: 0.4746 - val_accuracy: 0.8500\n",
            "Epoch 152/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4761 - accuracy: 0.8503 - val_loss: 0.4738 - val_accuracy: 0.8523\n",
            "Epoch 153/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4757 - accuracy: 0.8502 - val_loss: 0.4736 - val_accuracy: 0.8508\n",
            "Epoch 154/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4751 - accuracy: 0.8506 - val_loss: 0.4730 - val_accuracy: 0.8532\n",
            "Epoch 155/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4747 - accuracy: 0.8509 - val_loss: 0.4726 - val_accuracy: 0.8533\n",
            "Epoch 156/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4743 - accuracy: 0.8511 - val_loss: 0.4722 - val_accuracy: 0.8532\n",
            "Epoch 157/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4737 - accuracy: 0.8510 - val_loss: 0.4716 - val_accuracy: 0.8529\n",
            "Epoch 158/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4733 - accuracy: 0.8509 - val_loss: 0.4710 - val_accuracy: 0.8528\n",
            "Epoch 159/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4729 - accuracy: 0.8508 - val_loss: 0.4706 - val_accuracy: 0.8529\n",
            "Epoch 160/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4724 - accuracy: 0.8511 - val_loss: 0.4702 - val_accuracy: 0.8535\n",
            "Epoch 161/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4720 - accuracy: 0.8516 - val_loss: 0.4698 - val_accuracy: 0.8527\n",
            "Epoch 162/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4715 - accuracy: 0.8512 - val_loss: 0.4693 - val_accuracy: 0.8532\n",
            "Epoch 163/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.8512 - val_loss: 0.4695 - val_accuracy: 0.8550\n",
            "Epoch 164/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.4706 - accuracy: 0.8516 - val_loss: 0.4693 - val_accuracy: 0.8492\n",
            "Epoch 165/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4701 - accuracy: 0.8516 - val_loss: 0.4681 - val_accuracy: 0.8541\n",
            "Epoch 166/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4697 - accuracy: 0.8516 - val_loss: 0.4675 - val_accuracy: 0.8533\n",
            "Epoch 167/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4693 - accuracy: 0.8517 - val_loss: 0.4672 - val_accuracy: 0.8543\n",
            "Epoch 168/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4688 - accuracy: 0.8520 - val_loss: 0.4666 - val_accuracy: 0.8539\n",
            "Epoch 169/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4684 - accuracy: 0.8520 - val_loss: 0.4662 - val_accuracy: 0.8543\n",
            "Epoch 170/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4680 - accuracy: 0.8524 - val_loss: 0.4657 - val_accuracy: 0.8544\n",
            "Epoch 171/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4676 - accuracy: 0.8522 - val_loss: 0.4653 - val_accuracy: 0.8540\n",
            "Epoch 172/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.8521 - val_loss: 0.4649 - val_accuracy: 0.8540\n",
            "Epoch 173/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4668 - accuracy: 0.8526 - val_loss: 0.4647 - val_accuracy: 0.8550\n",
            "Epoch 174/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4663 - accuracy: 0.8520 - val_loss: 0.4643 - val_accuracy: 0.8551\n",
            "Epoch 175/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4660 - accuracy: 0.8525 - val_loss: 0.4638 - val_accuracy: 0.8532\n",
            "Epoch 176/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4654 - accuracy: 0.8525 - val_loss: 0.4633 - val_accuracy: 0.8543\n",
            "Epoch 177/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4651 - accuracy: 0.8526 - val_loss: 0.4628 - val_accuracy: 0.8544\n",
            "Epoch 178/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4647 - accuracy: 0.8529 - val_loss: 0.4624 - val_accuracy: 0.8542\n",
            "Epoch 179/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4642 - accuracy: 0.8532 - val_loss: 0.4622 - val_accuracy: 0.8527\n",
            "Epoch 180/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4639 - accuracy: 0.8529 - val_loss: 0.4616 - val_accuracy: 0.8549\n",
            "Epoch 181/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4635 - accuracy: 0.8532 - val_loss: 0.4618 - val_accuracy: 0.8526\n",
            "Epoch 182/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4630 - accuracy: 0.8536 - val_loss: 0.4608 - val_accuracy: 0.8551\n",
            "Epoch 183/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4626 - accuracy: 0.8534 - val_loss: 0.4603 - val_accuracy: 0.8551\n",
            "Epoch 184/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4622 - accuracy: 0.8534 - val_loss: 0.4600 - val_accuracy: 0.8555\n",
            "Epoch 185/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4618 - accuracy: 0.8535 - val_loss: 0.4603 - val_accuracy: 0.8572\n",
            "Epoch 186/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4615 - accuracy: 0.8538 - val_loss: 0.4592 - val_accuracy: 0.8561\n",
            "Epoch 187/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4611 - accuracy: 0.8540 - val_loss: 0.4588 - val_accuracy: 0.8563\n",
            "Epoch 188/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4607 - accuracy: 0.8540 - val_loss: 0.4586 - val_accuracy: 0.8557\n",
            "Epoch 189/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4603 - accuracy: 0.8539 - val_loss: 0.4581 - val_accuracy: 0.8548\n",
            "Epoch 190/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4599 - accuracy: 0.8542 - val_loss: 0.4580 - val_accuracy: 0.8539\n",
            "Epoch 191/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4596 - accuracy: 0.8539 - val_loss: 0.4575 - val_accuracy: 0.8570\n",
            "Epoch 192/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4592 - accuracy: 0.8539 - val_loss: 0.4571 - val_accuracy: 0.8568\n",
            "Epoch 193/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4587 - accuracy: 0.8545 - val_loss: 0.4565 - val_accuracy: 0.8563\n",
            "Epoch 194/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4584 - accuracy: 0.8545 - val_loss: 0.4561 - val_accuracy: 0.8565\n",
            "Epoch 195/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4581 - accuracy: 0.8547 - val_loss: 0.4559 - val_accuracy: 0.8566\n",
            "Epoch 196/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4576 - accuracy: 0.8543 - val_loss: 0.4557 - val_accuracy: 0.8572\n",
            "Epoch 197/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4573 - accuracy: 0.8548 - val_loss: 0.4550 - val_accuracy: 0.8564\n",
            "Epoch 198/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4570 - accuracy: 0.8551 - val_loss: 0.4546 - val_accuracy: 0.8568\n",
            "Epoch 199/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.8548 - val_loss: 0.4543 - val_accuracy: 0.8564\n",
            "Epoch 200/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4562 - accuracy: 0.8549 - val_loss: 0.4541 - val_accuracy: 0.8573\n",
            "Epoch 201/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4558 - accuracy: 0.8549 - val_loss: 0.4539 - val_accuracy: 0.8541\n",
            "Epoch 202/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4555 - accuracy: 0.8552 - val_loss: 0.4534 - val_accuracy: 0.8550\n",
            "Epoch 203/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4551 - accuracy: 0.8547 - val_loss: 0.4529 - val_accuracy: 0.8560\n",
            "Epoch 204/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4548 - accuracy: 0.8549 - val_loss: 0.4525 - val_accuracy: 0.8573\n",
            "Epoch 205/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4544 - accuracy: 0.8549 - val_loss: 0.4525 - val_accuracy: 0.8579\n",
            "Epoch 206/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4540 - accuracy: 0.8553 - val_loss: 0.4520 - val_accuracy: 0.8560\n",
            "Epoch 207/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4537 - accuracy: 0.8549 - val_loss: 0.4515 - val_accuracy: 0.8576\n",
            "Epoch 208/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.8553 - val_loss: 0.4511 - val_accuracy: 0.8576\n",
            "Epoch 209/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.8550 - val_loss: 0.4507 - val_accuracy: 0.8579\n",
            "Epoch 210/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4527 - accuracy: 0.8554 - val_loss: 0.4505 - val_accuracy: 0.8559\n",
            "Epoch 211/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.8555 - val_loss: 0.4505 - val_accuracy: 0.8584\n",
            "Epoch 212/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4519 - accuracy: 0.8558 - val_loss: 0.4498 - val_accuracy: 0.8561\n",
            "Epoch 213/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.8554 - val_loss: 0.4493 - val_accuracy: 0.8574\n",
            "Epoch 214/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.8555 - val_loss: 0.4490 - val_accuracy: 0.8581\n",
            "Epoch 215/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.8560 - val_loss: 0.4486 - val_accuracy: 0.8581\n",
            "Epoch 216/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.8555 - val_loss: 0.4502 - val_accuracy: 0.8595\n",
            "Epoch 217/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4502 - accuracy: 0.8562 - val_loss: 0.4480 - val_accuracy: 0.8579\n",
            "Epoch 218/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.8559 - val_loss: 0.4476 - val_accuracy: 0.8582\n",
            "Epoch 219/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.8555 - val_loss: 0.4474 - val_accuracy: 0.8572\n",
            "Epoch 220/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4492 - accuracy: 0.8561 - val_loss: 0.4472 - val_accuracy: 0.8590\n",
            "Epoch 221/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4489 - accuracy: 0.8565 - val_loss: 0.4466 - val_accuracy: 0.8580\n",
            "Epoch 222/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4486 - accuracy: 0.8559 - val_loss: 0.4463 - val_accuracy: 0.8583\n",
            "Epoch 223/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4483 - accuracy: 0.8561 - val_loss: 0.4461 - val_accuracy: 0.8582\n",
            "Epoch 224/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4480 - accuracy: 0.8565 - val_loss: 0.4457 - val_accuracy: 0.8586\n",
            "Epoch 225/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4477 - accuracy: 0.8565 - val_loss: 0.4456 - val_accuracy: 0.8594\n",
            "Epoch 226/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4472 - accuracy: 0.8563 - val_loss: 0.4458 - val_accuracy: 0.8600\n",
            "Epoch 227/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4470 - accuracy: 0.8567 - val_loss: 0.4447 - val_accuracy: 0.8584\n",
            "Epoch 228/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4467 - accuracy: 0.8570 - val_loss: 0.4444 - val_accuracy: 0.8589\n",
            "Epoch 229/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4464 - accuracy: 0.8566 - val_loss: 0.4442 - val_accuracy: 0.8587\n",
            "Epoch 230/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4460 - accuracy: 0.8571 - val_loss: 0.4438 - val_accuracy: 0.8591\n",
            "Epoch 231/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4457 - accuracy: 0.8569 - val_loss: 0.4435 - val_accuracy: 0.8586\n",
            "Epoch 232/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4454 - accuracy: 0.8569 - val_loss: 0.4432 - val_accuracy: 0.8590\n",
            "Epoch 233/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4451 - accuracy: 0.8569 - val_loss: 0.4429 - val_accuracy: 0.8591\n",
            "Epoch 234/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4447 - accuracy: 0.8571 - val_loss: 0.4427 - val_accuracy: 0.8600\n",
            "Epoch 235/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4445 - accuracy: 0.8569 - val_loss: 0.4422 - val_accuracy: 0.8584\n",
            "Epoch 236/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4441 - accuracy: 0.8569 - val_loss: 0.4421 - val_accuracy: 0.8569\n",
            "Epoch 237/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4437 - accuracy: 0.8574 - val_loss: 0.4418 - val_accuracy: 0.8576\n",
            "Epoch 238/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4435 - accuracy: 0.8568 - val_loss: 0.4413 - val_accuracy: 0.8581\n",
            "Epoch 239/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4432 - accuracy: 0.8575 - val_loss: 0.4410 - val_accuracy: 0.8594\n",
            "Epoch 240/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4429 - accuracy: 0.8571 - val_loss: 0.4413 - val_accuracy: 0.8607\n",
            "Epoch 241/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4426 - accuracy: 0.8571 - val_loss: 0.4410 - val_accuracy: 0.8562\n",
            "Epoch 242/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4423 - accuracy: 0.8575 - val_loss: 0.4400 - val_accuracy: 0.8595\n",
            "Epoch 243/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4419 - accuracy: 0.8573 - val_loss: 0.4401 - val_accuracy: 0.8608\n",
            "Epoch 244/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4416 - accuracy: 0.8577 - val_loss: 0.4395 - val_accuracy: 0.8594\n",
            "Epoch 245/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4414 - accuracy: 0.8576 - val_loss: 0.4392 - val_accuracy: 0.8599\n",
            "Epoch 246/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4410 - accuracy: 0.8581 - val_loss: 0.4388 - val_accuracy: 0.8598\n",
            "Epoch 247/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4408 - accuracy: 0.8578 - val_loss: 0.4388 - val_accuracy: 0.8593\n",
            "Epoch 248/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4404 - accuracy: 0.8577 - val_loss: 0.4382 - val_accuracy: 0.8591\n",
            "Epoch 249/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4401 - accuracy: 0.8581 - val_loss: 0.4379 - val_accuracy: 0.8603\n",
            "Epoch 250/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4398 - accuracy: 0.8576 - val_loss: 0.4380 - val_accuracy: 0.8610\n",
            "Epoch 251/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4396 - accuracy: 0.8577 - val_loss: 0.4373 - val_accuracy: 0.8603\n",
            "Epoch 252/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4393 - accuracy: 0.8579 - val_loss: 0.4372 - val_accuracy: 0.8601\n",
            "Epoch 253/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4390 - accuracy: 0.8579 - val_loss: 0.4371 - val_accuracy: 0.8575\n",
            "Epoch 254/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4387 - accuracy: 0.8581 - val_loss: 0.4367 - val_accuracy: 0.8610\n",
            "Epoch 255/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4383 - accuracy: 0.8584 - val_loss: 0.4362 - val_accuracy: 0.8596\n",
            "Epoch 256/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4381 - accuracy: 0.8582 - val_loss: 0.4359 - val_accuracy: 0.8601\n",
            "Epoch 257/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4379 - accuracy: 0.8583 - val_loss: 0.4356 - val_accuracy: 0.8595\n",
            "Epoch 258/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4375 - accuracy: 0.8582 - val_loss: 0.4353 - val_accuracy: 0.8611\n",
            "Epoch 259/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4372 - accuracy: 0.8580 - val_loss: 0.4353 - val_accuracy: 0.8615\n",
            "Epoch 260/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4370 - accuracy: 0.8585 - val_loss: 0.4348 - val_accuracy: 0.8609\n",
            "Epoch 261/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4367 - accuracy: 0.8586 - val_loss: 0.4344 - val_accuracy: 0.8610\n",
            "Epoch 262/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4364 - accuracy: 0.8582 - val_loss: 0.4344 - val_accuracy: 0.8605\n",
            "Epoch 263/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4361 - accuracy: 0.8585 - val_loss: 0.4339 - val_accuracy: 0.8606\n",
            "Epoch 264/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4358 - accuracy: 0.8587 - val_loss: 0.4335 - val_accuracy: 0.8606\n",
            "Epoch 265/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.8586 - val_loss: 0.4335 - val_accuracy: 0.8603\n",
            "Epoch 266/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4353 - accuracy: 0.8583 - val_loss: 0.4332 - val_accuracy: 0.8594\n",
            "Epoch 267/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4350 - accuracy: 0.8587 - val_loss: 0.4329 - val_accuracy: 0.8592\n",
            "Epoch 268/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4347 - accuracy: 0.8590 - val_loss: 0.4325 - val_accuracy: 0.8612\n",
            "Epoch 269/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4344 - accuracy: 0.8590 - val_loss: 0.4323 - val_accuracy: 0.8597\n",
            "Epoch 270/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4341 - accuracy: 0.8589 - val_loss: 0.4319 - val_accuracy: 0.8612\n",
            "Epoch 271/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4339 - accuracy: 0.8591 - val_loss: 0.4319 - val_accuracy: 0.8587\n",
            "Epoch 272/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4336 - accuracy: 0.8593 - val_loss: 0.4317 - val_accuracy: 0.8584\n",
            "Epoch 273/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4333 - accuracy: 0.8592 - val_loss: 0.4312 - val_accuracy: 0.8594\n",
            "Epoch 274/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4330 - accuracy: 0.8590 - val_loss: 0.4310 - val_accuracy: 0.8601\n",
            "Epoch 275/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4328 - accuracy: 0.8597 - val_loss: 0.4305 - val_accuracy: 0.8613\n",
            "Epoch 276/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4325 - accuracy: 0.8588 - val_loss: 0.4302 - val_accuracy: 0.8622\n",
            "Epoch 277/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4322 - accuracy: 0.8591 - val_loss: 0.4300 - val_accuracy: 0.8612\n",
            "Epoch 278/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4320 - accuracy: 0.8596 - val_loss: 0.4299 - val_accuracy: 0.8589\n",
            "Epoch 279/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4317 - accuracy: 0.8593 - val_loss: 0.4295 - val_accuracy: 0.8619\n",
            "Epoch 280/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4315 - accuracy: 0.8594 - val_loss: 0.4292 - val_accuracy: 0.8623\n",
            "Epoch 281/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4312 - accuracy: 0.8596 - val_loss: 0.4289 - val_accuracy: 0.8603\n",
            "Epoch 282/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4309 - accuracy: 0.8595 - val_loss: 0.4291 - val_accuracy: 0.8589\n",
            "Epoch 283/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4306 - accuracy: 0.8597 - val_loss: 0.4283 - val_accuracy: 0.8622\n",
            "Epoch 284/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4304 - accuracy: 0.8595 - val_loss: 0.4282 - val_accuracy: 0.8622\n",
            "Epoch 285/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4302 - accuracy: 0.8599 - val_loss: 0.4279 - val_accuracy: 0.8603\n",
            "Epoch 286/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4298 - accuracy: 0.8598 - val_loss: 0.4277 - val_accuracy: 0.8598\n",
            "Epoch 287/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4295 - accuracy: 0.8596 - val_loss: 0.4279 - val_accuracy: 0.8627\n",
            "Epoch 288/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4293 - accuracy: 0.8598 - val_loss: 0.4271 - val_accuracy: 0.8605\n",
            "Epoch 289/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4291 - accuracy: 0.8598 - val_loss: 0.4271 - val_accuracy: 0.8626\n",
            "Epoch 290/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4288 - accuracy: 0.8602 - val_loss: 0.4267 - val_accuracy: 0.8601\n",
            "Epoch 291/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4285 - accuracy: 0.8600 - val_loss: 0.4266 - val_accuracy: 0.8630\n",
            "Epoch 292/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4283 - accuracy: 0.8601 - val_loss: 0.4262 - val_accuracy: 0.8634\n",
            "Epoch 293/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4280 - accuracy: 0.8596 - val_loss: 0.4257 - val_accuracy: 0.8630\n",
            "Epoch 294/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4278 - accuracy: 0.8604 - val_loss: 0.4256 - val_accuracy: 0.8609\n",
            "Epoch 295/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4275 - accuracy: 0.8602 - val_loss: 0.4253 - val_accuracy: 0.8629\n",
            "Epoch 296/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4272 - accuracy: 0.8603 - val_loss: 0.4250 - val_accuracy: 0.8626\n",
            "Epoch 297/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4269 - accuracy: 0.8605 - val_loss: 0.4251 - val_accuracy: 0.8608\n",
            "Epoch 298/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4267 - accuracy: 0.8605 - val_loss: 0.4245 - val_accuracy: 0.8630\n",
            "Epoch 299/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4265 - accuracy: 0.8603 - val_loss: 0.4247 - val_accuracy: 0.8590\n",
            "Epoch 300/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4262 - accuracy: 0.8603 - val_loss: 0.4240 - val_accuracy: 0.8629\n",
            "Epoch 301/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4260 - accuracy: 0.8601 - val_loss: 0.4238 - val_accuracy: 0.8612\n",
            "Epoch 302/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4257 - accuracy: 0.8608 - val_loss: 0.4237 - val_accuracy: 0.8637\n",
            "Epoch 303/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4255 - accuracy: 0.8604 - val_loss: 0.4232 - val_accuracy: 0.8623\n",
            "Epoch 304/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4252 - accuracy: 0.8609 - val_loss: 0.4230 - val_accuracy: 0.8624\n",
            "Epoch 305/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4250 - accuracy: 0.8607 - val_loss: 0.4229 - val_accuracy: 0.8636\n",
            "Epoch 306/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4247 - accuracy: 0.8608 - val_loss: 0.4225 - val_accuracy: 0.8633\n",
            "Epoch 307/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4245 - accuracy: 0.8609 - val_loss: 0.4223 - val_accuracy: 0.8640\n",
            "Epoch 308/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4242 - accuracy: 0.8608 - val_loss: 0.4221 - val_accuracy: 0.8616\n",
            "Epoch 309/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4240 - accuracy: 0.8608 - val_loss: 0.4219 - val_accuracy: 0.8644\n",
            "Epoch 310/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4237 - accuracy: 0.8611 - val_loss: 0.4215 - val_accuracy: 0.8619\n",
            "Epoch 311/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4234 - accuracy: 0.8609 - val_loss: 0.4214 - val_accuracy: 0.8618\n",
            "Epoch 312/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4232 - accuracy: 0.8606 - val_loss: 0.4214 - val_accuracy: 0.8640\n",
            "Epoch 313/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4230 - accuracy: 0.8611 - val_loss: 0.4209 - val_accuracy: 0.8640\n",
            "Epoch 314/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4228 - accuracy: 0.8608 - val_loss: 0.4205 - val_accuracy: 0.8638\n",
            "Epoch 315/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4225 - accuracy: 0.8607 - val_loss: 0.4205 - val_accuracy: 0.8612\n",
            "Epoch 316/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4222 - accuracy: 0.8609 - val_loss: 0.4202 - val_accuracy: 0.8640\n",
            "Epoch 317/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4220 - accuracy: 0.8610 - val_loss: 0.4198 - val_accuracy: 0.8623\n",
            "Epoch 318/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4218 - accuracy: 0.8613 - val_loss: 0.4199 - val_accuracy: 0.8601\n",
            "Epoch 319/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4216 - accuracy: 0.8612 - val_loss: 0.4196 - val_accuracy: 0.8612\n",
            "Epoch 320/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4213 - accuracy: 0.8611 - val_loss: 0.4191 - val_accuracy: 0.8639\n",
            "Epoch 321/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4211 - accuracy: 0.8614 - val_loss: 0.4190 - val_accuracy: 0.8624\n",
            "Epoch 322/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4209 - accuracy: 0.8614 - val_loss: 0.4187 - val_accuracy: 0.8622\n",
            "Epoch 323/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4206 - accuracy: 0.8618 - val_loss: 0.4187 - val_accuracy: 0.8647\n",
            "Epoch 324/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4204 - accuracy: 0.8616 - val_loss: 0.4182 - val_accuracy: 0.8631\n",
            "Epoch 325/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4201 - accuracy: 0.8613 - val_loss: 0.4181 - val_accuracy: 0.8628\n",
            "Epoch 326/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4199 - accuracy: 0.8618 - val_loss: 0.4178 - val_accuracy: 0.8645\n",
            "Epoch 327/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4197 - accuracy: 0.8616 - val_loss: 0.4174 - val_accuracy: 0.8632\n",
            "Epoch 328/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4195 - accuracy: 0.8612 - val_loss: 0.4176 - val_accuracy: 0.8627\n",
            "Epoch 329/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4192 - accuracy: 0.8618 - val_loss: 0.4169 - val_accuracy: 0.8633\n",
            "Epoch 330/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4190 - accuracy: 0.8617 - val_loss: 0.4168 - val_accuracy: 0.8635\n",
            "Epoch 331/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4187 - accuracy: 0.8620 - val_loss: 0.4167 - val_accuracy: 0.8622\n",
            "Epoch 332/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4185 - accuracy: 0.8619 - val_loss: 0.4163 - val_accuracy: 0.8641\n",
            "Epoch 333/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4183 - accuracy: 0.8615 - val_loss: 0.4161 - val_accuracy: 0.8640\n",
            "Epoch 334/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4181 - accuracy: 0.8616 - val_loss: 0.4160 - val_accuracy: 0.8622\n",
            "Epoch 335/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4178 - accuracy: 0.8615 - val_loss: 0.4157 - val_accuracy: 0.8644\n",
            "Epoch 336/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4176 - accuracy: 0.8618 - val_loss: 0.4162 - val_accuracy: 0.8659\n",
            "Epoch 337/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4174 - accuracy: 0.8621 - val_loss: 0.4153 - val_accuracy: 0.8624\n",
            "Epoch 338/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4171 - accuracy: 0.8620 - val_loss: 0.4150 - val_accuracy: 0.8638\n",
            "Epoch 339/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4169 - accuracy: 0.8620 - val_loss: 0.4148 - val_accuracy: 0.8646\n",
            "Epoch 340/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4167 - accuracy: 0.8621 - val_loss: 0.4146 - val_accuracy: 0.8640\n",
            "Epoch 341/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4165 - accuracy: 0.8622 - val_loss: 0.4143 - val_accuracy: 0.8637\n",
            "Epoch 342/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4163 - accuracy: 0.8623 - val_loss: 0.4144 - val_accuracy: 0.8650\n",
            "Epoch 343/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4160 - accuracy: 0.8620 - val_loss: 0.4140 - val_accuracy: 0.8659\n",
            "Epoch 344/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4159 - accuracy: 0.8621 - val_loss: 0.4140 - val_accuracy: 0.8616\n",
            "Epoch 345/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4156 - accuracy: 0.8623 - val_loss: 0.4136 - val_accuracy: 0.8656\n",
            "Epoch 346/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4153 - accuracy: 0.8624 - val_loss: 0.4131 - val_accuracy: 0.8643\n",
            "Epoch 347/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4151 - accuracy: 0.8623 - val_loss: 0.4129 - val_accuracy: 0.8649\n",
            "Epoch 348/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4149 - accuracy: 0.8625 - val_loss: 0.4133 - val_accuracy: 0.8607\n",
            "Epoch 349/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4147 - accuracy: 0.8622 - val_loss: 0.4125 - val_accuracy: 0.8646\n",
            "Epoch 350/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4145 - accuracy: 0.8629 - val_loss: 0.4123 - val_accuracy: 0.8637\n",
            "Epoch 351/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4142 - accuracy: 0.8622 - val_loss: 0.4123 - val_accuracy: 0.8627\n",
            "Epoch 352/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4140 - accuracy: 0.8624 - val_loss: 0.4120 - val_accuracy: 0.8633\n",
            "Epoch 353/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4138 - accuracy: 0.8629 - val_loss: 0.4117 - val_accuracy: 0.8661\n",
            "Epoch 354/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4135 - accuracy: 0.8628 - val_loss: 0.4115 - val_accuracy: 0.8637\n",
            "Epoch 355/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4134 - accuracy: 0.8625 - val_loss: 0.4112 - val_accuracy: 0.8641\n",
            "Epoch 356/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4132 - accuracy: 0.8625 - val_loss: 0.4110 - val_accuracy: 0.8651\n",
            "Epoch 357/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4129 - accuracy: 0.8628 - val_loss: 0.4111 - val_accuracy: 0.8659\n",
            "Epoch 358/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4126 - accuracy: 0.8627 - val_loss: 0.4106 - val_accuracy: 0.8637\n",
            "Epoch 359/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4125 - accuracy: 0.8627 - val_loss: 0.4104 - val_accuracy: 0.8661\n",
            "Epoch 360/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4123 - accuracy: 0.8630 - val_loss: 0.4101 - val_accuracy: 0.8650\n",
            "Epoch 361/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4120 - accuracy: 0.8631 - val_loss: 0.4105 - val_accuracy: 0.8665\n",
            "Epoch 362/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4119 - accuracy: 0.8627 - val_loss: 0.4097 - val_accuracy: 0.8651\n",
            "Epoch 363/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4117 - accuracy: 0.8629 - val_loss: 0.4097 - val_accuracy: 0.8626\n",
            "Epoch 364/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4115 - accuracy: 0.8631 - val_loss: 0.4094 - val_accuracy: 0.8654\n",
            "Epoch 365/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4112 - accuracy: 0.8629 - val_loss: 0.4092 - val_accuracy: 0.8663\n",
            "Epoch 366/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4110 - accuracy: 0.8632 - val_loss: 0.4094 - val_accuracy: 0.8668\n",
            "Epoch 367/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4108 - accuracy: 0.8636 - val_loss: 0.4086 - val_accuracy: 0.8655\n",
            "Epoch 368/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4106 - accuracy: 0.8635 - val_loss: 0.4088 - val_accuracy: 0.8641\n",
            "Epoch 369/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4104 - accuracy: 0.8634 - val_loss: 0.4083 - val_accuracy: 0.8635\n",
            "Epoch 370/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4102 - accuracy: 0.8632 - val_loss: 0.4082 - val_accuracy: 0.8662\n",
            "Epoch 371/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4100 - accuracy: 0.8634 - val_loss: 0.4079 - val_accuracy: 0.8647\n",
            "Epoch 372/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4098 - accuracy: 0.8632 - val_loss: 0.4077 - val_accuracy: 0.8666\n",
            "Epoch 373/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4096 - accuracy: 0.8630 - val_loss: 0.4074 - val_accuracy: 0.8652\n",
            "Epoch 374/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4094 - accuracy: 0.8633 - val_loss: 0.4073 - val_accuracy: 0.8651\n",
            "Epoch 375/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4092 - accuracy: 0.8642 - val_loss: 0.4070 - val_accuracy: 0.8643\n",
            "Epoch 376/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4089 - accuracy: 0.8636 - val_loss: 0.4071 - val_accuracy: 0.8669\n",
            "Epoch 377/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4088 - accuracy: 0.8633 - val_loss: 0.4066 - val_accuracy: 0.8649\n",
            "Epoch 378/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4085 - accuracy: 0.8632 - val_loss: 0.4069 - val_accuracy: 0.8615\n",
            "Epoch 379/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4084 - accuracy: 0.8638 - val_loss: 0.4063 - val_accuracy: 0.8661\n",
            "Epoch 380/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4082 - accuracy: 0.8641 - val_loss: 0.4062 - val_accuracy: 0.8669\n",
            "Epoch 381/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4080 - accuracy: 0.8638 - val_loss: 0.4060 - val_accuracy: 0.8668\n",
            "Epoch 382/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4078 - accuracy: 0.8639 - val_loss: 0.4056 - val_accuracy: 0.8652\n",
            "Epoch 383/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4076 - accuracy: 0.8641 - val_loss: 0.4055 - val_accuracy: 0.8644\n",
            "Epoch 384/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4074 - accuracy: 0.8638 - val_loss: 0.4054 - val_accuracy: 0.8672\n",
            "Epoch 385/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4072 - accuracy: 0.8640 - val_loss: 0.4050 - val_accuracy: 0.8653\n",
            "Epoch 386/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4070 - accuracy: 0.8641 - val_loss: 0.4050 - val_accuracy: 0.8644\n",
            "Epoch 387/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4068 - accuracy: 0.8639 - val_loss: 0.4046 - val_accuracy: 0.8654\n",
            "Epoch 388/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4065 - accuracy: 0.8643 - val_loss: 0.4053 - val_accuracy: 0.8678\n",
            "Epoch 389/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4063 - accuracy: 0.8640 - val_loss: 0.4042 - val_accuracy: 0.8662\n",
            "Epoch 390/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4062 - accuracy: 0.8641 - val_loss: 0.4042 - val_accuracy: 0.8673\n",
            "Epoch 391/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4060 - accuracy: 0.8643 - val_loss: 0.4038 - val_accuracy: 0.8657\n",
            "Epoch 392/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4058 - accuracy: 0.8643 - val_loss: 0.4037 - val_accuracy: 0.8669\n",
            "Epoch 393/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4056 - accuracy: 0.8645 - val_loss: 0.4034 - val_accuracy: 0.8663\n",
            "Epoch 394/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4053 - accuracy: 0.8645 - val_loss: 0.4032 - val_accuracy: 0.8656\n",
            "Epoch 395/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4052 - accuracy: 0.8646 - val_loss: 0.4031 - val_accuracy: 0.8664\n",
            "Epoch 396/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4050 - accuracy: 0.8645 - val_loss: 0.4029 - val_accuracy: 0.8664\n",
            "Epoch 397/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4048 - accuracy: 0.8644 - val_loss: 0.4028 - val_accuracy: 0.8674\n",
            "Epoch 398/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4046 - accuracy: 0.8645 - val_loss: 0.4028 - val_accuracy: 0.8676\n",
            "Epoch 399/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4044 - accuracy: 0.8642 - val_loss: 0.4026 - val_accuracy: 0.8622\n",
            "Epoch 400/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4042 - accuracy: 0.8646 - val_loss: 0.4023 - val_accuracy: 0.8633\n",
            "Epoch 401/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4041 - accuracy: 0.8641 - val_loss: 0.4023 - val_accuracy: 0.8674\n",
            "Epoch 402/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4038 - accuracy: 0.8643 - val_loss: 0.4018 - val_accuracy: 0.8672\n",
            "Epoch 403/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4036 - accuracy: 0.8648 - val_loss: 0.4015 - val_accuracy: 0.8667\n",
            "Epoch 404/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4034 - accuracy: 0.8644 - val_loss: 0.4014 - val_accuracy: 0.8674\n",
            "Epoch 405/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4033 - accuracy: 0.8647 - val_loss: 0.4011 - val_accuracy: 0.8666\n",
            "Epoch 406/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4030 - accuracy: 0.8650 - val_loss: 0.4010 - val_accuracy: 0.8650\n",
            "Epoch 407/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.8646 - val_loss: 0.4007 - val_accuracy: 0.8666\n",
            "Epoch 408/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4027 - accuracy: 0.8651 - val_loss: 0.4008 - val_accuracy: 0.8655\n",
            "Epoch 409/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4025 - accuracy: 0.8647 - val_loss: 0.4004 - val_accuracy: 0.8666\n",
            "Epoch 410/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4023 - accuracy: 0.8647 - val_loss: 0.4002 - val_accuracy: 0.8661\n",
            "Epoch 411/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4021 - accuracy: 0.8651 - val_loss: 0.4000 - val_accuracy: 0.8666\n",
            "Epoch 412/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4019 - accuracy: 0.8652 - val_loss: 0.4000 - val_accuracy: 0.8673\n",
            "Epoch 413/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4018 - accuracy: 0.8649 - val_loss: 0.3997 - val_accuracy: 0.8673\n",
            "Epoch 414/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4016 - accuracy: 0.8652 - val_loss: 0.3995 - val_accuracy: 0.8668\n",
            "Epoch 415/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4014 - accuracy: 0.8653 - val_loss: 0.3993 - val_accuracy: 0.8668\n",
            "Epoch 416/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4012 - accuracy: 0.8649 - val_loss: 0.3993 - val_accuracy: 0.8637\n",
            "Epoch 417/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4010 - accuracy: 0.8651 - val_loss: 0.3989 - val_accuracy: 0.8668\n",
            "Epoch 418/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4008 - accuracy: 0.8650 - val_loss: 0.3988 - val_accuracy: 0.8645\n",
            "Epoch 419/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4006 - accuracy: 0.8648 - val_loss: 0.3990 - val_accuracy: 0.8680\n",
            "Epoch 420/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4004 - accuracy: 0.8658 - val_loss: 0.3985 - val_accuracy: 0.8676\n",
            "Epoch 421/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4003 - accuracy: 0.8652 - val_loss: 0.3983 - val_accuracy: 0.8681\n",
            "Epoch 422/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4001 - accuracy: 0.8654 - val_loss: 0.3980 - val_accuracy: 0.8670\n",
            "Epoch 423/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4000 - accuracy: 0.8656 - val_loss: 0.3978 - val_accuracy: 0.8669\n",
            "Epoch 424/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3997 - accuracy: 0.8656 - val_loss: 0.3976 - val_accuracy: 0.8673\n",
            "Epoch 425/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3995 - accuracy: 0.8655 - val_loss: 0.3978 - val_accuracy: 0.8684\n",
            "Epoch 426/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3994 - accuracy: 0.8652 - val_loss: 0.3973 - val_accuracy: 0.8675\n",
            "Epoch 427/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3992 - accuracy: 0.8655 - val_loss: 0.3971 - val_accuracy: 0.8673\n",
            "Epoch 428/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3990 - accuracy: 0.8655 - val_loss: 0.3970 - val_accuracy: 0.8676\n",
            "Epoch 429/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3988 - accuracy: 0.8661 - val_loss: 0.3971 - val_accuracy: 0.8633\n",
            "Epoch 430/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3986 - accuracy: 0.8660 - val_loss: 0.3967 - val_accuracy: 0.8680\n",
            "Epoch 431/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3985 - accuracy: 0.8661 - val_loss: 0.3966 - val_accuracy: 0.8687\n",
            "Epoch 432/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3983 - accuracy: 0.8661 - val_loss: 0.3966 - val_accuracy: 0.8648\n",
            "Epoch 433/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3981 - accuracy: 0.8658 - val_loss: 0.3962 - val_accuracy: 0.8682\n",
            "Epoch 434/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3979 - accuracy: 0.8657 - val_loss: 0.3958 - val_accuracy: 0.8671\n",
            "Epoch 435/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3978 - accuracy: 0.8661 - val_loss: 0.3957 - val_accuracy: 0.8667\n",
            "Epoch 436/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3976 - accuracy: 0.8655 - val_loss: 0.3955 - val_accuracy: 0.8674\n",
            "Epoch 437/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3974 - accuracy: 0.8657 - val_loss: 0.3953 - val_accuracy: 0.8673\n",
            "Epoch 438/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3972 - accuracy: 0.8660 - val_loss: 0.3951 - val_accuracy: 0.8673\n",
            "Epoch 439/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3971 - accuracy: 0.8660 - val_loss: 0.3950 - val_accuracy: 0.8672\n",
            "Epoch 440/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3969 - accuracy: 0.8662 - val_loss: 0.3951 - val_accuracy: 0.8690\n",
            "Epoch 441/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3967 - accuracy: 0.8659 - val_loss: 0.3947 - val_accuracy: 0.8676\n",
            "Epoch 442/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3965 - accuracy: 0.8662 - val_loss: 0.3945 - val_accuracy: 0.8673\n",
            "Epoch 443/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3963 - accuracy: 0.8659 - val_loss: 0.3943 - val_accuracy: 0.8679\n",
            "Epoch 444/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3961 - accuracy: 0.8661 - val_loss: 0.3942 - val_accuracy: 0.8666\n",
            "Epoch 445/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3960 - accuracy: 0.8661 - val_loss: 0.3940 - val_accuracy: 0.8674\n",
            "Epoch 446/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3958 - accuracy: 0.8668 - val_loss: 0.3938 - val_accuracy: 0.8660\n",
            "Epoch 447/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3956 - accuracy: 0.8667 - val_loss: 0.3943 - val_accuracy: 0.8665\n",
            "Epoch 448/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3955 - accuracy: 0.8664 - val_loss: 0.3936 - val_accuracy: 0.8665\n",
            "Epoch 449/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3953 - accuracy: 0.8666 - val_loss: 0.3934 - val_accuracy: 0.8688\n",
            "Epoch 450/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3952 - accuracy: 0.8666 - val_loss: 0.3931 - val_accuracy: 0.8687\n",
            "Epoch 451/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3950 - accuracy: 0.8664 - val_loss: 0.3931 - val_accuracy: 0.8658\n",
            "Epoch 452/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8666 - val_loss: 0.3930 - val_accuracy: 0.8690\n",
            "Epoch 453/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8667 - val_loss: 0.3926 - val_accuracy: 0.8674\n",
            "Epoch 454/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3945 - accuracy: 0.8668 - val_loss: 0.3925 - val_accuracy: 0.8686\n",
            "Epoch 455/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3942 - accuracy: 0.8670 - val_loss: 0.3931 - val_accuracy: 0.8705\n",
            "Epoch 456/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3941 - accuracy: 0.8668 - val_loss: 0.3923 - val_accuracy: 0.8672\n",
            "Epoch 457/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3939 - accuracy: 0.8665 - val_loss: 0.3921 - val_accuracy: 0.8689\n",
            "Epoch 458/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8669 - val_loss: 0.3918 - val_accuracy: 0.8661\n",
            "Epoch 459/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3936 - accuracy: 0.8667 - val_loss: 0.3919 - val_accuracy: 0.8652\n",
            "Epoch 460/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3935 - accuracy: 0.8669 - val_loss: 0.3914 - val_accuracy: 0.8672\n",
            "Epoch 461/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3933 - accuracy: 0.8668 - val_loss: 0.3912 - val_accuracy: 0.8677\n",
            "Epoch 462/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3931 - accuracy: 0.8669 - val_loss: 0.3911 - val_accuracy: 0.8667\n",
            "Epoch 463/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3929 - accuracy: 0.8666 - val_loss: 0.3911 - val_accuracy: 0.8654\n",
            "Epoch 464/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3928 - accuracy: 0.8670 - val_loss: 0.3908 - val_accuracy: 0.8674\n",
            "Epoch 465/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3926 - accuracy: 0.8670 - val_loss: 0.3906 - val_accuracy: 0.8683\n",
            "Epoch 466/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3925 - accuracy: 0.8670 - val_loss: 0.3905 - val_accuracy: 0.8677\n",
            "Epoch 467/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3923 - accuracy: 0.8666 - val_loss: 0.3906 - val_accuracy: 0.8695\n",
            "Epoch 468/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3921 - accuracy: 0.8670 - val_loss: 0.3902 - val_accuracy: 0.8696\n",
            "Epoch 469/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3920 - accuracy: 0.8670 - val_loss: 0.3900 - val_accuracy: 0.8690\n",
            "Epoch 470/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3918 - accuracy: 0.8670 - val_loss: 0.3902 - val_accuracy: 0.8662\n",
            "Epoch 471/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3917 - accuracy: 0.8672 - val_loss: 0.3896 - val_accuracy: 0.8699\n",
            "Epoch 472/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3914 - accuracy: 0.8670 - val_loss: 0.3896 - val_accuracy: 0.8695\n",
            "Epoch 473/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3913 - accuracy: 0.8673 - val_loss: 0.3893 - val_accuracy: 0.8686\n",
            "Epoch 474/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3911 - accuracy: 0.8678 - val_loss: 0.3892 - val_accuracy: 0.8667\n",
            "Epoch 475/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3909 - accuracy: 0.8673 - val_loss: 0.3895 - val_accuracy: 0.8648\n",
            "Epoch 476/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3908 - accuracy: 0.8673 - val_loss: 0.3888 - val_accuracy: 0.8695\n",
            "Epoch 477/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3907 - accuracy: 0.8677 - val_loss: 0.3886 - val_accuracy: 0.8686\n",
            "Epoch 478/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3904 - accuracy: 0.8677 - val_loss: 0.3887 - val_accuracy: 0.8699\n",
            "Epoch 479/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3904 - accuracy: 0.8675 - val_loss: 0.3883 - val_accuracy: 0.8698\n",
            "Epoch 480/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8677 - val_loss: 0.3882 - val_accuracy: 0.8678\n",
            "Epoch 481/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3900 - accuracy: 0.8681 - val_loss: 0.3881 - val_accuracy: 0.8673\n",
            "Epoch 482/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3898 - accuracy: 0.8673 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 483/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3897 - accuracy: 0.8679 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 484/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3895 - accuracy: 0.8676 - val_loss: 0.3875 - val_accuracy: 0.8701\n",
            "Epoch 485/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3893 - accuracy: 0.8679 - val_loss: 0.3874 - val_accuracy: 0.8701\n",
            "Epoch 486/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3892 - accuracy: 0.8677 - val_loss: 0.3873 - val_accuracy: 0.8680\n",
            "Epoch 487/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3891 - accuracy: 0.8683 - val_loss: 0.3871 - val_accuracy: 0.8691\n",
            "Epoch 488/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3889 - accuracy: 0.8681 - val_loss: 0.3873 - val_accuracy: 0.8658\n",
            "Epoch 489/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3887 - accuracy: 0.8676 - val_loss: 0.3873 - val_accuracy: 0.8706\n",
            "Epoch 490/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3886 - accuracy: 0.8679 - val_loss: 0.3866 - val_accuracy: 0.8698\n",
            "Epoch 491/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3884 - accuracy: 0.8684 - val_loss: 0.3865 - val_accuracy: 0.8709\n",
            "Epoch 492/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3882 - accuracy: 0.8683 - val_loss: 0.3864 - val_accuracy: 0.8710\n",
            "Epoch 493/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3881 - accuracy: 0.8680 - val_loss: 0.3864 - val_accuracy: 0.8706\n",
            "Epoch 494/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3878 - accuracy: 0.8683 - val_loss: 0.3867 - val_accuracy: 0.8712\n",
            "Epoch 495/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3878 - accuracy: 0.8684 - val_loss: 0.3860 - val_accuracy: 0.8703\n",
            "Epoch 496/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3876 - accuracy: 0.8683 - val_loss: 0.3858 - val_accuracy: 0.8700\n",
            "Epoch 497/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3874 - accuracy: 0.8690 - val_loss: 0.3858 - val_accuracy: 0.8712\n",
            "Epoch 498/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3873 - accuracy: 0.8685 - val_loss: 0.3856 - val_accuracy: 0.8712\n",
            "Epoch 499/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3872 - accuracy: 0.8684 - val_loss: 0.3855 - val_accuracy: 0.8710\n",
            "Epoch 500/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3870 - accuracy: 0.8684 - val_loss: 0.3852 - val_accuracy: 0.8710\n",
            "Epoch 501/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3869 - accuracy: 0.8686 - val_loss: 0.3849 - val_accuracy: 0.8709\n",
            "Epoch 502/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3867 - accuracy: 0.8684 - val_loss: 0.3847 - val_accuracy: 0.8702\n",
            "Epoch 503/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3866 - accuracy: 0.8686 - val_loss: 0.3847 - val_accuracy: 0.8679\n",
            "Epoch 504/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3864 - accuracy: 0.8687 - val_loss: 0.3846 - val_accuracy: 0.8709\n",
            "Epoch 505/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3863 - accuracy: 0.8685 - val_loss: 0.3844 - val_accuracy: 0.8702\n",
            "Epoch 506/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3861 - accuracy: 0.8684 - val_loss: 0.3843 - val_accuracy: 0.8712\n",
            "Epoch 507/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3859 - accuracy: 0.8691 - val_loss: 0.3840 - val_accuracy: 0.8704\n",
            "Epoch 508/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3858 - accuracy: 0.8688 - val_loss: 0.3840 - val_accuracy: 0.8710\n",
            "Epoch 509/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3856 - accuracy: 0.8690 - val_loss: 0.3839 - val_accuracy: 0.8681\n",
            "Epoch 510/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3855 - accuracy: 0.8689 - val_loss: 0.3835 - val_accuracy: 0.8698\n",
            "Epoch 511/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3853 - accuracy: 0.8693 - val_loss: 0.3835 - val_accuracy: 0.8694\n",
            "Epoch 512/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3852 - accuracy: 0.8691 - val_loss: 0.3834 - val_accuracy: 0.8708\n",
            "Epoch 513/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3850 - accuracy: 0.8690 - val_loss: 0.3833 - val_accuracy: 0.8692\n",
            "Epoch 514/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3849 - accuracy: 0.8690 - val_loss: 0.3832 - val_accuracy: 0.8717\n",
            "Epoch 515/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3848 - accuracy: 0.8695 - val_loss: 0.3829 - val_accuracy: 0.8695\n",
            "Epoch 516/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3846 - accuracy: 0.8690 - val_loss: 0.3828 - val_accuracy: 0.8716\n",
            "Epoch 517/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3845 - accuracy: 0.8690 - val_loss: 0.3828 - val_accuracy: 0.8717\n",
            "Epoch 518/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3843 - accuracy: 0.8694 - val_loss: 0.3824 - val_accuracy: 0.8713\n",
            "Epoch 519/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3842 - accuracy: 0.8696 - val_loss: 0.3822 - val_accuracy: 0.8710\n",
            "Epoch 520/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3840 - accuracy: 0.8693 - val_loss: 0.3822 - val_accuracy: 0.8717\n",
            "Epoch 521/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3838 - accuracy: 0.8698 - val_loss: 0.3821 - val_accuracy: 0.8694\n",
            "Epoch 522/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3837 - accuracy: 0.8696 - val_loss: 0.3821 - val_accuracy: 0.8679\n",
            "Epoch 523/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3836 - accuracy: 0.8692 - val_loss: 0.3818 - val_accuracy: 0.8703\n",
            "Epoch 524/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3834 - accuracy: 0.8696 - val_loss: 0.3816 - val_accuracy: 0.8699\n",
            "Epoch 525/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3832 - accuracy: 0.8695 - val_loss: 0.3817 - val_accuracy: 0.8724\n",
            "Epoch 526/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3831 - accuracy: 0.8697 - val_loss: 0.3814 - val_accuracy: 0.8701\n",
            "Epoch 527/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3830 - accuracy: 0.8698 - val_loss: 0.3811 - val_accuracy: 0.8716\n",
            "Epoch 528/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3828 - accuracy: 0.8697 - val_loss: 0.3810 - val_accuracy: 0.8712\n",
            "Epoch 529/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8699 - val_loss: 0.3811 - val_accuracy: 0.8717\n",
            "Epoch 530/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3826 - accuracy: 0.8700 - val_loss: 0.3807 - val_accuracy: 0.8720\n",
            "Epoch 531/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - accuracy: 0.8700 - val_loss: 0.3806 - val_accuracy: 0.8711\n",
            "Epoch 532/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3822 - accuracy: 0.8698 - val_loss: 0.3811 - val_accuracy: 0.8728\n",
            "Epoch 533/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3821 - accuracy: 0.8701 - val_loss: 0.3802 - val_accuracy: 0.8719\n",
            "Epoch 534/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8702 - val_loss: 0.3801 - val_accuracy: 0.8717\n",
            "Epoch 535/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3818 - accuracy: 0.8702 - val_loss: 0.3802 - val_accuracy: 0.8684\n",
            "Epoch 536/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3816 - accuracy: 0.8699 - val_loss: 0.3798 - val_accuracy: 0.8717\n",
            "Epoch 537/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3815 - accuracy: 0.8700 - val_loss: 0.3796 - val_accuracy: 0.8711\n",
            "Epoch 538/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3814 - accuracy: 0.8707 - val_loss: 0.3795 - val_accuracy: 0.8712\n",
            "Epoch 539/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3812 - accuracy: 0.8701 - val_loss: 0.3794 - val_accuracy: 0.8708\n",
            "Epoch 540/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3811 - accuracy: 0.8702 - val_loss: 0.3792 - val_accuracy: 0.8719\n",
            "Epoch 541/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3810 - accuracy: 0.8705 - val_loss: 0.3792 - val_accuracy: 0.8720\n",
            "Epoch 542/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3808 - accuracy: 0.8702 - val_loss: 0.3793 - val_accuracy: 0.8706\n",
            "Epoch 543/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3807 - accuracy: 0.8703 - val_loss: 0.3789 - val_accuracy: 0.8725\n",
            "Epoch 544/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3805 - accuracy: 0.8709 - val_loss: 0.3789 - val_accuracy: 0.8722\n",
            "Epoch 545/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3804 - accuracy: 0.8702 - val_loss: 0.3786 - val_accuracy: 0.8723\n",
            "Epoch 546/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3803 - accuracy: 0.8708 - val_loss: 0.3790 - val_accuracy: 0.8680\n",
            "Epoch 547/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3801 - accuracy: 0.8705 - val_loss: 0.3783 - val_accuracy: 0.8723\n",
            "Epoch 548/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3800 - accuracy: 0.8705 - val_loss: 0.3782 - val_accuracy: 0.8702\n",
            "Epoch 549/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3798 - accuracy: 0.8706 - val_loss: 0.3780 - val_accuracy: 0.8716\n",
            "Epoch 550/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3797 - accuracy: 0.8702 - val_loss: 0.3784 - val_accuracy: 0.8734\n",
            "Epoch 551/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3796 - accuracy: 0.8706 - val_loss: 0.3779 - val_accuracy: 0.8734\n",
            "Epoch 552/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3794 - accuracy: 0.8707 - val_loss: 0.3776 - val_accuracy: 0.8712\n",
            "Epoch 553/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3792 - accuracy: 0.8708 - val_loss: 0.3777 - val_accuracy: 0.8732\n",
            "Epoch 554/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3792 - accuracy: 0.8707 - val_loss: 0.3774 - val_accuracy: 0.8730\n",
            "Epoch 555/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3790 - accuracy: 0.8709 - val_loss: 0.3774 - val_accuracy: 0.8711\n",
            "Epoch 556/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3789 - accuracy: 0.8710 - val_loss: 0.3771 - val_accuracy: 0.8716\n",
            "Epoch 557/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3788 - accuracy: 0.8708 - val_loss: 0.3769 - val_accuracy: 0.8727\n",
            "Epoch 558/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3786 - accuracy: 0.8709 - val_loss: 0.3775 - val_accuracy: 0.8734\n",
            "Epoch 559/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3785 - accuracy: 0.8709 - val_loss: 0.3766 - val_accuracy: 0.8727\n",
            "Epoch 560/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3783 - accuracy: 0.8714 - val_loss: 0.3765 - val_accuracy: 0.8719\n",
            "Epoch 561/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8711 - val_loss: 0.3763 - val_accuracy: 0.8727\n",
            "Epoch 562/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3780 - accuracy: 0.8715 - val_loss: 0.3764 - val_accuracy: 0.8738\n",
            "Epoch 563/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8715 - val_loss: 0.3765 - val_accuracy: 0.8698\n",
            "Epoch 564/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3778 - accuracy: 0.8713 - val_loss: 0.3760 - val_accuracy: 0.8737\n",
            "Epoch 565/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3776 - accuracy: 0.8712 - val_loss: 0.3758 - val_accuracy: 0.8726\n",
            "Epoch 566/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3775 - accuracy: 0.8710 - val_loss: 0.3759 - val_accuracy: 0.8734\n",
            "Epoch 567/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8714 - val_loss: 0.3761 - val_accuracy: 0.8737\n",
            "Epoch 568/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3772 - accuracy: 0.8717 - val_loss: 0.3755 - val_accuracy: 0.8730\n",
            "Epoch 569/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8717 - val_loss: 0.3753 - val_accuracy: 0.8734\n",
            "Epoch 570/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3769 - accuracy: 0.8716 - val_loss: 0.3764 - val_accuracy: 0.8676\n",
            "Epoch 571/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3769 - accuracy: 0.8720 - val_loss: 0.3750 - val_accuracy: 0.8735\n",
            "Epoch 572/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3767 - accuracy: 0.8716 - val_loss: 0.3752 - val_accuracy: 0.8734\n",
            "Epoch 573/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3766 - accuracy: 0.8718 - val_loss: 0.3748 - val_accuracy: 0.8722\n",
            "Epoch 574/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8717 - val_loss: 0.3751 - val_accuracy: 0.8739\n",
            "Epoch 575/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3763 - accuracy: 0.8719 - val_loss: 0.3746 - val_accuracy: 0.8706\n",
            "Epoch 576/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3761 - accuracy: 0.8717 - val_loss: 0.3748 - val_accuracy: 0.8744\n",
            "Epoch 577/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3760 - accuracy: 0.8716 - val_loss: 0.3745 - val_accuracy: 0.8737\n",
            "Epoch 578/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3759 - accuracy: 0.8716 - val_loss: 0.3743 - val_accuracy: 0.8726\n",
            "Epoch 579/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3757 - accuracy: 0.8721 - val_loss: 0.3741 - val_accuracy: 0.8710\n",
            "Epoch 580/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3756 - accuracy: 0.8716 - val_loss: 0.3739 - val_accuracy: 0.8737\n",
            "Epoch 581/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3755 - accuracy: 0.8723 - val_loss: 0.3748 - val_accuracy: 0.8747\n",
            "Epoch 582/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3754 - accuracy: 0.8719 - val_loss: 0.3738 - val_accuracy: 0.8742\n",
            "Epoch 583/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3753 - accuracy: 0.8715 - val_loss: 0.3736 - val_accuracy: 0.8738\n",
            "Epoch 584/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8721 - val_loss: 0.3733 - val_accuracy: 0.8742\n",
            "Epoch 585/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3750 - accuracy: 0.8725 - val_loss: 0.3733 - val_accuracy: 0.8719\n",
            "Epoch 586/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3749 - accuracy: 0.8722 - val_loss: 0.3732 - val_accuracy: 0.8739\n",
            "Epoch 587/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3747 - accuracy: 0.8724 - val_loss: 0.3731 - val_accuracy: 0.8747\n",
            "Epoch 588/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3746 - accuracy: 0.8719 - val_loss: 0.3731 - val_accuracy: 0.8745\n",
            "Epoch 589/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3745 - accuracy: 0.8724 - val_loss: 0.3728 - val_accuracy: 0.8742\n",
            "Epoch 590/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3744 - accuracy: 0.8719 - val_loss: 0.3728 - val_accuracy: 0.8746\n",
            "Epoch 591/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8725 - val_loss: 0.3728 - val_accuracy: 0.8722\n",
            "Epoch 592/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3741 - accuracy: 0.8722 - val_loss: 0.3724 - val_accuracy: 0.8713\n",
            "Epoch 593/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3739 - accuracy: 0.8727 - val_loss: 0.3726 - val_accuracy: 0.8738\n",
            "Epoch 594/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.8730 - val_loss: 0.3721 - val_accuracy: 0.8745\n",
            "Epoch 595/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.8724 - val_loss: 0.3722 - val_accuracy: 0.8751\n",
            "Epoch 596/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3736 - accuracy: 0.8728 - val_loss: 0.3718 - val_accuracy: 0.8740\n",
            "Epoch 597/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3734 - accuracy: 0.8728 - val_loss: 0.3717 - val_accuracy: 0.8737\n",
            "Epoch 598/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3733 - accuracy: 0.8729 - val_loss: 0.3718 - val_accuracy: 0.8717\n",
            "Epoch 599/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3732 - accuracy: 0.8728 - val_loss: 0.3714 - val_accuracy: 0.8730\n",
            "Epoch 600/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3730 - accuracy: 0.8727 - val_loss: 0.3713 - val_accuracy: 0.8742\n",
            "Epoch 601/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3729 - accuracy: 0.8734 - val_loss: 0.3713 - val_accuracy: 0.8741\n",
            "Epoch 602/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3728 - accuracy: 0.8733 - val_loss: 0.3710 - val_accuracy: 0.8736\n",
            "Epoch 603/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3726 - accuracy: 0.8729 - val_loss: 0.3709 - val_accuracy: 0.8731\n",
            "Epoch 604/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3726 - accuracy: 0.8732 - val_loss: 0.3708 - val_accuracy: 0.8745\n",
            "Epoch 605/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3725 - accuracy: 0.8730 - val_loss: 0.3707 - val_accuracy: 0.8743\n",
            "Epoch 606/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3723 - accuracy: 0.8733 - val_loss: 0.3706 - val_accuracy: 0.8730\n",
            "Epoch 607/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3722 - accuracy: 0.8730 - val_loss: 0.3705 - val_accuracy: 0.8734\n",
            "Epoch 608/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3720 - accuracy: 0.8730 - val_loss: 0.3706 - val_accuracy: 0.8742\n",
            "Epoch 609/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3719 - accuracy: 0.8731 - val_loss: 0.3703 - val_accuracy: 0.8749\n",
            "Epoch 610/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3718 - accuracy: 0.8729 - val_loss: 0.3707 - val_accuracy: 0.8758\n",
            "Epoch 611/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3717 - accuracy: 0.8735 - val_loss: 0.3700 - val_accuracy: 0.8725\n",
            "Epoch 612/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3716 - accuracy: 0.8732 - val_loss: 0.3699 - val_accuracy: 0.8727\n",
            "Epoch 613/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3714 - accuracy: 0.8733 - val_loss: 0.3698 - val_accuracy: 0.8752\n",
            "Epoch 614/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3713 - accuracy: 0.8735 - val_loss: 0.3696 - val_accuracy: 0.8727\n",
            "Epoch 615/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3712 - accuracy: 0.8729 - val_loss: 0.3696 - val_accuracy: 0.8750\n",
            "Epoch 616/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3711 - accuracy: 0.8740 - val_loss: 0.3694 - val_accuracy: 0.8734\n",
            "Epoch 617/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3709 - accuracy: 0.8735 - val_loss: 0.3694 - val_accuracy: 0.8756\n",
            "Epoch 618/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3708 - accuracy: 0.8736 - val_loss: 0.3692 - val_accuracy: 0.8745\n",
            "Epoch 619/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3707 - accuracy: 0.8735 - val_loss: 0.3690 - val_accuracy: 0.8752\n",
            "Epoch 620/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3705 - accuracy: 0.8735 - val_loss: 0.3696 - val_accuracy: 0.8763\n",
            "Epoch 621/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3705 - accuracy: 0.8737 - val_loss: 0.3688 - val_accuracy: 0.8744\n",
            "Epoch 622/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3703 - accuracy: 0.8738 - val_loss: 0.3692 - val_accuracy: 0.8756\n",
            "Epoch 623/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3702 - accuracy: 0.8738 - val_loss: 0.3687 - val_accuracy: 0.8724\n",
            "Epoch 624/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3701 - accuracy: 0.8737 - val_loss: 0.3685 - val_accuracy: 0.8758\n",
            "Epoch 625/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3700 - accuracy: 0.8741 - val_loss: 0.3683 - val_accuracy: 0.8756\n",
            "Epoch 626/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3699 - accuracy: 0.8740 - val_loss: 0.3682 - val_accuracy: 0.8760\n",
            "Epoch 627/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3697 - accuracy: 0.8739 - val_loss: 0.3681 - val_accuracy: 0.8761\n",
            "Epoch 628/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3696 - accuracy: 0.8741 - val_loss: 0.3679 - val_accuracy: 0.8752\n",
            "Epoch 629/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3695 - accuracy: 0.8739 - val_loss: 0.3681 - val_accuracy: 0.8764\n",
            "Epoch 630/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3694 - accuracy: 0.8740 - val_loss: 0.3678 - val_accuracy: 0.8759\n",
            "Epoch 631/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3693 - accuracy: 0.8744 - val_loss: 0.3678 - val_accuracy: 0.8731\n",
            "Epoch 632/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3691 - accuracy: 0.8744 - val_loss: 0.3676 - val_accuracy: 0.8759\n",
            "Epoch 633/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3690 - accuracy: 0.8743 - val_loss: 0.3676 - val_accuracy: 0.8765\n",
            "Epoch 634/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8740 - val_loss: 0.3675 - val_accuracy: 0.8756\n",
            "Epoch 635/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3688 - accuracy: 0.8746 - val_loss: 0.3671 - val_accuracy: 0.8745\n",
            "Epoch 636/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3687 - accuracy: 0.8746 - val_loss: 0.3671 - val_accuracy: 0.8742\n",
            "Epoch 637/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3686 - accuracy: 0.8743 - val_loss: 0.3668 - val_accuracy: 0.8752\n",
            "Epoch 638/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3684 - accuracy: 0.8743 - val_loss: 0.3670 - val_accuracy: 0.8764\n",
            "Epoch 639/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3683 - accuracy: 0.8746 - val_loss: 0.3669 - val_accuracy: 0.8727\n",
            "Epoch 640/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3682 - accuracy: 0.8745 - val_loss: 0.3666 - val_accuracy: 0.8748\n",
            "Epoch 641/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3681 - accuracy: 0.8747 - val_loss: 0.3668 - val_accuracy: 0.8727\n",
            "Epoch 642/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3679 - accuracy: 0.8744 - val_loss: 0.3665 - val_accuracy: 0.8766\n",
            "Epoch 643/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3679 - accuracy: 0.8748 - val_loss: 0.3663 - val_accuracy: 0.8748\n",
            "Epoch 644/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3677 - accuracy: 0.8750 - val_loss: 0.3661 - val_accuracy: 0.8762\n",
            "Epoch 645/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3676 - accuracy: 0.8748 - val_loss: 0.3660 - val_accuracy: 0.8753\n",
            "Epoch 646/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3675 - accuracy: 0.8750 - val_loss: 0.3659 - val_accuracy: 0.8763\n",
            "Epoch 647/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3673 - accuracy: 0.8750 - val_loss: 0.3657 - val_accuracy: 0.8749\n",
            "Epoch 648/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3672 - accuracy: 0.8748 - val_loss: 0.3656 - val_accuracy: 0.8742\n",
            "Epoch 649/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3672 - accuracy: 0.8751 - val_loss: 0.3657 - val_accuracy: 0.8763\n",
            "Epoch 650/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3670 - accuracy: 0.8748 - val_loss: 0.3654 - val_accuracy: 0.8763\n",
            "Epoch 651/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3669 - accuracy: 0.8751 - val_loss: 0.3657 - val_accuracy: 0.8777\n",
            "Epoch 652/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3668 - accuracy: 0.8749 - val_loss: 0.3652 - val_accuracy: 0.8762\n",
            "Epoch 653/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3667 - accuracy: 0.8751 - val_loss: 0.3650 - val_accuracy: 0.8754\n",
            "Epoch 654/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3665 - accuracy: 0.8752 - val_loss: 0.3652 - val_accuracy: 0.8771\n",
            "Epoch 655/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3665 - accuracy: 0.8751 - val_loss: 0.3651 - val_accuracy: 0.8777\n",
            "Epoch 656/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3663 - accuracy: 0.8757 - val_loss: 0.3647 - val_accuracy: 0.8752\n",
            "Epoch 657/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3663 - accuracy: 0.8752 - val_loss: 0.3646 - val_accuracy: 0.8746\n",
            "Epoch 658/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3661 - accuracy: 0.8752 - val_loss: 0.3657 - val_accuracy: 0.8711\n",
            "Epoch 659/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3660 - accuracy: 0.8756 - val_loss: 0.3645 - val_accuracy: 0.8773\n",
            "Epoch 660/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3659 - accuracy: 0.8753 - val_loss: 0.3643 - val_accuracy: 0.8746\n",
            "Epoch 661/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3658 - accuracy: 0.8756 - val_loss: 0.3643 - val_accuracy: 0.8773\n",
            "Epoch 662/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3657 - accuracy: 0.8757 - val_loss: 0.3640 - val_accuracy: 0.8766\n",
            "Epoch 663/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3655 - accuracy: 0.8753 - val_loss: 0.3642 - val_accuracy: 0.8777\n",
            "Epoch 664/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3654 - accuracy: 0.8753 - val_loss: 0.3638 - val_accuracy: 0.8752\n",
            "Epoch 665/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3653 - accuracy: 0.8755 - val_loss: 0.3637 - val_accuracy: 0.8765\n",
            "Epoch 666/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3652 - accuracy: 0.8757 - val_loss: 0.3638 - val_accuracy: 0.8741\n",
            "Epoch 667/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3651 - accuracy: 0.8756 - val_loss: 0.3640 - val_accuracy: 0.8784\n",
            "Epoch 668/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3650 - accuracy: 0.8759 - val_loss: 0.3634 - val_accuracy: 0.8774\n",
            "Epoch 669/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3649 - accuracy: 0.8758 - val_loss: 0.3633 - val_accuracy: 0.8771\n",
            "Epoch 670/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3648 - accuracy: 0.8757 - val_loss: 0.3633 - val_accuracy: 0.8749\n",
            "Epoch 671/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3647 - accuracy: 0.8759 - val_loss: 0.3630 - val_accuracy: 0.8755\n",
            "Epoch 672/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3645 - accuracy: 0.8763 - val_loss: 0.3629 - val_accuracy: 0.8766\n",
            "Epoch 673/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3644 - accuracy: 0.8759 - val_loss: 0.3631 - val_accuracy: 0.8783\n",
            "Epoch 674/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3643 - accuracy: 0.8762 - val_loss: 0.3628 - val_accuracy: 0.8778\n",
            "Epoch 675/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3642 - accuracy: 0.8760 - val_loss: 0.3627 - val_accuracy: 0.8780\n",
            "Epoch 676/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3641 - accuracy: 0.8765 - val_loss: 0.3626 - val_accuracy: 0.8779\n",
            "Epoch 677/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3640 - accuracy: 0.8759 - val_loss: 0.3628 - val_accuracy: 0.8788\n",
            "Epoch 678/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3638 - accuracy: 0.8762 - val_loss: 0.3624 - val_accuracy: 0.8778\n",
            "Epoch 679/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3637 - accuracy: 0.8764 - val_loss: 0.3626 - val_accuracy: 0.8737\n",
            "Epoch 680/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3637 - accuracy: 0.8764 - val_loss: 0.3622 - val_accuracy: 0.8748\n",
            "Epoch 681/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3635 - accuracy: 0.8760 - val_loss: 0.3622 - val_accuracy: 0.8778\n",
            "Epoch 682/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3634 - accuracy: 0.8765 - val_loss: 0.3619 - val_accuracy: 0.8752\n",
            "Epoch 683/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3633 - accuracy: 0.8764 - val_loss: 0.3618 - val_accuracy: 0.8755\n",
            "Epoch 684/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3632 - accuracy: 0.8761 - val_loss: 0.3616 - val_accuracy: 0.8771\n",
            "Epoch 685/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3630 - accuracy: 0.8764 - val_loss: 0.3616 - val_accuracy: 0.8776\n",
            "Epoch 686/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3630 - accuracy: 0.8767 - val_loss: 0.3615 - val_accuracy: 0.8784\n",
            "Epoch 687/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3629 - accuracy: 0.8765 - val_loss: 0.3615 - val_accuracy: 0.8788\n",
            "Epoch 688/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3628 - accuracy: 0.8765 - val_loss: 0.3612 - val_accuracy: 0.8758\n",
            "Epoch 689/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3627 - accuracy: 0.8764 - val_loss: 0.3611 - val_accuracy: 0.8780\n",
            "Epoch 690/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3626 - accuracy: 0.8768 - val_loss: 0.3610 - val_accuracy: 0.8783\n",
            "Epoch 691/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3625 - accuracy: 0.8767 - val_loss: 0.3609 - val_accuracy: 0.8784\n",
            "Epoch 692/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3623 - accuracy: 0.8769 - val_loss: 0.3608 - val_accuracy: 0.8768\n",
            "Epoch 693/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3623 - accuracy: 0.8769 - val_loss: 0.3608 - val_accuracy: 0.8773\n",
            "Epoch 694/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3622 - accuracy: 0.8770 - val_loss: 0.3606 - val_accuracy: 0.8772\n",
            "Epoch 695/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3621 - accuracy: 0.8769 - val_loss: 0.3605 - val_accuracy: 0.8777\n",
            "Epoch 696/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3619 - accuracy: 0.8769 - val_loss: 0.3603 - val_accuracy: 0.8778\n",
            "Epoch 697/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3619 - accuracy: 0.8771 - val_loss: 0.3606 - val_accuracy: 0.8798\n",
            "Epoch 698/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3618 - accuracy: 0.8770 - val_loss: 0.3602 - val_accuracy: 0.8785\n",
            "Epoch 699/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3616 - accuracy: 0.8770 - val_loss: 0.3601 - val_accuracy: 0.8789\n",
            "Epoch 700/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3615 - accuracy: 0.8770 - val_loss: 0.3599 - val_accuracy: 0.8786\n",
            "Epoch 701/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3615 - accuracy: 0.8773 - val_loss: 0.3598 - val_accuracy: 0.8781\n",
            "Epoch 702/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3613 - accuracy: 0.8772 - val_loss: 0.3597 - val_accuracy: 0.8787\n",
            "Epoch 703/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3612 - accuracy: 0.8773 - val_loss: 0.3599 - val_accuracy: 0.8796\n",
            "Epoch 704/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3611 - accuracy: 0.8773 - val_loss: 0.3595 - val_accuracy: 0.8784\n",
            "Epoch 705/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3610 - accuracy: 0.8775 - val_loss: 0.3594 - val_accuracy: 0.8786\n",
            "Epoch 706/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3609 - accuracy: 0.8772 - val_loss: 0.3596 - val_accuracy: 0.8791\n",
            "Epoch 707/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3608 - accuracy: 0.8774 - val_loss: 0.3592 - val_accuracy: 0.8771\n",
            "Epoch 708/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3607 - accuracy: 0.8774 - val_loss: 0.3595 - val_accuracy: 0.8780\n",
            "Epoch 709/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3606 - accuracy: 0.8777 - val_loss: 0.3591 - val_accuracy: 0.8795\n",
            "Epoch 710/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3604 - accuracy: 0.8779 - val_loss: 0.3590 - val_accuracy: 0.8789\n",
            "Epoch 711/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3603 - accuracy: 0.8776 - val_loss: 0.3595 - val_accuracy: 0.8810\n",
            "Epoch 712/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3603 - accuracy: 0.8776 - val_loss: 0.3589 - val_accuracy: 0.8799\n",
            "Epoch 713/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3602 - accuracy: 0.8777 - val_loss: 0.3587 - val_accuracy: 0.8791\n",
            "Epoch 714/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3601 - accuracy: 0.8779 - val_loss: 0.3585 - val_accuracy: 0.8787\n",
            "Epoch 715/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3599 - accuracy: 0.8775 - val_loss: 0.3585 - val_accuracy: 0.8791\n",
            "Epoch 716/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3598 - accuracy: 0.8781 - val_loss: 0.3585 - val_accuracy: 0.8786\n",
            "Epoch 717/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3598 - accuracy: 0.8781 - val_loss: 0.3582 - val_accuracy: 0.8788\n",
            "Epoch 718/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3597 - accuracy: 0.8782 - val_loss: 0.3581 - val_accuracy: 0.8785\n",
            "Epoch 719/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3595 - accuracy: 0.8782 - val_loss: 0.3580 - val_accuracy: 0.8786\n",
            "Epoch 720/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3595 - accuracy: 0.8782 - val_loss: 0.3583 - val_accuracy: 0.8809\n",
            "Epoch 721/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3594 - accuracy: 0.8779 - val_loss: 0.3578 - val_accuracy: 0.8792\n",
            "Epoch 722/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3592 - accuracy: 0.8780 - val_loss: 0.3579 - val_accuracy: 0.8805\n",
            "Epoch 723/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3591 - accuracy: 0.8780 - val_loss: 0.3576 - val_accuracy: 0.8788\n",
            "Epoch 724/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3591 - accuracy: 0.8780 - val_loss: 0.3575 - val_accuracy: 0.8789\n",
            "Epoch 725/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3589 - accuracy: 0.8779 - val_loss: 0.3575 - val_accuracy: 0.8802\n",
            "Epoch 726/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3589 - accuracy: 0.8785 - val_loss: 0.3576 - val_accuracy: 0.8812\n",
            "Epoch 727/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3587 - accuracy: 0.8781 - val_loss: 0.3572 - val_accuracy: 0.8788\n",
            "Epoch 728/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3587 - accuracy: 0.8786 - val_loss: 0.3572 - val_accuracy: 0.8771\n",
            "Epoch 729/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3585 - accuracy: 0.8782 - val_loss: 0.3574 - val_accuracy: 0.8767\n",
            "Epoch 730/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3584 - accuracy: 0.8787 - val_loss: 0.3570 - val_accuracy: 0.8802\n",
            "Epoch 731/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3584 - accuracy: 0.8784 - val_loss: 0.3571 - val_accuracy: 0.8814\n",
            "Epoch 732/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3583 - accuracy: 0.8783 - val_loss: 0.3567 - val_accuracy: 0.8795\n",
            "Epoch 733/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3582 - accuracy: 0.8789 - val_loss: 0.3569 - val_accuracy: 0.8767\n",
            "Epoch 734/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3581 - accuracy: 0.8787 - val_loss: 0.3565 - val_accuracy: 0.8791\n",
            "Epoch 735/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3579 - accuracy: 0.8788 - val_loss: 0.3567 - val_accuracy: 0.8811\n",
            "Epoch 736/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3578 - accuracy: 0.8788 - val_loss: 0.3564 - val_accuracy: 0.8808\n",
            "Epoch 737/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3578 - accuracy: 0.8788 - val_loss: 0.3564 - val_accuracy: 0.8803\n",
            "Epoch 738/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3577 - accuracy: 0.8785 - val_loss: 0.3561 - val_accuracy: 0.8788\n",
            "Epoch 739/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3576 - accuracy: 0.8788 - val_loss: 0.3565 - val_accuracy: 0.8805\n",
            "Epoch 740/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3574 - accuracy: 0.8791 - val_loss: 0.3560 - val_accuracy: 0.8812\n",
            "Epoch 741/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3574 - accuracy: 0.8793 - val_loss: 0.3559 - val_accuracy: 0.8778\n",
            "Epoch 742/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3573 - accuracy: 0.8790 - val_loss: 0.3558 - val_accuracy: 0.8804\n",
            "Epoch 743/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3571 - accuracy: 0.8792 - val_loss: 0.3559 - val_accuracy: 0.8778\n",
            "Epoch 744/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3570 - accuracy: 0.8792 - val_loss: 0.3557 - val_accuracy: 0.8770\n",
            "Epoch 745/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3570 - accuracy: 0.8789 - val_loss: 0.3555 - val_accuracy: 0.8808\n",
            "Epoch 746/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3569 - accuracy: 0.8795 - val_loss: 0.3554 - val_accuracy: 0.8802\n",
            "Epoch 747/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3568 - accuracy: 0.8794 - val_loss: 0.3553 - val_accuracy: 0.8795\n",
            "Epoch 748/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3567 - accuracy: 0.8792 - val_loss: 0.3554 - val_accuracy: 0.8775\n",
            "Epoch 749/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3566 - accuracy: 0.8792 - val_loss: 0.3551 - val_accuracy: 0.8791\n",
            "Epoch 750/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3565 - accuracy: 0.8794 - val_loss: 0.3550 - val_accuracy: 0.8810\n",
            "Epoch 751/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3564 - accuracy: 0.8795 - val_loss: 0.3551 - val_accuracy: 0.8813\n",
            "Epoch 752/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3563 - accuracy: 0.8793 - val_loss: 0.3551 - val_accuracy: 0.8820\n",
            "Epoch 753/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3561 - accuracy: 0.8793 - val_loss: 0.3548 - val_accuracy: 0.8813\n",
            "Epoch 754/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3561 - accuracy: 0.8795 - val_loss: 0.3546 - val_accuracy: 0.8798\n",
            "Epoch 755/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3560 - accuracy: 0.8796 - val_loss: 0.3547 - val_accuracy: 0.8808\n",
            "Epoch 756/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3559 - accuracy: 0.8798 - val_loss: 0.3549 - val_accuracy: 0.8773\n",
            "Epoch 757/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3558 - accuracy: 0.8793 - val_loss: 0.3543 - val_accuracy: 0.8809\n",
            "Epoch 758/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3557 - accuracy: 0.8795 - val_loss: 0.3543 - val_accuracy: 0.8806\n",
            "Epoch 759/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3556 - accuracy: 0.8801 - val_loss: 0.3543 - val_accuracy: 0.8819\n",
            "Epoch 760/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3555 - accuracy: 0.8803 - val_loss: 0.3540 - val_accuracy: 0.8804\n",
            "Epoch 761/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3554 - accuracy: 0.8803 - val_loss: 0.3540 - val_accuracy: 0.8808\n",
            "Epoch 762/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3553 - accuracy: 0.8797 - val_loss: 0.3540 - val_accuracy: 0.8781\n",
            "Epoch 763/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3553 - accuracy: 0.8796 - val_loss: 0.3538 - val_accuracy: 0.8813\n",
            "Epoch 764/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3551 - accuracy: 0.8806 - val_loss: 0.3538 - val_accuracy: 0.8805\n",
            "Epoch 765/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3551 - accuracy: 0.8800 - val_loss: 0.3537 - val_accuracy: 0.8808\n",
            "Epoch 766/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3550 - accuracy: 0.8804 - val_loss: 0.3535 - val_accuracy: 0.8811\n",
            "Epoch 767/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3548 - accuracy: 0.8799 - val_loss: 0.3536 - val_accuracy: 0.8824\n",
            "Epoch 768/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3547 - accuracy: 0.8799 - val_loss: 0.3536 - val_accuracy: 0.8827\n",
            "Epoch 769/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3546 - accuracy: 0.8803 - val_loss: 0.3538 - val_accuracy: 0.8776\n",
            "Epoch 770/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3546 - accuracy: 0.8802 - val_loss: 0.3532 - val_accuracy: 0.8811\n",
            "Epoch 771/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3545 - accuracy: 0.8800 - val_loss: 0.3530 - val_accuracy: 0.8820\n",
            "Epoch 772/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3544 - accuracy: 0.8799 - val_loss: 0.3530 - val_accuracy: 0.8816\n",
            "Epoch 773/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3543 - accuracy: 0.8805 - val_loss: 0.3529 - val_accuracy: 0.8822\n",
            "Epoch 774/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3542 - accuracy: 0.8804 - val_loss: 0.3528 - val_accuracy: 0.8799\n",
            "Epoch 775/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3541 - accuracy: 0.8803 - val_loss: 0.3527 - val_accuracy: 0.8814\n",
            "Epoch 776/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3540 - accuracy: 0.8809 - val_loss: 0.3526 - val_accuracy: 0.8816\n",
            "Epoch 777/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3539 - accuracy: 0.8807 - val_loss: 0.3526 - val_accuracy: 0.8821\n",
            "Epoch 778/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3538 - accuracy: 0.8806 - val_loss: 0.3524 - val_accuracy: 0.8810\n",
            "Epoch 779/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3537 - accuracy: 0.8808 - val_loss: 0.3524 - val_accuracy: 0.8809\n",
            "Epoch 780/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3536 - accuracy: 0.8809 - val_loss: 0.3522 - val_accuracy: 0.8803\n",
            "Epoch 781/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8809 - val_loss: 0.3521 - val_accuracy: 0.8820\n",
            "Epoch 782/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8808 - val_loss: 0.3520 - val_accuracy: 0.8823\n",
            "Epoch 783/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3533 - accuracy: 0.8808 - val_loss: 0.3519 - val_accuracy: 0.8820\n",
            "Epoch 784/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3533 - accuracy: 0.8802 - val_loss: 0.3520 - val_accuracy: 0.8824\n",
            "Epoch 785/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3532 - accuracy: 0.8807 - val_loss: 0.3518 - val_accuracy: 0.8820\n",
            "Epoch 786/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3531 - accuracy: 0.8808 - val_loss: 0.3517 - val_accuracy: 0.8826\n",
            "Epoch 787/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3530 - accuracy: 0.8811 - val_loss: 0.3516 - val_accuracy: 0.8823\n",
            "Epoch 788/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3529 - accuracy: 0.8811 - val_loss: 0.3515 - val_accuracy: 0.8819\n",
            "Epoch 789/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3528 - accuracy: 0.8807 - val_loss: 0.3515 - val_accuracy: 0.8817\n",
            "Epoch 790/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3527 - accuracy: 0.8810 - val_loss: 0.3516 - val_accuracy: 0.8789\n",
            "Epoch 791/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3526 - accuracy: 0.8810 - val_loss: 0.3515 - val_accuracy: 0.8798\n",
            "Epoch 792/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3525 - accuracy: 0.8813 - val_loss: 0.3514 - val_accuracy: 0.8785\n",
            "Epoch 793/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3524 - accuracy: 0.8807 - val_loss: 0.3510 - val_accuracy: 0.8823\n",
            "Epoch 794/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3524 - accuracy: 0.8813 - val_loss: 0.3512 - val_accuracy: 0.8790\n",
            "Epoch 795/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3522 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8826\n",
            "Epoch 796/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3522 - accuracy: 0.8813 - val_loss: 0.3509 - val_accuracy: 0.8834\n",
            "Epoch 797/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3520 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8835\n",
            "Epoch 798/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3520 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8835\n",
            "Epoch 799/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3519 - accuracy: 0.8814 - val_loss: 0.3506 - val_accuracy: 0.8819\n",
            "Epoch 800/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3518 - accuracy: 0.8812 - val_loss: 0.3510 - val_accuracy: 0.8786\n",
            "Epoch 801/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3517 - accuracy: 0.8818 - val_loss: 0.3506 - val_accuracy: 0.8827\n",
            "Epoch 802/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3517 - accuracy: 0.8816 - val_loss: 0.3503 - val_accuracy: 0.8828\n",
            "Epoch 803/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3516 - accuracy: 0.8817 - val_loss: 0.3503 - val_accuracy: 0.8834\n",
            "Epoch 804/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3514 - accuracy: 0.8819 - val_loss: 0.3502 - val_accuracy: 0.8811\n",
            "Epoch 805/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3514 - accuracy: 0.8816 - val_loss: 0.3501 - val_accuracy: 0.8830\n",
            "Epoch 806/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3513 - accuracy: 0.8816 - val_loss: 0.3502 - val_accuracy: 0.8817\n",
            "Epoch 807/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3512 - accuracy: 0.8819 - val_loss: 0.3498 - val_accuracy: 0.8829\n",
            "Epoch 808/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.8816 - val_loss: 0.3500 - val_accuracy: 0.8831\n",
            "Epoch 809/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.8821 - val_loss: 0.3496 - val_accuracy: 0.8821\n",
            "Epoch 810/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3509 - accuracy: 0.8820 - val_loss: 0.3496 - val_accuracy: 0.8820\n",
            "Epoch 811/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3508 - accuracy: 0.8818 - val_loss: 0.3498 - val_accuracy: 0.8836\n",
            "Epoch 812/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3508 - accuracy: 0.8820 - val_loss: 0.3494 - val_accuracy: 0.8822\n",
            "Epoch 813/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3507 - accuracy: 0.8822 - val_loss: 0.3493 - val_accuracy: 0.8837\n",
            "Epoch 814/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3505 - accuracy: 0.8822 - val_loss: 0.3492 - val_accuracy: 0.8826\n",
            "Epoch 815/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3505 - accuracy: 0.8821 - val_loss: 0.3493 - val_accuracy: 0.8841\n",
            "Epoch 816/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3504 - accuracy: 0.8821 - val_loss: 0.3490 - val_accuracy: 0.8834\n",
            "Epoch 817/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3503 - accuracy: 0.8822 - val_loss: 0.3494 - val_accuracy: 0.8845\n",
            "Epoch 818/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3502 - accuracy: 0.8823 - val_loss: 0.3490 - val_accuracy: 0.8839\n",
            "Epoch 819/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3501 - accuracy: 0.8819 - val_loss: 0.3488 - val_accuracy: 0.8842\n",
            "Epoch 820/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3501 - accuracy: 0.8822 - val_loss: 0.3489 - val_accuracy: 0.8815\n",
            "Epoch 821/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3500 - accuracy: 0.8824 - val_loss: 0.3488 - val_accuracy: 0.8842\n",
            "Epoch 822/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3499 - accuracy: 0.8824 - val_loss: 0.3485 - val_accuracy: 0.8826\n",
            "Epoch 823/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3498 - accuracy: 0.8823 - val_loss: 0.3485 - val_accuracy: 0.8835\n",
            "Epoch 824/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3497 - accuracy: 0.8826 - val_loss: 0.3483 - val_accuracy: 0.8824\n",
            "Epoch 825/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8826 - val_loss: 0.3483 - val_accuracy: 0.8841\n",
            "Epoch 826/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8828 - val_loss: 0.3482 - val_accuracy: 0.8836\n",
            "Epoch 827/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3495 - accuracy: 0.8829 - val_loss: 0.3483 - val_accuracy: 0.8846\n",
            "Epoch 828/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3494 - accuracy: 0.8826 - val_loss: 0.3480 - val_accuracy: 0.8841\n",
            "Epoch 829/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3493 - accuracy: 0.8824 - val_loss: 0.3480 - val_accuracy: 0.8840\n",
            "Epoch 830/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3492 - accuracy: 0.8824 - val_loss: 0.3481 - val_accuracy: 0.8844\n",
            "Epoch 831/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3491 - accuracy: 0.8828 - val_loss: 0.3481 - val_accuracy: 0.8807\n",
            "Epoch 832/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3490 - accuracy: 0.8831 - val_loss: 0.3478 - val_accuracy: 0.8845\n",
            "Epoch 833/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3489 - accuracy: 0.8826 - val_loss: 0.3477 - val_accuracy: 0.8828\n",
            "Epoch 834/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3488 - accuracy: 0.8826 - val_loss: 0.3476 - val_accuracy: 0.8840\n",
            "Epoch 835/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3488 - accuracy: 0.8830 - val_loss: 0.3474 - val_accuracy: 0.8838\n",
            "Epoch 836/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3487 - accuracy: 0.8832 - val_loss: 0.3473 - val_accuracy: 0.8844\n",
            "Epoch 837/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3486 - accuracy: 0.8828 - val_loss: 0.3476 - val_accuracy: 0.8828\n",
            "Epoch 838/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3485 - accuracy: 0.8828 - val_loss: 0.3472 - val_accuracy: 0.8848\n",
            "Epoch 839/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3471 - val_accuracy: 0.8832\n",
            "Epoch 840/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3483 - accuracy: 0.8832 - val_loss: 0.3472 - val_accuracy: 0.8849\n",
            "Epoch 841/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3483 - accuracy: 0.8832 - val_loss: 0.3469 - val_accuracy: 0.8839\n",
            "Epoch 842/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3482 - accuracy: 0.8833 - val_loss: 0.3470 - val_accuracy: 0.8856\n",
            "Epoch 843/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3481 - accuracy: 0.8827 - val_loss: 0.3469 - val_accuracy: 0.8839\n",
            "Epoch 844/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3480 - accuracy: 0.8834 - val_loss: 0.3468 - val_accuracy: 0.8817\n",
            "Epoch 845/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3479 - accuracy: 0.8831 - val_loss: 0.3468 - val_accuracy: 0.8844\n",
            "Epoch 846/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3478 - accuracy: 0.8834 - val_loss: 0.3466 - val_accuracy: 0.8838\n",
            "Epoch 847/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3477 - accuracy: 0.8834 - val_loss: 0.3465 - val_accuracy: 0.8828\n",
            "Epoch 848/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3477 - accuracy: 0.8834 - val_loss: 0.3465 - val_accuracy: 0.8854\n",
            "Epoch 849/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3476 - accuracy: 0.8833 - val_loss: 0.3463 - val_accuracy: 0.8841\n",
            "Epoch 850/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3474 - accuracy: 0.8835 - val_loss: 0.3469 - val_accuracy: 0.8861\n",
            "Epoch 851/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3474 - accuracy: 0.8831 - val_loss: 0.3469 - val_accuracy: 0.8791\n",
            "Epoch 852/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3473 - accuracy: 0.8837 - val_loss: 0.3460 - val_accuracy: 0.8850\n",
            "Epoch 853/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3472 - accuracy: 0.8837 - val_loss: 0.3460 - val_accuracy: 0.8849\n",
            "Epoch 854/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3472 - accuracy: 0.8840 - val_loss: 0.3458 - val_accuracy: 0.8842\n",
            "Epoch 855/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3471 - accuracy: 0.8835 - val_loss: 0.3458 - val_accuracy: 0.8852\n",
            "Epoch 856/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3470 - accuracy: 0.8832 - val_loss: 0.3458 - val_accuracy: 0.8839\n",
            "Epoch 857/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3470 - accuracy: 0.8841 - val_loss: 0.3456 - val_accuracy: 0.8846\n",
            "Epoch 858/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3468 - accuracy: 0.8836 - val_loss: 0.3456 - val_accuracy: 0.8839\n",
            "Epoch 859/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3468 - accuracy: 0.8837 - val_loss: 0.3457 - val_accuracy: 0.8831\n",
            "Epoch 860/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3466 - accuracy: 0.8838 - val_loss: 0.3455 - val_accuracy: 0.8823\n",
            "Epoch 861/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3466 - accuracy: 0.8839 - val_loss: 0.3458 - val_accuracy: 0.8806\n",
            "Epoch 862/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3465 - accuracy: 0.8835 - val_loss: 0.3452 - val_accuracy: 0.8854\n",
            "Epoch 863/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3464 - accuracy: 0.8838 - val_loss: 0.3452 - val_accuracy: 0.8852\n",
            "Epoch 864/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3464 - accuracy: 0.8840 - val_loss: 0.3451 - val_accuracy: 0.8846\n",
            "Epoch 865/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3462 - accuracy: 0.8839 - val_loss: 0.3453 - val_accuracy: 0.8856\n",
            "Epoch 866/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3462 - accuracy: 0.8840 - val_loss: 0.3448 - val_accuracy: 0.8851\n",
            "Epoch 867/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3461 - accuracy: 0.8840 - val_loss: 0.3452 - val_accuracy: 0.8856\n",
            "Epoch 868/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3461 - accuracy: 0.8842 - val_loss: 0.3448 - val_accuracy: 0.8840\n",
            "Epoch 869/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3459 - accuracy: 0.8840 - val_loss: 0.3447 - val_accuracy: 0.8856\n",
            "Epoch 870/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3458 - accuracy: 0.8843 - val_loss: 0.3453 - val_accuracy: 0.8816\n",
            "Epoch 871/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3458 - accuracy: 0.8838 - val_loss: 0.3446 - val_accuracy: 0.8845\n",
            "Epoch 872/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3457 - accuracy: 0.8838 - val_loss: 0.3444 - val_accuracy: 0.8853\n",
            "Epoch 873/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3456 - accuracy: 0.8846 - val_loss: 0.3443 - val_accuracy: 0.8849\n",
            "Epoch 874/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3455 - accuracy: 0.8840 - val_loss: 0.3443 - val_accuracy: 0.8854\n",
            "Epoch 875/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3455 - accuracy: 0.8845 - val_loss: 0.3443 - val_accuracy: 0.8860\n",
            "Epoch 876/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3454 - accuracy: 0.8843 - val_loss: 0.3445 - val_accuracy: 0.8867\n",
            "Epoch 877/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3453 - accuracy: 0.8843 - val_loss: 0.3441 - val_accuracy: 0.8852\n",
            "Epoch 878/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3452 - accuracy: 0.8843 - val_loss: 0.3440 - val_accuracy: 0.8859\n",
            "Epoch 879/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3452 - accuracy: 0.8847 - val_loss: 0.3439 - val_accuracy: 0.8859\n",
            "Epoch 880/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3451 - accuracy: 0.8847 - val_loss: 0.3439 - val_accuracy: 0.8861\n",
            "Epoch 881/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3450 - accuracy: 0.8847 - val_loss: 0.3438 - val_accuracy: 0.8859\n",
            "Epoch 882/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3449 - accuracy: 0.8848 - val_loss: 0.3436 - val_accuracy: 0.8853\n",
            "Epoch 883/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3449 - accuracy: 0.8846 - val_loss: 0.3435 - val_accuracy: 0.8854\n",
            "Epoch 884/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3447 - accuracy: 0.8845 - val_loss: 0.3436 - val_accuracy: 0.8832\n",
            "Epoch 885/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3447 - accuracy: 0.8845 - val_loss: 0.3435 - val_accuracy: 0.8863\n",
            "Epoch 886/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3446 - accuracy: 0.8848 - val_loss: 0.3434 - val_accuracy: 0.8841\n",
            "Epoch 887/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3445 - accuracy: 0.8851 - val_loss: 0.3433 - val_accuracy: 0.8860\n",
            "Epoch 888/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3444 - accuracy: 0.8848 - val_loss: 0.3432 - val_accuracy: 0.8862\n",
            "Epoch 889/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3443 - accuracy: 0.8845 - val_loss: 0.3439 - val_accuracy: 0.8881\n",
            "Epoch 890/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3443 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8849\n",
            "Epoch 891/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3442 - accuracy: 0.8850 - val_loss: 0.3429 - val_accuracy: 0.8864\n",
            "Epoch 892/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3441 - accuracy: 0.8849 - val_loss: 0.3428 - val_accuracy: 0.8865\n",
            "Epoch 893/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3440 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8868\n",
            "Epoch 894/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3440 - accuracy: 0.8847 - val_loss: 0.3430 - val_accuracy: 0.8870\n",
            "Epoch 895/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3439 - accuracy: 0.8856 - val_loss: 0.3426 - val_accuracy: 0.8863\n",
            "Epoch 896/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3438 - accuracy: 0.8856 - val_loss: 0.3426 - val_accuracy: 0.8861\n",
            "Epoch 897/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3437 - accuracy: 0.8854 - val_loss: 0.3426 - val_accuracy: 0.8856\n",
            "Epoch 898/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3437 - accuracy: 0.8853 - val_loss: 0.3424 - val_accuracy: 0.8865\n",
            "Epoch 899/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3436 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8866\n",
            "Epoch 900/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3435 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8867\n",
            "Epoch 901/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3434 - accuracy: 0.8854 - val_loss: 0.3421 - val_accuracy: 0.8857\n",
            "Epoch 902/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3433 - accuracy: 0.8853 - val_loss: 0.3424 - val_accuracy: 0.8871\n",
            "Epoch 903/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3432 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8844\n",
            "Epoch 904/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3432 - accuracy: 0.8848 - val_loss: 0.3420 - val_accuracy: 0.8867\n",
            "Epoch 905/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8856 - val_loss: 0.3418 - val_accuracy: 0.8863\n",
            "Epoch 906/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8853 - val_loss: 0.3422 - val_accuracy: 0.8880\n",
            "Epoch 907/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3430 - accuracy: 0.8853 - val_loss: 0.3417 - val_accuracy: 0.8860\n",
            "Epoch 908/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3428 - accuracy: 0.8856 - val_loss: 0.3417 - val_accuracy: 0.8859\n",
            "Epoch 909/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3428 - accuracy: 0.8856 - val_loss: 0.3417 - val_accuracy: 0.8859\n",
            "Epoch 910/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3427 - accuracy: 0.8858 - val_loss: 0.3415 - val_accuracy: 0.8862\n",
            "Epoch 911/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3427 - accuracy: 0.8855 - val_loss: 0.3414 - val_accuracy: 0.8867\n",
            "Epoch 912/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3426 - accuracy: 0.8860 - val_loss: 0.3416 - val_accuracy: 0.8866\n",
            "Epoch 913/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3424 - accuracy: 0.8855 - val_loss: 0.3413 - val_accuracy: 0.8863\n",
            "Epoch 914/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3424 - accuracy: 0.8853 - val_loss: 0.3412 - val_accuracy: 0.8867\n",
            "Epoch 915/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3424 - accuracy: 0.8859 - val_loss: 0.3411 - val_accuracy: 0.8864\n",
            "Epoch 916/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3423 - accuracy: 0.8859 - val_loss: 0.3410 - val_accuracy: 0.8860\n",
            "Epoch 917/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3422 - accuracy: 0.8857 - val_loss: 0.3414 - val_accuracy: 0.8843\n",
            "Epoch 918/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3421 - accuracy: 0.8858 - val_loss: 0.3411 - val_accuracy: 0.8849\n",
            "Epoch 919/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3421 - accuracy: 0.8858 - val_loss: 0.3408 - val_accuracy: 0.8859\n",
            "Epoch 920/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3420 - accuracy: 0.8861 - val_loss: 0.3410 - val_accuracy: 0.8878\n",
            "Epoch 921/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3419 - accuracy: 0.8861 - val_loss: 0.3410 - val_accuracy: 0.8856\n",
            "Epoch 922/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3418 - accuracy: 0.8858 - val_loss: 0.3408 - val_accuracy: 0.8844\n",
            "Epoch 923/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3418 - accuracy: 0.8860 - val_loss: 0.3405 - val_accuracy: 0.8868\n",
            "Epoch 924/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3417 - accuracy: 0.8860 - val_loss: 0.3404 - val_accuracy: 0.8867\n",
            "Epoch 925/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3416 - accuracy: 0.8861 - val_loss: 0.3405 - val_accuracy: 0.8856\n",
            "Epoch 926/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3415 - accuracy: 0.8860 - val_loss: 0.3405 - val_accuracy: 0.8853\n",
            "Epoch 927/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3415 - accuracy: 0.8861 - val_loss: 0.3403 - val_accuracy: 0.8860\n",
            "Epoch 928/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3414 - accuracy: 0.8858 - val_loss: 0.3402 - val_accuracy: 0.8864\n",
            "Epoch 929/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3413 - accuracy: 0.8860 - val_loss: 0.3402 - val_accuracy: 0.8881\n",
            "Epoch 930/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3413 - accuracy: 0.8864 - val_loss: 0.3401 - val_accuracy: 0.8878\n",
            "Epoch 931/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3412 - accuracy: 0.8863 - val_loss: 0.3403 - val_accuracy: 0.8842\n",
            "Epoch 932/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3411 - accuracy: 0.8860 - val_loss: 0.3401 - val_accuracy: 0.8850\n",
            "Epoch 933/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3410 - accuracy: 0.8863 - val_loss: 0.3398 - val_accuracy: 0.8871\n",
            "Epoch 934/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8860 - val_loss: 0.3397 - val_accuracy: 0.8868\n",
            "Epoch 935/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8861 - val_loss: 0.3397 - val_accuracy: 0.8873\n",
            "Epoch 936/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3408 - accuracy: 0.8862 - val_loss: 0.3399 - val_accuracy: 0.8878\n",
            "Epoch 937/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3407 - accuracy: 0.8862 - val_loss: 0.3396 - val_accuracy: 0.8881\n",
            "Epoch 938/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3407 - accuracy: 0.8868 - val_loss: 0.3395 - val_accuracy: 0.8866\n",
            "Epoch 939/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3406 - accuracy: 0.8864 - val_loss: 0.3395 - val_accuracy: 0.8878\n",
            "Epoch 940/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8866 - val_loss: 0.3394 - val_accuracy: 0.8887\n",
            "Epoch 941/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8870 - val_loss: 0.3395 - val_accuracy: 0.8885\n",
            "Epoch 942/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3404 - accuracy: 0.8862 - val_loss: 0.3398 - val_accuracy: 0.8892\n",
            "Epoch 943/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3403 - accuracy: 0.8869 - val_loss: 0.3391 - val_accuracy: 0.8864\n",
            "Epoch 944/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3402 - accuracy: 0.8864 - val_loss: 0.3395 - val_accuracy: 0.8881\n",
            "Epoch 945/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3401 - accuracy: 0.8863 - val_loss: 0.3393 - val_accuracy: 0.8870\n",
            "Epoch 946/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8869 - val_loss: 0.3389 - val_accuracy: 0.8868\n",
            "Epoch 947/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8868 - val_loss: 0.3388 - val_accuracy: 0.8868\n",
            "Epoch 948/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3399 - accuracy: 0.8865 - val_loss: 0.3388 - val_accuracy: 0.8884\n",
            "Epoch 949/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3399 - accuracy: 0.8864 - val_loss: 0.3389 - val_accuracy: 0.8892\n",
            "Epoch 950/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8866 - val_loss: 0.3386 - val_accuracy: 0.8863\n",
            "Epoch 951/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8868 - val_loss: 0.3386 - val_accuracy: 0.8877\n",
            "Epoch 952/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3397 - accuracy: 0.8867 - val_loss: 0.3385 - val_accuracy: 0.8881\n",
            "Epoch 953/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3396 - accuracy: 0.8869 - val_loss: 0.3384 - val_accuracy: 0.8887\n",
            "Epoch 954/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3395 - accuracy: 0.8871 - val_loss: 0.3384 - val_accuracy: 0.8876\n",
            "Epoch 955/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3394 - accuracy: 0.8867 - val_loss: 0.3383 - val_accuracy: 0.8888\n",
            "Epoch 956/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3394 - accuracy: 0.8869 - val_loss: 0.3381 - val_accuracy: 0.8878\n",
            "Epoch 957/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3393 - accuracy: 0.8870 - val_loss: 0.3382 - val_accuracy: 0.8888\n",
            "Epoch 958/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3392 - accuracy: 0.8875 - val_loss: 0.3384 - val_accuracy: 0.8852\n",
            "Epoch 959/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3391 - accuracy: 0.8869 - val_loss: 0.3380 - val_accuracy: 0.8870\n",
            "Epoch 960/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3390 - accuracy: 0.8868 - val_loss: 0.3379 - val_accuracy: 0.8892\n",
            "Epoch 961/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3390 - accuracy: 0.8874 - val_loss: 0.3379 - val_accuracy: 0.8878\n",
            "Epoch 962/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8871 - val_loss: 0.3377 - val_accuracy: 0.8884\n",
            "Epoch 963/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8871 - val_loss: 0.3378 - val_accuracy: 0.8866\n",
            "Epoch 964/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3388 - accuracy: 0.8868 - val_loss: 0.3377 - val_accuracy: 0.8870\n",
            "Epoch 965/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3387 - accuracy: 0.8872 - val_loss: 0.3376 - val_accuracy: 0.8877\n",
            "Epoch 966/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8871\n",
            "Epoch 967/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8892\n",
            "Epoch 968/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3385 - accuracy: 0.8875 - val_loss: 0.3374 - val_accuracy: 0.8867\n",
            "Epoch 969/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3385 - accuracy: 0.8872 - val_loss: 0.3373 - val_accuracy: 0.8878\n",
            "Epoch 970/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3384 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8902\n",
            "Epoch 971/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3383 - accuracy: 0.8878 - val_loss: 0.3372 - val_accuracy: 0.8874\n",
            "Epoch 972/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3382 - accuracy: 0.8873 - val_loss: 0.3371 - val_accuracy: 0.8883\n",
            "Epoch 973/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8873 - val_loss: 0.3372 - val_accuracy: 0.8866\n",
            "Epoch 974/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8875 - val_loss: 0.3369 - val_accuracy: 0.8878\n",
            "Epoch 975/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.8875 - val_loss: 0.3370 - val_accuracy: 0.8898\n",
            "Epoch 976/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3380 - accuracy: 0.8872 - val_loss: 0.3369 - val_accuracy: 0.8891\n",
            "Epoch 977/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3379 - accuracy: 0.8874 - val_loss: 0.3368 - val_accuracy: 0.8892\n",
            "Epoch 978/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3378 - accuracy: 0.8872 - val_loss: 0.3366 - val_accuracy: 0.8888\n",
            "Epoch 979/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3377 - accuracy: 0.8876 - val_loss: 0.3371 - val_accuracy: 0.8906\n",
            "Epoch 980/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8882 - val_loss: 0.3366 - val_accuracy: 0.8900\n",
            "Epoch 981/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3376 - accuracy: 0.8875 - val_loss: 0.3368 - val_accuracy: 0.8907\n",
            "Epoch 982/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3376 - accuracy: 0.8877 - val_loss: 0.3365 - val_accuracy: 0.8868\n",
            "Epoch 983/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3375 - accuracy: 0.8879 - val_loss: 0.3364 - val_accuracy: 0.8875\n",
            "Epoch 984/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3374 - accuracy: 0.8875 - val_loss: 0.3362 - val_accuracy: 0.8892\n",
            "Epoch 985/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3373 - accuracy: 0.8877 - val_loss: 0.3370 - val_accuracy: 0.8860\n",
            "Epoch 986/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3372 - accuracy: 0.8878 - val_loss: 0.3362 - val_accuracy: 0.8891\n",
            "Epoch 987/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3372 - accuracy: 0.8880 - val_loss: 0.3361 - val_accuracy: 0.8893\n",
            "Epoch 988/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3371 - accuracy: 0.8877 - val_loss: 0.3361 - val_accuracy: 0.8885\n",
            "Epoch 989/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3371 - accuracy: 0.8881 - val_loss: 0.3360 - val_accuracy: 0.8873\n",
            "Epoch 990/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3370 - accuracy: 0.8879 - val_loss: 0.3359 - val_accuracy: 0.8883\n",
            "Epoch 991/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3369 - accuracy: 0.8879 - val_loss: 0.3361 - val_accuracy: 0.8903\n",
            "Epoch 992/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3368 - accuracy: 0.8881 - val_loss: 0.3358 - val_accuracy: 0.8879\n",
            "Epoch 993/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3368 - accuracy: 0.8881 - val_loss: 0.3358 - val_accuracy: 0.8910\n",
            "Epoch 994/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3367 - accuracy: 0.8884 - val_loss: 0.3356 - val_accuracy: 0.8881\n",
            "Epoch 995/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3367 - accuracy: 0.8881 - val_loss: 0.3355 - val_accuracy: 0.8893\n",
            "Epoch 996/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3366 - accuracy: 0.8877 - val_loss: 0.3355 - val_accuracy: 0.8906\n",
            "Epoch 997/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3365 - accuracy: 0.8880 - val_loss: 0.3356 - val_accuracy: 0.8886\n",
            "Epoch 998/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3364 - accuracy: 0.8883 - val_loss: 0.3354 - val_accuracy: 0.8891\n",
            "Epoch 999/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3364 - accuracy: 0.8883 - val_loss: 0.3353 - val_accuracy: 0.8895\n",
            "Epoch 1000/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3363 - accuracy: 0.8885 - val_loss: 0.3360 - val_accuracy: 0.8863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = network.predict(xtest_std)"
      ],
      "metadata": {
        "id": "RrUIPDfdM5wB",
        "outputId": "bd8b8e1e-94d9-4327-e98e-fdb1fc7d4769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat.shape)"
      ],
      "metadata": {
        "id": "GJWR1M7LN6rv",
        "outputId": "8f8fe9a0-e945-4254-fd21-31ad53ecbf2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytest.shape)"
      ],
      "metadata": {
        "id": "pFXuFm6HPG0g",
        "outputId": "4a9b76b0-68d2-4483-ab9e-1ce15043d7f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat =np.argmax(yhat, axis = -1)\n",
        "ytest = np.argmax(ytest, axis= -1)"
      ],
      "metadata": {
        "id": "V162us36U6Ij"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = accuracy_score(ytest,yhat)\n",
        "cm = confusion_matrix(ytest,yhat)\n",
        "print(f\"El grado de precisión de los datos son los siguientes {100*precision}\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "yXPBisYxORs_",
        "outputId": "bc960abf-acc8-4605-932f-a99705634373",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El grado de precisión de los datos son los siguientes 88.625\n",
            "[[11302   160   427]\n",
            " [  520  3240    32]\n",
            " [ 1134     2  3183]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función logarítimica\n",
        "\n",
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "plt.title(\"Grafica de aprendizaje del modelo de 500 Epochs\")\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"accuracy\"])\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_accuracy\"])\n",
        "\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "JbkIxANdZHMB",
        "outputId": "76a1edb8-9f2b-4923-d8ef-346673666ce5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"loss\"])\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_loss\"])\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "VD_qykwMajLa",
        "outputId": "c29db087-64f9-4c86-ed25-db087b54c709"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT6UlEQVR4nO3deXwU9f3H8dfskc193yEQLrkFBEHEWw5FqVjrSRWp1arQaumheCFaxWqL1tZKPVB/tQjVKlpFFIOIKIdy3zcEgSSEkDvZbHbn98dCNAWRwGYn2byfj8c8mp2dmf3sxwDvfuc7M4ZpmiYiIiIiIcJmdQEiIiIigaRwIyIiIiFF4UZERERCisKNiIiIhBSFGxEREQkpCjciIiISUhRuREREJKQ4rC4g2Hw+H/v27SMmJgbDMKwuR0RERE6AaZqUl5eTmZmJzXb8sZlWF2727dtHdna21WWIiIjISdizZw9t2rQ57jatLtzExMQA/ubExsYG7Lgej4ePP/6YYcOG4XQ6A3ZcOZp6HRzqc3Coz8GhPgdPU/W6rKyM7Ozs+n/Hj6fVhZsjp6JiY2MDHm4iIyOJjY3VH5wmpl4Hh/ocHOpzcKjPwdPUvT6RKSWaUCwiIiIhReFGREREQorCjYiIiIQUhRsREREJKQo3IiIiElIUbkRERCSkKNyIiIhISFG4ERERkZCicCMiIiIhReFGREREQorCjYiIiIQUhRsREREJKQo3AeKu81Hshv2lNVaXIiIi0qop3ATI+n1lTF7h4KfTv7K6FBERkVZN4SZA7Db/I9i9PtPiSkRERFo3hZsAcRwON3UKNyIiIpZSuAmQ+nDjVbgRERGxksJNgDjs/lbqtJSIiIi1FG4C5MjIjcfns7gSERGR1k3hJkA0oVhERKR5ULgJEIddc25ERESaA4WbAPnu1VKmqYAjIiJiFYWbAHHYvm2lzkyJiIhYR+EmQI7MuQHweDWpWERExCoKNwHitH8bbjSpWERExDoKNwHy3ZEbTSoWERGxjsJNgDi+G250rxsRERHLKNwEiGEY2PCP2Oi0lIiIiHUcVhcQMjxVdLF9g8c08CjciIiIWEbhJkCM/DV8GHYPO3zpeL03Wl2OiIhIq6XTUoFidwHgMjx6vpSIiIiFFG4CxHT4w00YHs25ERERsZDCTaAcDjcuPLqJn4iIiIUUbgLlyGkp6jRyIyIiYiHLw81zzz1HTk4O4eHhDBw4kGXLln3vth6Ph0ceeYSOHTsSHh5O7969mTt3bhCrPQ7Ht3Nu6jRyIyIiYhlLw82sWbOYMGECkyZNYsWKFfTu3Zvhw4dTWFh4zO0feOAB/vGPf/DXv/6VDRs2cPvtt3PllVeycuXKIFd+DIdHbgC8HreFhYiIiLRuloabqVOncuuttzJ27Fi6d+/OtGnTiIyMZPr06cfc/p///Cf33XcfI0aMoEOHDtxxxx2MGDGCP//5z0Gu/Bgc34Ybn6fGwkJERERaN8vuc1NbW8vy5cuZOHFi/TqbzcaQIUNYvHjxMfdxu92Eh4c3WBcREcGiRYu+93Pcbjdu97cjKWVlZYD/FJfH4zmVr9CAx2fgPPxzbU1lQI8tDR3prXrctNTn4FCfg0N9Dp6m6nVjjmdZuCkqKsLr9ZKWltZgfVpaGps2bTrmPsOHD2fq1Kmcd955dOzYkdzcXN5++228Xu/3fs6UKVOYPHnyUes//vhjIiMjT+1L/I9LcOLCw+rlyyjO2x7QY8vR5s2bZ3UJrYL6HBzqc3Coz8ET6F5XVVWd8LYt6g7Ff/nLX7j11lvp2rUrhmHQsWNHxo4d+72nsQAmTpzIhAkT6l+XlZWRnZ3NsGHDiI2NDVhtHo8Hz0oHLjz06t6Fs88cELBjS0Mej4d58+YxdOhQnE7nD+8gJ0V9Dg71OTjU5+Bpql4fOfNyIiwLN8nJydjtdgoKChqsLygoID09/Zj7pKSkMHv2bGpqajh48CCZmZnce++9dOjQ4Xs/x+Vy4XK5jlrvdDoD/gtegROoxvB69IcnCJriv6EcTX0ODvU5ONTn4Al0rxtzLMsmFIeFhdGvXz9yc3Pr1/l8PnJzcxk0aNBx9w0PDycrK4u6ujr+85//cMUVVzR1uSfEc3jWjadWE4pFRESsYulpqQkTJjBmzBj69+/PgAEDeOaZZ6isrGTs2LEA3HTTTWRlZTFlyhQAli5dyt69e+nTpw979+7l4Ycfxufz8fvf/97Kr1HPYzjBBJ/CjYiIiGUsDTfXXnstBw4c4KGHHiI/P58+ffowd+7c+knGeXl52GzfDi7V1NTwwAMPsGPHDqKjoxkxYgT//Oc/iY+Pt+gbNFR3uJ1eXQouIiJiGcsnFI8fP57x48cf870FCxY0eH3++eezYcOGIFR1co6M3CjciIiIWMfyxy+EEq/hn3Ojm/iJiIhYR+EmgOoOhxtTj18QERGxjMJNAHkN/1k+s04jNyIiIlZRuAmgI6elzDqN3IiIiFhF4SaAjoQbFG5EREQso3ATQD6bwo2IiIjVFG4CyHd4zo3hVbgRERGxisJNAB0ZuVG4ERERsY7CTQAdCTc2b63FlYiIiLReCjcBZBpHwo1GbkRERKyicBNAps0/58bm08iNiIiIVRRuAsi0+0du7Ao3IiIillG4CaTDIzcKNyIiItZRuAkg8/CEYoepcCMiImIVhZtAOhxu7KbH4kJERERaL4WbADIOz7kJM92YpmlxNSIiIq2Twk0g2cMAiKCWWq/P4mJERERaJ4WbADLt4QBE4MZdp3AjIiJiBYWbADLtLgAiDTc1Hq/F1YiIiLROCjcB5DscbqKowe3RyI2IiIgVFG4CqM7mDzf+01IauREREbGCwk0AeQ+HG6fhxV1TY3E1IiIirZPCTQAdGbkBqK2usLASERGR1kvhJoBMmwMP/kcwuKvLLa5GRESkdVK4CTC34b8c3FOlcCMiImIFhZsAq7X5w41OS4mIiFhD4SbAam0RANTVKNyIiIhYQeEmwDyHR27q3JUWVyIiItI6KdwEWJ0jEgCfRm5EREQsoXATYD67/7SUWauRGxERESso3ASY1+kfuVG4ERERsYbCTYCZh8MNniprCxEREWmlFG4C7XC4MRRuRERELKFwE2BGWBQAtjqFGxERESso3ASY4fKHG4fCjYiIiCUUbgLMfnjkxuGttrgSERGR1knhJsDs4dEAhHk1ciMiImIFhZsAs0fEAuDyKdyIiIhYQeEmwJyR8QBEKtyIiIhYQuEmwMKi4gCIooraOp/F1YiIiLQ+CjcB5jocbmKMaqprvRZXIyIi0voo3ASYMyoegBiqqKyts7YYERGRVkjhJtDCYgAINzxUVGnejYiISLAp3ASaK7r+x6ryEuvqEBERaaUsDzfPPfccOTk5hIeHM3DgQJYtW3bc7Z955hm6dOlCREQE2dnZ/PrXv6ampiZI1Z4Am4MaXABUVxyyuBgREZHWx9JwM2vWLCZMmMCkSZNYsWIFvXv3Zvjw4RQWFh5z+xkzZnDvvfcyadIkNm7cyMsvv8ysWbO47777glz58VXZ/HcpdleUWlyJiIhI62NpuJk6dSq33norY8eOpXv37kybNo3IyEimT59+zO2//PJLBg8ezA033EBOTg7Dhg3j+uuv/8HRnmBz2/3hxlNVYm0hIiIirZDDqg+ura1l+fLlTJw4sX6dzWZjyJAhLF68+Jj7nH322bz++ussW7aMAQMGsGPHDubMmcONN974vZ/jdrtxu931r8vKygDweDx4PJ4AfRvqj+XxeKi1R4EHaisOBfQzxO+7vZamoz4Hh/ocHOpz8DRVrxtzPMvCTVFREV6vl7S0tAbr09LS2LRp0zH3ueGGGygqKuKcc87BNE3q6uq4/fbbj3taasqUKUyePPmo9R9//DGRkZGn9iWOYd68eXSs87d1/+5tzJkzJ+CfIX7z5s2zuoRWQX0ODvU5ONTn4Al0r6sacQWyZeHmZCxYsIDHH3+cv//97wwcOJBt27Zx11138eijj/Lggw8ec5+JEycyYcKE+tdlZWVkZ2czbNgwYmNjA1abx+Nh3rx5DB06lD27psMhSI2L4NIRIwL2GeL33V47nU6rywlZ6nNwqM/BoT4HT1P1+siZlxNhWbhJTk7GbrdTUFDQYH1BQQHp6enH3OfBBx/kxhtv5Oc//zkAvXr1orKykttuu437778fm+3oKUQulwuXy3XUeqfT2SS/4E6nE1z+e93Yaiv0h6gJNdV/Q2lIfQ4O9Tk41OfgCXSvG3MsyyYUh4WF0a9fP3Jzc+vX+Xw+cnNzGTRo0DH3qaqqOirA2O12AEzTbLpiGyvc/wgGo7bc4kJERERaH0tPS02YMIExY8bQv39/BgwYwDPPPENlZSVjx44F4KabbiIrK4spU6YAMHLkSKZOnUrfvn3rT0s9+OCDjBw5sj7kNAdGuH/kxuFRuBEREQk2S8PNtddey4EDB3jooYfIz8+nT58+zJ07t36ScV5eXoORmgceeADDMHjggQfYu3cvKSkpjBw5kscee8yqr3BM9gj/yI2jrtLiSkRERFofyycUjx8/nvHjxx/zvQULFjR47XA4mDRpEpMmTQpCZSfPEekPN2F1FRZXIiIi0vpY/viFUOQ6HG7CfRq5ERERCTaFmybgio4HIMJX1bwmOouIiLQCCjdNIOJwuImmmqpar7XFiIiItDIKN03gyMhNjFFFeU2dtcWIiIi0Mgo3TcBw+e98HE015TV6jomIiEgwKdw0hXB/uHEZdZRX6F43IiIiwaRw0xTCYvBhAFBdXmxxMSIiIq2Lwk1TsNmoMqIAcCvciIiIBJXCTROpsvsfwVBXqXAjIiISTAo3TcTt8M+7qas8ZHElIiIirYvCTROpdfrDja9K4UZERCSYFG6aiM/lfwSDWV1ibSEiIiKtjMJNEzHD/eHGqCmxthAREZFWRuGmiRgRCQDY3KUWVyIiItK6KNw0EXuUP9w4a8ssrkRERKR1UbhpImHRiQC46nSHYhERkWBSuGki4TFJAET4FG5ERESCSeGmiUTG+cNNjFlJda3X4mpERERaD4WbJhJxeOQmzqikpLrW4mpERERaD4WbJmJE+icUJ1DOoUqPxdWIiIi0Hgo3TSXSP3ITbngoKyuxthYREZFWROGmqYRFU4sTgKqSQouLERERaT0UbpqKYVBh99+l2F12wOJiREREWg+FmyZU44wHoK5c4UZERCRYFG6aUE2Yf1Kxr6LI4kpERERaD4WbJlTn8t+lmOqD1hYiIiLSiijcNCEz0h9uHNXFFlciIiLSeijcNCEjKhkAZ+0hiysRERFpPRRumpAj2h9uwj0l1hYiIiLSiijcNKHw+DQAoupKrC1ERESkFVG4aULRCf5wE+sro7bOZ3E1IiIirYPCTROKjk8FINEo42Cl2+JqREREWgeFmyZki04BIJ4KikqrLa5GRESkdVC4aUqHLwW3GyYlh3SXYhERkWBQuGlKdieVRhQAFYfyLS5GRESkdVC4aWJVh58vVa0ng4uIiASFwk0Tc4f5T03VlSnciIiIBIPCTRPzRPgnFRsVOi0lIiISDAo3TcwXnQ6As0ojNyIiIsGgcNPE7LH+cBPu1tVSIiIiwaBw08TC4jMBiPEctLgSERGR1kHhpolFJrUBINFXTJ1Xj2AQERFpago3TSwmOQuAFKOE4spai6sREREJfQo3TcwemwFAslFGYWmFxdWIiIiEPoWbphaZRB12AEoK91pcjIiISOhrFuHmueeeIycnh/DwcAYOHMiyZcu+d9sLLrgAwzCOWi677LIgVtwINhtldv+N/MqLvrG4GBERkdBnebiZNWsWEyZMYNKkSaxYsYLevXszfPhwCguPfV+Yt99+m/3799cv69atw263c/XVVwe58hNX5UoGoKZ4n8WViIiIhD6H1QVMnTqVW2+9lbFjxwIwbdo0PvjgA6ZPn86999571PaJiYkNXs+cOZPIyMjvDTdutxu3213/uqysDACPx4PH4wnU16g/1rGOWRueAlUbqSvdG9DPbK2O12sJHPU5ONTn4FCfg6epet2Y4xmmaZoB/fRGqK2tJTIykrfeeotRo0bVrx8zZgwlJSW8++67P3iMXr16MWjQIF544YVjvv/www8zefLko9bPmDGDyMjIk669MTK2vMqAyvn8034lsadfGZTPFBERCSVVVVXccMMNlJaWEhsbe9xtLR25KSoqwuv1kpaW1mB9WloamzZt+sH9ly1bxrp163j55Ze/d5uJEycyYcKE+tdlZWVkZ2czbNiwH2xOY3g8HubNm8fQoUNxOp0N3tvr+QrWzSfBqGT4iBEB+8zW6ni9lsBRn4NDfQ4O9Tl4mqrXR868nAjLT0udipdffplevXoxYMCA793G5XLhcrmOWu90OpvkF/xYx41KaQdAnKcQh8OBYRgB/9zWqKn+G0pD6nNwqM/BoT4HT6B73ZhjWTqhODk5GbvdTkFBQYP1BQUFpKenH3ffyspKZs6cyS233NKUJQZETHp7ANLMA5S76yyuRkREJLRZGm7CwsLo168fubm59et8Ph+5ubkMGjTouPu++eabuN1ufvrTnzZ1macsPCkHgCyjiPySamuLERERCXGWXwo+YcIEXnzxRV577TU2btzIHXfcQWVlZf3VUzfddBMTJ048ar+XX36ZUaNGkZSUFOySGy/O/wiGKMNN0YGCH9hYRERETkWj59zk5OTws5/9jJtvvpm2bduecgHXXnstBw4c4KGHHiI/P58+ffowd+7c+knGeXl52GwNM9jmzZtZtGgRH3/88Sl/flA4Iyi1xRPnK6GiYBf06mx1RSIiIiGr0SM3d999N2+//TYdOnRg6NChzJw5s8F9ZE7G+PHj2b17N263m6VLlzJw4MD69xYsWMCrr77aYPsuXbpgmiZDhw49pc8NpjKX/xlTNQd3WVuIiIhIiDupcLNq1SqWLVtGt27d+OUvf0lGRgbjx49nxYoVTVFjSHBH+sON79AeiysREREJbSc95+aMM87g2WefZd++fUyaNImXXnqJM888kz59+jB9+nQsvDdgs2TGZwPgKNfzpURERJrSSd/nxuPx8M477/DKK68wb948zjrrLG655Ra++eYb7rvvPj755BNmzJgRyFpbNFdSO9gOEdX7rS5FREQkpDU63KxYsYJXXnmFN954A5vNxk033cTTTz9N165d67e58sorOfPMMwNaaEsXm+a/101SXQEerw+n3fIL1UREREJSo8PNmWeeydChQ3n++ecZNWrUMe8Y2L59e6677rqAFBgqYg/fyC/TOMi+kmraJUVZXJGIiEhoanS42bFjB+3atTvuNlFRUbzyyisnXVQosiX4e5ZqlPDFgRKFGxERkSbS6HMjhYWFLF269Kj1S5cu5euvvw5IUSEpIoFqIwKAQ/u2W1yMiIhI6Gp0uBk3bhx79hx9OfPevXsZN25cQIoKSYZRf6+bqsIdFhcjIiISuhodbjZs2MAZZ5xx1Pq+ffuyYcOGgBQVqmqi2gDgPZRncSUiIiKhq9HhxuVyHfUUb4D9+/fjcJz0leWtw5F73ZTpRn4iIiJNpdHhZtiwYUycOJHS0tL6dSUlJdx3330t6nEIVghL9l8xFVOzz+JKREREQlejh1r+9Kc/cd5559GuXTv69u0LwKpVq0hLS+Of//xnwAsMJbEZHQFI8RZQ6a4jyqWRLhERkUBr9L+uWVlZrFmzhn/961+sXr2aiIgIxo4dy/XXX3/Me97It6JS/SM3bY1CvjlUTZf0GIsrEhERCT0nNXQQFRXFbbfdFuhaQl/i4ZEbo5S1BYUKNyIiIk3gpM+LbNiwgby8PGpraxus/9GPfnTKRYWs8FhK7YnEeYspyVsPvTtaXZGIiEjIOak7FF955ZWsXbsWwzDqn/5tGAYAXq83sBWGmLKoHOLKinEXbLa6FBERkZDU6Kul7rrrLtq3b09hYSGRkZGsX7+ehQsX0r9/fxYsWNAEJYYWX2InABzFWy2uREREJDQ1OtwsXryYRx55hOTkZGw2GzabjXPOOYcpU6bwq1/9qilqDCnhGV0AiKvaXT/qJSIiIoHT6HDj9XqJifFPhE1OTmbfPv89W9q1a8fmzTrV8kMSsnsAkO3bS1FF7Q9sLSIiIo3V6Dk3PXv2ZPXq1bRv356BAwfy5JNPEhYWxgsvvECHDh2aosaQEpZ2GgDtjXxWFpSREpNicUUiIiKhpdHh5oEHHqCyshKARx55hMsvv5xzzz2XpKQkZs2aFfACQ058O+pwEG54yM/bCp0UbkRERAKp0eFm+PDh9T936tSJTZs2UVxcTEJCQv0VU3IcdgeHwtuQUrOLin0bgbOtrkhERCSkNGrOjcfjweFwsG7dugbrExMTFWwawR13+PRdka6YEhERCbRGhRun00nbtm11L5tTZE/1XzEVWbbT4kpERERCT6Ovlrr//vu57777KC4ubop6WoXY7O4AZNXtptJdZ3E1IiIioaXRc27+9re/sW3bNjIzM2nXrh1RUVEN3l+xYkXAigtVUdl9AOhm7GZLfhl92yVaW5CIiEgIaXS4GTVqVBOU0cqkdKUOB3FGFbt3bqZvu0FWVyQiIhIyGh1uJk2a1BR1tC6OMA5GtietaisVu1YCCjciIiKB0ug5NxIY7uSeADgK11pciYiISGhpdLix2WzY7fbvXeTERLbtA0By5Ra8Pj1jSkREJFAafVrqnXfeafDa4/GwcuVKXnvtNSZPnhywwkJdQod+sAi6soudRZV0So22uiQREZGQ0Ohwc8UVVxy17ic/+Qk9evRg1qxZ3HLLLQEpLNTZM3oB0MYoYs6uPDqldre4IhERkdAQsDk3Z511Frm5uYE6XOiLiOdQWAYAh3bq8nkREZFACUi4qa6u5tlnnyUrKysQh2s1KhIOj9bsX2NtISIiIiGk0ael/vcBmaZpUl5eTmRkJK+//npAiwt1zqzeUJBLbOkmTNPU87lEREQCoNHh5umnn27wj7DNZiMlJYWBAweSkJAQ0OJCXVKnfrACOnl3svtgFTnJUT+8k4iIiBxXo8PNzTff3ARltE7OrD4AdDa+4f3te8lJPs3agkREREJAo+fcvPLKK7z55ptHrX/zzTd57bXXAlJUqxGbRZkzBYfh48CWxVZXIyIiEhIaHW6mTJlCcnLyUetTU1N5/PHHA1JUq2EYVKb1B8C5d5nFxYiIiISGRoebvLw82rdvf9T6du3akZeXF5CiWpOYzucA0LZyHaXVHourERERafkaHW5SU1NZs+boS5dXr15NUlJSQIpqTaI7nQ1AP9sWVuUVW1yNiIhIy9focHP99dfzq1/9ik8//RSv14vX62X+/PncddddXHfddU1RY2hL74XbCCfOqGLXJt3MT0RE5FQ1+mqpRx99lF27dnHxxRfjcPh39/l83HTTTZpzczLsTg4l9CK9+CtqdywGLrW6IhERkRat0eEmLCyMWbNm8Yc//IFVq1YRERFBr169aNeuXVPU1yqEtR8ExV+RdGglNR4v4U49XV1ERORknfTjFzp37szVV1/N5ZdffkrB5rnnniMnJ4fw8HAGDhzIsmXHv2qopKSEcePGkZGRgcvl4rTTTmPOnDkn/fnNQUKXcwHoy2aW7z5kcTUiIiItW6PDzVVXXcUf//jHo9Y/+eSTXH311Y061qxZs5gwYQKTJk1ixYoV9O7dm+HDh1NYWHjM7Wtraxk6dCi7du3irbfeYvPmzbz44ost/plWRvYAfBi0txWwcsNmq8sRERFp0RodbhYuXMiIESOOWn/ppZeycOHCRh1r6tSp3HrrrYwdO5bu3bszbdo0IiMjmT59+jG3nz59OsXFxcyePZvBgweTk5PD+eefT+/evRv7NZqXiHjKYjsDUL31M4uLERERadkaPeemoqKCsLCwo9Y7nU7KyspO+Di1tbUsX76ciRMn1q+z2WwMGTKExYuPfbfe9957j0GDBjFu3DjeffddUlJSuOGGG7jnnnuw2489T8XtduN2u+tfH6nR4/Hg8QTuvjJHjnWyx7R1uBBWbSGnZAlFZVXERTgDVluoOdVey4lRn4NDfQ4O9Tl4mqrXjTleo8NNr169mDVrFg899FCD9TNnzqR79+4nfJyioiK8Xi9paWkN1qelpbFp06Zj7rNjxw7mz5/P6NGjmTNnDtu2bePOO+/E4/EwadKkY+4zZcoUJk+efNT6jz/+mMjIyBOu90TNmzfvpPZLKY/jbOBc2xr+/uY8eh99E2j5Hyfba2kc9Tk41OfgUJ+DJ9C9rqqqOuFtGx1uHnzwQX784x+zfft2LrroIgByc3OZMWMGb731VmMP1yg+n4/U1FReeOEF7HY7/fr1Y+/evTz11FPfG24mTpzIhAkT6l+XlZWRnZ3NsGHDiI2NDVhtHo+HefPmMXToUJzOkxh1qbuI2if/QjqHiA33MWLE5QGrLdSccq/lhKjPwaE+B4f6HDxN1evGnB1qdLgZOXIks2fP5vHHH+ett94iIiKC3r17M3/+fBITE0/4OMnJydjtdgoKChqsLygoID09/Zj7ZGRk4HQ6G5yC6tatG/n5+dTW1h7zdJnL5cLlch213ul0Nskv+Ekf1+nkYPoAkvZ/jm3HpzgcozAMI+D1hZKm+m8oDanPwaE+B4f6HDyB7nVjjnVSl4JfdtllfPHFF1RWVrJjxw6uueYafvvb3zZqYm9YWBj9+vUjNze3fp3P5yM3N5dBgwYdc5/Bgwezbds2fD5f/botW7aQkZFxzGDT0sT2vASAPrUrWL/vxBOqiIiIfOuk73OzcOFCxowZQ2ZmJn/+85+56KKLWLJkSaOOMWHCBF588UVee+01Nm7cyB133EFlZSVjx44F4Kabbmow4fiOO+6guLiYu+66iy1btvDBBx/w+OOPM27cuJP9Gs2K87ShAAy0beKzdbstrkZERKRlatRpqfz8fF599VVefvllysrKuOaaa3C73cyePbtRk4mPuPbaazlw4AAPPfQQ+fn59OnTh7lz59ZPMs7Ly8Nm+zZ/ZWdn89FHH/HrX/+a008/naysLO666y7uueeeRn92s5R8GhURWURX76Vk3Ucw/HSrKxIREWlxTjjcjBw5koULF3LZZZfxzDPPcMkll2C325k2bdopFTB+/HjGjx9/zPcWLFhw1LpBgwY1eoSoxTAMbN0ugxUv0PnQ5xSU/ZK02HCrqxIREWlRTvi01Icffsgtt9zC5MmTueyyy773vjJyaiJ7+q+Susi+knnr9lpcjYiISMtzwuFm0aJFlJeX069fPwYOHMjf/vY3ioqKmrK21qnd2bgdMSQbZWz++lOrqxEREWlxTjjcnHXWWbz44ovs37+fX/ziF8ycOZPMzEx8Ph/z5s2jvLy8KetsPexOvJ2GA9CpcC77SqotLkhERKRlafTVUlFRUfzsZz9j0aJFrF27lt/85jc88cQTpKam8qMf/agpamx1IvtdD8BI+2I+WKWrpkRERBrjpC8FB+jSpQtPPvkk33zzDW+88UagapIOF1AdlkSiUcH+5R9YXY2IiEiLckrh5gi73c6oUaN47733AnE4sTug108AOKPkI7YVVlhckIiISMsRkHAjgRfRfzQAQ20reG/JBourERERaTkUbpqr9NOpiO2Ey/BQueo/1Nb5fngfERERUbhptgyDiP43ADC07jPmbyr4gR1EREQEFG6aNXvvazExOMu2kXmLv7a6HBERkRZB4aY5i2tDTdbZALTd/TZ5B6ssLkhERKT5U7hp5iIG/RyAm+1zmfHFJourERERaf4Ubpq77qOoicwkzqiibMVbVLrrrK5IRESkWVO4ae5sNsLO8o/e3Op7izeW6o7FIiIix6Nw0wLYzrqdOnsE7W0FfPnZR9R4vFaXJCIi0mwp3LQEYVEY3a8A4Jrat/n313ssLkhERKT5UrhpIezn/hoTg0vsX/Hx/Pm46zR6IyIiciwKNy1Fald83fyjN9fVzOI/y/daXJCIiEjzpHDTgtgv+D0AI2xL+WD+p3i8eiSDiIjI/1K4aUnSeuA97XJshslPqmbx9opvrK5IRESk2VG4aWHsF/pHb66wfckHH82lqlb3vREREfkuhZuWJqM33h5XYTNM7q79By8t3G51RSIiIs2Kwk0LZB/+B+ockZxh28Y3C/+PwvIaq0sSERFpNhRuWqLYTOznTgDgFmYzde56iwsSERFpPhRuWijjzFuoc8XTxfYNkateYdHWIqtLEhERaRYUblqqyEQcwyYDMMHxJk+99SkVeqimiIiIwk2L1vcmvJn9iDZq+HnVS/zxw01WVyQiImI5hZuWzGbDPvJpTMPGSPsSdi57ny+36/SUiIi0bgo3LV1Gb4wBtwHwhPNFpr45X/e+ERGRVk3hJhRceB++uHa0MYoYX/k3ntTpKRERacUUbkJBeBy2n76Fz+bkAvtqCpb+my+26fSUiIi0Tgo3oSLlNGzn/BqASc7/Y/LMzzhQ7ra4KBERkeBTuAkl507Al9CedOMQj9U+wW9mLcfrM62uSkREJKgUbkKJMwLbDf/G54ziTNsWTtv5On/+eLPVVYmIiASVwk2oSTkN27BHAbjHMZNln33A+2v2WVyUiIhI8CjchKL+P4OeV+E0vPw97FmefHMBa78ptboqERGRoFC4CUWGASOfxUzpRqpRwgvG44yf/ik7iyqtrkxERKTJKdyEKlc0xg0z8UWn0dW2h0c9f+Lml76ksKzG6spERESalMJNKEvIwTb6LUxHJOfZ1/Jw5aOMe+kTymo8VlcmIiLSZBRuQl3G6Rg//gcAF9pX85uSP3Dnq19Q4/FaXJiIiEjTULhpDbr/CK74OwBn2TZy+TdPc9fMldR5fRYXJiIiEngKN61F39Fw3QxMDK5zLCBy41vcPWsVHgUcEREJMQo3rUnXyzAGjQPg6bDniVn/Or+csZLaOgUcEREJHQo3rc3QR6DfzQBMcb5Myqb/45bXvqJck4xFRCRENItw89xzz5GTk0N4eDgDBw5k2bJl37vtq6++imEYDZbw8PAgVtvC2exw2VQ4604AHnW+yhk7/sE1/1hCgS4TFxGREGB5uJk1axYTJkxg0qRJrFixgt69ezN8+HAKCwu/d5/Y2Fj2799fv+zevTuIFYcAmx2GPw7n/R6AXzv/wxUH/sHVf1vAloJyi4sTERE5NZaHm6lTp3LrrbcyduxYunfvzrRp04iMjGT69Onfu49hGKSnp9cvaWlpQaw4RBgGXHQ/nH8PALc7/ssdVdO4+vlFLN5+0OLiRERETp7Dyg+vra1l+fLlTJw4sX6dzWZjyJAhLF68+Hv3q6iooF27dvh8Ps444wwef/xxevToccxt3W43bre7/nVZWRkAHo8Hjydw80yOHCuQxwyKc36HLTwR+0f3cL3jU9K8h5gw/Rf87sfnMPL0DKurO6YW2+sWRn0ODvU5ONTn4GmqXjfmeIZpmmZAP70R9u3bR1ZWFl9++SWDBg2qX//73/+ezz77jKVLlx61z+LFi9m6dSunn346paWl/OlPf2LhwoWsX7+eNm3aHLX9ww8/zOTJk49aP2PGDCIjIwP7hVqwrENL6Lv7Reymh+2+DG6ovZ/eWfFcmu3DZlhdnYiItHZVVVXccMMNlJaWEhsbe9xtW1y4+V8ej4du3bpx/fXX8+ijjx71/rFGbrKzsykqKvrB5jSGx+Nh3rx5DB06FKfTGbDjBlXBOhz//ilG2Tfkmwn82nMntDuHp685naRol9XV1QuJXrcA6nNwqM/BoT4HT1P1uqysjOTk5BMKN5aelkpOTsZut1NQUNBgfUFBAenp6Sd0DKfTSd++fdm2bdsx33e5XLhcR//D7HQ6m+QXvKmOGxRt+sLYD2DGtaQf2MQbYY8xY89FXPH8OJ674Qz65yRaXWEDLbrXLYj6HBzqc3Coz8ET6F435liWTigOCwujX79+5Obm1q/z+Xzk5uY2GMk5Hq/Xy9q1a8nIaJ7zQ1qchBy4ZR6cMQaAGxzzua/6z9z+wse89PkOLBzoExEROSGWXy01YcIEXnzxRV577TU2btzIHXfcQWVlJWPHjgXgpptuajDh+JFHHuHjjz9mx44drFixgp/+9Kfs3r2bn//851Z9hdATHgs/ehaGT8E07Fxh/5J3HA/w1pyPuOP1FXqquIiINGuWnpYCuPbaazlw4AAPPfQQ+fn59OnTh7lz59Zf3p2Xl4fN9m0GO3ToELfeeiv5+fkkJCTQr18/vvzyS7p3727VVwhdg+7EyDgd893xZB/ayTthD/HgprFc+nQJT17dm8Gdkq2uUERE5CiWhxuA8ePHM378+GO+t2DBggavn376aZ5++ukgVCUA5JyDcet8+M/Pidiey5+c/+CDqpX85qUbGXJWXyZe2o0oV7P4NRIREQGawWkpaQEiE2H0m3DRg5g2B5fZl/Gl61cMXP5brn3mfd30T0REmhWFGzkxNjuc91uMn38CWf2wGSYj7Ut4oPIJ7nhxHg/OXkeFu87qKkVERBRupJEy+/qvpup/CwBn2Tbyiet3HFw2i+FPL+TTzd//TDAREZFgULiRxrPZ4fKpcNtnkNKNZKOMv4c9y72Vf+SBV+bws1e/YvuBCqurFBGRVkrhRk5eZh/4xUI4ZwImBiPtS8h1/ZY+2/7GqKc/5tH3N1BarcvGRUQkuBRu5NQ4wmDIJIxfLISccwk3PPzKMZsPnb+DxX/joqfm8/qS3dR5fVZXKiIirYTCjQRGxukw5r9wzT8hKpU2RhEPOv/FM55HeOHdXC7/6yK+3FZkdZUiItIKKNxI4BgGdP8R3LkYLnoA07Bzrn0dn7h+x6iiF/jZSwu57f++ZvfBSqsrFRGREKZwI4EXlQzn/c5/2XjOuYRRx+2O//KR6x6yN7/Cr6b+H1M+3Ei5HuMgIiJNQOFGmk7WGf5TVdfPhJhM2hmFPOh8nXed9+Jb9CwXPPkp0z7brvvjiIhIQCncSNMyDOhyKYz/Ci68HzMmE4D7nTOYVnc/782dyzl/nM+zuVt1ZZWIiASEwo0Ehysazv89xoQNcMFETEcEZ9q2MMd1H095prAidxbnPJHLnz7aTHFlrdXViohIC6ZwI8FlGHDBvRi//Bp6/gQTg6H2Fbwa9hTP+h7nywVzOO+Pn/D4nI0UltdYXa2IiLRACjdijbg28JOXMcYthbPuxLQ5udC+mrddD5Nr3MG2RW9xyR8/4OH31rOvpNrqakVEpAVRuBFrpXSBS6Zg3LkEuo8CIM0oYXrYn3jP/nvWLZ7L+U/NZ+Lba8g7WGVtrSIi0iI4rC5ABIDkTnDNa3BwO3wyCTb+lzZGEW+5HmGNrz2vfH0Jw78exKV92vHzwe2srlZERJoxjdxI85LUEa59He5eB31/CnYXp9t28nTY8yx0/pK41S/xo78u5PkNNj7fVoRpmlZXLCIizYzCjTRP8dlwxXMwYQNc9ADEZJBilDLJ+U+WuMZzU+XL3P/aPIY/s5CZy/Ko8XitrlhERJoJhRtp3g7f7Zi718KlT0F0GslGGTc4PmVx+C95oPh+3njnHc5+Yj5TP96sK6xERERzbqSFsDth4G3Qfyx1Wz6h9P2HSKrcwnn2tZxnX8t6Tzv+/dkFzPi8itjsnnS56KcM6pCEzWZYXbmIiASZwo20LHYnZqchLOrsZkT/HJxf/QNz9Rv0sO1msu01/zb73uTMl5IJi8/k6v5tuKZ/NpnxEdbWLSIiQaNwIy2TYUBaD7jyeYwLJ8LqmfDFs1BbDsAX4Xcxp3IA/55/Ae/mJtPutF5cP6AtF3dNxWHX2VgRkVCmcCMtX3xbOP/3MPB2WPtvWP4aYflrGGX/klH2LwF4afulTNx8Bc7YFK7pn82VfbPokBJtceEiItIUFG4kdITHwpk/9y/7VsLyV/0L8HPHh9zs+Jjc6r78Z8G5DJ/fl+7ZyVzZJ5PLe2eSHO2ytHQREQkchRsJTZl9/cvlz8DK1+Grl3DsX8Vw+9cMt3/NQTOG1fkdWTanK4M+GMngzqmM6pPFsB5pRIbpj4WISEumv8UltBkGnHGjfynYAKtnwJp/k1RRwEX2VVxkX8Wvzf/w520/YeqWAdznzGRY9zSu6JvFuZ2SNT9HRKQFUriR1iOtOwz7A1z8MOz4FDa9D8tfxWV4uM/5BvfxBqt8HfnnmqFMWNUHe3Qyl5+eyai+WfRuE4dh6LJyEZGWQOFGWh+7AzoP9S9DH/VPQl7zb9izlD627fQJ204NYbxTM5gvl/Tg6i8HkJUUy6i+WYzqk0VOcpTV30BERI5D4UZat+9OQs5fC+v+A1s+JrxwPdc7PuV6PqXKdPFu6dnMmT+Q5z7pTo/sZEb1yWTE6RmkxoRb/Q1EROR/KNyIHJHey79cPAl2fwHr34EN7xFZWVgfdIrMWP67fxDL93bmsfcH0DcnlRE907mkZwbpcQo6IiLNgcKNyP8yDMg5x78Mfxx2LoTVb8CuRSRXFDDW8RFj+Yg8Xwr/3TOIj3b34uH/dqdfu0Qu7ZnOpb0yyNIdkUVELKNwI3I8Dte383O8HtjyEexYABtm07byAONs7zGO9ygxo8jd15cl33Tn5Q96kZrdkUt6pDOsRxoddbNAEZGgUrgROVF2J3S73L8MnQzrZ8P2+bDpfeLrKrnKvoir7IvACZ/m9+atvefz1NwBtE+J4eJuaQztnsYZbROw62GeIiJNSuFG5GSERUHf0f7FXQ4b/wt7l8POz6FoMxfaV3OhfTUlZhRbS7NY92V7blt4JfboFIZ2T+OSnukM6pBEmEP30RERCTSFG5FT5YqBPjf4F9OEPcv899BZ8RrxNaWcaWzhTNsWRjtyWeLuxoLlfZj8VW8OhGVz7mkpXHBaKud3SSEtVhOSRUQCQeFGJJAMA9oO9C8XT4K8xf6gs2YWYdWHOM++lvPsa3mIf5LnS2H1po7MWn8h9/m60TkjkQu6pHDBaSmc0S4Bp+6OLCJyUhRuRJqK3QHtz/UvlzwBRVtg6zzYNg9z95e05QBtOcBI+xLKzQjWFHXgw8IBjFswALcricGdkrmgSwrnd0khI05XX4mInCiFG5FgMAxI6eJfzh6P4a7w30tn3duw9SNiqg8x2L6ewfb1THa+xte+01i5uTP/3tCP+82OdE6P5/zTUjjvtBT6tUsg3Gm3+huJiDRbCjciVnBFw2nD/YvXA/vXwO5FsH429n0rGGjbxEDbJm53/Jf9ZiL7ipPYvTiNXy+8njJnEgPaJ3Fup2TOPS2ZLmkxeu6ViMh3KNyIWM3uhDb9/Mvgu6AkDza8Bxvfg4INZNQWk2EU04+t/Ni+iAIznuU7T2P+9r588GEW30R255zOyZzTOYVzOydrYrKItHoKNyLNTXxbOHu8f/FU+09frZ4FuxZB+T7SjBJG2Jcxwr4MgOWezry39myeX92T35qZdEyJ5uyOyZzdMYlBHZOIjwyz+AuJiASXwo1Ic+aMgE5D/AtARaH/cRD5a2DVDKg8QD/bVvrZtgKw30xkTUkHyr6OZMays5lodiArI5PBnZIZ1CGJ/jkJxIQ7LfxCIiJNT+FGpCWJToVeP/EvQx+Boq2w6QPY8SnsXkyGt5gMezEAV7MQgJ1FabxcMIKHP+/FHtLomRXPWR2SGNg+kf45icRFKOyISGhRuBFpyZI7wzl3+xdPNexZ6g87W+ZC1SGoLae9rYA/2F4BYK+ZRElhNIvye/LnzwezkXZ0SYulf04CZ+Yk0q9dAlnxEZqgLCItmsKNSKhwRkCHC/zLiKfA54W8Jf6g883X8M1XZPkOkmUcpIdtN79wfMA+M5GS4hhqi+28/tVQ7vKeR0ZcBP1zEjkjO5aqSvD6TDS2IyItSbMIN8899xxPPfUU+fn59O7dm7/+9a8MGDDgB/ebOXMm119/PVdccQWzZ89u+kJFWhKbHXIG+xcAdwXs/hK2fQL7VkL+GjLrisk0/Kex+tj+wQOO1/m8qheb1rVlydpMNplteX7zp5zRLoEz2yXQLyeBvtkJRITpPjsi0nxZHm5mzZrFhAkTmDZtGgMHDuSZZ55h+PDhbN68mdTU1O/db9euXfz2t7/l3HPPDWK1Ii2YKxpOG+ZfwB929q/yP9n88z8DBvFGJSPtSxhpX1K/21JfVxbv6M6Gbdm87OtOhS2WHllxnNkugf45CfRrl0hKjMuSryQiciyWh5upU6dy6623MnbsWACmTZvGBx98wPTp07n33nuPuY/X62X06NFMnjyZzz//nJKSku89vtvtxu12178uKysDwOPx4PF4AvY9jhwrkMeUY1OvA8TmgqyB/uW8ieCpwti/GmPPUoyDWzALN2EUrK+/oSCABwf7fQks3H86G/e1419fpnK3rwupifH0bhNXv3TLiMWlJ56fEP0+B4f6HDxN1evGHM8wTdMM6Kc3Qm1tLZGRkbz11luMGjWqfv2YMWMoKSnh3XffPeZ+kyZNYs2aNbzzzjvcfPPNlJSUfO9pqYcffpjJkycftX7GjBlERkYG4muIhKyI2iLSS1eRWLGF+OqdRLsLjtrGbTpZ5OvJLjOdJb5u7DAz2EUmbaKgXbRJu2iTnBiTJJf/KRQiIiejqqqKG264gdLSUmJjY4+7raUjN0VFRXi9XtLS0hqsT0tLY9OmTcfcZ9GiRbz88susWrXqhD5j4sSJTJgwof51WVkZ2dnZDBs27Aeb0xgej4d58+YxdOhQnE5Nv2xK6nVwHOlzpxv+WN9nT+kejIL1GLs+x9i3AmPfclx4uNi+EoBb+BCAb8xkvqzpwZKqbnxd0I7ZZgqOyDhOPzyy06eN/2ddhq7f52BRn4OnqXp95MzLibD8tFRjlJeXc+ONN/Liiy+SnJx8Qvu4XC5crqPnAzidzib5BW+q48rR1OvgaNDn5A7+pcdI/2uf139Dwe3z/ZOUC9ZjHtpFG4q4xvEZ1/AZALWmg2WeLhTvjKViRwRTvRexyWxL+6QoerVLpm92PH2yE+iaEYPT3jpPZ+n3OTjU5+AJdK8bcyxLw01ycjJ2u52CgoZD3QUFBaSnpx+1/fbt29m1axcjR46sX+fz+QBwOBxs3ryZjh07Nm3RIvItmx0y+/qXwwx3OexZ5r+x4J6vIH8NYZ4qzrGvr9/mBsd8/w+V8MXaHvx39SCmeXtxwJFG1/QYemXF0btNPKdnx9EpJRpHKw08InJyLA03YWFh9OvXj9zc3Po5Nz6fj9zcXMaPH3/U9l27dmXt2rUN1j3wwAOUl5fzl7/8hezs7GCULSLH44qBThf7lyMKNsA3y2DXF7B/NZTvB7d/iHmwfT2D7evBCRVmOIsLurM/P4mdXycxzdefYnsy7dOT6dkmgZ5ZsfTMiqNzagxhmrAsIt/D8tNSEyZMYMyYMfTv358BAwbwzDPPUFlZWX/11E033URWVhZTpkwhPDycnj17Ntg/Pj4e4Kj1ItKMpHX3L/1u9r/2+WDfCti7HIq2wK5FmAc2E23UMNS+on63e5gJwMbCbD7N78uHy7rwjK8tB+3JdM2IpUdmHD2zYumVFcdpaTGEO3X/HRFpBuHm2muv5cCBAzz00EPk5+fTp08f5s6dWz/JOC8vD5tN/w9NJKTYbNCmv385zKithMKNsHcFVBbC9vmY+1ZimD662fbQzbaHOw9vW2xGU1iYQH5BIp8v78lufLzlu4D45HS6psfQIzOO7hmxdM+MJTXGpcdJiLQylocbgPHjxx/zNBTAggULjrvvq6++GviCRCT4wqIaBp6LHsCoLoEDm/yPkchfAwUbMIu2kEgFiUYFXdnDBfbVANxjzmRjaTvWHOrA9g2ZvGRms8nXFjMqhW4ZMXRL94edbhmxdEyJ1mktkRDWLMKNiMgxRcRD27P8y2GGpwYKN/hHefavguKdmDs/w+6tpaexi562XQ0OUVgXz8bdbdm4qy2f+dryD7MtebYsclIT6JYRQ/eMWLqkx3BaWoxGeURChMKNiLQsznDIOsO/9B0NgGGaULbXP4dn/2r/PJ6CDZjFO0g1Ski1l3A+a+oP4TYd7DiYSVFRLF+u7smnOPmQMBY4z6VNhv/UVpf0GLqm+4NPtEt/VYq0JPoTKyItn2FAXBv/0v2Kb1e7K/wjPAXr/Ev+OsyC9bhqy+lm5AFwrn3ddw70Ml/tPY3le7qww4xliZnAQWIpje1CenoWndKi6ZQSTee0GDqnRhOl0CPSLOlPpoiELlc0ZJ/pXw4zTBNKdvsvTy/a4h/tObDJ/zNwpm0LZ9q2NDiMu9pB2c5Ilm/vwte+01hNGCVEsz7uQjqnx9Ex1R96OqZG0zEliphw3SROxEoKNyLSuhgGJOT4F0Z8u7620n+l1oFN/qV0LxSsh9I8XEYdKZRxif0rLrF/Vb9LeeVL7N+WyNqtHUimlEjjIH/1nsdHkZfTJi2ZjinRdEqNrv9fzekRCQ6FGxER8F+t1f5c//JddbWQ96V/pKckDw7thC1zAYgxqokx9nIae+s3v8/2Bvd53qB4TzT5eUkkGOW85x3EH7zncDAsk4yU5MMjPP7A0y4hHK8vmF9UJPQp3IiIHI8jDDpc4F++q6oYinfC/pVwYAvkr/WHoMMSDf/l6gC/cHzALxwfAFB4IJ7Cwni2mZl87D2drWYWm2jL37Z/Qee06AajPR10ikvkpCjciIicjMhE/9KmX8P13jqoKIBDu2DPUlj2AsRkYBbvwKgp8V+9ZZTQk12MsvvDkNc02FeWTF5pKns2p2AaXmb6TmOZryvu6GzapMTTISmcnJRY2idH0z45kuzESFwO3ZFZ5FgUbkREAsnugLgs/5IzGM6dAByeyFx10D9xef9q/5K/FrN4B3ZPFdnGAbI5UH+Yq+yfA+CudcJeE9e+Ojb5spnpvZCXzbaUEo07riPZKfG0T45qsGTGR2C3aW6PtF4KNyIiwWAYEJXsX9qdXb+6rtZN7nszGXJGRxxle/wjPts+AU8VZskeXLXl9dt2te3hYdv/fXvMaji4O4a1Ozuw30xkNXH825fNaqMr4YltaJ8STU5yFBlx4bRJiKR9chRtEyN1d2YJeQo3IiJWMmy4nfGY2QPBeY5/3YUT/W/5fFCyC0r2wK5FULYPqoowC9ZBeT6Gr44ko7z+ERTfVV4WQU1ZGHu2pbDDzCTL2I1JHXd6r2NX1BkkJiaSnRhFdmIE2Qn+01zZiRGkxYRj06iPtHAKNyIizZXNBokd/EuH8+tXG+B/snr1If9l6/tXQfl+KN2LWbgBirYSQzUxVJNilHIG2+r3fcn2Z6iFA/tjYb/Bl74e7DTTWWnGUWTGUWaLozSuK4mJSf7AkxDZIAAlRDp1Obs0ewo3IiItkc0GUUkQNdg/t+cwA/yXrxfvgNJvIH811LkhbzHsXIjpiMCoqybFKAPgCvuXRx+7EtaXt2P7rky+MVNYbCbzpplCnplKqTOV1IQ42hxj1Cc7IVJ3bZZmQb+FIiKhxhEGqV39S+chDd4yfF6oPAAHt8PBbf4AVHkAKg9gVhTiO7Qbe2UBPWy76cHuYx6+ssTFukPt2b41gyLi2IaXL8wEPDhY6LqAxMQk2iRE0ua74SchgqyECF3hJUGhcCMi0prY7BCT7l++M+ID/lEfu2n6b1S4fw2U7vHP9ynJg5I8/+XsddVEGW4GGpsYaNt01OE93tcoPxDBjsJM3KaT9WYO88xUqkwXB4mjNKo9YYnZtEmMps3h0OMf+YkkPTZcV3lJQCjciIjItwzj23k+//uWzweVhf5HUxzc6r+JYclu/+jPod1QmofT8JJIBYmG//lcg1nf8CAeoAC+yU+m1Ixiq5nF5742FJDALrIwolOJjE8hOSGRzMQoMuIiSI9zkRoTTpuECOIiNOdHfpjCjYiInBib7dtRn/+9eSGAaULZXv/9fAo2HA4+e6BsP2ZFAWZ5AbYq/7182hhFtDGK/Ke+vnumyg0UwKH8aMrNCDaZbdloZrHATGCPmYo3LIb0KDuHks8gNT6GzPgI0mPDyYgPJzMugvS4cMKdOvXV2inciIhIYBgGxLXxLxm9G751eMFd7h/xqSz0P6z0m6+gvACzbC++A1uwVR/CMOtIMCpIMCpoywGGsbzh51RCTYWT3WYaBWYC+WYiX5FIgZlIvplAVXgarphkouOTSUxIJCM+nNToMHaXQl5xFW2SojX3J8Qp3IiISPC4YiDj9G9fd78CODzfB8BTA95a/xPZj5zyKtkN5fn4SvfirTqEo7KAcDx0Mb6hC98c/Rk+oBS8JQYFu/zhByDddPHO5v+y3cykKiIDX2wWkfHppMVHkhYbTmqMy/+/sS7SYsKJ12XvLZbCjYiINB/OcP/SbpB/+Q7b4YU6t3/0p3yf/8aGZfuhfB9m2T68JXuhfD/26oPYDZNMisk0iuuPcY798BwgL3AI3MUO9ptJVOOimjDW+3JYaKZxwIyjxhZFZWQbEuJiCUvuQFqcPwClxoaTFuufB5Qa69IoUDOkcCMiIi2Lw/Xtpe7fYfCdf9RM039jw8KNUFNCXVUpO7/+hI4JBt7yAij9BkdVAS7qyDEK6o9xhm1bg2NSCxyAykIX+WYi+81EiohjnRlFgZnAXjOZLFcVKS4fy5NGEpmQdnj0J5y0wyNB6XHhJEaF4bTrsRfBonAjIiKhxzAgNtO/AKbHw4b9SeSMGIHT6fRv4/X4A1DJHv/E5/L94K6Aos34qsuoqzqE/dDhy99x09HYT0f2H/1ZJlADY/f+H4e+iabUjCLcqKXIjGOL2YaNpoNyIqkLi2VF7EXER7qwxWQQHxdLSozLv0S7SI11kRIdTmyEQ6fDTpHCjYiItE52J8S39S//wwaEHXlR5/bP/Snb67/nT+le/4NNKwqoO7gTs2wfzrI9GJj1E6EB0o1D9GTXtwf1ASUzoQSqzbD6CdF12CkiHJdRxAe+Xmw1cqiNSIHoNIy4bFJjnCTFRpEaE05KjIvUw4EoOdqlh6B+D4UbERGR43G4IKmjf/kOA3AeeeHz+S+BrzoI1cX++/6U74PaKsyC9fiKtvrnB5le7F43EUYtXY09dGVPg2P2s231/1ALFIPnoB2n4SXfTKDQjGejrx0bieeAGU+FGUGcC6oiMzGiU6lL6HQ4BLlIjAojKdo/IpQcE0ZSlKtV3SBR4UZERORU2WwQneJfANqdXf9W/ZVgR3jr/DdBLNsH5fn+q8PK82HVDHxRKdR5ajHK92KvLcfp8wD+UaB04xCn23Y2/FwTqPQvnnw7VbgoMBOINNxs8mXztZlMGZF4sZPjLKE2LJ7V8UOoic4mKiae5JiI+lNjydH+UJQc7SIirGVPkla4ERERCSa7A1K7+ZfvunBiw9Nh3jr/XCDT57867OBW/32CKgr9p8TKCvDWlEFNOXZ3Cc66CuKoIs6oAqCNvajh8U3ADVcXvA0F/lNjhWY8RcRRh51tZjJ5vjSKiaHSHkedKxEjKhFXZBy22HTiYqJJC68jJi6R5MMhKCnGRVJ0WLO7YkzhRkREpDmyOyCxvf/npI4NHoJ65JRYg9Ni5fugphQqCv2n0vaugPL9+KqKcfts+A5swag8QHhFHjbTS4RRSzujkHYUAjAQGg4xeYCSw8u+b1fvMxOJoZoDZhyzfQPwYqPQkYE7PA1XZBTDPJ+y1XYGMKIJmnJiFG5ERERaOpvt27tDp/Xwrzt8aswGRHx3W5/v8Kmw/VBR4A9Dh3ZBTQlm5UG8lQepqyjCrDyIvfoAYe5DDT7qyH2DYoxq7rS99+0bNYcXoBtfguc2cMY1xbf9QQo3IiIirYnNBrZw/6jQkZGhw47cK6hBOPDWgbusfkI0B7f7w1D1Icy6GjzlB6kr2w+VBzHcZdQaTuZG/oRrnZHB+07/Q+FGREREvp/dAZGJ/gUaPDfMwD9HKOw7mzs8HmLmzAlmhUfRBfIiIiISUhRuREREJKQo3IiIiEhIUbgRERGRkKJwIyIiIiFF4UZERERCisKNiIiIhBSFGxEREQkpCjciIiISUhRuREREJKQo3IiIiEhIUbgRERGRkKJwIyIiIiFF4UZERERCisPqAoLNNE0AysrKAnpcj8dDVVUVZWVlOJ3OgB5bGlKvg0N9Dg71OTjU5+Bpql4f+Xf7yL/jx9Pqwk15eTkA2dnZFlciIiIijVVeXk5cXNxxtzHME4lAIcTn87Fv3z5iYmIwDCNgxy0rKyM7O5s9e/YQGxsbsOPK0dTr4FCfg0N9Dg71OXiaqtemaVJeXk5mZiY22/Fn1bS6kRubzUabNm2a7PixsbH6gxMk6nVwqM/BoT4Hh/ocPE3R6x8asTlCE4pFREQkpCjciIiISEhRuAkQl8vFpEmTcLlcVpcS8tTr4FCfg0N9Dg71OXiaQ69b3YRiERERCW0auREREZGQonAjIiIiIUXhRkREREKKwo2IiIiEFIWbAHnuuefIyckhPDycgQMHsmzZMqtLalGmTJnCmWeeSUxMDKmpqYwaNYrNmzc32KampoZx48aRlJREdHQ0V111FQUFBQ22ycvL47LLLiMyMpLU1FR+97vfUVdXF8yv0mI88cQTGIbB3XffXb9OPQ6cvXv38tOf/pSkpCQiIiLo1asXX3/9df37pmny0EMPkZGRQUREBEOGDGHr1q0NjlFcXMzo0aOJjY0lPj6eW265hYqKimB/lWbL6/Xy4IMP0r59eyIiIujYsSOPPvpog2cPqc8nZ+HChYwcOZLMzEwMw2D27NkN3g9UX9esWcO5555LeHg42dnZPPnkk4H5AqacspkzZ5phYWHm9OnTzfXr15u33nqrGR8fbxYUFFhdWosxfPhw85VXXjHXrVtnrlq1yhwxYoTZtm1bs6Kion6b22+/3czOzjZzc3PNr7/+2jzrrLPMs88+u/79uro6s2fPnuaQIUPMlStXmnPmzDGTk5PNiRMnWvGVmrVly5aZOTk55umnn27edddd9evV48AoLi4227VrZ958883m0qVLzR07dpgfffSRuW3btvptnnjiCTMuLs6cPXu2uXr1avNHP/qR2b59e7O6urp+m0suucTs3bu3uWTJEvPzzz83O3XqZF5//fVWfKVm6bHHHjOTkpLM999/39y5c6f55ptvmtHR0eZf/vKX+m3U55MzZ84c8/777zfffvttEzDfeeedBu8Hoq+lpaVmWlqaOXr0aHPdunXmG2+8YUZERJj/+Mc/Trl+hZsAGDBggDlu3Lj6116v18zMzDSnTJliYVUtW2FhoQmYn332mWmapllSUmI6nU7zzTffrN9m48aNJmAuXrzYNE3/H0abzWbm5+fXb/P888+bsbGxptvtDu4XaMbKy8vNzp07m/PmzTPPP//8+nCjHgfOPffcY55zzjnf+77P5zPT09PNp556qn5dSUmJ6XK5zDfeeMM0TdPcsGGDCZhfffVV/TYffvihaRiGuXfv3qYrvgW57LLLzJ/97GcN1v34xz82R48ebZqm+hwo/xtuAtXXv//972ZCQkKDvzvuueces0uXLqdcs05LnaLa2lqWL1/OkCFD6tfZbDaGDBnC4sWLLaysZSstLQUgMTERgOXLl+PxeBr0uWvXrrRt27a+z4sXL6ZXr16kpaXVbzN8+HDKyspYv359EKtv3saNG8dll13WoJegHgfSe++9R//+/bn66qtJTU2lb9++vPjii/Xv79y5k/z8/Aa9jouLY+DAgQ16HR8fT//+/eu3GTJkCDabjaVLlwbvyzRjZ599Nrm5uWzZsgWA1atXs2jRIi699FJAfW4qgerr4sWLOe+88wgLC6vfZvjw4WzevJlDhw6dUo2t7sGZgVZUVITX623wlz1AWloamzZtsqiqls3n83H33XczePBgevbsCUB+fj5hYWHEx8c32DYtLY38/Pz6bY713+HIewIzZ85kxYoVfPXVV0e9px4Hzo4dO3j++eeZMGEC9913H1999RW/+tWvCAsLY8yYMfW9OlYvv9vr1NTUBu87HA4SExPV68PuvfdeysrK6Nq1K3a7Ha/Xy2OPPcbo0aMB1OcmEqi+5ufn0759+6OOceS9hISEk65R4UaanXHjxrFu3ToWLVpkdSkhZc+ePdx1113MmzeP8PBwq8sJaT6fj/79+/P4448D0LdvX9atW8e0adMYM2aMxdWFjn//+9/861//YsaMGfTo0YNVq1Zx9913k5mZqT63cjotdYqSk5Ox2+1HXVFSUFBAenq6RVW1XOPHj+f999/n008/pU2bNvXr09PTqa2tpaSkpMH23+1zenr6Mf87HHmvtVu+fDmFhYWcccYZOBwOHA4Hn332Gc8++ywOh4O0tDT1OEAyMjLo3r17g3XdunUjLy8P+LZXx/t7Iz09ncLCwgbv19XVUVxcrF4f9rvf/Y57772X6667jl69enHjjTfy61//milTpgDqc1MJVF+b8u8ThZtTFBYWRr9+/cjNza1f5/P5yM3NZdCgQRZW1rKYpsn48eN55513mD9//lFDlf369cPpdDbo8+bNm8nLy6vv86BBg1i7dm2DP1Dz5s0jNjb2qH9oWqOLL76YtWvXsmrVqvqlf//+jB49uv5n9TgwBg8efNStDLZs2UK7du0AaN++Penp6Q16XVZWxtKlSxv0uqSkhOXLl9dvM3/+fHw+HwMHDgzCt2j+qqqqsNka/jNmt9vx+XyA+txUAtXXQYMGsXDhQjweT/028+bNo0uXLqd0SgrQpeCBMHPmTNPlcpmvvvqquWHDBvO2224z4+PjG1xRIsd3xx13mHFxceaCBQvM/fv31y9VVVX129x+++1m27Ztzfnz55tff/21OWjQIHPQoEH17x+5THnYsGHmqlWrzLlz55opKSm6TPk4vnu1lGmqx4GybNky0+FwmI899pi5detW81//+pcZGRlpvv766/XbPPHEE2Z8fLz57rvvmmvWrDGvuOKKY15K27dvX3Pp0qXmokWLzM6dO7f6S5S/a8yYMWZWVlb9peBvv/22mZycbP7+97+v30Z9Pjnl5eXmypUrzZUrV5qAOXXqVHPlypXm7t27TdMMTF9LSkrMtLQ088YbbzTXrVtnzpw504yMjNSl4M3JX//6V7Nt27ZmWFiYOWDAAHPJkiVWl9SiAMdcXnnllfptqqurzTvvvNNMSEgwIyMjzSuvvNLcv39/g+Ps2rXLvPTSS82IiAgzOTnZ/M1vfmN6PJ4gf5uW43/DjXocOP/973/Nnj17mi6Xy+zatav5wgsvNHjf5/OZDz74oJmWlma6XC7z4osvNjdv3txgm4MHD5rXX3+9GR0dbcbGxppjx441y8vLg/k1mrWysjLzrrvuMtu2bWuGh4ebHTp0MO+///4Glxarzyfn008/PebfyWPGjDFNM3B9Xb16tXnOOeeYLpfLzMrKMp944omA1G+Y5ndu5SgiIiLSwmnOjYiIiIQUhRsREREJKQo3IiIiElIUbkRERCSkKNyIiIhISFG4ERERkZCicCMiIiIhReFGREREQorCjYi0SoZhMHv2bKvLEJEmoHAjIkF38803YxjGUcsll1xidWkiEgIcVhcgIq3TJZdcwiuvvNJgncvlsqgaEQklGrkREUu4XC7S09MbLAkJCYD/lNHzzz/PpZdeSkREBB06dOCtt95qsP/atWu56KKLiIiIICkpidtuu42KiooG20yfPp0ePXrgcrnIyMhg/PjxDd4vKiriyiuvJDIyks6dO/Pee+/Vv3fo0CFGjx5NSkoKERERdO7c+agwJiLNk8KNiDRLDz74IFdddRWrV69m9OjRXHfddWzcuBGAyspKhg8fTkJCAl999RVvvvkmn3zySYPw8vzzzzNu3Dhuu+021q5dy3vvvUenTp0afMbkyZO55pprWLNmDSNGjGD06NEUFxfXf/6GDRv48MMP2bhxI88//zzJycnBa4CInLyAPFtcRKQRxowZY9rtdjMqKqrB8thjj5mmaZqAefvttzfYZ+DAgeYdd9xhmqZpvvDCC2ZCQoJZUVFR//4HH3xg2mw2Mz8/3zRN08zMzDTvv//+760BMB944IH61xUVFSZgfvjhh6ZpmubIkSPNsWPHBuYLi0hQac6NiFjiwgsv5Pnnn2+wLjExsf7nQYMGNXhv0KBBrFq1CoCNGzfSu3dvoqKi6t8fPHgwPp+PzZs3YxgG+/bt4+KLLz5uDaeffnr9z1FRUcTGxlJYWAjAHXfcwVVXXcWKFSsYNmwYo0aN4uyzzz6p7yoiwaVwIyKWiIqKOuo0UaBERESc0HZOp7PBa8Mw8Pl8AFx66aXs3r2bOXPmMG/ePC6++GLGjRvHn/70p4DXKyKBpTk3ItIsLVmy5KjX3bp1A6Bbt26sXr2aysrK+ve/+OILbDYbXbp0ISYmhpycHHJzc0+phpSUFMaMGcPrr7/OM888wwsvvHBKxxOR4NDIjYhYwu12k5+f32Cdw+Gon7T75ptv0r9/f8455xz+9a9/sWzZMl5++WUARo8ezaRJkxgzZgwPP/wwBw4c4Je//CU33ngjaWlpADz88MPcfvvtpKamcumll1JeXs4XX3zBL3/5yxOq76GHHqJfv3706NEDt9vN+++/Xx+uRKR5U7gREUvMnTuXjIyMBuu6dOnCpk2bAP+VTDNnzuTOO+8kIyODN954g+7duwMQGRnJRx99xF133cWZZ55JZGQkV111FVOnTq0/1pgxY6ipqeHpp5/mt7/9LcnJyfzkJz854frCwsKYOHEiu3btIiIignPPPZeZM2cG4JuLSFMzTNM0rS5CROS7DMPgnXfeYdSoUVaXIiItkObciIiISEhRuBEREZGQojk3ItLs6Gy5iJwKjdyIiIhISFG4ERERkZCicCMiIiIhReFGREREQorCjYiIiIQUhRsREREJKQo3IiIiElIUbkRERCSk/D+Ns/K6ESyuOQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir un mapa de calor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "sns.heatmap(xtrain_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Entrenamiento\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n"
      ],
      "metadata": {
        "id": "lE0LmmEE1LMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un mapa de calor para los datos de prueba\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "sns.heatmap(xtest_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Prueba\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Py3_zIxs4elw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}