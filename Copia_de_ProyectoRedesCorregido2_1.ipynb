{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObA1XaJqQNnyogkAC2z49x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosQuark/Machine-Learning-Astrophysics/blob/main/Copia_de_ProyectoRedesCorregido2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# PROYECTO DE MACHINE LEARNING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvURBlWmT07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZV03xjlnj-NB"
      },
      "outputs": [],
      "source": [
        "#librerias Comunes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#liberias de PCA\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import eig\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder #Change the class to str for another type the int.\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#librerias de sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#librerias de Keras y Redes Neuronales\n",
        "\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = pd.read_csv(\"star_classification.csv\")\n",
        "data_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "OQ6pTIb2mimr",
        "outputId": "3e10e0a8-8068-4d46-90e8-2ad4d07cc5cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237660e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237660e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237660e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237660e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543780e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176010e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030110e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891860e+18   \n",
              "\n",
              "   redshift  plate    MJD  fiber_ID   class  \n",
              "0  0.634794   5812  56354       171  GALAXY  \n",
              "1  0.779136  10445  58158       427  GALAXY  \n",
              "2  0.644195   4576  55592       299  GALAXY  \n",
              "3  0.932346   9149  58039       775  GALAXY  \n",
              "4  0.116123   6121  56187       842  GALAXY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87b7df07-cb77-443b-aaab-cb63a5948fbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543780e+18</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176010e+19</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030110e+19</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891860e+18</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b7df07-cb77-443b-aaab-cb63a5948fbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87b7df07-cb77-443b-aaab-cb63a5948fbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87b7df07-cb77-443b-aaab-cb63a5948fbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9c19507-52cd-4455-a9af-e69a1a3016bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9c19507-52cd-4455-a9af-e69a1a3016bf')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9c19507-52cd-4455-a9af-e69a1a3016bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nlql6Qz1Znk",
        "outputId": "25c35a38-bed9-4508-8973-246463072e15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 18 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   obj_ID       100000 non-null  float64\n",
            " 1   alpha        100000 non-null  float64\n",
            " 2   delta        100000 non-null  float64\n",
            " 3   u            100000 non-null  float64\n",
            " 4   g            100000 non-null  float64\n",
            " 5   r            100000 non-null  float64\n",
            " 6   i            100000 non-null  float64\n",
            " 7   z            100000 non-null  float64\n",
            " 8   run_ID       100000 non-null  int64  \n",
            " 9   rerun_ID     100000 non-null  int64  \n",
            " 10  cam_col      100000 non-null  int64  \n",
            " 11  field_ID     100000 non-null  int64  \n",
            " 12  spec_obj_ID  100000 non-null  float64\n",
            " 13  redshift     100000 non-null  float64\n",
            " 14  plate        100000 non-null  int64  \n",
            " 15  MJD          100000 non-null  int64  \n",
            " 16  fiber_ID     100000 non-null  int64  \n",
            " 17  class        100000 non-null  object \n",
            "dtypes: float64(10), int64(7), object(1)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enconder = LabelEncoder()\n",
        "\n",
        "data_set[\"class\"] = enconder.fit_transform(data_set[\"class\"])"
      ],
      "metadata": {
        "id": "lVhT4P72weJt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar los datos\n",
        "\n",
        "Y = np.array(data_set[\"class\"])\n",
        "\n",
        "df_new = data_set.drop([\"class\"], axis =1)\n",
        "\n",
        "X = np.array(df_new)\n"
      ],
      "metadata": {
        "id": "5VSRDHJhn75L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components= 17)\n",
        "PCA_objeto.fit(X)"
      ],
      "metadata": {
        "id": "Akeqp3SySWYi",
        "outputId": "7662b86d-f611-4128-cf20-fb6d2592910e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PCA_objeto.explained_variance_)"
      ],
      "metadata": {
        "id": "3jmLTxmoSp0Q",
        "outputId": "8b2452e6-a188-4051-9520-7992f8761636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.10491489e+37 5.34345995e+28 3.63783147e+06 1.90094686e+05\n",
            " 6.89069641e+04 2.22875371e+04 8.93542373e+03 3.01724592e+03\n",
            " 3.23491013e+02 6.79740439e+00 3.42870277e+00 2.46778931e+00\n",
            " 1.93784010e+00 4.09255753e-01 3.26988977e-01 4.66492584e-02\n",
            " 3.72772496e-34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components = 17)\n",
        "Z = PCA_objeto.fit_transform(X)"
      ],
      "metadata": {
        "id": "0dytpcETSr5A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento de los datos\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Z,Y, test_size = 0.2, stratify=Y)"
      ],
      "metadata": {
        "id": "MXeQdyFvxQQ6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estandarizar los datos\n",
        "\n",
        "scaler = MinMaxScaler().fit(xtrain)\n",
        "\n",
        "xtrain_std = scaler.transform(xtrain)\n",
        "\n",
        "xtest_std = scaler.transform(xtest)\n"
      ],
      "metadata": {
        "id": "i6dJHiUQxpVc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Este apartado se utilizar para poder dar inicio el entrenamiento a una red\n",
        "neuronal\n",
        "\n",
        "   Todo esto viene dentro de la página oficial de Keras.\n",
        "\n",
        "   Dense es una capa de neurona que está conectada con todas las anteriores\n",
        "\n",
        "   Sequential es utilizado para crear secuencias en redes neuronales.\n",
        "\n",
        "   Optimizador: Adam.\n",
        "\n",
        "   units es la candtidad de clases que tienes.\n",
        "\n",
        "   activation: \"Qué tipo de función de activación almacenas\".\n",
        "\n",
        "   input_dim = la dimensionalidad.\n",
        "\n",
        "\"\"\"\n",
        "network = Sequential([\n",
        "\n",
        "    Dense(units=3, activation= \"softmax\" , input_dim = 17)\n",
        "])\n",
        "\n",
        "#Que copilador voy a utilizar, Adam, puede hacer eso.\n",
        "\n",
        "Adam(learning_rate=0.0001) #Taza de aprendizaje pequeña\n",
        "\n",
        "network.compile()\n",
        "\n",
        "#Función de perdida que se utilizará en la sala de entrenamient como su métrica.\n",
        "\n",
        "network.compile(loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QbP87Xplx-fX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"La libreria de keras para to_categorical\n",
        "\n",
        "   se utiliza para poder experesar problemas de clasificación de multiclase.\n",
        "   Para convertir nuestras etiquetas númericas en tipo one-hot.\n",
        "\n",
        "   Supongamso que tienes 3 clases (etiqeutas númericas 0,1,2)\n",
        "\n",
        "   En la primera linea convierte la una matriz en one-hot\n",
        "\n",
        "   Cada fila corresponde a un etiqueta, y cada columna, representa una clase.\n",
        "\n",
        "   AQUÍ INICIAMOS LA ETAPA DE ENTRENAMIENTO DE LA RED\n",
        "\n",
        "   El profe explica que es el batch_size, es para reducir el costo\n",
        "   computacional,\n",
        "   crea grupos para filas de hasta 100,000 dimensiones.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#network.fit(xtrain_std, ytrain, epochs=50, batch_size=128 )\n",
        "\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "epoch_accuracy =network.fit(xtrain_std, ytrain, epochs=1000, batch_size=80,\n",
        "                             validation_data=(xtest_std,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMrjFO3yNnb",
        "outputId": "8c66b6a5-351f-4357-81a8-d567263d54c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 0.9428 - accuracy: 0.5842 - val_loss: 0.9140 - val_accuracy: 0.5950\n",
            "Epoch 2/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8957 - accuracy: 0.5966 - val_loss: 0.8825 - val_accuracy: 0.5997\n",
            "Epoch 3/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8681 - accuracy: 0.6037 - val_loss: 0.8583 - val_accuracy: 0.6085\n",
            "Epoch 4/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8463 - accuracy: 0.6119 - val_loss: 0.8386 - val_accuracy: 0.6157\n",
            "Epoch 5/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8277 - accuracy: 0.6188 - val_loss: 0.8211 - val_accuracy: 0.6187\n",
            "Epoch 6/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8112 - accuracy: 0.6260 - val_loss: 0.8054 - val_accuracy: 0.6254\n",
            "Epoch 7/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7961 - accuracy: 0.6345 - val_loss: 0.7908 - val_accuracy: 0.6370\n",
            "Epoch 8/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7825 - accuracy: 0.6455 - val_loss: 0.7774 - val_accuracy: 0.6517\n",
            "Epoch 9/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7695 - accuracy: 0.6565 - val_loss: 0.7644 - val_accuracy: 0.6575\n",
            "Epoch 10/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7573 - accuracy: 0.6680 - val_loss: 0.7527 - val_accuracy: 0.6667\n",
            "Epoch 11/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7461 - accuracy: 0.6787 - val_loss: 0.7419 - val_accuracy: 0.6910\n",
            "Epoch 12/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7358 - accuracy: 0.6887 - val_loss: 0.7317 - val_accuracy: 0.6903\n",
            "Epoch 13/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7261 - accuracy: 0.6980 - val_loss: 0.7219 - val_accuracy: 0.7000\n",
            "Epoch 14/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7169 - accuracy: 0.7078 - val_loss: 0.7132 - val_accuracy: 0.7055\n",
            "Epoch 15/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7085 - accuracy: 0.7162 - val_loss: 0.7049 - val_accuracy: 0.7208\n",
            "Epoch 16/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7006 - accuracy: 0.7253 - val_loss: 0.6970 - val_accuracy: 0.7337\n",
            "Epoch 17/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.7329 - val_loss: 0.6906 - val_accuracy: 0.7209\n",
            "Epoch 18/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6860 - accuracy: 0.7394 - val_loss: 0.6830 - val_accuracy: 0.7523\n",
            "Epoch 19/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.7463 - val_loss: 0.6764 - val_accuracy: 0.7521\n",
            "Epoch 20/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6729 - accuracy: 0.7525 - val_loss: 0.6694 - val_accuracy: 0.7526\n",
            "Epoch 21/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6667 - accuracy: 0.7567 - val_loss: 0.6633 - val_accuracy: 0.7631\n",
            "Epoch 22/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6609 - accuracy: 0.7623 - val_loss: 0.6576 - val_accuracy: 0.7690\n",
            "Epoch 23/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6554 - accuracy: 0.7659 - val_loss: 0.6525 - val_accuracy: 0.7764\n",
            "Epoch 24/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6500 - accuracy: 0.7704 - val_loss: 0.6472 - val_accuracy: 0.7747\n",
            "Epoch 25/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6450 - accuracy: 0.7745 - val_loss: 0.6419 - val_accuracy: 0.7760\n",
            "Epoch 26/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6403 - accuracy: 0.7777 - val_loss: 0.6374 - val_accuracy: 0.7878\n",
            "Epoch 27/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6357 - accuracy: 0.7811 - val_loss: 0.6326 - val_accuracy: 0.7843\n",
            "Epoch 28/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6313 - accuracy: 0.7839 - val_loss: 0.6283 - val_accuracy: 0.7867\n",
            "Epoch 29/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6272 - accuracy: 0.7866 - val_loss: 0.6241 - val_accuracy: 0.7894\n",
            "Epoch 30/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6230 - accuracy: 0.7900 - val_loss: 0.6203 - val_accuracy: 0.7984\n",
            "Epoch 31/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6192 - accuracy: 0.7922 - val_loss: 0.6166 - val_accuracy: 0.8015\n",
            "Epoch 32/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6156 - accuracy: 0.7947 - val_loss: 0.6126 - val_accuracy: 0.7990\n",
            "Epoch 33/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6121 - accuracy: 0.7969 - val_loss: 0.6093 - val_accuracy: 0.7990\n",
            "Epoch 34/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6087 - accuracy: 0.7994 - val_loss: 0.6059 - val_accuracy: 0.8030\n",
            "Epoch 35/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6054 - accuracy: 0.8008 - val_loss: 0.6025 - val_accuracy: 0.8067\n",
            "Epoch 36/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6023 - accuracy: 0.8030 - val_loss: 0.5993 - val_accuracy: 0.8076\n",
            "Epoch 37/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5992 - accuracy: 0.8048 - val_loss: 0.5964 - val_accuracy: 0.8093\n",
            "Epoch 38/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5963 - accuracy: 0.8060 - val_loss: 0.5934 - val_accuracy: 0.8134\n",
            "Epoch 39/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5934 - accuracy: 0.8081 - val_loss: 0.5907 - val_accuracy: 0.8159\n",
            "Epoch 40/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5907 - accuracy: 0.8097 - val_loss: 0.5878 - val_accuracy: 0.8133\n",
            "Epoch 41/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5880 - accuracy: 0.8108 - val_loss: 0.5853 - val_accuracy: 0.8139\n",
            "Epoch 42/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5855 - accuracy: 0.8124 - val_loss: 0.5827 - val_accuracy: 0.8169\n",
            "Epoch 43/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5830 - accuracy: 0.8133 - val_loss: 0.5804 - val_accuracy: 0.8203\n",
            "Epoch 44/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5806 - accuracy: 0.8147 - val_loss: 0.5778 - val_accuracy: 0.8195\n",
            "Epoch 45/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5783 - accuracy: 0.8158 - val_loss: 0.5757 - val_accuracy: 0.8180\n",
            "Epoch 46/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5761 - accuracy: 0.8169 - val_loss: 0.5733 - val_accuracy: 0.8201\n",
            "Epoch 47/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5739 - accuracy: 0.8182 - val_loss: 0.5714 - val_accuracy: 0.8185\n",
            "Epoch 48/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5717 - accuracy: 0.8184 - val_loss: 0.5692 - val_accuracy: 0.8226\n",
            "Epoch 49/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.8199 - val_loss: 0.5669 - val_accuracy: 0.8243\n",
            "Epoch 50/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.8209 - val_loss: 0.5653 - val_accuracy: 0.8280\n",
            "Epoch 51/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5657 - accuracy: 0.8211 - val_loss: 0.5631 - val_accuracy: 0.8278\n",
            "Epoch 52/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5638 - accuracy: 0.8219 - val_loss: 0.5617 - val_accuracy: 0.8300\n",
            "Epoch 53/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5620 - accuracy: 0.8229 - val_loss: 0.5593 - val_accuracy: 0.8276\n",
            "Epoch 54/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5603 - accuracy: 0.8237 - val_loss: 0.5576 - val_accuracy: 0.8281\n",
            "Epoch 55/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5585 - accuracy: 0.8241 - val_loss: 0.5559 - val_accuracy: 0.8295\n",
            "Epoch 56/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5569 - accuracy: 0.8250 - val_loss: 0.5543 - val_accuracy: 0.8300\n",
            "Epoch 57/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5552 - accuracy: 0.8253 - val_loss: 0.5526 - val_accuracy: 0.8303\n",
            "Epoch 58/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5536 - accuracy: 0.8264 - val_loss: 0.5510 - val_accuracy: 0.8303\n",
            "Epoch 59/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5520 - accuracy: 0.8269 - val_loss: 0.5493 - val_accuracy: 0.8324\n",
            "Epoch 60/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.8274 - val_loss: 0.5478 - val_accuracy: 0.8326\n",
            "Epoch 61/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.8280 - val_loss: 0.5466 - val_accuracy: 0.8293\n",
            "Epoch 62/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.8284 - val_loss: 0.5453 - val_accuracy: 0.8344\n",
            "Epoch 63/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.8292 - val_loss: 0.5434 - val_accuracy: 0.8340\n",
            "Epoch 64/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.8295 - val_loss: 0.5421 - val_accuracy: 0.8321\n",
            "Epoch 65/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5430 - accuracy: 0.8298 - val_loss: 0.5411 - val_accuracy: 0.8364\n",
            "Epoch 66/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.8311 - val_loss: 0.5396 - val_accuracy: 0.8309\n",
            "Epoch 67/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.8309 - val_loss: 0.5380 - val_accuracy: 0.8334\n",
            "Epoch 68/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.8314 - val_loss: 0.5365 - val_accuracy: 0.8346\n",
            "Epoch 69/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.8322 - val_loss: 0.5353 - val_accuracy: 0.8347\n",
            "Epoch 70/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.8330 - val_loss: 0.5341 - val_accuracy: 0.8370\n",
            "Epoch 71/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5353 - accuracy: 0.8328 - val_loss: 0.5334 - val_accuracy: 0.8393\n",
            "Epoch 72/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.8336 - val_loss: 0.5321 - val_accuracy: 0.8396\n",
            "Epoch 73/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.8337 - val_loss: 0.5307 - val_accuracy: 0.8383\n",
            "Epoch 74/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.8343 - val_loss: 0.5293 - val_accuracy: 0.8369\n",
            "Epoch 75/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.8349 - val_loss: 0.5281 - val_accuracy: 0.8379\n",
            "Epoch 76/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.8350 - val_loss: 0.5273 - val_accuracy: 0.8362\n",
            "Epoch 77/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5284 - accuracy: 0.8356 - val_loss: 0.5259 - val_accuracy: 0.8395\n",
            "Epoch 78/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5273 - accuracy: 0.8361 - val_loss: 0.5248 - val_accuracy: 0.8384\n",
            "Epoch 79/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5263 - accuracy: 0.8359 - val_loss: 0.5237 - val_accuracy: 0.8393\n",
            "Epoch 80/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5252 - accuracy: 0.8364 - val_loss: 0.5227 - val_accuracy: 0.8401\n",
            "Epoch 81/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5241 - accuracy: 0.8374 - val_loss: 0.5217 - val_accuracy: 0.8403\n",
            "Epoch 82/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5231 - accuracy: 0.8369 - val_loss: 0.5207 - val_accuracy: 0.8400\n",
            "Epoch 83/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5223 - accuracy: 0.8376 - val_loss: 0.5199 - val_accuracy: 0.8426\n",
            "Epoch 84/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5212 - accuracy: 0.8374 - val_loss: 0.5189 - val_accuracy: 0.8429\n",
            "Epoch 85/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5203 - accuracy: 0.8378 - val_loss: 0.5179 - val_accuracy: 0.8406\n",
            "Epoch 86/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5193 - accuracy: 0.8378 - val_loss: 0.5168 - val_accuracy: 0.8418\n",
            "Epoch 87/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5184 - accuracy: 0.8385 - val_loss: 0.5159 - val_accuracy: 0.8415\n",
            "Epoch 88/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5175 - accuracy: 0.8390 - val_loss: 0.5150 - val_accuracy: 0.8429\n",
            "Epoch 89/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5166 - accuracy: 0.8392 - val_loss: 0.5149 - val_accuracy: 0.8382\n",
            "Epoch 90/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5157 - accuracy: 0.8393 - val_loss: 0.5135 - val_accuracy: 0.8413\n",
            "Epoch 91/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5148 - accuracy: 0.8396 - val_loss: 0.5130 - val_accuracy: 0.8449\n",
            "Epoch 92/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5140 - accuracy: 0.8396 - val_loss: 0.5116 - val_accuracy: 0.8449\n",
            "Epoch 93/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5131 - accuracy: 0.8400 - val_loss: 0.5106 - val_accuracy: 0.8432\n",
            "Epoch 94/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5122 - accuracy: 0.8405 - val_loss: 0.5097 - val_accuracy: 0.8440\n",
            "Epoch 95/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5114 - accuracy: 0.8406 - val_loss: 0.5092 - val_accuracy: 0.8419\n",
            "Epoch 96/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5105 - accuracy: 0.8410 - val_loss: 0.5080 - val_accuracy: 0.8444\n",
            "Epoch 97/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5097 - accuracy: 0.8415 - val_loss: 0.5075 - val_accuracy: 0.8429\n",
            "Epoch 98/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5089 - accuracy: 0.8414 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
            "Epoch 99/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5081 - accuracy: 0.8416 - val_loss: 0.5058 - val_accuracy: 0.8450\n",
            "Epoch 100/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5074 - accuracy: 0.8420 - val_loss: 0.5052 - val_accuracy: 0.8464\n",
            "Epoch 101/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5066 - accuracy: 0.8424 - val_loss: 0.5042 - val_accuracy: 0.8449\n",
            "Epoch 102/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5058 - accuracy: 0.8423 - val_loss: 0.5034 - val_accuracy: 0.8454\n",
            "Epoch 103/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5050 - accuracy: 0.8424 - val_loss: 0.5027 - val_accuracy: 0.8466\n",
            "Epoch 104/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5043 - accuracy: 0.8430 - val_loss: 0.5023 - val_accuracy: 0.8433\n",
            "Epoch 105/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5036 - accuracy: 0.8427 - val_loss: 0.5012 - val_accuracy: 0.8464\n",
            "Epoch 106/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5028 - accuracy: 0.8427 - val_loss: 0.5004 - val_accuracy: 0.8468\n",
            "Epoch 107/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5021 - accuracy: 0.8439 - val_loss: 0.4997 - val_accuracy: 0.8468\n",
            "Epoch 108/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5014 - accuracy: 0.8434 - val_loss: 0.4991 - val_accuracy: 0.8465\n",
            "Epoch 109/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5007 - accuracy: 0.8438 - val_loss: 0.4986 - val_accuracy: 0.8486\n",
            "Epoch 110/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5000 - accuracy: 0.8438 - val_loss: 0.4977 - val_accuracy: 0.8484\n",
            "Epoch 111/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4993 - accuracy: 0.8442 - val_loss: 0.4970 - val_accuracy: 0.8472\n",
            "Epoch 112/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4987 - accuracy: 0.8444 - val_loss: 0.4963 - val_accuracy: 0.8485\n",
            "Epoch 113/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4980 - accuracy: 0.8445 - val_loss: 0.4958 - val_accuracy: 0.8485\n",
            "Epoch 114/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.8448 - val_loss: 0.4950 - val_accuracy: 0.8475\n",
            "Epoch 115/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4967 - accuracy: 0.8448 - val_loss: 0.4945 - val_accuracy: 0.8461\n",
            "Epoch 116/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.8449 - val_loss: 0.4943 - val_accuracy: 0.8494\n",
            "Epoch 117/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4954 - accuracy: 0.8450 - val_loss: 0.4930 - val_accuracy: 0.8490\n",
            "Epoch 118/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.8457 - val_loss: 0.4925 - val_accuracy: 0.8476\n",
            "Epoch 119/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4941 - accuracy: 0.8455 - val_loss: 0.4917 - val_accuracy: 0.8493\n",
            "Epoch 120/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4935 - accuracy: 0.8460 - val_loss: 0.4914 - val_accuracy: 0.8484\n",
            "Epoch 121/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4929 - accuracy: 0.8459 - val_loss: 0.4907 - val_accuracy: 0.8478\n",
            "Epoch 122/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4923 - accuracy: 0.8459 - val_loss: 0.4900 - val_accuracy: 0.8482\n",
            "Epoch 123/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4916 - accuracy: 0.8462 - val_loss: 0.4895 - val_accuracy: 0.8499\n",
            "Epoch 124/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4911 - accuracy: 0.8463 - val_loss: 0.4891 - val_accuracy: 0.8466\n",
            "Epoch 125/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4905 - accuracy: 0.8465 - val_loss: 0.4881 - val_accuracy: 0.8495\n",
            "Epoch 126/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4898 - accuracy: 0.8469 - val_loss: 0.4875 - val_accuracy: 0.8501\n",
            "Epoch 127/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4892 - accuracy: 0.8469 - val_loss: 0.4870 - val_accuracy: 0.8493\n",
            "Epoch 128/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4887 - accuracy: 0.8470 - val_loss: 0.4865 - val_accuracy: 0.8502\n",
            "Epoch 129/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4882 - accuracy: 0.8469 - val_loss: 0.4858 - val_accuracy: 0.8503\n",
            "Epoch 130/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4875 - accuracy: 0.8478 - val_loss: 0.4855 - val_accuracy: 0.8474\n",
            "Epoch 131/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4870 - accuracy: 0.8474 - val_loss: 0.4849 - val_accuracy: 0.8505\n",
            "Epoch 132/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4865 - accuracy: 0.8478 - val_loss: 0.4842 - val_accuracy: 0.8508\n",
            "Epoch 133/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4859 - accuracy: 0.8475 - val_loss: 0.4845 - val_accuracy: 0.8513\n",
            "Epoch 134/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4854 - accuracy: 0.8481 - val_loss: 0.4832 - val_accuracy: 0.8512\n",
            "Epoch 135/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.8479 - val_loss: 0.4825 - val_accuracy: 0.8504\n",
            "Epoch 136/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4843 - accuracy: 0.8479 - val_loss: 0.4820 - val_accuracy: 0.8512\n",
            "Epoch 137/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4838 - accuracy: 0.8482 - val_loss: 0.4816 - val_accuracy: 0.8514\n",
            "Epoch 138/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4832 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.8512\n",
            "Epoch 139/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4826 - accuracy: 0.8485 - val_loss: 0.4803 - val_accuracy: 0.8511\n",
            "Epoch 140/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4821 - accuracy: 0.8486 - val_loss: 0.4798 - val_accuracy: 0.8513\n",
            "Epoch 141/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4816 - accuracy: 0.8489 - val_loss: 0.4793 - val_accuracy: 0.8509\n",
            "Epoch 142/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4811 - accuracy: 0.8488 - val_loss: 0.4788 - val_accuracy: 0.8511\n",
            "Epoch 143/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4806 - accuracy: 0.8490 - val_loss: 0.4783 - val_accuracy: 0.8513\n",
            "Epoch 144/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4801 - accuracy: 0.8488 - val_loss: 0.4780 - val_accuracy: 0.8515\n",
            "Epoch 145/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4796 - accuracy: 0.8490 - val_loss: 0.4773 - val_accuracy: 0.8509\n",
            "Epoch 146/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4791 - accuracy: 0.8497 - val_loss: 0.4768 - val_accuracy: 0.8519\n",
            "Epoch 147/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4786 - accuracy: 0.8497 - val_loss: 0.4765 - val_accuracy: 0.8522\n",
            "Epoch 148/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4781 - accuracy: 0.8500 - val_loss: 0.4758 - val_accuracy: 0.8519\n",
            "Epoch 149/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4775 - accuracy: 0.8502 - val_loss: 0.4755 - val_accuracy: 0.8504\n",
            "Epoch 150/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4770 - accuracy: 0.8499 - val_loss: 0.4754 - val_accuracy: 0.8486\n",
            "Epoch 151/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4766 - accuracy: 0.8503 - val_loss: 0.4746 - val_accuracy: 0.8500\n",
            "Epoch 152/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4761 - accuracy: 0.8503 - val_loss: 0.4738 - val_accuracy: 0.8523\n",
            "Epoch 153/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4757 - accuracy: 0.8502 - val_loss: 0.4736 - val_accuracy: 0.8508\n",
            "Epoch 154/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4751 - accuracy: 0.8506 - val_loss: 0.4730 - val_accuracy: 0.8532\n",
            "Epoch 155/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4747 - accuracy: 0.8509 - val_loss: 0.4726 - val_accuracy: 0.8533\n",
            "Epoch 156/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4743 - accuracy: 0.8511 - val_loss: 0.4722 - val_accuracy: 0.8532\n",
            "Epoch 157/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4737 - accuracy: 0.8510 - val_loss: 0.4716 - val_accuracy: 0.8529\n",
            "Epoch 158/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4733 - accuracy: 0.8509 - val_loss: 0.4710 - val_accuracy: 0.8528\n",
            "Epoch 159/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4729 - accuracy: 0.8508 - val_loss: 0.4706 - val_accuracy: 0.8529\n",
            "Epoch 160/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4724 - accuracy: 0.8511 - val_loss: 0.4702 - val_accuracy: 0.8535\n",
            "Epoch 161/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4720 - accuracy: 0.8516 - val_loss: 0.4698 - val_accuracy: 0.8527\n",
            "Epoch 162/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4715 - accuracy: 0.8512 - val_loss: 0.4693 - val_accuracy: 0.8532\n",
            "Epoch 163/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.8512 - val_loss: 0.4695 - val_accuracy: 0.8550\n",
            "Epoch 164/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.4706 - accuracy: 0.8516 - val_loss: 0.4693 - val_accuracy: 0.8492\n",
            "Epoch 165/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4701 - accuracy: 0.8516 - val_loss: 0.4681 - val_accuracy: 0.8541\n",
            "Epoch 166/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4697 - accuracy: 0.8516 - val_loss: 0.4675 - val_accuracy: 0.8533\n",
            "Epoch 167/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4693 - accuracy: 0.8517 - val_loss: 0.4672 - val_accuracy: 0.8543\n",
            "Epoch 168/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4688 - accuracy: 0.8520 - val_loss: 0.4666 - val_accuracy: 0.8539\n",
            "Epoch 169/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4684 - accuracy: 0.8520 - val_loss: 0.4662 - val_accuracy: 0.8543\n",
            "Epoch 170/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4680 - accuracy: 0.8524 - val_loss: 0.4657 - val_accuracy: 0.8544\n",
            "Epoch 171/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4676 - accuracy: 0.8522 - val_loss: 0.4653 - val_accuracy: 0.8540\n",
            "Epoch 172/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.8521 - val_loss: 0.4649 - val_accuracy: 0.8540\n",
            "Epoch 173/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4668 - accuracy: 0.8526 - val_loss: 0.4647 - val_accuracy: 0.8550\n",
            "Epoch 174/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4663 - accuracy: 0.8520 - val_loss: 0.4643 - val_accuracy: 0.8551\n",
            "Epoch 175/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4660 - accuracy: 0.8525 - val_loss: 0.4638 - val_accuracy: 0.8532\n",
            "Epoch 176/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4654 - accuracy: 0.8525 - val_loss: 0.4633 - val_accuracy: 0.8543\n",
            "Epoch 177/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4651 - accuracy: 0.8526 - val_loss: 0.4628 - val_accuracy: 0.8544\n",
            "Epoch 178/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4647 - accuracy: 0.8529 - val_loss: 0.4624 - val_accuracy: 0.8542\n",
            "Epoch 179/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4642 - accuracy: 0.8532 - val_loss: 0.4622 - val_accuracy: 0.8527\n",
            "Epoch 180/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4639 - accuracy: 0.8529 - val_loss: 0.4616 - val_accuracy: 0.8549\n",
            "Epoch 181/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4635 - accuracy: 0.8532 - val_loss: 0.4618 - val_accuracy: 0.8526\n",
            "Epoch 182/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4630 - accuracy: 0.8536 - val_loss: 0.4608 - val_accuracy: 0.8551\n",
            "Epoch 183/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4626 - accuracy: 0.8534 - val_loss: 0.4603 - val_accuracy: 0.8551\n",
            "Epoch 184/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4622 - accuracy: 0.8534 - val_loss: 0.4600 - val_accuracy: 0.8555\n",
            "Epoch 185/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4618 - accuracy: 0.8535 - val_loss: 0.4603 - val_accuracy: 0.8572\n",
            "Epoch 186/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4615 - accuracy: 0.8538 - val_loss: 0.4592 - val_accuracy: 0.8561\n",
            "Epoch 187/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4611 - accuracy: 0.8540 - val_loss: 0.4588 - val_accuracy: 0.8563\n",
            "Epoch 188/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4607 - accuracy: 0.8540 - val_loss: 0.4586 - val_accuracy: 0.8557\n",
            "Epoch 189/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4603 - accuracy: 0.8539 - val_loss: 0.4581 - val_accuracy: 0.8548\n",
            "Epoch 190/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4599 - accuracy: 0.8542 - val_loss: 0.4580 - val_accuracy: 0.8539\n",
            "Epoch 191/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4596 - accuracy: 0.8539 - val_loss: 0.4575 - val_accuracy: 0.8570\n",
            "Epoch 192/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4592 - accuracy: 0.8539 - val_loss: 0.4571 - val_accuracy: 0.8568\n",
            "Epoch 193/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4587 - accuracy: 0.8545 - val_loss: 0.4565 - val_accuracy: 0.8563\n",
            "Epoch 194/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4584 - accuracy: 0.8545 - val_loss: 0.4561 - val_accuracy: 0.8565\n",
            "Epoch 195/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4581 - accuracy: 0.8547 - val_loss: 0.4559 - val_accuracy: 0.8566\n",
            "Epoch 196/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4576 - accuracy: 0.8543 - val_loss: 0.4557 - val_accuracy: 0.8572\n",
            "Epoch 197/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4573 - accuracy: 0.8548 - val_loss: 0.4550 - val_accuracy: 0.8564\n",
            "Epoch 198/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4570 - accuracy: 0.8551 - val_loss: 0.4546 - val_accuracy: 0.8568\n",
            "Epoch 199/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.8548 - val_loss: 0.4543 - val_accuracy: 0.8564\n",
            "Epoch 200/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4562 - accuracy: 0.8549 - val_loss: 0.4541 - val_accuracy: 0.8573\n",
            "Epoch 201/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4558 - accuracy: 0.8549 - val_loss: 0.4539 - val_accuracy: 0.8541\n",
            "Epoch 202/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4555 - accuracy: 0.8552 - val_loss: 0.4534 - val_accuracy: 0.8550\n",
            "Epoch 203/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4551 - accuracy: 0.8547 - val_loss: 0.4529 - val_accuracy: 0.8560\n",
            "Epoch 204/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4548 - accuracy: 0.8549 - val_loss: 0.4525 - val_accuracy: 0.8573\n",
            "Epoch 205/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4544 - accuracy: 0.8549 - val_loss: 0.4525 - val_accuracy: 0.8579\n",
            "Epoch 206/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4540 - accuracy: 0.8553 - val_loss: 0.4520 - val_accuracy: 0.8560\n",
            "Epoch 207/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4537 - accuracy: 0.8549 - val_loss: 0.4515 - val_accuracy: 0.8576\n",
            "Epoch 208/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.8553 - val_loss: 0.4511 - val_accuracy: 0.8576\n",
            "Epoch 209/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.8550 - val_loss: 0.4507 - val_accuracy: 0.8579\n",
            "Epoch 210/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4527 - accuracy: 0.8554 - val_loss: 0.4505 - val_accuracy: 0.8559\n",
            "Epoch 211/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.8555 - val_loss: 0.4505 - val_accuracy: 0.8584\n",
            "Epoch 212/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4519 - accuracy: 0.8558 - val_loss: 0.4498 - val_accuracy: 0.8561\n",
            "Epoch 213/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.8554 - val_loss: 0.4493 - val_accuracy: 0.8574\n",
            "Epoch 214/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.8555 - val_loss: 0.4490 - val_accuracy: 0.8581\n",
            "Epoch 215/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.8560 - val_loss: 0.4486 - val_accuracy: 0.8581\n",
            "Epoch 216/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.8555 - val_loss: 0.4502 - val_accuracy: 0.8595\n",
            "Epoch 217/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4502 - accuracy: 0.8562 - val_loss: 0.4480 - val_accuracy: 0.8579\n",
            "Epoch 218/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.8559 - val_loss: 0.4476 - val_accuracy: 0.8582\n",
            "Epoch 219/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.8555 - val_loss: 0.4474 - val_accuracy: 0.8572\n",
            "Epoch 220/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4492 - accuracy: 0.8561 - val_loss: 0.4472 - val_accuracy: 0.8590\n",
            "Epoch 221/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4489 - accuracy: 0.8565 - val_loss: 0.4466 - val_accuracy: 0.8580\n",
            "Epoch 222/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4486 - accuracy: 0.8559 - val_loss: 0.4463 - val_accuracy: 0.8583\n",
            "Epoch 223/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4483 - accuracy: 0.8561 - val_loss: 0.4461 - val_accuracy: 0.8582\n",
            "Epoch 224/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4480 - accuracy: 0.8565 - val_loss: 0.4457 - val_accuracy: 0.8586\n",
            "Epoch 225/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4477 - accuracy: 0.8565 - val_loss: 0.4456 - val_accuracy: 0.8594\n",
            "Epoch 226/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4472 - accuracy: 0.8563 - val_loss: 0.4458 - val_accuracy: 0.8600\n",
            "Epoch 227/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4470 - accuracy: 0.8567 - val_loss: 0.4447 - val_accuracy: 0.8584\n",
            "Epoch 228/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4467 - accuracy: 0.8570 - val_loss: 0.4444 - val_accuracy: 0.8589\n",
            "Epoch 229/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4464 - accuracy: 0.8566 - val_loss: 0.4442 - val_accuracy: 0.8587\n",
            "Epoch 230/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4460 - accuracy: 0.8571 - val_loss: 0.4438 - val_accuracy: 0.8591\n",
            "Epoch 231/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4457 - accuracy: 0.8569 - val_loss: 0.4435 - val_accuracy: 0.8586\n",
            "Epoch 232/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4454 - accuracy: 0.8569 - val_loss: 0.4432 - val_accuracy: 0.8590\n",
            "Epoch 233/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4451 - accuracy: 0.8569 - val_loss: 0.4429 - val_accuracy: 0.8591\n",
            "Epoch 234/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4447 - accuracy: 0.8571 - val_loss: 0.4427 - val_accuracy: 0.8600\n",
            "Epoch 235/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4445 - accuracy: 0.8569 - val_loss: 0.4422 - val_accuracy: 0.8584\n",
            "Epoch 236/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4441 - accuracy: 0.8569 - val_loss: 0.4421 - val_accuracy: 0.8569\n",
            "Epoch 237/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4437 - accuracy: 0.8574 - val_loss: 0.4418 - val_accuracy: 0.8576\n",
            "Epoch 238/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4435 - accuracy: 0.8568 - val_loss: 0.4413 - val_accuracy: 0.8581\n",
            "Epoch 239/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4432 - accuracy: 0.8575 - val_loss: 0.4410 - val_accuracy: 0.8594\n",
            "Epoch 240/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4429 - accuracy: 0.8571 - val_loss: 0.4413 - val_accuracy: 0.8607\n",
            "Epoch 241/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4426 - accuracy: 0.8571 - val_loss: 0.4410 - val_accuracy: 0.8562\n",
            "Epoch 242/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4423 - accuracy: 0.8575 - val_loss: 0.4400 - val_accuracy: 0.8595\n",
            "Epoch 243/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4419 - accuracy: 0.8573 - val_loss: 0.4401 - val_accuracy: 0.8608\n",
            "Epoch 244/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4416 - accuracy: 0.8577 - val_loss: 0.4395 - val_accuracy: 0.8594\n",
            "Epoch 245/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4414 - accuracy: 0.8576 - val_loss: 0.4392 - val_accuracy: 0.8599\n",
            "Epoch 246/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4410 - accuracy: 0.8581 - val_loss: 0.4388 - val_accuracy: 0.8598\n",
            "Epoch 247/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4408 - accuracy: 0.8578 - val_loss: 0.4388 - val_accuracy: 0.8593\n",
            "Epoch 248/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4404 - accuracy: 0.8577 - val_loss: 0.4382 - val_accuracy: 0.8591\n",
            "Epoch 249/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4401 - accuracy: 0.8581 - val_loss: 0.4379 - val_accuracy: 0.8603\n",
            "Epoch 250/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4398 - accuracy: 0.8576 - val_loss: 0.4380 - val_accuracy: 0.8610\n",
            "Epoch 251/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4396 - accuracy: 0.8577 - val_loss: 0.4373 - val_accuracy: 0.8603\n",
            "Epoch 252/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4393 - accuracy: 0.8579 - val_loss: 0.4372 - val_accuracy: 0.8601\n",
            "Epoch 253/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4390 - accuracy: 0.8579 - val_loss: 0.4371 - val_accuracy: 0.8575\n",
            "Epoch 254/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4387 - accuracy: 0.8581 - val_loss: 0.4367 - val_accuracy: 0.8610\n",
            "Epoch 255/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4383 - accuracy: 0.8584 - val_loss: 0.4362 - val_accuracy: 0.8596\n",
            "Epoch 256/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4381 - accuracy: 0.8582 - val_loss: 0.4359 - val_accuracy: 0.8601\n",
            "Epoch 257/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4379 - accuracy: 0.8583 - val_loss: 0.4356 - val_accuracy: 0.8595\n",
            "Epoch 258/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4375 - accuracy: 0.8582 - val_loss: 0.4353 - val_accuracy: 0.8611\n",
            "Epoch 259/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4372 - accuracy: 0.8580 - val_loss: 0.4353 - val_accuracy: 0.8615\n",
            "Epoch 260/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4370 - accuracy: 0.8585 - val_loss: 0.4348 - val_accuracy: 0.8609\n",
            "Epoch 261/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4367 - accuracy: 0.8586 - val_loss: 0.4344 - val_accuracy: 0.8610\n",
            "Epoch 262/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4364 - accuracy: 0.8582 - val_loss: 0.4344 - val_accuracy: 0.8605\n",
            "Epoch 263/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4361 - accuracy: 0.8585 - val_loss: 0.4339 - val_accuracy: 0.8606\n",
            "Epoch 264/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4358 - accuracy: 0.8587 - val_loss: 0.4335 - val_accuracy: 0.8606\n",
            "Epoch 265/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.8586 - val_loss: 0.4335 - val_accuracy: 0.8603\n",
            "Epoch 266/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4353 - accuracy: 0.8583 - val_loss: 0.4332 - val_accuracy: 0.8594\n",
            "Epoch 267/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4350 - accuracy: 0.8587 - val_loss: 0.4329 - val_accuracy: 0.8592\n",
            "Epoch 268/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4347 - accuracy: 0.8590 - val_loss: 0.4325 - val_accuracy: 0.8612\n",
            "Epoch 269/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4344 - accuracy: 0.8590 - val_loss: 0.4323 - val_accuracy: 0.8597\n",
            "Epoch 270/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4341 - accuracy: 0.8589 - val_loss: 0.4319 - val_accuracy: 0.8612\n",
            "Epoch 271/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4339 - accuracy: 0.8591 - val_loss: 0.4319 - val_accuracy: 0.8587\n",
            "Epoch 272/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4336 - accuracy: 0.8593 - val_loss: 0.4317 - val_accuracy: 0.8584\n",
            "Epoch 273/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4333 - accuracy: 0.8592 - val_loss: 0.4312 - val_accuracy: 0.8594\n",
            "Epoch 274/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4330 - accuracy: 0.8590 - val_loss: 0.4310 - val_accuracy: 0.8601\n",
            "Epoch 275/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4328 - accuracy: 0.8597 - val_loss: 0.4305 - val_accuracy: 0.8613\n",
            "Epoch 276/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4325 - accuracy: 0.8588 - val_loss: 0.4302 - val_accuracy: 0.8622\n",
            "Epoch 277/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4322 - accuracy: 0.8591 - val_loss: 0.4300 - val_accuracy: 0.8612\n",
            "Epoch 278/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4320 - accuracy: 0.8596 - val_loss: 0.4299 - val_accuracy: 0.8589\n",
            "Epoch 279/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4317 - accuracy: 0.8593 - val_loss: 0.4295 - val_accuracy: 0.8619\n",
            "Epoch 280/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4315 - accuracy: 0.8594 - val_loss: 0.4292 - val_accuracy: 0.8623\n",
            "Epoch 281/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4312 - accuracy: 0.8596 - val_loss: 0.4289 - val_accuracy: 0.8603\n",
            "Epoch 282/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4309 - accuracy: 0.8595 - val_loss: 0.4291 - val_accuracy: 0.8589\n",
            "Epoch 283/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4306 - accuracy: 0.8597 - val_loss: 0.4283 - val_accuracy: 0.8622\n",
            "Epoch 284/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4304 - accuracy: 0.8595 - val_loss: 0.4282 - val_accuracy: 0.8622\n",
            "Epoch 285/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4302 - accuracy: 0.8599 - val_loss: 0.4279 - val_accuracy: 0.8603\n",
            "Epoch 286/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4298 - accuracy: 0.8598 - val_loss: 0.4277 - val_accuracy: 0.8598\n",
            "Epoch 287/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4295 - accuracy: 0.8596 - val_loss: 0.4279 - val_accuracy: 0.8627\n",
            "Epoch 288/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4293 - accuracy: 0.8598 - val_loss: 0.4271 - val_accuracy: 0.8605\n",
            "Epoch 289/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4291 - accuracy: 0.8598 - val_loss: 0.4271 - val_accuracy: 0.8626\n",
            "Epoch 290/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4288 - accuracy: 0.8602 - val_loss: 0.4267 - val_accuracy: 0.8601\n",
            "Epoch 291/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4285 - accuracy: 0.8600 - val_loss: 0.4266 - val_accuracy: 0.8630\n",
            "Epoch 292/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4283 - accuracy: 0.8601 - val_loss: 0.4262 - val_accuracy: 0.8634\n",
            "Epoch 293/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4280 - accuracy: 0.8596 - val_loss: 0.4257 - val_accuracy: 0.8630\n",
            "Epoch 294/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4278 - accuracy: 0.8604 - val_loss: 0.4256 - val_accuracy: 0.8609\n",
            "Epoch 295/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4275 - accuracy: 0.8602 - val_loss: 0.4253 - val_accuracy: 0.8629\n",
            "Epoch 296/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4272 - accuracy: 0.8603 - val_loss: 0.4250 - val_accuracy: 0.8626\n",
            "Epoch 297/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4269 - accuracy: 0.8605 - val_loss: 0.4251 - val_accuracy: 0.8608\n",
            "Epoch 298/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4267 - accuracy: 0.8605 - val_loss: 0.4245 - val_accuracy: 0.8630\n",
            "Epoch 299/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4265 - accuracy: 0.8603 - val_loss: 0.4247 - val_accuracy: 0.8590\n",
            "Epoch 300/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4262 - accuracy: 0.8603 - val_loss: 0.4240 - val_accuracy: 0.8629\n",
            "Epoch 301/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4260 - accuracy: 0.8601 - val_loss: 0.4238 - val_accuracy: 0.8612\n",
            "Epoch 302/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4257 - accuracy: 0.8608 - val_loss: 0.4237 - val_accuracy: 0.8637\n",
            "Epoch 303/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4255 - accuracy: 0.8604 - val_loss: 0.4232 - val_accuracy: 0.8623\n",
            "Epoch 304/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4252 - accuracy: 0.8609 - val_loss: 0.4230 - val_accuracy: 0.8624\n",
            "Epoch 305/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4250 - accuracy: 0.8607 - val_loss: 0.4229 - val_accuracy: 0.8636\n",
            "Epoch 306/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4247 - accuracy: 0.8608 - val_loss: 0.4225 - val_accuracy: 0.8633\n",
            "Epoch 307/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4245 - accuracy: 0.8609 - val_loss: 0.4223 - val_accuracy: 0.8640\n",
            "Epoch 308/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4242 - accuracy: 0.8608 - val_loss: 0.4221 - val_accuracy: 0.8616\n",
            "Epoch 309/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4240 - accuracy: 0.8608 - val_loss: 0.4219 - val_accuracy: 0.8644\n",
            "Epoch 310/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4237 - accuracy: 0.8611 - val_loss: 0.4215 - val_accuracy: 0.8619\n",
            "Epoch 311/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4234 - accuracy: 0.8609 - val_loss: 0.4214 - val_accuracy: 0.8618\n",
            "Epoch 312/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4232 - accuracy: 0.8606 - val_loss: 0.4214 - val_accuracy: 0.8640\n",
            "Epoch 313/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4230 - accuracy: 0.8611 - val_loss: 0.4209 - val_accuracy: 0.8640\n",
            "Epoch 314/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4228 - accuracy: 0.8608 - val_loss: 0.4205 - val_accuracy: 0.8638\n",
            "Epoch 315/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4225 - accuracy: 0.8607 - val_loss: 0.4205 - val_accuracy: 0.8612\n",
            "Epoch 316/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4222 - accuracy: 0.8609 - val_loss: 0.4202 - val_accuracy: 0.8640\n",
            "Epoch 317/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4220 - accuracy: 0.8610 - val_loss: 0.4198 - val_accuracy: 0.8623\n",
            "Epoch 318/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4218 - accuracy: 0.8613 - val_loss: 0.4199 - val_accuracy: 0.8601\n",
            "Epoch 319/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4216 - accuracy: 0.8612 - val_loss: 0.4196 - val_accuracy: 0.8612\n",
            "Epoch 320/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4213 - accuracy: 0.8611 - val_loss: 0.4191 - val_accuracy: 0.8639\n",
            "Epoch 321/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4211 - accuracy: 0.8614 - val_loss: 0.4190 - val_accuracy: 0.8624\n",
            "Epoch 322/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4209 - accuracy: 0.8614 - val_loss: 0.4187 - val_accuracy: 0.8622\n",
            "Epoch 323/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4206 - accuracy: 0.8618 - val_loss: 0.4187 - val_accuracy: 0.8647\n",
            "Epoch 324/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4204 - accuracy: 0.8616 - val_loss: 0.4182 - val_accuracy: 0.8631\n",
            "Epoch 325/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4201 - accuracy: 0.8613 - val_loss: 0.4181 - val_accuracy: 0.8628\n",
            "Epoch 326/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4199 - accuracy: 0.8618 - val_loss: 0.4178 - val_accuracy: 0.8645\n",
            "Epoch 327/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4197 - accuracy: 0.8616 - val_loss: 0.4174 - val_accuracy: 0.8632\n",
            "Epoch 328/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4195 - accuracy: 0.8612 - val_loss: 0.4176 - val_accuracy: 0.8627\n",
            "Epoch 329/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4192 - accuracy: 0.8618 - val_loss: 0.4169 - val_accuracy: 0.8633\n",
            "Epoch 330/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4190 - accuracy: 0.8617 - val_loss: 0.4168 - val_accuracy: 0.8635\n",
            "Epoch 331/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4187 - accuracy: 0.8620 - val_loss: 0.4167 - val_accuracy: 0.8622\n",
            "Epoch 332/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4185 - accuracy: 0.8619 - val_loss: 0.4163 - val_accuracy: 0.8641\n",
            "Epoch 333/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4183 - accuracy: 0.8615 - val_loss: 0.4161 - val_accuracy: 0.8640\n",
            "Epoch 334/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4181 - accuracy: 0.8616 - val_loss: 0.4160 - val_accuracy: 0.8622\n",
            "Epoch 335/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4178 - accuracy: 0.8615 - val_loss: 0.4157 - val_accuracy: 0.8644\n",
            "Epoch 336/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4176 - accuracy: 0.8618 - val_loss: 0.4162 - val_accuracy: 0.8659\n",
            "Epoch 337/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4174 - accuracy: 0.8621 - val_loss: 0.4153 - val_accuracy: 0.8624\n",
            "Epoch 338/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4171 - accuracy: 0.8620 - val_loss: 0.4150 - val_accuracy: 0.8638\n",
            "Epoch 339/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4169 - accuracy: 0.8620 - val_loss: 0.4148 - val_accuracy: 0.8646\n",
            "Epoch 340/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4167 - accuracy: 0.8621 - val_loss: 0.4146 - val_accuracy: 0.8640\n",
            "Epoch 341/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4165 - accuracy: 0.8622 - val_loss: 0.4143 - val_accuracy: 0.8637\n",
            "Epoch 342/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4163 - accuracy: 0.8623 - val_loss: 0.4144 - val_accuracy: 0.8650\n",
            "Epoch 343/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4160 - accuracy: 0.8620 - val_loss: 0.4140 - val_accuracy: 0.8659\n",
            "Epoch 344/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4159 - accuracy: 0.8621 - val_loss: 0.4140 - val_accuracy: 0.8616\n",
            "Epoch 345/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4156 - accuracy: 0.8623 - val_loss: 0.4136 - val_accuracy: 0.8656\n",
            "Epoch 346/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4153 - accuracy: 0.8624 - val_loss: 0.4131 - val_accuracy: 0.8643\n",
            "Epoch 347/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4151 - accuracy: 0.8623 - val_loss: 0.4129 - val_accuracy: 0.8649\n",
            "Epoch 348/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4149 - accuracy: 0.8625 - val_loss: 0.4133 - val_accuracy: 0.8607\n",
            "Epoch 349/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4147 - accuracy: 0.8622 - val_loss: 0.4125 - val_accuracy: 0.8646\n",
            "Epoch 350/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4145 - accuracy: 0.8629 - val_loss: 0.4123 - val_accuracy: 0.8637\n",
            "Epoch 351/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4142 - accuracy: 0.8622 - val_loss: 0.4123 - val_accuracy: 0.8627\n",
            "Epoch 352/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4140 - accuracy: 0.8624 - val_loss: 0.4120 - val_accuracy: 0.8633\n",
            "Epoch 353/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4138 - accuracy: 0.8629 - val_loss: 0.4117 - val_accuracy: 0.8661\n",
            "Epoch 354/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4135 - accuracy: 0.8628 - val_loss: 0.4115 - val_accuracy: 0.8637\n",
            "Epoch 355/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4134 - accuracy: 0.8625 - val_loss: 0.4112 - val_accuracy: 0.8641\n",
            "Epoch 356/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4132 - accuracy: 0.8625 - val_loss: 0.4110 - val_accuracy: 0.8651\n",
            "Epoch 357/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4129 - accuracy: 0.8628 - val_loss: 0.4111 - val_accuracy: 0.8659\n",
            "Epoch 358/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4126 - accuracy: 0.8627 - val_loss: 0.4106 - val_accuracy: 0.8637\n",
            "Epoch 359/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4125 - accuracy: 0.8627 - val_loss: 0.4104 - val_accuracy: 0.8661\n",
            "Epoch 360/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4123 - accuracy: 0.8630 - val_loss: 0.4101 - val_accuracy: 0.8650\n",
            "Epoch 361/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4120 - accuracy: 0.8631 - val_loss: 0.4105 - val_accuracy: 0.8665\n",
            "Epoch 362/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4119 - accuracy: 0.8627 - val_loss: 0.4097 - val_accuracy: 0.8651\n",
            "Epoch 363/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4117 - accuracy: 0.8629 - val_loss: 0.4097 - val_accuracy: 0.8626\n",
            "Epoch 364/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4115 - accuracy: 0.8631 - val_loss: 0.4094 - val_accuracy: 0.8654\n",
            "Epoch 365/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4112 - accuracy: 0.8629 - val_loss: 0.4092 - val_accuracy: 0.8663\n",
            "Epoch 366/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4110 - accuracy: 0.8632 - val_loss: 0.4094 - val_accuracy: 0.8668\n",
            "Epoch 367/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4108 - accuracy: 0.8636 - val_loss: 0.4086 - val_accuracy: 0.8655\n",
            "Epoch 368/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4106 - accuracy: 0.8635 - val_loss: 0.4088 - val_accuracy: 0.8641\n",
            "Epoch 369/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4104 - accuracy: 0.8634 - val_loss: 0.4083 - val_accuracy: 0.8635\n",
            "Epoch 370/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4102 - accuracy: 0.8632 - val_loss: 0.4082 - val_accuracy: 0.8662\n",
            "Epoch 371/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4100 - accuracy: 0.8634 - val_loss: 0.4079 - val_accuracy: 0.8647\n",
            "Epoch 372/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4098 - accuracy: 0.8632 - val_loss: 0.4077 - val_accuracy: 0.8666\n",
            "Epoch 373/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4096 - accuracy: 0.8630 - val_loss: 0.4074 - val_accuracy: 0.8652\n",
            "Epoch 374/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4094 - accuracy: 0.8633 - val_loss: 0.4073 - val_accuracy: 0.8651\n",
            "Epoch 375/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4092 - accuracy: 0.8642 - val_loss: 0.4070 - val_accuracy: 0.8643\n",
            "Epoch 376/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4089 - accuracy: 0.8636 - val_loss: 0.4071 - val_accuracy: 0.8669\n",
            "Epoch 377/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4088 - accuracy: 0.8633 - val_loss: 0.4066 - val_accuracy: 0.8649\n",
            "Epoch 378/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4085 - accuracy: 0.8632 - val_loss: 0.4069 - val_accuracy: 0.8615\n",
            "Epoch 379/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4084 - accuracy: 0.8638 - val_loss: 0.4063 - val_accuracy: 0.8661\n",
            "Epoch 380/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4082 - accuracy: 0.8641 - val_loss: 0.4062 - val_accuracy: 0.8669\n",
            "Epoch 381/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4080 - accuracy: 0.8638 - val_loss: 0.4060 - val_accuracy: 0.8668\n",
            "Epoch 382/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4078 - accuracy: 0.8639 - val_loss: 0.4056 - val_accuracy: 0.8652\n",
            "Epoch 383/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4076 - accuracy: 0.8641 - val_loss: 0.4055 - val_accuracy: 0.8644\n",
            "Epoch 384/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4074 - accuracy: 0.8638 - val_loss: 0.4054 - val_accuracy: 0.8672\n",
            "Epoch 385/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4072 - accuracy: 0.8640 - val_loss: 0.4050 - val_accuracy: 0.8653\n",
            "Epoch 386/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4070 - accuracy: 0.8641 - val_loss: 0.4050 - val_accuracy: 0.8644\n",
            "Epoch 387/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4068 - accuracy: 0.8639 - val_loss: 0.4046 - val_accuracy: 0.8654\n",
            "Epoch 388/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4065 - accuracy: 0.8643 - val_loss: 0.4053 - val_accuracy: 0.8678\n",
            "Epoch 389/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4063 - accuracy: 0.8640 - val_loss: 0.4042 - val_accuracy: 0.8662\n",
            "Epoch 390/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4062 - accuracy: 0.8641 - val_loss: 0.4042 - val_accuracy: 0.8673\n",
            "Epoch 391/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4060 - accuracy: 0.8643 - val_loss: 0.4038 - val_accuracy: 0.8657\n",
            "Epoch 392/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4058 - accuracy: 0.8643 - val_loss: 0.4037 - val_accuracy: 0.8669\n",
            "Epoch 393/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4056 - accuracy: 0.8645 - val_loss: 0.4034 - val_accuracy: 0.8663\n",
            "Epoch 394/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4053 - accuracy: 0.8645 - val_loss: 0.4032 - val_accuracy: 0.8656\n",
            "Epoch 395/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4052 - accuracy: 0.8646 - val_loss: 0.4031 - val_accuracy: 0.8664\n",
            "Epoch 396/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4050 - accuracy: 0.8645 - val_loss: 0.4029 - val_accuracy: 0.8664\n",
            "Epoch 397/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4048 - accuracy: 0.8644 - val_loss: 0.4028 - val_accuracy: 0.8674\n",
            "Epoch 398/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4046 - accuracy: 0.8645 - val_loss: 0.4028 - val_accuracy: 0.8676\n",
            "Epoch 399/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4044 - accuracy: 0.8642 - val_loss: 0.4026 - val_accuracy: 0.8622\n",
            "Epoch 400/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4042 - accuracy: 0.8646 - val_loss: 0.4023 - val_accuracy: 0.8633\n",
            "Epoch 401/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4041 - accuracy: 0.8641 - val_loss: 0.4023 - val_accuracy: 0.8674\n",
            "Epoch 402/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4038 - accuracy: 0.8643 - val_loss: 0.4018 - val_accuracy: 0.8672\n",
            "Epoch 403/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4036 - accuracy: 0.8648 - val_loss: 0.4015 - val_accuracy: 0.8667\n",
            "Epoch 404/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4034 - accuracy: 0.8644 - val_loss: 0.4014 - val_accuracy: 0.8674\n",
            "Epoch 405/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4033 - accuracy: 0.8647 - val_loss: 0.4011 - val_accuracy: 0.8666\n",
            "Epoch 406/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4030 - accuracy: 0.8650 - val_loss: 0.4010 - val_accuracy: 0.8650\n",
            "Epoch 407/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.8646 - val_loss: 0.4007 - val_accuracy: 0.8666\n",
            "Epoch 408/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4027 - accuracy: 0.8651 - val_loss: 0.4008 - val_accuracy: 0.8655\n",
            "Epoch 409/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4025 - accuracy: 0.8647 - val_loss: 0.4004 - val_accuracy: 0.8666\n",
            "Epoch 410/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4023 - accuracy: 0.8647 - val_loss: 0.4002 - val_accuracy: 0.8661\n",
            "Epoch 411/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4021 - accuracy: 0.8651 - val_loss: 0.4000 - val_accuracy: 0.8666\n",
            "Epoch 412/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4019 - accuracy: 0.8652 - val_loss: 0.4000 - val_accuracy: 0.8673\n",
            "Epoch 413/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4018 - accuracy: 0.8649 - val_loss: 0.3997 - val_accuracy: 0.8673\n",
            "Epoch 414/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4016 - accuracy: 0.8652 - val_loss: 0.3995 - val_accuracy: 0.8668\n",
            "Epoch 415/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4014 - accuracy: 0.8653 - val_loss: 0.3993 - val_accuracy: 0.8668\n",
            "Epoch 416/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4012 - accuracy: 0.8649 - val_loss: 0.3993 - val_accuracy: 0.8637\n",
            "Epoch 417/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4010 - accuracy: 0.8651 - val_loss: 0.3989 - val_accuracy: 0.8668\n",
            "Epoch 418/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4008 - accuracy: 0.8650 - val_loss: 0.3988 - val_accuracy: 0.8645\n",
            "Epoch 419/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4006 - accuracy: 0.8648 - val_loss: 0.3990 - val_accuracy: 0.8680\n",
            "Epoch 420/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4004 - accuracy: 0.8658 - val_loss: 0.3985 - val_accuracy: 0.8676\n",
            "Epoch 421/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4003 - accuracy: 0.8652 - val_loss: 0.3983 - val_accuracy: 0.8681\n",
            "Epoch 422/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4001 - accuracy: 0.8654 - val_loss: 0.3980 - val_accuracy: 0.8670\n",
            "Epoch 423/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4000 - accuracy: 0.8656 - val_loss: 0.3978 - val_accuracy: 0.8669\n",
            "Epoch 424/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3997 - accuracy: 0.8656 - val_loss: 0.3976 - val_accuracy: 0.8673\n",
            "Epoch 425/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3995 - accuracy: 0.8655 - val_loss: 0.3978 - val_accuracy: 0.8684\n",
            "Epoch 426/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3994 - accuracy: 0.8652 - val_loss: 0.3973 - val_accuracy: 0.8675\n",
            "Epoch 427/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3992 - accuracy: 0.8655 - val_loss: 0.3971 - val_accuracy: 0.8673\n",
            "Epoch 428/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3990 - accuracy: 0.8655 - val_loss: 0.3970 - val_accuracy: 0.8676\n",
            "Epoch 429/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3988 - accuracy: 0.8661 - val_loss: 0.3971 - val_accuracy: 0.8633\n",
            "Epoch 430/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3986 - accuracy: 0.8660 - val_loss: 0.3967 - val_accuracy: 0.8680\n",
            "Epoch 431/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3985 - accuracy: 0.8661 - val_loss: 0.3966 - val_accuracy: 0.8687\n",
            "Epoch 432/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3983 - accuracy: 0.8661 - val_loss: 0.3966 - val_accuracy: 0.8648\n",
            "Epoch 433/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3981 - accuracy: 0.8658 - val_loss: 0.3962 - val_accuracy: 0.8682\n",
            "Epoch 434/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3979 - accuracy: 0.8657 - val_loss: 0.3958 - val_accuracy: 0.8671\n",
            "Epoch 435/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3978 - accuracy: 0.8661 - val_loss: 0.3957 - val_accuracy: 0.8667\n",
            "Epoch 436/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3976 - accuracy: 0.8655 - val_loss: 0.3955 - val_accuracy: 0.8674\n",
            "Epoch 437/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3974 - accuracy: 0.8657 - val_loss: 0.3953 - val_accuracy: 0.8673\n",
            "Epoch 438/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3972 - accuracy: 0.8660 - val_loss: 0.3951 - val_accuracy: 0.8673\n",
            "Epoch 439/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3971 - accuracy: 0.8660 - val_loss: 0.3950 - val_accuracy: 0.8672\n",
            "Epoch 440/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3969 - accuracy: 0.8662 - val_loss: 0.3951 - val_accuracy: 0.8690\n",
            "Epoch 441/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3967 - accuracy: 0.8659 - val_loss: 0.3947 - val_accuracy: 0.8676\n",
            "Epoch 442/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3965 - accuracy: 0.8662 - val_loss: 0.3945 - val_accuracy: 0.8673\n",
            "Epoch 443/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3963 - accuracy: 0.8659 - val_loss: 0.3943 - val_accuracy: 0.8679\n",
            "Epoch 444/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3961 - accuracy: 0.8661 - val_loss: 0.3942 - val_accuracy: 0.8666\n",
            "Epoch 445/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3960 - accuracy: 0.8661 - val_loss: 0.3940 - val_accuracy: 0.8674\n",
            "Epoch 446/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3958 - accuracy: 0.8668 - val_loss: 0.3938 - val_accuracy: 0.8660\n",
            "Epoch 447/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3956 - accuracy: 0.8667 - val_loss: 0.3943 - val_accuracy: 0.8665\n",
            "Epoch 448/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3955 - accuracy: 0.8664 - val_loss: 0.3936 - val_accuracy: 0.8665\n",
            "Epoch 449/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3953 - accuracy: 0.8666 - val_loss: 0.3934 - val_accuracy: 0.8688\n",
            "Epoch 450/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3952 - accuracy: 0.8666 - val_loss: 0.3931 - val_accuracy: 0.8687\n",
            "Epoch 451/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3950 - accuracy: 0.8664 - val_loss: 0.3931 - val_accuracy: 0.8658\n",
            "Epoch 452/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8666 - val_loss: 0.3930 - val_accuracy: 0.8690\n",
            "Epoch 453/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8667 - val_loss: 0.3926 - val_accuracy: 0.8674\n",
            "Epoch 454/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3945 - accuracy: 0.8668 - val_loss: 0.3925 - val_accuracy: 0.8686\n",
            "Epoch 455/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3942 - accuracy: 0.8670 - val_loss: 0.3931 - val_accuracy: 0.8705\n",
            "Epoch 456/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3941 - accuracy: 0.8668 - val_loss: 0.3923 - val_accuracy: 0.8672\n",
            "Epoch 457/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3939 - accuracy: 0.8665 - val_loss: 0.3921 - val_accuracy: 0.8689\n",
            "Epoch 458/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8669 - val_loss: 0.3918 - val_accuracy: 0.8661\n",
            "Epoch 459/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3936 - accuracy: 0.8667 - val_loss: 0.3919 - val_accuracy: 0.8652\n",
            "Epoch 460/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3935 - accuracy: 0.8669 - val_loss: 0.3914 - val_accuracy: 0.8672\n",
            "Epoch 461/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3933 - accuracy: 0.8668 - val_loss: 0.3912 - val_accuracy: 0.8677\n",
            "Epoch 462/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3931 - accuracy: 0.8669 - val_loss: 0.3911 - val_accuracy: 0.8667\n",
            "Epoch 463/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3929 - accuracy: 0.8666 - val_loss: 0.3911 - val_accuracy: 0.8654\n",
            "Epoch 464/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3928 - accuracy: 0.8670 - val_loss: 0.3908 - val_accuracy: 0.8674\n",
            "Epoch 465/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3926 - accuracy: 0.8670 - val_loss: 0.3906 - val_accuracy: 0.8683\n",
            "Epoch 466/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3925 - accuracy: 0.8670 - val_loss: 0.3905 - val_accuracy: 0.8677\n",
            "Epoch 467/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3923 - accuracy: 0.8666 - val_loss: 0.3906 - val_accuracy: 0.8695\n",
            "Epoch 468/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3921 - accuracy: 0.8670 - val_loss: 0.3902 - val_accuracy: 0.8696\n",
            "Epoch 469/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3920 - accuracy: 0.8670 - val_loss: 0.3900 - val_accuracy: 0.8690\n",
            "Epoch 470/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3918 - accuracy: 0.8670 - val_loss: 0.3902 - val_accuracy: 0.8662\n",
            "Epoch 471/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3917 - accuracy: 0.8672 - val_loss: 0.3896 - val_accuracy: 0.8699\n",
            "Epoch 472/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3914 - accuracy: 0.8670 - val_loss: 0.3896 - val_accuracy: 0.8695\n",
            "Epoch 473/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3913 - accuracy: 0.8673 - val_loss: 0.3893 - val_accuracy: 0.8686\n",
            "Epoch 474/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3911 - accuracy: 0.8678 - val_loss: 0.3892 - val_accuracy: 0.8667\n",
            "Epoch 475/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3909 - accuracy: 0.8673 - val_loss: 0.3895 - val_accuracy: 0.8648\n",
            "Epoch 476/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3908 - accuracy: 0.8673 - val_loss: 0.3888 - val_accuracy: 0.8695\n",
            "Epoch 477/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3907 - accuracy: 0.8677 - val_loss: 0.3886 - val_accuracy: 0.8686\n",
            "Epoch 478/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3904 - accuracy: 0.8677 - val_loss: 0.3887 - val_accuracy: 0.8699\n",
            "Epoch 479/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3904 - accuracy: 0.8675 - val_loss: 0.3883 - val_accuracy: 0.8698\n",
            "Epoch 480/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8677 - val_loss: 0.3882 - val_accuracy: 0.8678\n",
            "Epoch 481/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3900 - accuracy: 0.8681 - val_loss: 0.3881 - val_accuracy: 0.8673\n",
            "Epoch 482/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3898 - accuracy: 0.8673 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 483/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3897 - accuracy: 0.8679 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 484/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3895 - accuracy: 0.8676 - val_loss: 0.3875 - val_accuracy: 0.8701\n",
            "Epoch 485/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3893 - accuracy: 0.8679 - val_loss: 0.3874 - val_accuracy: 0.8701\n",
            "Epoch 486/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3892 - accuracy: 0.8677 - val_loss: 0.3873 - val_accuracy: 0.8680\n",
            "Epoch 487/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3891 - accuracy: 0.8683 - val_loss: 0.3871 - val_accuracy: 0.8691\n",
            "Epoch 488/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3889 - accuracy: 0.8681 - val_loss: 0.3873 - val_accuracy: 0.8658\n",
            "Epoch 489/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3887 - accuracy: 0.8676 - val_loss: 0.3873 - val_accuracy: 0.8706\n",
            "Epoch 490/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3886 - accuracy: 0.8679 - val_loss: 0.3866 - val_accuracy: 0.8698\n",
            "Epoch 491/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3884 - accuracy: 0.8684 - val_loss: 0.3865 - val_accuracy: 0.8709\n",
            "Epoch 492/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3882 - accuracy: 0.8683 - val_loss: 0.3864 - val_accuracy: 0.8710\n",
            "Epoch 493/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3881 - accuracy: 0.8680 - val_loss: 0.3864 - val_accuracy: 0.8706\n",
            "Epoch 494/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3878 - accuracy: 0.8683 - val_loss: 0.3867 - val_accuracy: 0.8712\n",
            "Epoch 495/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3878 - accuracy: 0.8684 - val_loss: 0.3860 - val_accuracy: 0.8703\n",
            "Epoch 496/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3876 - accuracy: 0.8683 - val_loss: 0.3858 - val_accuracy: 0.8700\n",
            "Epoch 497/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3874 - accuracy: 0.8690 - val_loss: 0.3858 - val_accuracy: 0.8712\n",
            "Epoch 498/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3873 - accuracy: 0.8685 - val_loss: 0.3856 - val_accuracy: 0.8712\n",
            "Epoch 499/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3872 - accuracy: 0.8684 - val_loss: 0.3855 - val_accuracy: 0.8710\n",
            "Epoch 500/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3870 - accuracy: 0.8684 - val_loss: 0.3852 - val_accuracy: 0.8710\n",
            "Epoch 501/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3869 - accuracy: 0.8686 - val_loss: 0.3849 - val_accuracy: 0.8709\n",
            "Epoch 502/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3867 - accuracy: 0.8684 - val_loss: 0.3847 - val_accuracy: 0.8702\n",
            "Epoch 503/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3866 - accuracy: 0.8686 - val_loss: 0.3847 - val_accuracy: 0.8679\n",
            "Epoch 504/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3864 - accuracy: 0.8687 - val_loss: 0.3846 - val_accuracy: 0.8709\n",
            "Epoch 505/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3863 - accuracy: 0.8685 - val_loss: 0.3844 - val_accuracy: 0.8702\n",
            "Epoch 506/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3861 - accuracy: 0.8684 - val_loss: 0.3843 - val_accuracy: 0.8712\n",
            "Epoch 507/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3859 - accuracy: 0.8691 - val_loss: 0.3840 - val_accuracy: 0.8704\n",
            "Epoch 508/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3858 - accuracy: 0.8688 - val_loss: 0.3840 - val_accuracy: 0.8710\n",
            "Epoch 509/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3856 - accuracy: 0.8690 - val_loss: 0.3839 - val_accuracy: 0.8681\n",
            "Epoch 510/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3855 - accuracy: 0.8689 - val_loss: 0.3835 - val_accuracy: 0.8698\n",
            "Epoch 511/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3853 - accuracy: 0.8693 - val_loss: 0.3835 - val_accuracy: 0.8694\n",
            "Epoch 512/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3852 - accuracy: 0.8691 - val_loss: 0.3834 - val_accuracy: 0.8708\n",
            "Epoch 513/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3850 - accuracy: 0.8690 - val_loss: 0.3833 - val_accuracy: 0.8692\n",
            "Epoch 514/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3849 - accuracy: 0.8690 - val_loss: 0.3832 - val_accuracy: 0.8717\n",
            "Epoch 515/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3848 - accuracy: 0.8695 - val_loss: 0.3829 - val_accuracy: 0.8695\n",
            "Epoch 516/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3846 - accuracy: 0.8690 - val_loss: 0.3828 - val_accuracy: 0.8716\n",
            "Epoch 517/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3845 - accuracy: 0.8690 - val_loss: 0.3828 - val_accuracy: 0.8717\n",
            "Epoch 518/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3843 - accuracy: 0.8694 - val_loss: 0.3824 - val_accuracy: 0.8713\n",
            "Epoch 519/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3842 - accuracy: 0.8696 - val_loss: 0.3822 - val_accuracy: 0.8710\n",
            "Epoch 520/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3840 - accuracy: 0.8693 - val_loss: 0.3822 - val_accuracy: 0.8717\n",
            "Epoch 521/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3838 - accuracy: 0.8698 - val_loss: 0.3821 - val_accuracy: 0.8694\n",
            "Epoch 522/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3837 - accuracy: 0.8696 - val_loss: 0.3821 - val_accuracy: 0.8679\n",
            "Epoch 523/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3836 - accuracy: 0.8692 - val_loss: 0.3818 - val_accuracy: 0.8703\n",
            "Epoch 524/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3834 - accuracy: 0.8696 - val_loss: 0.3816 - val_accuracy: 0.8699\n",
            "Epoch 525/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3832 - accuracy: 0.8695 - val_loss: 0.3817 - val_accuracy: 0.8724\n",
            "Epoch 526/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3831 - accuracy: 0.8697 - val_loss: 0.3814 - val_accuracy: 0.8701\n",
            "Epoch 527/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3830 - accuracy: 0.8698 - val_loss: 0.3811 - val_accuracy: 0.8716\n",
            "Epoch 528/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3828 - accuracy: 0.8697 - val_loss: 0.3810 - val_accuracy: 0.8712\n",
            "Epoch 529/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8699 - val_loss: 0.3811 - val_accuracy: 0.8717\n",
            "Epoch 530/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3826 - accuracy: 0.8700 - val_loss: 0.3807 - val_accuracy: 0.8720\n",
            "Epoch 531/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - accuracy: 0.8700 - val_loss: 0.3806 - val_accuracy: 0.8711\n",
            "Epoch 532/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3822 - accuracy: 0.8698 - val_loss: 0.3811 - val_accuracy: 0.8728\n",
            "Epoch 533/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3821 - accuracy: 0.8701 - val_loss: 0.3802 - val_accuracy: 0.8719\n",
            "Epoch 534/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8702 - val_loss: 0.3801 - val_accuracy: 0.8717\n",
            "Epoch 535/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3818 - accuracy: 0.8702 - val_loss: 0.3802 - val_accuracy: 0.8684\n",
            "Epoch 536/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3816 - accuracy: 0.8699 - val_loss: 0.3798 - val_accuracy: 0.8717\n",
            "Epoch 537/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3815 - accuracy: 0.8700 - val_loss: 0.3796 - val_accuracy: 0.8711\n",
            "Epoch 538/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3814 - accuracy: 0.8707 - val_loss: 0.3795 - val_accuracy: 0.8712\n",
            "Epoch 539/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3812 - accuracy: 0.8701 - val_loss: 0.3794 - val_accuracy: 0.8708\n",
            "Epoch 540/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3811 - accuracy: 0.8702 - val_loss: 0.3792 - val_accuracy: 0.8719\n",
            "Epoch 541/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3810 - accuracy: 0.8705 - val_loss: 0.3792 - val_accuracy: 0.8720\n",
            "Epoch 542/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3808 - accuracy: 0.8702 - val_loss: 0.3793 - val_accuracy: 0.8706\n",
            "Epoch 543/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3807 - accuracy: 0.8703 - val_loss: 0.3789 - val_accuracy: 0.8725\n",
            "Epoch 544/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3805 - accuracy: 0.8709 - val_loss: 0.3789 - val_accuracy: 0.8722\n",
            "Epoch 545/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3804 - accuracy: 0.8702 - val_loss: 0.3786 - val_accuracy: 0.8723\n",
            "Epoch 546/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3803 - accuracy: 0.8708 - val_loss: 0.3790 - val_accuracy: 0.8680\n",
            "Epoch 547/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3801 - accuracy: 0.8705 - val_loss: 0.3783 - val_accuracy: 0.8723\n",
            "Epoch 548/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3800 - accuracy: 0.8705 - val_loss: 0.3782 - val_accuracy: 0.8702\n",
            "Epoch 549/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3798 - accuracy: 0.8706 - val_loss: 0.3780 - val_accuracy: 0.8716\n",
            "Epoch 550/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3797 - accuracy: 0.8702 - val_loss: 0.3784 - val_accuracy: 0.8734\n",
            "Epoch 551/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3796 - accuracy: 0.8706 - val_loss: 0.3779 - val_accuracy: 0.8734\n",
            "Epoch 552/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3794 - accuracy: 0.8707 - val_loss: 0.3776 - val_accuracy: 0.8712\n",
            "Epoch 553/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3792 - accuracy: 0.8708 - val_loss: 0.3777 - val_accuracy: 0.8732\n",
            "Epoch 554/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3792 - accuracy: 0.8707 - val_loss: 0.3774 - val_accuracy: 0.8730\n",
            "Epoch 555/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3790 - accuracy: 0.8709 - val_loss: 0.3774 - val_accuracy: 0.8711\n",
            "Epoch 556/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3789 - accuracy: 0.8710 - val_loss: 0.3771 - val_accuracy: 0.8716\n",
            "Epoch 557/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3788 - accuracy: 0.8708 - val_loss: 0.3769 - val_accuracy: 0.8727\n",
            "Epoch 558/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3786 - accuracy: 0.8709 - val_loss: 0.3775 - val_accuracy: 0.8734\n",
            "Epoch 559/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3785 - accuracy: 0.8709 - val_loss: 0.3766 - val_accuracy: 0.8727\n",
            "Epoch 560/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3783 - accuracy: 0.8714 - val_loss: 0.3765 - val_accuracy: 0.8719\n",
            "Epoch 561/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8711 - val_loss: 0.3763 - val_accuracy: 0.8727\n",
            "Epoch 562/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3780 - accuracy: 0.8715 - val_loss: 0.3764 - val_accuracy: 0.8738\n",
            "Epoch 563/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8715 - val_loss: 0.3765 - val_accuracy: 0.8698\n",
            "Epoch 564/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3778 - accuracy: 0.8713 - val_loss: 0.3760 - val_accuracy: 0.8737\n",
            "Epoch 565/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3776 - accuracy: 0.8712 - val_loss: 0.3758 - val_accuracy: 0.8726\n",
            "Epoch 566/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3775 - accuracy: 0.8710 - val_loss: 0.3759 - val_accuracy: 0.8734\n",
            "Epoch 567/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8714 - val_loss: 0.3761 - val_accuracy: 0.8737\n",
            "Epoch 568/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3772 - accuracy: 0.8717 - val_loss: 0.3755 - val_accuracy: 0.8730\n",
            "Epoch 569/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8717 - val_loss: 0.3753 - val_accuracy: 0.8734\n",
            "Epoch 570/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3769 - accuracy: 0.8716 - val_loss: 0.3764 - val_accuracy: 0.8676\n",
            "Epoch 571/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3769 - accuracy: 0.8720 - val_loss: 0.3750 - val_accuracy: 0.8735\n",
            "Epoch 572/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3767 - accuracy: 0.8716 - val_loss: 0.3752 - val_accuracy: 0.8734\n",
            "Epoch 573/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3766 - accuracy: 0.8718 - val_loss: 0.3748 - val_accuracy: 0.8722\n",
            "Epoch 574/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8717 - val_loss: 0.3751 - val_accuracy: 0.8739\n",
            "Epoch 575/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3763 - accuracy: 0.8719 - val_loss: 0.3746 - val_accuracy: 0.8706\n",
            "Epoch 576/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3761 - accuracy: 0.8717 - val_loss: 0.3748 - val_accuracy: 0.8744\n",
            "Epoch 577/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3760 - accuracy: 0.8716 - val_loss: 0.3745 - val_accuracy: 0.8737\n",
            "Epoch 578/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3759 - accuracy: 0.8716 - val_loss: 0.3743 - val_accuracy: 0.8726\n",
            "Epoch 579/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3757 - accuracy: 0.8721 - val_loss: 0.3741 - val_accuracy: 0.8710\n",
            "Epoch 580/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3756 - accuracy: 0.8716 - val_loss: 0.3739 - val_accuracy: 0.8737\n",
            "Epoch 581/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3755 - accuracy: 0.8723 - val_loss: 0.3748 - val_accuracy: 0.8747\n",
            "Epoch 582/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3754 - accuracy: 0.8719 - val_loss: 0.3738 - val_accuracy: 0.8742\n",
            "Epoch 583/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3753 - accuracy: 0.8715 - val_loss: 0.3736 - val_accuracy: 0.8738\n",
            "Epoch 584/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8721 - val_loss: 0.3733 - val_accuracy: 0.8742\n",
            "Epoch 585/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3750 - accuracy: 0.8725 - val_loss: 0.3733 - val_accuracy: 0.8719\n",
            "Epoch 586/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3749 - accuracy: 0.8722 - val_loss: 0.3732 - val_accuracy: 0.8739\n",
            "Epoch 587/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3747 - accuracy: 0.8724 - val_loss: 0.3731 - val_accuracy: 0.8747\n",
            "Epoch 588/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3746 - accuracy: 0.8719 - val_loss: 0.3731 - val_accuracy: 0.8745\n",
            "Epoch 589/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3745 - accuracy: 0.8724 - val_loss: 0.3728 - val_accuracy: 0.8742\n",
            "Epoch 590/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3744 - accuracy: 0.8719 - val_loss: 0.3728 - val_accuracy: 0.8746\n",
            "Epoch 591/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8725 - val_loss: 0.3728 - val_accuracy: 0.8722\n",
            "Epoch 592/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3741 - accuracy: 0.8722 - val_loss: 0.3724 - val_accuracy: 0.8713\n",
            "Epoch 593/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3739 - accuracy: 0.8727 - val_loss: 0.3726 - val_accuracy: 0.8738\n",
            "Epoch 594/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.8730 - val_loss: 0.3721 - val_accuracy: 0.8745\n",
            "Epoch 595/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.8724 - val_loss: 0.3722 - val_accuracy: 0.8751\n",
            "Epoch 596/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3736 - accuracy: 0.8728 - val_loss: 0.3718 - val_accuracy: 0.8740\n",
            "Epoch 597/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3734 - accuracy: 0.8728 - val_loss: 0.3717 - val_accuracy: 0.8737\n",
            "Epoch 598/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3733 - accuracy: 0.8729 - val_loss: 0.3718 - val_accuracy: 0.8717\n",
            "Epoch 599/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3732 - accuracy: 0.8728 - val_loss: 0.3714 - val_accuracy: 0.8730\n",
            "Epoch 600/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3730 - accuracy: 0.8727 - val_loss: 0.3713 - val_accuracy: 0.8742\n",
            "Epoch 601/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3729 - accuracy: 0.8734 - val_loss: 0.3713 - val_accuracy: 0.8741\n",
            "Epoch 602/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3728 - accuracy: 0.8733 - val_loss: 0.3710 - val_accuracy: 0.8736\n",
            "Epoch 603/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3726 - accuracy: 0.8729 - val_loss: 0.3709 - val_accuracy: 0.8731\n",
            "Epoch 604/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3726 - accuracy: 0.8732 - val_loss: 0.3708 - val_accuracy: 0.8745\n",
            "Epoch 605/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3725 - accuracy: 0.8730 - val_loss: 0.3707 - val_accuracy: 0.8743\n",
            "Epoch 606/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3723 - accuracy: 0.8733 - val_loss: 0.3706 - val_accuracy: 0.8730\n",
            "Epoch 607/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3722 - accuracy: 0.8730 - val_loss: 0.3705 - val_accuracy: 0.8734\n",
            "Epoch 608/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3720 - accuracy: 0.8730 - val_loss: 0.3706 - val_accuracy: 0.8742\n",
            "Epoch 609/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3719 - accuracy: 0.8731 - val_loss: 0.3703 - val_accuracy: 0.8749\n",
            "Epoch 610/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3718 - accuracy: 0.8729 - val_loss: 0.3707 - val_accuracy: 0.8758\n",
            "Epoch 611/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3717 - accuracy: 0.8735 - val_loss: 0.3700 - val_accuracy: 0.8725\n",
            "Epoch 612/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3716 - accuracy: 0.8732 - val_loss: 0.3699 - val_accuracy: 0.8727\n",
            "Epoch 613/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3714 - accuracy: 0.8733 - val_loss: 0.3698 - val_accuracy: 0.8752\n",
            "Epoch 614/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3713 - accuracy: 0.8735 - val_loss: 0.3696 - val_accuracy: 0.8727\n",
            "Epoch 615/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3712 - accuracy: 0.8729 - val_loss: 0.3696 - val_accuracy: 0.8750\n",
            "Epoch 616/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3711 - accuracy: 0.8740 - val_loss: 0.3694 - val_accuracy: 0.8734\n",
            "Epoch 617/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3709 - accuracy: 0.8735 - val_loss: 0.3694 - val_accuracy: 0.8756\n",
            "Epoch 618/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3708 - accuracy: 0.8736 - val_loss: 0.3692 - val_accuracy: 0.8745\n",
            "Epoch 619/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3707 - accuracy: 0.8735 - val_loss: 0.3690 - val_accuracy: 0.8752\n",
            "Epoch 620/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3705 - accuracy: 0.8735 - val_loss: 0.3696 - val_accuracy: 0.8763\n",
            "Epoch 621/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3705 - accuracy: 0.8737 - val_loss: 0.3688 - val_accuracy: 0.8744\n",
            "Epoch 622/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3703 - accuracy: 0.8738 - val_loss: 0.3692 - val_accuracy: 0.8756\n",
            "Epoch 623/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3702 - accuracy: 0.8738 - val_loss: 0.3687 - val_accuracy: 0.8724\n",
            "Epoch 624/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3701 - accuracy: 0.8737 - val_loss: 0.3685 - val_accuracy: 0.8758\n",
            "Epoch 625/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3700 - accuracy: 0.8741 - val_loss: 0.3683 - val_accuracy: 0.8756\n",
            "Epoch 626/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3699 - accuracy: 0.8740 - val_loss: 0.3682 - val_accuracy: 0.8760\n",
            "Epoch 627/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3697 - accuracy: 0.8739 - val_loss: 0.3681 - val_accuracy: 0.8761\n",
            "Epoch 628/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3696 - accuracy: 0.8741 - val_loss: 0.3679 - val_accuracy: 0.8752\n",
            "Epoch 629/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3695 - accuracy: 0.8739 - val_loss: 0.3681 - val_accuracy: 0.8764\n",
            "Epoch 630/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3694 - accuracy: 0.8740 - val_loss: 0.3678 - val_accuracy: 0.8759\n",
            "Epoch 631/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3693 - accuracy: 0.8744 - val_loss: 0.3678 - val_accuracy: 0.8731\n",
            "Epoch 632/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3691 - accuracy: 0.8744 - val_loss: 0.3676 - val_accuracy: 0.8759\n",
            "Epoch 633/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3690 - accuracy: 0.8743 - val_loss: 0.3676 - val_accuracy: 0.8765\n",
            "Epoch 634/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8740 - val_loss: 0.3675 - val_accuracy: 0.8756\n",
            "Epoch 635/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3688 - accuracy: 0.8746 - val_loss: 0.3671 - val_accuracy: 0.8745\n",
            "Epoch 636/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3687 - accuracy: 0.8746 - val_loss: 0.3671 - val_accuracy: 0.8742\n",
            "Epoch 637/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3686 - accuracy: 0.8743 - val_loss: 0.3668 - val_accuracy: 0.8752\n",
            "Epoch 638/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3684 - accuracy: 0.8743 - val_loss: 0.3670 - val_accuracy: 0.8764\n",
            "Epoch 639/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3683 - accuracy: 0.8746 - val_loss: 0.3669 - val_accuracy: 0.8727\n",
            "Epoch 640/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3682 - accuracy: 0.8745 - val_loss: 0.3666 - val_accuracy: 0.8748\n",
            "Epoch 641/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3681 - accuracy: 0.8747 - val_loss: 0.3668 - val_accuracy: 0.8727\n",
            "Epoch 642/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3679 - accuracy: 0.8744 - val_loss: 0.3665 - val_accuracy: 0.8766\n",
            "Epoch 643/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3679 - accuracy: 0.8748 - val_loss: 0.3663 - val_accuracy: 0.8748\n",
            "Epoch 644/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3677 - accuracy: 0.8750 - val_loss: 0.3661 - val_accuracy: 0.8762\n",
            "Epoch 645/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3676 - accuracy: 0.8748 - val_loss: 0.3660 - val_accuracy: 0.8753\n",
            "Epoch 646/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3675 - accuracy: 0.8750 - val_loss: 0.3659 - val_accuracy: 0.8763\n",
            "Epoch 647/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3673 - accuracy: 0.8750 - val_loss: 0.3657 - val_accuracy: 0.8749\n",
            "Epoch 648/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3672 - accuracy: 0.8748 - val_loss: 0.3656 - val_accuracy: 0.8742\n",
            "Epoch 649/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3672 - accuracy: 0.8751 - val_loss: 0.3657 - val_accuracy: 0.8763\n",
            "Epoch 650/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3670 - accuracy: 0.8748 - val_loss: 0.3654 - val_accuracy: 0.8763\n",
            "Epoch 651/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3669 - accuracy: 0.8751 - val_loss: 0.3657 - val_accuracy: 0.8777\n",
            "Epoch 652/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3668 - accuracy: 0.8749 - val_loss: 0.3652 - val_accuracy: 0.8762\n",
            "Epoch 653/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3667 - accuracy: 0.8751 - val_loss: 0.3650 - val_accuracy: 0.8754\n",
            "Epoch 654/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3665 - accuracy: 0.8752 - val_loss: 0.3652 - val_accuracy: 0.8771\n",
            "Epoch 655/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3665 - accuracy: 0.8751 - val_loss: 0.3651 - val_accuracy: 0.8777\n",
            "Epoch 656/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3663 - accuracy: 0.8757 - val_loss: 0.3647 - val_accuracy: 0.8752\n",
            "Epoch 657/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3663 - accuracy: 0.8752 - val_loss: 0.3646 - val_accuracy: 0.8746\n",
            "Epoch 658/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3661 - accuracy: 0.8752 - val_loss: 0.3657 - val_accuracy: 0.8711\n",
            "Epoch 659/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3660 - accuracy: 0.8756 - val_loss: 0.3645 - val_accuracy: 0.8773\n",
            "Epoch 660/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3659 - accuracy: 0.8753 - val_loss: 0.3643 - val_accuracy: 0.8746\n",
            "Epoch 661/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3658 - accuracy: 0.8756 - val_loss: 0.3643 - val_accuracy: 0.8773\n",
            "Epoch 662/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3657 - accuracy: 0.8757 - val_loss: 0.3640 - val_accuracy: 0.8766\n",
            "Epoch 663/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3655 - accuracy: 0.8753 - val_loss: 0.3642 - val_accuracy: 0.8777\n",
            "Epoch 664/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3654 - accuracy: 0.8753 - val_loss: 0.3638 - val_accuracy: 0.8752\n",
            "Epoch 665/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3653 - accuracy: 0.8755 - val_loss: 0.3637 - val_accuracy: 0.8765\n",
            "Epoch 666/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3652 - accuracy: 0.8757 - val_loss: 0.3638 - val_accuracy: 0.8741\n",
            "Epoch 667/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3651 - accuracy: 0.8756 - val_loss: 0.3640 - val_accuracy: 0.8784\n",
            "Epoch 668/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3650 - accuracy: 0.8759 - val_loss: 0.3634 - val_accuracy: 0.8774\n",
            "Epoch 669/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3649 - accuracy: 0.8758 - val_loss: 0.3633 - val_accuracy: 0.8771\n",
            "Epoch 670/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3648 - accuracy: 0.8757 - val_loss: 0.3633 - val_accuracy: 0.8749\n",
            "Epoch 671/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3647 - accuracy: 0.8759 - val_loss: 0.3630 - val_accuracy: 0.8755\n",
            "Epoch 672/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3645 - accuracy: 0.8763 - val_loss: 0.3629 - val_accuracy: 0.8766\n",
            "Epoch 673/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3644 - accuracy: 0.8759 - val_loss: 0.3631 - val_accuracy: 0.8783\n",
            "Epoch 674/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3643 - accuracy: 0.8762 - val_loss: 0.3628 - val_accuracy: 0.8778\n",
            "Epoch 675/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3642 - accuracy: 0.8760 - val_loss: 0.3627 - val_accuracy: 0.8780\n",
            "Epoch 676/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3641 - accuracy: 0.8765 - val_loss: 0.3626 - val_accuracy: 0.8779\n",
            "Epoch 677/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3640 - accuracy: 0.8759 - val_loss: 0.3628 - val_accuracy: 0.8788\n",
            "Epoch 678/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3638 - accuracy: 0.8762 - val_loss: 0.3624 - val_accuracy: 0.8778\n",
            "Epoch 679/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3637 - accuracy: 0.8764 - val_loss: 0.3626 - val_accuracy: 0.8737\n",
            "Epoch 680/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3637 - accuracy: 0.8764 - val_loss: 0.3622 - val_accuracy: 0.8748\n",
            "Epoch 681/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3635 - accuracy: 0.8760 - val_loss: 0.3622 - val_accuracy: 0.8778\n",
            "Epoch 682/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3634 - accuracy: 0.8765 - val_loss: 0.3619 - val_accuracy: 0.8752\n",
            "Epoch 683/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3633 - accuracy: 0.8764 - val_loss: 0.3618 - val_accuracy: 0.8755\n",
            "Epoch 684/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3632 - accuracy: 0.8761 - val_loss: 0.3616 - val_accuracy: 0.8771\n",
            "Epoch 685/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3630 - accuracy: 0.8764 - val_loss: 0.3616 - val_accuracy: 0.8776\n",
            "Epoch 686/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3630 - accuracy: 0.8767 - val_loss: 0.3615 - val_accuracy: 0.8784\n",
            "Epoch 687/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3629 - accuracy: 0.8765 - val_loss: 0.3615 - val_accuracy: 0.8788\n",
            "Epoch 688/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3628 - accuracy: 0.8765 - val_loss: 0.3612 - val_accuracy: 0.8758\n",
            "Epoch 689/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3627 - accuracy: 0.8764 - val_loss: 0.3611 - val_accuracy: 0.8780\n",
            "Epoch 690/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3626 - accuracy: 0.8768 - val_loss: 0.3610 - val_accuracy: 0.8783\n",
            "Epoch 691/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3625 - accuracy: 0.8767 - val_loss: 0.3609 - val_accuracy: 0.8784\n",
            "Epoch 692/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3623 - accuracy: 0.8769 - val_loss: 0.3608 - val_accuracy: 0.8768\n",
            "Epoch 693/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3623 - accuracy: 0.8769 - val_loss: 0.3608 - val_accuracy: 0.8773\n",
            "Epoch 694/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3622 - accuracy: 0.8770 - val_loss: 0.3606 - val_accuracy: 0.8772\n",
            "Epoch 695/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3621 - accuracy: 0.8769 - val_loss: 0.3605 - val_accuracy: 0.8777\n",
            "Epoch 696/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3619 - accuracy: 0.8769 - val_loss: 0.3603 - val_accuracy: 0.8778\n",
            "Epoch 697/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3619 - accuracy: 0.8771 - val_loss: 0.3606 - val_accuracy: 0.8798\n",
            "Epoch 698/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3618 - accuracy: 0.8770 - val_loss: 0.3602 - val_accuracy: 0.8785\n",
            "Epoch 699/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3616 - accuracy: 0.8770 - val_loss: 0.3601 - val_accuracy: 0.8789\n",
            "Epoch 700/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3615 - accuracy: 0.8770 - val_loss: 0.3599 - val_accuracy: 0.8786\n",
            "Epoch 701/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3615 - accuracy: 0.8773 - val_loss: 0.3598 - val_accuracy: 0.8781\n",
            "Epoch 702/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3613 - accuracy: 0.8772 - val_loss: 0.3597 - val_accuracy: 0.8787\n",
            "Epoch 703/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3612 - accuracy: 0.8773 - val_loss: 0.3599 - val_accuracy: 0.8796\n",
            "Epoch 704/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3611 - accuracy: 0.8773 - val_loss: 0.3595 - val_accuracy: 0.8784\n",
            "Epoch 705/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3610 - accuracy: 0.8775 - val_loss: 0.3594 - val_accuracy: 0.8786\n",
            "Epoch 706/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3609 - accuracy: 0.8772 - val_loss: 0.3596 - val_accuracy: 0.8791\n",
            "Epoch 707/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3608 - accuracy: 0.8774 - val_loss: 0.3592 - val_accuracy: 0.8771\n",
            "Epoch 708/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3607 - accuracy: 0.8774 - val_loss: 0.3595 - val_accuracy: 0.8780\n",
            "Epoch 709/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3606 - accuracy: 0.8777 - val_loss: 0.3591 - val_accuracy: 0.8795\n",
            "Epoch 710/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3604 - accuracy: 0.8779 - val_loss: 0.3590 - val_accuracy: 0.8789\n",
            "Epoch 711/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3603 - accuracy: 0.8776 - val_loss: 0.3595 - val_accuracy: 0.8810\n",
            "Epoch 712/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3603 - accuracy: 0.8776 - val_loss: 0.3589 - val_accuracy: 0.8799\n",
            "Epoch 713/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3602 - accuracy: 0.8777 - val_loss: 0.3587 - val_accuracy: 0.8791\n",
            "Epoch 714/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3601 - accuracy: 0.8779 - val_loss: 0.3585 - val_accuracy: 0.8787\n",
            "Epoch 715/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3599 - accuracy: 0.8775 - val_loss: 0.3585 - val_accuracy: 0.8791\n",
            "Epoch 716/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3598 - accuracy: 0.8781 - val_loss: 0.3585 - val_accuracy: 0.8786\n",
            "Epoch 717/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3598 - accuracy: 0.8781 - val_loss: 0.3582 - val_accuracy: 0.8788\n",
            "Epoch 718/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3597 - accuracy: 0.8782 - val_loss: 0.3581 - val_accuracy: 0.8785\n",
            "Epoch 719/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3595 - accuracy: 0.8782 - val_loss: 0.3580 - val_accuracy: 0.8786\n",
            "Epoch 720/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3595 - accuracy: 0.8782 - val_loss: 0.3583 - val_accuracy: 0.8809\n",
            "Epoch 721/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3594 - accuracy: 0.8779 - val_loss: 0.3578 - val_accuracy: 0.8792\n",
            "Epoch 722/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3592 - accuracy: 0.8780 - val_loss: 0.3579 - val_accuracy: 0.8805\n",
            "Epoch 723/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3591 - accuracy: 0.8780 - val_loss: 0.3576 - val_accuracy: 0.8788\n",
            "Epoch 724/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3591 - accuracy: 0.8780 - val_loss: 0.3575 - val_accuracy: 0.8789\n",
            "Epoch 725/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3589 - accuracy: 0.8779 - val_loss: 0.3575 - val_accuracy: 0.8802\n",
            "Epoch 726/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3589 - accuracy: 0.8785 - val_loss: 0.3576 - val_accuracy: 0.8812\n",
            "Epoch 727/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3587 - accuracy: 0.8781 - val_loss: 0.3572 - val_accuracy: 0.8788\n",
            "Epoch 728/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3587 - accuracy: 0.8786 - val_loss: 0.3572 - val_accuracy: 0.8771\n",
            "Epoch 729/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3585 - accuracy: 0.8782 - val_loss: 0.3574 - val_accuracy: 0.8767\n",
            "Epoch 730/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3584 - accuracy: 0.8787 - val_loss: 0.3570 - val_accuracy: 0.8802\n",
            "Epoch 731/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3584 - accuracy: 0.8784 - val_loss: 0.3571 - val_accuracy: 0.8814\n",
            "Epoch 732/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3583 - accuracy: 0.8783 - val_loss: 0.3567 - val_accuracy: 0.8795\n",
            "Epoch 733/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3582 - accuracy: 0.8789 - val_loss: 0.3569 - val_accuracy: 0.8767\n",
            "Epoch 734/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3581 - accuracy: 0.8787 - val_loss: 0.3565 - val_accuracy: 0.8791\n",
            "Epoch 735/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3579 - accuracy: 0.8788 - val_loss: 0.3567 - val_accuracy: 0.8811\n",
            "Epoch 736/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3578 - accuracy: 0.8788 - val_loss: 0.3564 - val_accuracy: 0.8808\n",
            "Epoch 737/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3578 - accuracy: 0.8788 - val_loss: 0.3564 - val_accuracy: 0.8803\n",
            "Epoch 738/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3577 - accuracy: 0.8785 - val_loss: 0.3561 - val_accuracy: 0.8788\n",
            "Epoch 739/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3576 - accuracy: 0.8788 - val_loss: 0.3565 - val_accuracy: 0.8805\n",
            "Epoch 740/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3574 - accuracy: 0.8791 - val_loss: 0.3560 - val_accuracy: 0.8812\n",
            "Epoch 741/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3574 - accuracy: 0.8793 - val_loss: 0.3559 - val_accuracy: 0.8778\n",
            "Epoch 742/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3573 - accuracy: 0.8790 - val_loss: 0.3558 - val_accuracy: 0.8804\n",
            "Epoch 743/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3571 - accuracy: 0.8792 - val_loss: 0.3559 - val_accuracy: 0.8778\n",
            "Epoch 744/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3570 - accuracy: 0.8792 - val_loss: 0.3557 - val_accuracy: 0.8770\n",
            "Epoch 745/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3570 - accuracy: 0.8789 - val_loss: 0.3555 - val_accuracy: 0.8808\n",
            "Epoch 746/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3569 - accuracy: 0.8795 - val_loss: 0.3554 - val_accuracy: 0.8802\n",
            "Epoch 747/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3568 - accuracy: 0.8794 - val_loss: 0.3553 - val_accuracy: 0.8795\n",
            "Epoch 748/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3567 - accuracy: 0.8792 - val_loss: 0.3554 - val_accuracy: 0.8775\n",
            "Epoch 749/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3566 - accuracy: 0.8792 - val_loss: 0.3551 - val_accuracy: 0.8791\n",
            "Epoch 750/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3565 - accuracy: 0.8794 - val_loss: 0.3550 - val_accuracy: 0.8810\n",
            "Epoch 751/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3564 - accuracy: 0.8795 - val_loss: 0.3551 - val_accuracy: 0.8813\n",
            "Epoch 752/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3563 - accuracy: 0.8793 - val_loss: 0.3551 - val_accuracy: 0.8820\n",
            "Epoch 753/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3561 - accuracy: 0.8793 - val_loss: 0.3548 - val_accuracy: 0.8813\n",
            "Epoch 754/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3561 - accuracy: 0.8795 - val_loss: 0.3546 - val_accuracy: 0.8798\n",
            "Epoch 755/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3560 - accuracy: 0.8796 - val_loss: 0.3547 - val_accuracy: 0.8808\n",
            "Epoch 756/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3559 - accuracy: 0.8798 - val_loss: 0.3549 - val_accuracy: 0.8773\n",
            "Epoch 757/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3558 - accuracy: 0.8793 - val_loss: 0.3543 - val_accuracy: 0.8809\n",
            "Epoch 758/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3557 - accuracy: 0.8795 - val_loss: 0.3543 - val_accuracy: 0.8806\n",
            "Epoch 759/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3556 - accuracy: 0.8801 - val_loss: 0.3543 - val_accuracy: 0.8819\n",
            "Epoch 760/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3555 - accuracy: 0.8803 - val_loss: 0.3540 - val_accuracy: 0.8804\n",
            "Epoch 761/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3554 - accuracy: 0.8803 - val_loss: 0.3540 - val_accuracy: 0.8808\n",
            "Epoch 762/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3553 - accuracy: 0.8797 - val_loss: 0.3540 - val_accuracy: 0.8781\n",
            "Epoch 763/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3553 - accuracy: 0.8796 - val_loss: 0.3538 - val_accuracy: 0.8813\n",
            "Epoch 764/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3551 - accuracy: 0.8806 - val_loss: 0.3538 - val_accuracy: 0.8805\n",
            "Epoch 765/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3551 - accuracy: 0.8800 - val_loss: 0.3537 - val_accuracy: 0.8808\n",
            "Epoch 766/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3550 - accuracy: 0.8804 - val_loss: 0.3535 - val_accuracy: 0.8811\n",
            "Epoch 767/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3548 - accuracy: 0.8799 - val_loss: 0.3536 - val_accuracy: 0.8824\n",
            "Epoch 768/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3547 - accuracy: 0.8799 - val_loss: 0.3536 - val_accuracy: 0.8827\n",
            "Epoch 769/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3546 - accuracy: 0.8803 - val_loss: 0.3538 - val_accuracy: 0.8776\n",
            "Epoch 770/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3546 - accuracy: 0.8802 - val_loss: 0.3532 - val_accuracy: 0.8811\n",
            "Epoch 771/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3545 - accuracy: 0.8800 - val_loss: 0.3530 - val_accuracy: 0.8820\n",
            "Epoch 772/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3544 - accuracy: 0.8799 - val_loss: 0.3530 - val_accuracy: 0.8816\n",
            "Epoch 773/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3543 - accuracy: 0.8805 - val_loss: 0.3529 - val_accuracy: 0.8822\n",
            "Epoch 774/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3542 - accuracy: 0.8804 - val_loss: 0.3528 - val_accuracy: 0.8799\n",
            "Epoch 775/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3541 - accuracy: 0.8803 - val_loss: 0.3527 - val_accuracy: 0.8814\n",
            "Epoch 776/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3540 - accuracy: 0.8809 - val_loss: 0.3526 - val_accuracy: 0.8816\n",
            "Epoch 777/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3539 - accuracy: 0.8807 - val_loss: 0.3526 - val_accuracy: 0.8821\n",
            "Epoch 778/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3538 - accuracy: 0.8806 - val_loss: 0.3524 - val_accuracy: 0.8810\n",
            "Epoch 779/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3537 - accuracy: 0.8808 - val_loss: 0.3524 - val_accuracy: 0.8809\n",
            "Epoch 780/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3536 - accuracy: 0.8809 - val_loss: 0.3522 - val_accuracy: 0.8803\n",
            "Epoch 781/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8809 - val_loss: 0.3521 - val_accuracy: 0.8820\n",
            "Epoch 782/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8808 - val_loss: 0.3520 - val_accuracy: 0.8823\n",
            "Epoch 783/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3533 - accuracy: 0.8808 - val_loss: 0.3519 - val_accuracy: 0.8820\n",
            "Epoch 784/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3533 - accuracy: 0.8802 - val_loss: 0.3520 - val_accuracy: 0.8824\n",
            "Epoch 785/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3532 - accuracy: 0.8807 - val_loss: 0.3518 - val_accuracy: 0.8820\n",
            "Epoch 786/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3531 - accuracy: 0.8808 - val_loss: 0.3517 - val_accuracy: 0.8826\n",
            "Epoch 787/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3530 - accuracy: 0.8811 - val_loss: 0.3516 - val_accuracy: 0.8823\n",
            "Epoch 788/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3529 - accuracy: 0.8811 - val_loss: 0.3515 - val_accuracy: 0.8819\n",
            "Epoch 789/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3528 - accuracy: 0.8807 - val_loss: 0.3515 - val_accuracy: 0.8817\n",
            "Epoch 790/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3527 - accuracy: 0.8810 - val_loss: 0.3516 - val_accuracy: 0.8789\n",
            "Epoch 791/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3526 - accuracy: 0.8810 - val_loss: 0.3515 - val_accuracy: 0.8798\n",
            "Epoch 792/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3525 - accuracy: 0.8813 - val_loss: 0.3514 - val_accuracy: 0.8785\n",
            "Epoch 793/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3524 - accuracy: 0.8807 - val_loss: 0.3510 - val_accuracy: 0.8823\n",
            "Epoch 794/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3524 - accuracy: 0.8813 - val_loss: 0.3512 - val_accuracy: 0.8790\n",
            "Epoch 795/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3522 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8826\n",
            "Epoch 796/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3522 - accuracy: 0.8813 - val_loss: 0.3509 - val_accuracy: 0.8834\n",
            "Epoch 797/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3520 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8835\n",
            "Epoch 798/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3520 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8835\n",
            "Epoch 799/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3519 - accuracy: 0.8814 - val_loss: 0.3506 - val_accuracy: 0.8819\n",
            "Epoch 800/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3518 - accuracy: 0.8812 - val_loss: 0.3510 - val_accuracy: 0.8786\n",
            "Epoch 801/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3517 - accuracy: 0.8818 - val_loss: 0.3506 - val_accuracy: 0.8827\n",
            "Epoch 802/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3517 - accuracy: 0.8816 - val_loss: 0.3503 - val_accuracy: 0.8828\n",
            "Epoch 803/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3516 - accuracy: 0.8817 - val_loss: 0.3503 - val_accuracy: 0.8834\n",
            "Epoch 804/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3514 - accuracy: 0.8819 - val_loss: 0.3502 - val_accuracy: 0.8811\n",
            "Epoch 805/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3514 - accuracy: 0.8816 - val_loss: 0.3501 - val_accuracy: 0.8830\n",
            "Epoch 806/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3513 - accuracy: 0.8816 - val_loss: 0.3502 - val_accuracy: 0.8817\n",
            "Epoch 807/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3512 - accuracy: 0.8819 - val_loss: 0.3498 - val_accuracy: 0.8829\n",
            "Epoch 808/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.8816 - val_loss: 0.3500 - val_accuracy: 0.8831\n",
            "Epoch 809/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.8821 - val_loss: 0.3496 - val_accuracy: 0.8821\n",
            "Epoch 810/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3509 - accuracy: 0.8820 - val_loss: 0.3496 - val_accuracy: 0.8820\n",
            "Epoch 811/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3508 - accuracy: 0.8818 - val_loss: 0.3498 - val_accuracy: 0.8836\n",
            "Epoch 812/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3508 - accuracy: 0.8820 - val_loss: 0.3494 - val_accuracy: 0.8822\n",
            "Epoch 813/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3507 - accuracy: 0.8822 - val_loss: 0.3493 - val_accuracy: 0.8837\n",
            "Epoch 814/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3505 - accuracy: 0.8822 - val_loss: 0.3492 - val_accuracy: 0.8826\n",
            "Epoch 815/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3505 - accuracy: 0.8821 - val_loss: 0.3493 - val_accuracy: 0.8841\n",
            "Epoch 816/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3504 - accuracy: 0.8821 - val_loss: 0.3490 - val_accuracy: 0.8834\n",
            "Epoch 817/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3503 - accuracy: 0.8822 - val_loss: 0.3494 - val_accuracy: 0.8845\n",
            "Epoch 818/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3502 - accuracy: 0.8823 - val_loss: 0.3490 - val_accuracy: 0.8839\n",
            "Epoch 819/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3501 - accuracy: 0.8819 - val_loss: 0.3488 - val_accuracy: 0.8842\n",
            "Epoch 820/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3501 - accuracy: 0.8822 - val_loss: 0.3489 - val_accuracy: 0.8815\n",
            "Epoch 821/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3500 - accuracy: 0.8824 - val_loss: 0.3488 - val_accuracy: 0.8842\n",
            "Epoch 822/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3499 - accuracy: 0.8824 - val_loss: 0.3485 - val_accuracy: 0.8826\n",
            "Epoch 823/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3498 - accuracy: 0.8823 - val_loss: 0.3485 - val_accuracy: 0.8835\n",
            "Epoch 824/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3497 - accuracy: 0.8826 - val_loss: 0.3483 - val_accuracy: 0.8824\n",
            "Epoch 825/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8826 - val_loss: 0.3483 - val_accuracy: 0.8841\n",
            "Epoch 826/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8828 - val_loss: 0.3482 - val_accuracy: 0.8836\n",
            "Epoch 827/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3495 - accuracy: 0.8829 - val_loss: 0.3483 - val_accuracy: 0.8846\n",
            "Epoch 828/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3494 - accuracy: 0.8826 - val_loss: 0.3480 - val_accuracy: 0.8841\n",
            "Epoch 829/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3493 - accuracy: 0.8824 - val_loss: 0.3480 - val_accuracy: 0.8840\n",
            "Epoch 830/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3492 - accuracy: 0.8824 - val_loss: 0.3481 - val_accuracy: 0.8844\n",
            "Epoch 831/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3491 - accuracy: 0.8828 - val_loss: 0.3481 - val_accuracy: 0.8807\n",
            "Epoch 832/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3490 - accuracy: 0.8831 - val_loss: 0.3478 - val_accuracy: 0.8845\n",
            "Epoch 833/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3489 - accuracy: 0.8826 - val_loss: 0.3477 - val_accuracy: 0.8828\n",
            "Epoch 834/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3488 - accuracy: 0.8826 - val_loss: 0.3476 - val_accuracy: 0.8840\n",
            "Epoch 835/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3488 - accuracy: 0.8830 - val_loss: 0.3474 - val_accuracy: 0.8838\n",
            "Epoch 836/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3487 - accuracy: 0.8832 - val_loss: 0.3473 - val_accuracy: 0.8844\n",
            "Epoch 837/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3486 - accuracy: 0.8828 - val_loss: 0.3476 - val_accuracy: 0.8828\n",
            "Epoch 838/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3485 - accuracy: 0.8828 - val_loss: 0.3472 - val_accuracy: 0.8848\n",
            "Epoch 839/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3471 - val_accuracy: 0.8832\n",
            "Epoch 840/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3483 - accuracy: 0.8832 - val_loss: 0.3472 - val_accuracy: 0.8849\n",
            "Epoch 841/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3483 - accuracy: 0.8832 - val_loss: 0.3469 - val_accuracy: 0.8839\n",
            "Epoch 842/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3482 - accuracy: 0.8833 - val_loss: 0.3470 - val_accuracy: 0.8856\n",
            "Epoch 843/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3481 - accuracy: 0.8827 - val_loss: 0.3469 - val_accuracy: 0.8839\n",
            "Epoch 844/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3480 - accuracy: 0.8834 - val_loss: 0.3468 - val_accuracy: 0.8817\n",
            "Epoch 845/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3479 - accuracy: 0.8831 - val_loss: 0.3468 - val_accuracy: 0.8844\n",
            "Epoch 846/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3478 - accuracy: 0.8834 - val_loss: 0.3466 - val_accuracy: 0.8838\n",
            "Epoch 847/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3477 - accuracy: 0.8834 - val_loss: 0.3465 - val_accuracy: 0.8828\n",
            "Epoch 848/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3477 - accuracy: 0.8834 - val_loss: 0.3465 - val_accuracy: 0.8854\n",
            "Epoch 849/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3476 - accuracy: 0.8833 - val_loss: 0.3463 - val_accuracy: 0.8841\n",
            "Epoch 850/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3474 - accuracy: 0.8835 - val_loss: 0.3469 - val_accuracy: 0.8861\n",
            "Epoch 851/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3474 - accuracy: 0.8831 - val_loss: 0.3469 - val_accuracy: 0.8791\n",
            "Epoch 852/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3473 - accuracy: 0.8837 - val_loss: 0.3460 - val_accuracy: 0.8850\n",
            "Epoch 853/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3472 - accuracy: 0.8837 - val_loss: 0.3460 - val_accuracy: 0.8849\n",
            "Epoch 854/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3472 - accuracy: 0.8840 - val_loss: 0.3458 - val_accuracy: 0.8842\n",
            "Epoch 855/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3471 - accuracy: 0.8835 - val_loss: 0.3458 - val_accuracy: 0.8852\n",
            "Epoch 856/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3470 - accuracy: 0.8832 - val_loss: 0.3458 - val_accuracy: 0.8839\n",
            "Epoch 857/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3470 - accuracy: 0.8841 - val_loss: 0.3456 - val_accuracy: 0.8846\n",
            "Epoch 858/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3468 - accuracy: 0.8836 - val_loss: 0.3456 - val_accuracy: 0.8839\n",
            "Epoch 859/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3468 - accuracy: 0.8837 - val_loss: 0.3457 - val_accuracy: 0.8831\n",
            "Epoch 860/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3466 - accuracy: 0.8838 - val_loss: 0.3455 - val_accuracy: 0.8823\n",
            "Epoch 861/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3466 - accuracy: 0.8839 - val_loss: 0.3458 - val_accuracy: 0.8806\n",
            "Epoch 862/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3465 - accuracy: 0.8835 - val_loss: 0.3452 - val_accuracy: 0.8854\n",
            "Epoch 863/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3464 - accuracy: 0.8838 - val_loss: 0.3452 - val_accuracy: 0.8852\n",
            "Epoch 864/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3464 - accuracy: 0.8840 - val_loss: 0.3451 - val_accuracy: 0.8846\n",
            "Epoch 865/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3462 - accuracy: 0.8839 - val_loss: 0.3453 - val_accuracy: 0.8856\n",
            "Epoch 866/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3462 - accuracy: 0.8840 - val_loss: 0.3448 - val_accuracy: 0.8851\n",
            "Epoch 867/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3461 - accuracy: 0.8840 - val_loss: 0.3452 - val_accuracy: 0.8856\n",
            "Epoch 868/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3461 - accuracy: 0.8842 - val_loss: 0.3448 - val_accuracy: 0.8840\n",
            "Epoch 869/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3459 - accuracy: 0.8840 - val_loss: 0.3447 - val_accuracy: 0.8856\n",
            "Epoch 870/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3458 - accuracy: 0.8843 - val_loss: 0.3453 - val_accuracy: 0.8816\n",
            "Epoch 871/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3458 - accuracy: 0.8838 - val_loss: 0.3446 - val_accuracy: 0.8845\n",
            "Epoch 872/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3457 - accuracy: 0.8838 - val_loss: 0.3444 - val_accuracy: 0.8853\n",
            "Epoch 873/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3456 - accuracy: 0.8846 - val_loss: 0.3443 - val_accuracy: 0.8849\n",
            "Epoch 874/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3455 - accuracy: 0.8840 - val_loss: 0.3443 - val_accuracy: 0.8854\n",
            "Epoch 875/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3455 - accuracy: 0.8845 - val_loss: 0.3443 - val_accuracy: 0.8860\n",
            "Epoch 876/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3454 - accuracy: 0.8843 - val_loss: 0.3445 - val_accuracy: 0.8867\n",
            "Epoch 877/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3453 - accuracy: 0.8843 - val_loss: 0.3441 - val_accuracy: 0.8852\n",
            "Epoch 878/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3452 - accuracy: 0.8843 - val_loss: 0.3440 - val_accuracy: 0.8859\n",
            "Epoch 879/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3452 - accuracy: 0.8847 - val_loss: 0.3439 - val_accuracy: 0.8859\n",
            "Epoch 880/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3451 - accuracy: 0.8847 - val_loss: 0.3439 - val_accuracy: 0.8861\n",
            "Epoch 881/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3450 - accuracy: 0.8847 - val_loss: 0.3438 - val_accuracy: 0.8859\n",
            "Epoch 882/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3449 - accuracy: 0.8848 - val_loss: 0.3436 - val_accuracy: 0.8853\n",
            "Epoch 883/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3449 - accuracy: 0.8846 - val_loss: 0.3435 - val_accuracy: 0.8854\n",
            "Epoch 884/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3447 - accuracy: 0.8845 - val_loss: 0.3436 - val_accuracy: 0.8832\n",
            "Epoch 885/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3447 - accuracy: 0.8845 - val_loss: 0.3435 - val_accuracy: 0.8863\n",
            "Epoch 886/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3446 - accuracy: 0.8848 - val_loss: 0.3434 - val_accuracy: 0.8841\n",
            "Epoch 887/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3445 - accuracy: 0.8851 - val_loss: 0.3433 - val_accuracy: 0.8860\n",
            "Epoch 888/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3444 - accuracy: 0.8848 - val_loss: 0.3432 - val_accuracy: 0.8862\n",
            "Epoch 889/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3443 - accuracy: 0.8845 - val_loss: 0.3439 - val_accuracy: 0.8881\n",
            "Epoch 890/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3443 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8849\n",
            "Epoch 891/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3442 - accuracy: 0.8850 - val_loss: 0.3429 - val_accuracy: 0.8864\n",
            "Epoch 892/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3441 - accuracy: 0.8849 - val_loss: 0.3428 - val_accuracy: 0.8865\n",
            "Epoch 893/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3440 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8868\n",
            "Epoch 894/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3440 - accuracy: 0.8847 - val_loss: 0.3430 - val_accuracy: 0.8870\n",
            "Epoch 895/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3439 - accuracy: 0.8856 - val_loss: 0.3426 - val_accuracy: 0.8863\n",
            "Epoch 896/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3438 - accuracy: 0.8856 - val_loss: 0.3426 - val_accuracy: 0.8861\n",
            "Epoch 897/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3437 - accuracy: 0.8854 - val_loss: 0.3426 - val_accuracy: 0.8856\n",
            "Epoch 898/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3437 - accuracy: 0.8853 - val_loss: 0.3424 - val_accuracy: 0.8865\n",
            "Epoch 899/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3436 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8866\n",
            "Epoch 900/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3435 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8867\n",
            "Epoch 901/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3434 - accuracy: 0.8854 - val_loss: 0.3421 - val_accuracy: 0.8857\n",
            "Epoch 902/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3433 - accuracy: 0.8853 - val_loss: 0.3424 - val_accuracy: 0.8871\n",
            "Epoch 903/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3432 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8844\n",
            "Epoch 904/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3432 - accuracy: 0.8848 - val_loss: 0.3420 - val_accuracy: 0.8867\n",
            "Epoch 905/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8856 - val_loss: 0.3418 - val_accuracy: 0.8863\n",
            "Epoch 906/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8853 - val_loss: 0.3422 - val_accuracy: 0.8880\n",
            "Epoch 907/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3430 - accuracy: 0.8853 - val_loss: 0.3417 - val_accuracy: 0.8860\n",
            "Epoch 908/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3428 - accuracy: 0.8856 - val_loss: 0.3417 - val_accuracy: 0.8859\n",
            "Epoch 909/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3428 - accuracy: 0.8856 - val_loss: 0.3417 - val_accuracy: 0.8859\n",
            "Epoch 910/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3427 - accuracy: 0.8858 - val_loss: 0.3415 - val_accuracy: 0.8862\n",
            "Epoch 911/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3427 - accuracy: 0.8855 - val_loss: 0.3414 - val_accuracy: 0.8867\n",
            "Epoch 912/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3426 - accuracy: 0.8860 - val_loss: 0.3416 - val_accuracy: 0.8866\n",
            "Epoch 913/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3424 - accuracy: 0.8855 - val_loss: 0.3413 - val_accuracy: 0.8863\n",
            "Epoch 914/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3424 - accuracy: 0.8853 - val_loss: 0.3412 - val_accuracy: 0.8867\n",
            "Epoch 915/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3424 - accuracy: 0.8859 - val_loss: 0.3411 - val_accuracy: 0.8864\n",
            "Epoch 916/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3423 - accuracy: 0.8859 - val_loss: 0.3410 - val_accuracy: 0.8860\n",
            "Epoch 917/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3422 - accuracy: 0.8857 - val_loss: 0.3414 - val_accuracy: 0.8843\n",
            "Epoch 918/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3421 - accuracy: 0.8858 - val_loss: 0.3411 - val_accuracy: 0.8849\n",
            "Epoch 919/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3421 - accuracy: 0.8858 - val_loss: 0.3408 - val_accuracy: 0.8859\n",
            "Epoch 920/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3420 - accuracy: 0.8861 - val_loss: 0.3410 - val_accuracy: 0.8878\n",
            "Epoch 921/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3419 - accuracy: 0.8861 - val_loss: 0.3410 - val_accuracy: 0.8856\n",
            "Epoch 922/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3418 - accuracy: 0.8858 - val_loss: 0.3408 - val_accuracy: 0.8844\n",
            "Epoch 923/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3418 - accuracy: 0.8860 - val_loss: 0.3405 - val_accuracy: 0.8868\n",
            "Epoch 924/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3417 - accuracy: 0.8860 - val_loss: 0.3404 - val_accuracy: 0.8867\n",
            "Epoch 925/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3416 - accuracy: 0.8861 - val_loss: 0.3405 - val_accuracy: 0.8856\n",
            "Epoch 926/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3415 - accuracy: 0.8860 - val_loss: 0.3405 - val_accuracy: 0.8853\n",
            "Epoch 927/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3415 - accuracy: 0.8861 - val_loss: 0.3403 - val_accuracy: 0.8860\n",
            "Epoch 928/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3414 - accuracy: 0.8858 - val_loss: 0.3402 - val_accuracy: 0.8864\n",
            "Epoch 929/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3413 - accuracy: 0.8860 - val_loss: 0.3402 - val_accuracy: 0.8881\n",
            "Epoch 930/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3413 - accuracy: 0.8864 - val_loss: 0.3401 - val_accuracy: 0.8878\n",
            "Epoch 931/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3412 - accuracy: 0.8863 - val_loss: 0.3403 - val_accuracy: 0.8842\n",
            "Epoch 932/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3411 - accuracy: 0.8860 - val_loss: 0.3401 - val_accuracy: 0.8850\n",
            "Epoch 933/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3410 - accuracy: 0.8863 - val_loss: 0.3398 - val_accuracy: 0.8871\n",
            "Epoch 934/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8860 - val_loss: 0.3397 - val_accuracy: 0.8868\n",
            "Epoch 935/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8861 - val_loss: 0.3397 - val_accuracy: 0.8873\n",
            "Epoch 936/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3408 - accuracy: 0.8862 - val_loss: 0.3399 - val_accuracy: 0.8878\n",
            "Epoch 937/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3407 - accuracy: 0.8862 - val_loss: 0.3396 - val_accuracy: 0.8881\n",
            "Epoch 938/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3407 - accuracy: 0.8868 - val_loss: 0.3395 - val_accuracy: 0.8866\n",
            "Epoch 939/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3406 - accuracy: 0.8864 - val_loss: 0.3395 - val_accuracy: 0.8878\n",
            "Epoch 940/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8866 - val_loss: 0.3394 - val_accuracy: 0.8887\n",
            "Epoch 941/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8870 - val_loss: 0.3395 - val_accuracy: 0.8885\n",
            "Epoch 942/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3404 - accuracy: 0.8862 - val_loss: 0.3398 - val_accuracy: 0.8892\n",
            "Epoch 943/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3403 - accuracy: 0.8869 - val_loss: 0.3391 - val_accuracy: 0.8864\n",
            "Epoch 944/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3402 - accuracy: 0.8864 - val_loss: 0.3395 - val_accuracy: 0.8881\n",
            "Epoch 945/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3401 - accuracy: 0.8863 - val_loss: 0.3393 - val_accuracy: 0.8870\n",
            "Epoch 946/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8869 - val_loss: 0.3389 - val_accuracy: 0.8868\n",
            "Epoch 947/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8868 - val_loss: 0.3388 - val_accuracy: 0.8868\n",
            "Epoch 948/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3399 - accuracy: 0.8865 - val_loss: 0.3388 - val_accuracy: 0.8884\n",
            "Epoch 949/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3399 - accuracy: 0.8864 - val_loss: 0.3389 - val_accuracy: 0.8892\n",
            "Epoch 950/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8866 - val_loss: 0.3386 - val_accuracy: 0.8863\n",
            "Epoch 951/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8868 - val_loss: 0.3386 - val_accuracy: 0.8877\n",
            "Epoch 952/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3397 - accuracy: 0.8867 - val_loss: 0.3385 - val_accuracy: 0.8881\n",
            "Epoch 953/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3396 - accuracy: 0.8869 - val_loss: 0.3384 - val_accuracy: 0.8887\n",
            "Epoch 954/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3395 - accuracy: 0.8871 - val_loss: 0.3384 - val_accuracy: 0.8876\n",
            "Epoch 955/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3394 - accuracy: 0.8867 - val_loss: 0.3383 - val_accuracy: 0.8888\n",
            "Epoch 956/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3394 - accuracy: 0.8869 - val_loss: 0.3381 - val_accuracy: 0.8878\n",
            "Epoch 957/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3393 - accuracy: 0.8870 - val_loss: 0.3382 - val_accuracy: 0.8888\n",
            "Epoch 958/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3392 - accuracy: 0.8875 - val_loss: 0.3384 - val_accuracy: 0.8852\n",
            "Epoch 959/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3391 - accuracy: 0.8869 - val_loss: 0.3380 - val_accuracy: 0.8870\n",
            "Epoch 960/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3390 - accuracy: 0.8868 - val_loss: 0.3379 - val_accuracy: 0.8892\n",
            "Epoch 961/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3390 - accuracy: 0.8874 - val_loss: 0.3379 - val_accuracy: 0.8878\n",
            "Epoch 962/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8871 - val_loss: 0.3377 - val_accuracy: 0.8884\n",
            "Epoch 963/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8871 - val_loss: 0.3378 - val_accuracy: 0.8866\n",
            "Epoch 964/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3388 - accuracy: 0.8868 - val_loss: 0.3377 - val_accuracy: 0.8870\n",
            "Epoch 965/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3387 - accuracy: 0.8872 - val_loss: 0.3376 - val_accuracy: 0.8877\n",
            "Epoch 966/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8871\n",
            "Epoch 967/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8892\n",
            "Epoch 968/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3385 - accuracy: 0.8875 - val_loss: 0.3374 - val_accuracy: 0.8867\n",
            "Epoch 969/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3385 - accuracy: 0.8872 - val_loss: 0.3373 - val_accuracy: 0.8878\n",
            "Epoch 970/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3384 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8902\n",
            "Epoch 971/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3383 - accuracy: 0.8878 - val_loss: 0.3372 - val_accuracy: 0.8874\n",
            "Epoch 972/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3382 - accuracy: 0.8873 - val_loss: 0.3371 - val_accuracy: 0.8883\n",
            "Epoch 973/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8873 - val_loss: 0.3372 - val_accuracy: 0.8866\n",
            "Epoch 974/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8875 - val_loss: 0.3369 - val_accuracy: 0.8878\n",
            "Epoch 975/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.8875 - val_loss: 0.3370 - val_accuracy: 0.8898\n",
            "Epoch 976/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3380 - accuracy: 0.8872 - val_loss: 0.3369 - val_accuracy: 0.8891\n",
            "Epoch 977/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3379 - accuracy: 0.8874 - val_loss: 0.3368 - val_accuracy: 0.8892\n",
            "Epoch 978/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3378 - accuracy: 0.8872 - val_loss: 0.3366 - val_accuracy: 0.8888\n",
            "Epoch 979/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3377 - accuracy: 0.8876 - val_loss: 0.3371 - val_accuracy: 0.8906\n",
            "Epoch 980/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8882 - val_loss: 0.3366 - val_accuracy: 0.8900\n",
            "Epoch 981/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3376 - accuracy: 0.8875 - val_loss: 0.3368 - val_accuracy: 0.8907\n",
            "Epoch 982/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3376 - accuracy: 0.8877 - val_loss: 0.3365 - val_accuracy: 0.8868\n",
            "Epoch 983/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3375 - accuracy: 0.8879 - val_loss: 0.3364 - val_accuracy: 0.8875\n",
            "Epoch 984/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3374 - accuracy: 0.8875 - val_loss: 0.3362 - val_accuracy: 0.8892\n",
            "Epoch 985/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3373 - accuracy: 0.8877 - val_loss: 0.3370 - val_accuracy: 0.8860\n",
            "Epoch 986/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3372 - accuracy: 0.8878 - val_loss: 0.3362 - val_accuracy: 0.8891\n",
            "Epoch 987/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3372 - accuracy: 0.8880 - val_loss: 0.3361 - val_accuracy: 0.8893\n",
            "Epoch 988/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3371 - accuracy: 0.8877 - val_loss: 0.3361 - val_accuracy: 0.8885\n",
            "Epoch 989/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3371 - accuracy: 0.8881 - val_loss: 0.3360 - val_accuracy: 0.8873\n",
            "Epoch 990/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3370 - accuracy: 0.8879 - val_loss: 0.3359 - val_accuracy: 0.8883\n",
            "Epoch 991/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3369 - accuracy: 0.8879 - val_loss: 0.3361 - val_accuracy: 0.8903\n",
            "Epoch 992/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3368 - accuracy: 0.8881 - val_loss: 0.3358 - val_accuracy: 0.8879\n",
            "Epoch 993/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3368 - accuracy: 0.8881 - val_loss: 0.3358 - val_accuracy: 0.8910\n",
            "Epoch 994/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3367 - accuracy: 0.8884 - val_loss: 0.3356 - val_accuracy: 0.8881\n",
            "Epoch 995/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3367 - accuracy: 0.8881 - val_loss: 0.3355 - val_accuracy: 0.8893\n",
            "Epoch 996/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3366 - accuracy: 0.8877 - val_loss: 0.3355 - val_accuracy: 0.8906\n",
            "Epoch 997/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3365 - accuracy: 0.8880 - val_loss: 0.3356 - val_accuracy: 0.8886\n",
            "Epoch 998/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3364 - accuracy: 0.8883 - val_loss: 0.3354 - val_accuracy: 0.8891\n",
            "Epoch 999/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3364 - accuracy: 0.8883 - val_loss: 0.3353 - val_accuracy: 0.8895\n",
            "Epoch 1000/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3363 - accuracy: 0.8885 - val_loss: 0.3360 - val_accuracy: 0.8863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = network.predict(xtest_std)"
      ],
      "metadata": {
        "id": "RrUIPDfdM5wB",
        "outputId": "91f333fc-8a46-4498-c6fc-64327834b433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat.shape)"
      ],
      "metadata": {
        "id": "GJWR1M7LN6rv",
        "outputId": "784d5925-2da5-42b3-b768-87bb6e908399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytest.shape)"
      ],
      "metadata": {
        "id": "pFXuFm6HPG0g",
        "outputId": "b1f51fcd-b608-4dfe-b0f0-4255550e35cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat =np.argmax(yhat, axis = -1)\n",
        "ytest = np.argmax(ytest, axis= -1)"
      ],
      "metadata": {
        "id": "V162us36U6Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = accuracy_score(ytest,yhat)\n",
        "cm = confusion_matrix(ytest,yhat)\n",
        "print(f\"El grado de precisión de los datos son los siguientes {100*precision}\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "yXPBisYxORs_",
        "outputId": "ca1b745c-f6c9-45ee-c91d-06ad51025d35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El grado de precisión de los datos son los siguientes 87.02\n",
            "[[11227   213   449]\n",
            " [  498  3259    35]\n",
            " [ 1392     9  2918]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función logarítimica\n",
        "\n",
        "epocas = list(range(1,501,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "plt.title(\"Grafica de aprendizaje del modelo de 500 Epochs\")\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"accuracy\"])\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_accuracy\"])\n",
        "\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "JbkIxANdZHMB",
        "outputId": "ab219508-76a5-4612-ea76-557de713283c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epocas = list(range(1,501,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"loss\"])\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_loss\"])\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "VD_qykwMajLa",
        "outputId": "d28adfd6-9493-4ae9-e82c-92979adef6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir un mapa de calor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "sns.heatmap(xtrain_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Entrenamiento\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n"
      ],
      "metadata": {
        "id": "lE0LmmEE1LMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un mapa de calor para los datos de prueba\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "sns.heatmap(xtest_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Prueba\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Py3_zIxs4elw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}