{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Proyecto_Sigmoid_Redes",
      "authorship_tag": "ABX9TyO124+ZLqknKu8gbnGXdGWY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosQuark/Machine-Learning-Astrophysics/blob/main/Proyecto_Sigmoid_Redes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# PROYECTO DE MACHINE LEARNING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvURBlWmT07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZV03xjlnj-NB"
      },
      "outputs": [],
      "source": [
        "#librerias Comunes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#liberias de PCA\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import eig\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder #Change the class to str for another type the int.\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#librerias de sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#librerias de Keras y Redes Neuronales\n",
        "\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = pd.read_csv(\"star_classification.csv\")\n",
        "data_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "OQ6pTIb2mimr",
        "outputId": "dcecbeeb-0962-4fb0-aa05-dd38327d4ee2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237660e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237660e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237660e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237660e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543780e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176010e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030110e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891860e+18   \n",
              "\n",
              "   redshift  plate    MJD  fiber_ID   class  \n",
              "0  0.634794   5812  56354       171  GALAXY  \n",
              "1  0.779136  10445  58158       427  GALAXY  \n",
              "2  0.644195   4576  55592       299  GALAXY  \n",
              "3  0.932346   9149  58039       775  GALAXY  \n",
              "4  0.116123   6121  56187       842  GALAXY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5811cba8-a968-451f-96cf-ed686342b025\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543780e+18</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176010e+19</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030110e+19</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891860e+18</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5811cba8-a968-451f-96cf-ed686342b025')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5811cba8-a968-451f-96cf-ed686342b025 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5811cba8-a968-451f-96cf-ed686342b025');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-530548f3-20e1-4e40-90de-5eac9589a525\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-530548f3-20e1-4e40-90de-5eac9589a525')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-530548f3-20e1-4e40-90de-5eac9589a525 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nlql6Qz1Znk",
        "outputId": "e983b125-54d5-4de7-e2ba-4a413826be9e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 18 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   obj_ID       100000 non-null  float64\n",
            " 1   alpha        100000 non-null  float64\n",
            " 2   delta        100000 non-null  float64\n",
            " 3   u            100000 non-null  float64\n",
            " 4   g            100000 non-null  float64\n",
            " 5   r            100000 non-null  float64\n",
            " 6   i            100000 non-null  float64\n",
            " 7   z            100000 non-null  float64\n",
            " 8   run_ID       100000 non-null  int64  \n",
            " 9   rerun_ID     100000 non-null  int64  \n",
            " 10  cam_col      100000 non-null  int64  \n",
            " 11  field_ID     100000 non-null  int64  \n",
            " 12  spec_obj_ID  100000 non-null  float64\n",
            " 13  redshift     100000 non-null  float64\n",
            " 14  plate        100000 non-null  int64  \n",
            " 15  MJD          100000 non-null  int64  \n",
            " 16  fiber_ID     100000 non-null  int64  \n",
            " 17  class        100000 non-null  object \n",
            "dtypes: float64(10), int64(7), object(1)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enconder = LabelEncoder()\n",
        "\n",
        "data_set[\"class\"] = enconder.fit_transform(data_set[\"class\"])"
      ],
      "metadata": {
        "id": "lVhT4P72weJt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar los datos\n",
        "\n",
        "Y = np.array(data_set[\"class\"])\n",
        "\n",
        "df_new = data_set.drop([\"class\"], axis =1)\n",
        "\n",
        "X = np.array(df_new)\n"
      ],
      "metadata": {
        "id": "5VSRDHJhn75L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components= 17)\n",
        "PCA_objeto.fit(X)"
      ],
      "metadata": {
        "id": "Akeqp3SySWYi",
        "outputId": "7abf16c7-d717-456d-9d3d-3de75beee01e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PCA_objeto.explained_variance_)"
      ],
      "metadata": {
        "id": "3jmLTxmoSp0Q",
        "outputId": "340dda2e-2446-41c6-a0ed-73edb649b2ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.10491489e+37 5.34345995e+28 3.63783147e+06 1.90094686e+05\n",
            " 6.89069641e+04 2.22875371e+04 8.93542373e+03 3.01724592e+03\n",
            " 3.23491013e+02 6.79740439e+00 3.42870277e+00 2.46778931e+00\n",
            " 1.93784010e+00 4.09255753e-01 3.26988977e-01 4.66492584e-02\n",
            " 3.72772496e-34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components = 17)\n",
        "Z = PCA_objeto.fit_transform(X)"
      ],
      "metadata": {
        "id": "0dytpcETSr5A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento de los datos\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Z,Y, test_size = 0.2, stratify=Y)"
      ],
      "metadata": {
        "id": "MXeQdyFvxQQ6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estandarizar los datos\n",
        "\n",
        "scaler = MinMaxScaler().fit(xtrain)\n",
        "\n",
        "xtrain_std = scaler.transform(xtrain)\n",
        "\n",
        "xtest_std = scaler.transform(xtest)\n"
      ],
      "metadata": {
        "id": "i6dJHiUQxpVc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Este apartado se utilizar para poder dar inicio el entrenamiento a una red\n",
        "neuronal\n",
        "\n",
        "   Todo esto viene dentro de la página oficial de Keras.\n",
        "\n",
        "   Dense es una capa de neurona que está conectada con todas las anteriores\n",
        "\n",
        "   Sequential es utilizado para crear secuencias en redes neuronales.\n",
        "\n",
        "   Optimizador: Adam.\n",
        "\n",
        "   units es la candtidad de clases que tienes.\n",
        "\n",
        "   activation: \"Qué tipo de función de activación almacenas\".\n",
        "\n",
        "   input_dim = la dimensionalidad.\n",
        "\n",
        "\"\"\"\n",
        "network = Sequential([\n",
        "\n",
        "    Dense(units=3, activation= \"sigmoid\" , input_dim = 17)\n",
        "])\n",
        "\n",
        "#Que copilador voy a utilizar, Adam, puede hacer eso.\n",
        "\n",
        "Adam(learning_rate=0.0001) #Taza de aprendizaje pequeña\n",
        "\n",
        "network.compile()\n",
        "\n",
        "#Función de perdida que se utilizará en la sala de entrenamient como su métrica.\n",
        "\n",
        "network.compile(loss= \"mean_squared_error\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QbP87Xplx-fX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"La libreria de keras para to_categorical\n",
        "\n",
        "   se utiliza para poder experesar problemas de clasificación de multiclase.\n",
        "   Para convertir nuestras etiquetas númericas en tipo one-hot.\n",
        "\n",
        "   Supongamso que tienes 3 clases (etiqeutas númericas 0,1,2)\n",
        "\n",
        "   En la primera linea convierte la una matriz en one-hot\n",
        "\n",
        "   Cada fila corresponde a un etiqueta, y cada columna, representa una clase.\n",
        "\n",
        "   AQUÍ INICIAMOS LA ETAPA DE ENTRENAMIENTO DE LA RED\n",
        "\n",
        "   El profe explica que es el batch_size, es para reducir el costo\n",
        "   computacional,\n",
        "   crea grupos para filas de hasta 100,000 dimensiones.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#network.fit(xtrain_std, ytrain, epochs=50, batch_size=128 )\n",
        "\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "epoch_accuracy =network.fit(xtrain_std, ytrain, epochs=1000, batch_size=80,\n",
        "                             validation_data=(xtest_std,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMrjFO3yNnb",
        "outputId": "6c35c40f-aa5a-4bc4-dedc-5705e6c78581"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.1911 - accuracy: 0.5929 - val_loss: 0.1835 - val_accuracy: 0.5944\n",
            "Epoch 2/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1814 - accuracy: 0.5945 - val_loss: 0.1792 - val_accuracy: 0.5946\n",
            "Epoch 3/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1774 - accuracy: 0.5951 - val_loss: 0.1756 - val_accuracy: 0.5961\n",
            "Epoch 4/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1742 - accuracy: 0.5970 - val_loss: 0.1726 - val_accuracy: 0.5990\n",
            "Epoch 5/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1714 - accuracy: 0.6001 - val_loss: 0.1700 - val_accuracy: 0.6028\n",
            "Epoch 6/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1689 - accuracy: 0.6031 - val_loss: 0.1675 - val_accuracy: 0.6040\n",
            "Epoch 7/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1666 - accuracy: 0.6063 - val_loss: 0.1654 - val_accuracy: 0.6058\n",
            "Epoch 8/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1645 - accuracy: 0.6095 - val_loss: 0.1631 - val_accuracy: 0.6123\n",
            "Epoch 9/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1623 - accuracy: 0.6130 - val_loss: 0.1610 - val_accuracy: 0.6173\n",
            "Epoch 10/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1603 - accuracy: 0.6182 - val_loss: 0.1589 - val_accuracy: 0.6178\n",
            "Epoch 11/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1583 - accuracy: 0.6235 - val_loss: 0.1569 - val_accuracy: 0.6255\n",
            "Epoch 12/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1564 - accuracy: 0.6303 - val_loss: 0.1551 - val_accuracy: 0.6337\n",
            "Epoch 13/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1546 - accuracy: 0.6380 - val_loss: 0.1533 - val_accuracy: 0.6451\n",
            "Epoch 14/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1528 - accuracy: 0.6450 - val_loss: 0.1515 - val_accuracy: 0.6435\n",
            "Epoch 15/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1512 - accuracy: 0.6524 - val_loss: 0.1498 - val_accuracy: 0.6549\n",
            "Epoch 16/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1496 - accuracy: 0.6604 - val_loss: 0.1482 - val_accuracy: 0.6679\n",
            "Epoch 17/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1480 - accuracy: 0.6686 - val_loss: 0.1467 - val_accuracy: 0.6699\n",
            "Epoch 18/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1465 - accuracy: 0.6767 - val_loss: 0.1452 - val_accuracy: 0.6827\n",
            "Epoch 19/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1451 - accuracy: 0.6852 - val_loss: 0.1437 - val_accuracy: 0.6887\n",
            "Epoch 20/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1436 - accuracy: 0.6931 - val_loss: 0.1423 - val_accuracy: 0.7023\n",
            "Epoch 21/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1423 - accuracy: 0.7022 - val_loss: 0.1410 - val_accuracy: 0.7002\n",
            "Epoch 22/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1410 - accuracy: 0.7084 - val_loss: 0.1397 - val_accuracy: 0.7193\n",
            "Epoch 23/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1397 - accuracy: 0.7158 - val_loss: 0.1384 - val_accuracy: 0.7236\n",
            "Epoch 24/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1385 - accuracy: 0.7224 - val_loss: 0.1372 - val_accuracy: 0.7279\n",
            "Epoch 25/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1374 - accuracy: 0.7285 - val_loss: 0.1361 - val_accuracy: 0.7376\n",
            "Epoch 26/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1362 - accuracy: 0.7348 - val_loss: 0.1349 - val_accuracy: 0.7348\n",
            "Epoch 27/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1351 - accuracy: 0.7391 - val_loss: 0.1338 - val_accuracy: 0.7455\n",
            "Epoch 28/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1341 - accuracy: 0.7453 - val_loss: 0.1328 - val_accuracy: 0.7455\n",
            "Epoch 29/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1331 - accuracy: 0.7488 - val_loss: 0.1317 - val_accuracy: 0.7516\n",
            "Epoch 30/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1321 - accuracy: 0.7539 - val_loss: 0.1308 - val_accuracy: 0.7552\n",
            "Epoch 31/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1311 - accuracy: 0.7580 - val_loss: 0.1298 - val_accuracy: 0.7621\n",
            "Epoch 32/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1302 - accuracy: 0.7621 - val_loss: 0.1289 - val_accuracy: 0.7628\n",
            "Epoch 33/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1293 - accuracy: 0.7656 - val_loss: 0.1280 - val_accuracy: 0.7671\n",
            "Epoch 34/1000\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1284 - accuracy: 0.7691 - val_loss: 0.1271 - val_accuracy: 0.7717\n",
            "Epoch 35/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1275 - accuracy: 0.7730 - val_loss: 0.1262 - val_accuracy: 0.7735\n",
            "Epoch 36/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1267 - accuracy: 0.7761 - val_loss: 0.1254 - val_accuracy: 0.7760\n",
            "Epoch 37/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1259 - accuracy: 0.7787 - val_loss: 0.1246 - val_accuracy: 0.7817\n",
            "Epoch 38/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1252 - accuracy: 0.7814 - val_loss: 0.1239 - val_accuracy: 0.7807\n",
            "Epoch 39/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1244 - accuracy: 0.7840 - val_loss: 0.1232 - val_accuracy: 0.7829\n",
            "Epoch 40/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1237 - accuracy: 0.7863 - val_loss: 0.1224 - val_accuracy: 0.7904\n",
            "Epoch 41/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1230 - accuracy: 0.7890 - val_loss: 0.1217 - val_accuracy: 0.7915\n",
            "Epoch 42/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1223 - accuracy: 0.7908 - val_loss: 0.1210 - val_accuracy: 0.7965\n",
            "Epoch 43/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1217 - accuracy: 0.7934 - val_loss: 0.1204 - val_accuracy: 0.7990\n",
            "Epoch 44/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1210 - accuracy: 0.7955 - val_loss: 0.1197 - val_accuracy: 0.8030\n",
            "Epoch 45/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1204 - accuracy: 0.7977 - val_loss: 0.1191 - val_accuracy: 0.7993\n",
            "Epoch 46/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1198 - accuracy: 0.7992 - val_loss: 0.1185 - val_accuracy: 0.8073\n",
            "Epoch 47/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1192 - accuracy: 0.8015 - val_loss: 0.1179 - val_accuracy: 0.8066\n",
            "Epoch 48/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1186 - accuracy: 0.8027 - val_loss: 0.1173 - val_accuracy: 0.8098\n",
            "Epoch 49/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1180 - accuracy: 0.8048 - val_loss: 0.1167 - val_accuracy: 0.8066\n",
            "Epoch 50/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1175 - accuracy: 0.8059 - val_loss: 0.1162 - val_accuracy: 0.8123\n",
            "Epoch 51/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1169 - accuracy: 0.8077 - val_loss: 0.1157 - val_accuracy: 0.8119\n",
            "Epoch 52/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1165 - accuracy: 0.8093 - val_loss: 0.1152 - val_accuracy: 0.8139\n",
            "Epoch 53/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1160 - accuracy: 0.8110 - val_loss: 0.1147 - val_accuracy: 0.8109\n",
            "Epoch 54/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1155 - accuracy: 0.8117 - val_loss: 0.1142 - val_accuracy: 0.8168\n",
            "Epoch 55/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1150 - accuracy: 0.8131 - val_loss: 0.1137 - val_accuracy: 0.8163\n",
            "Epoch 56/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1145 - accuracy: 0.8137 - val_loss: 0.1132 - val_accuracy: 0.8187\n",
            "Epoch 57/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1141 - accuracy: 0.8154 - val_loss: 0.1128 - val_accuracy: 0.8183\n",
            "Epoch 58/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1137 - accuracy: 0.8161 - val_loss: 0.1123 - val_accuracy: 0.8199\n",
            "Epoch 59/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1132 - accuracy: 0.8169 - val_loss: 0.1119 - val_accuracy: 0.8202\n",
            "Epoch 60/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1128 - accuracy: 0.8179 - val_loss: 0.1115 - val_accuracy: 0.8195\n",
            "Epoch 61/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1124 - accuracy: 0.8190 - val_loss: 0.1112 - val_accuracy: 0.8199\n",
            "Epoch 62/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1120 - accuracy: 0.8195 - val_loss: 0.1107 - val_accuracy: 0.8237\n",
            "Epoch 63/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1116 - accuracy: 0.8202 - val_loss: 0.1103 - val_accuracy: 0.8235\n",
            "Epoch 64/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1112 - accuracy: 0.8215 - val_loss: 0.1099 - val_accuracy: 0.8244\n",
            "Epoch 65/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1109 - accuracy: 0.8217 - val_loss: 0.1095 - val_accuracy: 0.8267\n",
            "Epoch 66/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1105 - accuracy: 0.8226 - val_loss: 0.1092 - val_accuracy: 0.8261\n",
            "Epoch 67/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1101 - accuracy: 0.8233 - val_loss: 0.1088 - val_accuracy: 0.8256\n",
            "Epoch 68/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1098 - accuracy: 0.8236 - val_loss: 0.1085 - val_accuracy: 0.8275\n",
            "Epoch 69/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1095 - accuracy: 0.8245 - val_loss: 0.1081 - val_accuracy: 0.8264\n",
            "Epoch 70/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1091 - accuracy: 0.8249 - val_loss: 0.1078 - val_accuracy: 0.8269\n",
            "Epoch 71/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1088 - accuracy: 0.8256 - val_loss: 0.1075 - val_accuracy: 0.8268\n",
            "Epoch 72/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1085 - accuracy: 0.8257 - val_loss: 0.1072 - val_accuracy: 0.8296\n",
            "Epoch 73/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1082 - accuracy: 0.8265 - val_loss: 0.1069 - val_accuracy: 0.8303\n",
            "Epoch 74/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1079 - accuracy: 0.8271 - val_loss: 0.1065 - val_accuracy: 0.8303\n",
            "Epoch 75/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1076 - accuracy: 0.8275 - val_loss: 0.1063 - val_accuracy: 0.8281\n",
            "Epoch 76/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1073 - accuracy: 0.8279 - val_loss: 0.1059 - val_accuracy: 0.8309\n",
            "Epoch 77/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1070 - accuracy: 0.8283 - val_loss: 0.1056 - val_accuracy: 0.8321\n",
            "Epoch 78/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1067 - accuracy: 0.8286 - val_loss: 0.1054 - val_accuracy: 0.8314\n",
            "Epoch 79/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1065 - accuracy: 0.8289 - val_loss: 0.1051 - val_accuracy: 0.8330\n",
            "Epoch 80/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1062 - accuracy: 0.8295 - val_loss: 0.1049 - val_accuracy: 0.8315\n",
            "Epoch 81/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1060 - accuracy: 0.8296 - val_loss: 0.1046 - val_accuracy: 0.8326\n",
            "Epoch 82/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1057 - accuracy: 0.8303 - val_loss: 0.1043 - val_accuracy: 0.8337\n",
            "Epoch 83/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1054 - accuracy: 0.8309 - val_loss: 0.1040 - val_accuracy: 0.8343\n",
            "Epoch 84/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1052 - accuracy: 0.8311 - val_loss: 0.1038 - val_accuracy: 0.8348\n",
            "Epoch 85/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1049 - accuracy: 0.8316 - val_loss: 0.1035 - val_accuracy: 0.8350\n",
            "Epoch 86/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1047 - accuracy: 0.8317 - val_loss: 0.1033 - val_accuracy: 0.8347\n",
            "Epoch 87/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1045 - accuracy: 0.8323 - val_loss: 0.1031 - val_accuracy: 0.8354\n",
            "Epoch 88/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1042 - accuracy: 0.8326 - val_loss: 0.1028 - val_accuracy: 0.8345\n",
            "Epoch 89/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1040 - accuracy: 0.8331 - val_loss: 0.1026 - val_accuracy: 0.8352\n",
            "Epoch 90/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1038 - accuracy: 0.8334 - val_loss: 0.1024 - val_accuracy: 0.8368\n",
            "Epoch 91/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1036 - accuracy: 0.8333 - val_loss: 0.1022 - val_accuracy: 0.8361\n",
            "Epoch 92/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1034 - accuracy: 0.8335 - val_loss: 0.1019 - val_accuracy: 0.8360\n",
            "Epoch 93/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1032 - accuracy: 0.8339 - val_loss: 0.1018 - val_accuracy: 0.8371\n",
            "Epoch 94/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1030 - accuracy: 0.8344 - val_loss: 0.1015 - val_accuracy: 0.8367\n",
            "Epoch 95/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1028 - accuracy: 0.8347 - val_loss: 0.1013 - val_accuracy: 0.8371\n",
            "Epoch 96/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1026 - accuracy: 0.8356 - val_loss: 0.1012 - val_accuracy: 0.8370\n",
            "Epoch 97/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1024 - accuracy: 0.8354 - val_loss: 0.1009 - val_accuracy: 0.8375\n",
            "Epoch 98/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1022 - accuracy: 0.8354 - val_loss: 0.1007 - val_accuracy: 0.8378\n",
            "Epoch 99/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1020 - accuracy: 0.8360 - val_loss: 0.1006 - val_accuracy: 0.8396\n",
            "Epoch 100/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1018 - accuracy: 0.8362 - val_loss: 0.1003 - val_accuracy: 0.8376\n",
            "Epoch 101/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1016 - accuracy: 0.8364 - val_loss: 0.1002 - val_accuracy: 0.8393\n",
            "Epoch 102/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1014 - accuracy: 0.8367 - val_loss: 0.1000 - val_accuracy: 0.8384\n",
            "Epoch 103/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1013 - accuracy: 0.8367 - val_loss: 0.0998 - val_accuracy: 0.8385\n",
            "Epoch 104/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1011 - accuracy: 0.8375 - val_loss: 0.0997 - val_accuracy: 0.8381\n",
            "Epoch 105/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1009 - accuracy: 0.8374 - val_loss: 0.0995 - val_accuracy: 0.8390\n",
            "Epoch 106/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1007 - accuracy: 0.8374 - val_loss: 0.0993 - val_accuracy: 0.8389\n",
            "Epoch 107/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1006 - accuracy: 0.8374 - val_loss: 0.0991 - val_accuracy: 0.8397\n",
            "Epoch 108/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1004 - accuracy: 0.8377 - val_loss: 0.0989 - val_accuracy: 0.8400\n",
            "Epoch 109/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1002 - accuracy: 0.8382 - val_loss: 0.0988 - val_accuracy: 0.8406\n",
            "Epoch 110/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1001 - accuracy: 0.8383 - val_loss: 0.0986 - val_accuracy: 0.8410\n",
            "Epoch 111/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0999 - accuracy: 0.8387 - val_loss: 0.0984 - val_accuracy: 0.8421\n",
            "Epoch 112/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0998 - accuracy: 0.8389 - val_loss: 0.0983 - val_accuracy: 0.8400\n",
            "Epoch 113/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0996 - accuracy: 0.8390 - val_loss: 0.0981 - val_accuracy: 0.8402\n",
            "Epoch 114/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0994 - accuracy: 0.8391 - val_loss: 0.0979 - val_accuracy: 0.8418\n",
            "Epoch 115/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0993 - accuracy: 0.8395 - val_loss: 0.0978 - val_accuracy: 0.8408\n",
            "Epoch 116/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0992 - accuracy: 0.8397 - val_loss: 0.0976 - val_accuracy: 0.8413\n",
            "Epoch 117/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0990 - accuracy: 0.8398 - val_loss: 0.0975 - val_accuracy: 0.8414\n",
            "Epoch 118/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0989 - accuracy: 0.8398 - val_loss: 0.0973 - val_accuracy: 0.8419\n",
            "Epoch 119/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0987 - accuracy: 0.8398 - val_loss: 0.0972 - val_accuracy: 0.8418\n",
            "Epoch 120/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0986 - accuracy: 0.8404 - val_loss: 0.0971 - val_accuracy: 0.8443\n",
            "Epoch 121/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0985 - accuracy: 0.8404 - val_loss: 0.0970 - val_accuracy: 0.8430\n",
            "Epoch 122/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0983 - accuracy: 0.8404 - val_loss: 0.0968 - val_accuracy: 0.8425\n",
            "Epoch 123/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0982 - accuracy: 0.8408 - val_loss: 0.0966 - val_accuracy: 0.8440\n",
            "Epoch 124/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0981 - accuracy: 0.8409 - val_loss: 0.0965 - val_accuracy: 0.8431\n",
            "Epoch 125/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0979 - accuracy: 0.8409 - val_loss: 0.0964 - val_accuracy: 0.8439\n",
            "Epoch 126/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0978 - accuracy: 0.8413 - val_loss: 0.0963 - val_accuracy: 0.8436\n",
            "Epoch 127/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0977 - accuracy: 0.8418 - val_loss: 0.0962 - val_accuracy: 0.8425\n",
            "Epoch 128/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0975 - accuracy: 0.8413 - val_loss: 0.0960 - val_accuracy: 0.8440\n",
            "Epoch 129/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0974 - accuracy: 0.8422 - val_loss: 0.0959 - val_accuracy: 0.8439\n",
            "Epoch 130/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0973 - accuracy: 0.8419 - val_loss: 0.0958 - val_accuracy: 0.8441\n",
            "Epoch 131/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0972 - accuracy: 0.8418 - val_loss: 0.0956 - val_accuracy: 0.8450\n",
            "Epoch 132/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0971 - accuracy: 0.8421 - val_loss: 0.0955 - val_accuracy: 0.8444\n",
            "Epoch 133/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0969 - accuracy: 0.8423 - val_loss: 0.0954 - val_accuracy: 0.8453\n",
            "Epoch 134/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0968 - accuracy: 0.8425 - val_loss: 0.0953 - val_accuracy: 0.8446\n",
            "Epoch 135/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0967 - accuracy: 0.8428 - val_loss: 0.0952 - val_accuracy: 0.8449\n",
            "Epoch 136/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0966 - accuracy: 0.8426 - val_loss: 0.0950 - val_accuracy: 0.8453\n",
            "Epoch 137/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0965 - accuracy: 0.8432 - val_loss: 0.0950 - val_accuracy: 0.8448\n",
            "Epoch 138/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0964 - accuracy: 0.8431 - val_loss: 0.0948 - val_accuracy: 0.8454\n",
            "Epoch 139/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0963 - accuracy: 0.8433 - val_loss: 0.0947 - val_accuracy: 0.8461\n",
            "Epoch 140/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0962 - accuracy: 0.8432 - val_loss: 0.0946 - val_accuracy: 0.8467\n",
            "Epoch 141/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0960 - accuracy: 0.8438 - val_loss: 0.0945 - val_accuracy: 0.8464\n",
            "Epoch 142/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0959 - accuracy: 0.8437 - val_loss: 0.0943 - val_accuracy: 0.8470\n",
            "Epoch 143/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0958 - accuracy: 0.8437 - val_loss: 0.0942 - val_accuracy: 0.8470\n",
            "Epoch 144/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0957 - accuracy: 0.8441 - val_loss: 0.0942 - val_accuracy: 0.8462\n",
            "Epoch 145/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0956 - accuracy: 0.8440 - val_loss: 0.0940 - val_accuracy: 0.8475\n",
            "Epoch 146/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0955 - accuracy: 0.8444 - val_loss: 0.0939 - val_accuracy: 0.8478\n",
            "Epoch 147/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0954 - accuracy: 0.8446 - val_loss: 0.0939 - val_accuracy: 0.8466\n",
            "Epoch 148/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0953 - accuracy: 0.8444 - val_loss: 0.0937 - val_accuracy: 0.8479\n",
            "Epoch 149/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0952 - accuracy: 0.8447 - val_loss: 0.0937 - val_accuracy: 0.8457\n",
            "Epoch 150/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0951 - accuracy: 0.8445 - val_loss: 0.0935 - val_accuracy: 0.8485\n",
            "Epoch 151/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0950 - accuracy: 0.8448 - val_loss: 0.0934 - val_accuracy: 0.8482\n",
            "Epoch 152/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0949 - accuracy: 0.8453 - val_loss: 0.0933 - val_accuracy: 0.8485\n",
            "Epoch 153/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0948 - accuracy: 0.8454 - val_loss: 0.0932 - val_accuracy: 0.8478\n",
            "Epoch 154/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0948 - accuracy: 0.8455 - val_loss: 0.0931 - val_accuracy: 0.8483\n",
            "Epoch 155/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.8453 - val_loss: 0.0931 - val_accuracy: 0.8472\n",
            "Epoch 156/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0946 - accuracy: 0.8456 - val_loss: 0.0930 - val_accuracy: 0.8475\n",
            "Epoch 157/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0945 - accuracy: 0.8456 - val_loss: 0.0928 - val_accuracy: 0.8493\n",
            "Epoch 158/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0944 - accuracy: 0.8458 - val_loss: 0.0927 - val_accuracy: 0.8490\n",
            "Epoch 159/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0943 - accuracy: 0.8462 - val_loss: 0.0927 - val_accuracy: 0.8489\n",
            "Epoch 160/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0942 - accuracy: 0.8461 - val_loss: 0.0926 - val_accuracy: 0.8483\n",
            "Epoch 161/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0941 - accuracy: 0.8464 - val_loss: 0.0925 - val_accuracy: 0.8494\n",
            "Epoch 162/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0940 - accuracy: 0.8464 - val_loss: 0.0924 - val_accuracy: 0.8492\n",
            "Epoch 163/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0939 - accuracy: 0.8466 - val_loss: 0.0924 - val_accuracy: 0.8498\n",
            "Epoch 164/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0939 - accuracy: 0.8466 - val_loss: 0.0922 - val_accuracy: 0.8494\n",
            "Epoch 165/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0938 - accuracy: 0.8465 - val_loss: 0.0922 - val_accuracy: 0.8488\n",
            "Epoch 166/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0937 - accuracy: 0.8467 - val_loss: 0.0920 - val_accuracy: 0.8493\n",
            "Epoch 167/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0936 - accuracy: 0.8469 - val_loss: 0.0920 - val_accuracy: 0.8504\n",
            "Epoch 168/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0935 - accuracy: 0.8472 - val_loss: 0.0919 - val_accuracy: 0.8494\n",
            "Epoch 169/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0935 - accuracy: 0.8471 - val_loss: 0.0918 - val_accuracy: 0.8495\n",
            "Epoch 170/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0934 - accuracy: 0.8474 - val_loss: 0.0917 - val_accuracy: 0.8500\n",
            "Epoch 171/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0933 - accuracy: 0.8476 - val_loss: 0.0917 - val_accuracy: 0.8504\n",
            "Epoch 172/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0932 - accuracy: 0.8476 - val_loss: 0.0916 - val_accuracy: 0.8503\n",
            "Epoch 173/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0931 - accuracy: 0.8476 - val_loss: 0.0915 - val_accuracy: 0.8508\n",
            "Epoch 174/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0931 - accuracy: 0.8480 - val_loss: 0.0914 - val_accuracy: 0.8496\n",
            "Epoch 175/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0930 - accuracy: 0.8478 - val_loss: 0.0913 - val_accuracy: 0.8509\n",
            "Epoch 176/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0929 - accuracy: 0.8483 - val_loss: 0.0912 - val_accuracy: 0.8502\n",
            "Epoch 177/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0928 - accuracy: 0.8481 - val_loss: 0.0912 - val_accuracy: 0.8498\n",
            "Epoch 178/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0928 - accuracy: 0.8487 - val_loss: 0.0911 - val_accuracy: 0.8504\n",
            "Epoch 179/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0927 - accuracy: 0.8483 - val_loss: 0.0910 - val_accuracy: 0.8508\n",
            "Epoch 180/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0926 - accuracy: 0.8484 - val_loss: 0.0909 - val_accuracy: 0.8511\n",
            "Epoch 181/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0926 - accuracy: 0.8486 - val_loss: 0.0909 - val_accuracy: 0.8514\n",
            "Epoch 182/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0925 - accuracy: 0.8486 - val_loss: 0.0908 - val_accuracy: 0.8512\n",
            "Epoch 183/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0924 - accuracy: 0.8487 - val_loss: 0.0907 - val_accuracy: 0.8514\n",
            "Epoch 184/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0923 - accuracy: 0.8490 - val_loss: 0.0907 - val_accuracy: 0.8504\n",
            "Epoch 185/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0923 - accuracy: 0.8487 - val_loss: 0.0906 - val_accuracy: 0.8505\n",
            "Epoch 186/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0922 - accuracy: 0.8489 - val_loss: 0.0905 - val_accuracy: 0.8511\n",
            "Epoch 187/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0921 - accuracy: 0.8493 - val_loss: 0.0904 - val_accuracy: 0.8516\n",
            "Epoch 188/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0921 - accuracy: 0.8493 - val_loss: 0.0904 - val_accuracy: 0.8519\n",
            "Epoch 189/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0920 - accuracy: 0.8495 - val_loss: 0.0903 - val_accuracy: 0.8515\n",
            "Epoch 190/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.8494 - val_loss: 0.0902 - val_accuracy: 0.8518\n",
            "Epoch 191/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.8496 - val_loss: 0.0902 - val_accuracy: 0.8515\n",
            "Epoch 192/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0918 - accuracy: 0.8497 - val_loss: 0.0901 - val_accuracy: 0.8529\n",
            "Epoch 193/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0917 - accuracy: 0.8498 - val_loss: 0.0900 - val_accuracy: 0.8522\n",
            "Epoch 194/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0917 - accuracy: 0.8500 - val_loss: 0.0900 - val_accuracy: 0.8528\n",
            "Epoch 195/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0916 - accuracy: 0.8500 - val_loss: 0.0899 - val_accuracy: 0.8522\n",
            "Epoch 196/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0915 - accuracy: 0.8502 - val_loss: 0.0898 - val_accuracy: 0.8521\n",
            "Epoch 197/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0915 - accuracy: 0.8501 - val_loss: 0.0898 - val_accuracy: 0.8522\n",
            "Epoch 198/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0914 - accuracy: 0.8502 - val_loss: 0.0897 - val_accuracy: 0.8523\n",
            "Epoch 199/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0914 - accuracy: 0.8503 - val_loss: 0.0897 - val_accuracy: 0.8528\n",
            "Epoch 200/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0913 - accuracy: 0.8505 - val_loss: 0.0896 - val_accuracy: 0.8525\n",
            "Epoch 201/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0912 - accuracy: 0.8505 - val_loss: 0.0895 - val_accuracy: 0.8530\n",
            "Epoch 202/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0912 - accuracy: 0.8507 - val_loss: 0.0895 - val_accuracy: 0.8521\n",
            "Epoch 203/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0911 - accuracy: 0.8504 - val_loss: 0.0894 - val_accuracy: 0.8529\n",
            "Epoch 204/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0911 - accuracy: 0.8508 - val_loss: 0.0893 - val_accuracy: 0.8531\n",
            "Epoch 205/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0910 - accuracy: 0.8508 - val_loss: 0.0893 - val_accuracy: 0.8537\n",
            "Epoch 206/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0909 - accuracy: 0.8510 - val_loss: 0.0892 - val_accuracy: 0.8532\n",
            "Epoch 207/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0909 - accuracy: 0.8513 - val_loss: 0.0892 - val_accuracy: 0.8542\n",
            "Epoch 208/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0908 - accuracy: 0.8511 - val_loss: 0.0891 - val_accuracy: 0.8530\n",
            "Epoch 209/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0908 - accuracy: 0.8513 - val_loss: 0.0890 - val_accuracy: 0.8541\n",
            "Epoch 210/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0907 - accuracy: 0.8514 - val_loss: 0.0890 - val_accuracy: 0.8536\n",
            "Epoch 211/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0906 - accuracy: 0.8514 - val_loss: 0.0889 - val_accuracy: 0.8543\n",
            "Epoch 212/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0906 - accuracy: 0.8514 - val_loss: 0.0888 - val_accuracy: 0.8543\n",
            "Epoch 213/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0905 - accuracy: 0.8515 - val_loss: 0.0888 - val_accuracy: 0.8541\n",
            "Epoch 214/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0905 - accuracy: 0.8520 - val_loss: 0.0888 - val_accuracy: 0.8536\n",
            "Epoch 215/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0904 - accuracy: 0.8515 - val_loss: 0.0887 - val_accuracy: 0.8540\n",
            "Epoch 216/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0904 - accuracy: 0.8519 - val_loss: 0.0886 - val_accuracy: 0.8547\n",
            "Epoch 217/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0903 - accuracy: 0.8519 - val_loss: 0.0885 - val_accuracy: 0.8545\n",
            "Epoch 218/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0903 - accuracy: 0.8522 - val_loss: 0.0885 - val_accuracy: 0.8550\n",
            "Epoch 219/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0902 - accuracy: 0.8522 - val_loss: 0.0885 - val_accuracy: 0.8540\n",
            "Epoch 220/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0902 - accuracy: 0.8522 - val_loss: 0.0884 - val_accuracy: 0.8544\n",
            "Epoch 221/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0901 - accuracy: 0.8521 - val_loss: 0.0884 - val_accuracy: 0.8555\n",
            "Epoch 222/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0901 - accuracy: 0.8522 - val_loss: 0.0884 - val_accuracy: 0.8543\n",
            "Epoch 223/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0900 - accuracy: 0.8523 - val_loss: 0.0882 - val_accuracy: 0.8551\n",
            "Epoch 224/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.8524 - val_loss: 0.0882 - val_accuracy: 0.8546\n",
            "Epoch 225/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0899 - accuracy: 0.8525 - val_loss: 0.0881 - val_accuracy: 0.8551\n",
            "Epoch 226/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0898 - accuracy: 0.8526 - val_loss: 0.0881 - val_accuracy: 0.8554\n",
            "Epoch 227/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0898 - accuracy: 0.8527 - val_loss: 0.0880 - val_accuracy: 0.8553\n",
            "Epoch 228/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0898 - accuracy: 0.8525 - val_loss: 0.0880 - val_accuracy: 0.8551\n",
            "Epoch 229/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0897 - accuracy: 0.8527 - val_loss: 0.0879 - val_accuracy: 0.8556\n",
            "Epoch 230/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0896 - accuracy: 0.8528 - val_loss: 0.0879 - val_accuracy: 0.8556\n",
            "Epoch 231/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0896 - accuracy: 0.8528 - val_loss: 0.0878 - val_accuracy: 0.8559\n",
            "Epoch 232/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0895 - accuracy: 0.8533 - val_loss: 0.0878 - val_accuracy: 0.8558\n",
            "Epoch 233/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0895 - accuracy: 0.8531 - val_loss: 0.0877 - val_accuracy: 0.8558\n",
            "Epoch 234/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0895 - accuracy: 0.8531 - val_loss: 0.0877 - val_accuracy: 0.8553\n",
            "Epoch 235/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0894 - accuracy: 0.8533 - val_loss: 0.0876 - val_accuracy: 0.8560\n",
            "Epoch 236/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0894 - accuracy: 0.8535 - val_loss: 0.0876 - val_accuracy: 0.8561\n",
            "Epoch 237/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0893 - accuracy: 0.8536 - val_loss: 0.0875 - val_accuracy: 0.8562\n",
            "Epoch 238/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.8534 - val_loss: 0.0875 - val_accuracy: 0.8568\n",
            "Epoch 239/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0892 - accuracy: 0.8539 - val_loss: 0.0875 - val_accuracy: 0.8558\n",
            "Epoch 240/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0892 - accuracy: 0.8534 - val_loss: 0.0874 - val_accuracy: 0.8562\n",
            "Epoch 241/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0891 - accuracy: 0.8537 - val_loss: 0.0874 - val_accuracy: 0.8551\n",
            "Epoch 242/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0891 - accuracy: 0.8538 - val_loss: 0.0873 - val_accuracy: 0.8561\n",
            "Epoch 243/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0890 - accuracy: 0.8537 - val_loss: 0.0872 - val_accuracy: 0.8571\n",
            "Epoch 244/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.8536 - val_loss: 0.0872 - val_accuracy: 0.8567\n",
            "Epoch 245/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0889 - accuracy: 0.8538 - val_loss: 0.0871 - val_accuracy: 0.8568\n",
            "Epoch 246/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0889 - accuracy: 0.8539 - val_loss: 0.0871 - val_accuracy: 0.8562\n",
            "Epoch 247/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0888 - accuracy: 0.8540 - val_loss: 0.0871 - val_accuracy: 0.8565\n",
            "Epoch 248/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0888 - accuracy: 0.8539 - val_loss: 0.0870 - val_accuracy: 0.8569\n",
            "Epoch 249/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0888 - accuracy: 0.8541 - val_loss: 0.0870 - val_accuracy: 0.8569\n",
            "Epoch 250/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0887 - accuracy: 0.8541 - val_loss: 0.0869 - val_accuracy: 0.8571\n",
            "Epoch 251/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0887 - accuracy: 0.8545 - val_loss: 0.0869 - val_accuracy: 0.8577\n",
            "Epoch 252/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.8540 - val_loss: 0.0869 - val_accuracy: 0.8567\n",
            "Epoch 253/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.8544 - val_loss: 0.0868 - val_accuracy: 0.8573\n",
            "Epoch 254/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0885 - accuracy: 0.8546 - val_loss: 0.0867 - val_accuracy: 0.8572\n",
            "Epoch 255/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0885 - accuracy: 0.8547 - val_loss: 0.0867 - val_accuracy: 0.8578\n",
            "Epoch 256/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0885 - accuracy: 0.8546 - val_loss: 0.0866 - val_accuracy: 0.8576\n",
            "Epoch 257/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.8544 - val_loss: 0.0866 - val_accuracy: 0.8579\n",
            "Epoch 258/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.8548 - val_loss: 0.0865 - val_accuracy: 0.8578\n",
            "Epoch 259/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0883 - accuracy: 0.8551 - val_loss: 0.0865 - val_accuracy: 0.8577\n",
            "Epoch 260/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0883 - accuracy: 0.8546 - val_loss: 0.0865 - val_accuracy: 0.8572\n",
            "Epoch 261/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0883 - accuracy: 0.8548 - val_loss: 0.0864 - val_accuracy: 0.8578\n",
            "Epoch 262/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0882 - accuracy: 0.8546 - val_loss: 0.0864 - val_accuracy: 0.8577\n",
            "Epoch 263/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.8548 - val_loss: 0.0864 - val_accuracy: 0.8575\n",
            "Epoch 264/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.8547 - val_loss: 0.0863 - val_accuracy: 0.8584\n",
            "Epoch 265/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.8551 - val_loss: 0.0863 - val_accuracy: 0.8580\n",
            "Epoch 266/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.8549 - val_loss: 0.0862 - val_accuracy: 0.8583\n",
            "Epoch 267/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.8553 - val_loss: 0.0862 - val_accuracy: 0.8581\n",
            "Epoch 268/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0880 - accuracy: 0.8551 - val_loss: 0.0861 - val_accuracy: 0.8580\n",
            "Epoch 269/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0879 - accuracy: 0.8550 - val_loss: 0.0861 - val_accuracy: 0.8589\n",
            "Epoch 270/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0879 - accuracy: 0.8551 - val_loss: 0.0861 - val_accuracy: 0.8586\n",
            "Epoch 271/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0879 - accuracy: 0.8553 - val_loss: 0.0860 - val_accuracy: 0.8583\n",
            "Epoch 272/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0878 - accuracy: 0.8554 - val_loss: 0.0860 - val_accuracy: 0.8582\n",
            "Epoch 273/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0878 - accuracy: 0.8553 - val_loss: 0.0860 - val_accuracy: 0.8584\n",
            "Epoch 274/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0877 - accuracy: 0.8555 - val_loss: 0.0859 - val_accuracy: 0.8586\n",
            "Epoch 275/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8555 - val_loss: 0.0859 - val_accuracy: 0.8587\n",
            "Epoch 276/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8555 - val_loss: 0.0859 - val_accuracy: 0.8584\n",
            "Epoch 277/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.8555 - val_loss: 0.0858 - val_accuracy: 0.8587\n",
            "Epoch 278/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.8558 - val_loss: 0.0858 - val_accuracy: 0.8587\n",
            "Epoch 279/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.8555 - val_loss: 0.0857 - val_accuracy: 0.8587\n",
            "Epoch 280/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0875 - accuracy: 0.8558 - val_loss: 0.0857 - val_accuracy: 0.8590\n",
            "Epoch 281/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.8558 - val_loss: 0.0856 - val_accuracy: 0.8589\n",
            "Epoch 282/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.8561 - val_loss: 0.0856 - val_accuracy: 0.8590\n",
            "Epoch 283/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0874 - accuracy: 0.8561 - val_loss: 0.0856 - val_accuracy: 0.8584\n",
            "Epoch 284/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0874 - accuracy: 0.8559 - val_loss: 0.0856 - val_accuracy: 0.8590\n",
            "Epoch 285/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0874 - accuracy: 0.8561 - val_loss: 0.0855 - val_accuracy: 0.8592\n",
            "Epoch 286/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0873 - accuracy: 0.8562 - val_loss: 0.0855 - val_accuracy: 0.8589\n",
            "Epoch 287/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0873 - accuracy: 0.8560 - val_loss: 0.0854 - val_accuracy: 0.8593\n",
            "Epoch 288/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0872 - accuracy: 0.8561 - val_loss: 0.0854 - val_accuracy: 0.8593\n",
            "Epoch 289/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0872 - accuracy: 0.8563 - val_loss: 0.0853 - val_accuracy: 0.8589\n",
            "Epoch 290/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0872 - accuracy: 0.8562 - val_loss: 0.0853 - val_accuracy: 0.8594\n",
            "Epoch 291/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.8564 - val_loss: 0.0853 - val_accuracy: 0.8593\n",
            "Epoch 292/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0871 - accuracy: 0.8561 - val_loss: 0.0852 - val_accuracy: 0.8593\n",
            "Epoch 293/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.8565 - val_loss: 0.0852 - val_accuracy: 0.8596\n",
            "Epoch 294/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.8566 - val_loss: 0.0851 - val_accuracy: 0.8596\n",
            "Epoch 295/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.8565 - val_loss: 0.0851 - val_accuracy: 0.8592\n",
            "Epoch 296/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.8563 - val_loss: 0.0851 - val_accuracy: 0.8597\n",
            "Epoch 297/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.8566 - val_loss: 0.0851 - val_accuracy: 0.8603\n",
            "Epoch 298/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.8569 - val_loss: 0.0851 - val_accuracy: 0.8597\n",
            "Epoch 299/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.8566 - val_loss: 0.0851 - val_accuracy: 0.8595\n",
            "Epoch 300/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.8566 - val_loss: 0.0850 - val_accuracy: 0.8594\n",
            "Epoch 301/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.8569 - val_loss: 0.0849 - val_accuracy: 0.8598\n",
            "Epoch 302/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.8568 - val_loss: 0.0849 - val_accuracy: 0.8602\n",
            "Epoch 303/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0867 - accuracy: 0.8570 - val_loss: 0.0849 - val_accuracy: 0.8600\n",
            "Epoch 304/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0867 - accuracy: 0.8569 - val_loss: 0.0849 - val_accuracy: 0.8598\n",
            "Epoch 305/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0867 - accuracy: 0.8570 - val_loss: 0.0848 - val_accuracy: 0.8601\n",
            "Epoch 306/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0866 - accuracy: 0.8569 - val_loss: 0.0848 - val_accuracy: 0.8601\n",
            "Epoch 307/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0866 - accuracy: 0.8571 - val_loss: 0.0847 - val_accuracy: 0.8598\n",
            "Epoch 308/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0866 - accuracy: 0.8572 - val_loss: 0.0848 - val_accuracy: 0.8591\n",
            "Epoch 309/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8571 - val_loss: 0.0847 - val_accuracy: 0.8594\n",
            "Epoch 310/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8571 - val_loss: 0.0846 - val_accuracy: 0.8602\n",
            "Epoch 311/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0865 - accuracy: 0.8574 - val_loss: 0.0846 - val_accuracy: 0.8604\n",
            "Epoch 312/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8573 - val_loss: 0.0846 - val_accuracy: 0.8601\n",
            "Epoch 313/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8571 - val_loss: 0.0845 - val_accuracy: 0.8606\n",
            "Epoch 314/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8571 - val_loss: 0.0845 - val_accuracy: 0.8602\n",
            "Epoch 315/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8573 - val_loss: 0.0845 - val_accuracy: 0.8605\n",
            "Epoch 316/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0863 - accuracy: 0.8575 - val_loss: 0.0844 - val_accuracy: 0.8607\n",
            "Epoch 317/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0863 - accuracy: 0.8574 - val_loss: 0.0844 - val_accuracy: 0.8604\n",
            "Epoch 318/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0863 - accuracy: 0.8574 - val_loss: 0.0844 - val_accuracy: 0.8607\n",
            "Epoch 319/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8576 - val_loss: 0.0844 - val_accuracy: 0.8610\n",
            "Epoch 320/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8577 - val_loss: 0.0843 - val_accuracy: 0.8608\n",
            "Epoch 321/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8577 - val_loss: 0.0843 - val_accuracy: 0.8605\n",
            "Epoch 322/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0861 - accuracy: 0.8579 - val_loss: 0.0842 - val_accuracy: 0.8610\n",
            "Epoch 323/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0861 - accuracy: 0.8577 - val_loss: 0.0842 - val_accuracy: 0.8608\n",
            "Epoch 324/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0861 - accuracy: 0.8578 - val_loss: 0.0842 - val_accuracy: 0.8607\n",
            "Epoch 325/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0861 - accuracy: 0.8580 - val_loss: 0.0841 - val_accuracy: 0.8607\n",
            "Epoch 326/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8579 - val_loss: 0.0841 - val_accuracy: 0.8611\n",
            "Epoch 327/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8580 - val_loss: 0.0841 - val_accuracy: 0.8611\n",
            "Epoch 328/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8583 - val_loss: 0.0840 - val_accuracy: 0.8614\n",
            "Epoch 329/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0859 - accuracy: 0.8582 - val_loss: 0.0840 - val_accuracy: 0.8615\n",
            "Epoch 330/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8579 - val_loss: 0.0840 - val_accuracy: 0.8611\n",
            "Epoch 331/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8583 - val_loss: 0.0840 - val_accuracy: 0.8612\n",
            "Epoch 332/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8580 - val_loss: 0.0839 - val_accuracy: 0.8612\n",
            "Epoch 333/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8585 - val_loss: 0.0839 - val_accuracy: 0.8616\n",
            "Epoch 334/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8582 - val_loss: 0.0839 - val_accuracy: 0.8613\n",
            "Epoch 335/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0858 - accuracy: 0.8584 - val_loss: 0.0838 - val_accuracy: 0.8616\n",
            "Epoch 336/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8584 - val_loss: 0.0839 - val_accuracy: 0.8612\n",
            "Epoch 337/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8584 - val_loss: 0.0838 - val_accuracy: 0.8615\n",
            "Epoch 338/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8584 - val_loss: 0.0838 - val_accuracy: 0.8615\n",
            "Epoch 339/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8586 - val_loss: 0.0838 - val_accuracy: 0.8611\n",
            "Epoch 340/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0856 - accuracy: 0.8587 - val_loss: 0.0837 - val_accuracy: 0.8619\n",
            "Epoch 341/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0856 - accuracy: 0.8584 - val_loss: 0.0837 - val_accuracy: 0.8617\n",
            "Epoch 342/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8586 - val_loss: 0.0837 - val_accuracy: 0.8615\n",
            "Epoch 343/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0855 - accuracy: 0.8586 - val_loss: 0.0836 - val_accuracy: 0.8618\n",
            "Epoch 344/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0855 - accuracy: 0.8586 - val_loss: 0.0836 - val_accuracy: 0.8619\n",
            "Epoch 345/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0855 - accuracy: 0.8586 - val_loss: 0.0835 - val_accuracy: 0.8618\n",
            "Epoch 346/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0855 - accuracy: 0.8590 - val_loss: 0.0835 - val_accuracy: 0.8621\n",
            "Epoch 347/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8589 - val_loss: 0.0835 - val_accuracy: 0.8619\n",
            "Epoch 348/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8589 - val_loss: 0.0835 - val_accuracy: 0.8619\n",
            "Epoch 349/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8589 - val_loss: 0.0834 - val_accuracy: 0.8618\n",
            "Epoch 350/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8589 - val_loss: 0.0834 - val_accuracy: 0.8620\n",
            "Epoch 351/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.8588 - val_loss: 0.0834 - val_accuracy: 0.8622\n",
            "Epoch 352/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0853 - accuracy: 0.8591 - val_loss: 0.0834 - val_accuracy: 0.8620\n",
            "Epoch 353/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.8589 - val_loss: 0.0833 - val_accuracy: 0.8619\n",
            "Epoch 354/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.8590 - val_loss: 0.0833 - val_accuracy: 0.8622\n",
            "Epoch 355/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.8591 - val_loss: 0.0833 - val_accuracy: 0.8620\n",
            "Epoch 356/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.8592 - val_loss: 0.0832 - val_accuracy: 0.8626\n",
            "Epoch 357/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.8591 - val_loss: 0.0832 - val_accuracy: 0.8620\n",
            "Epoch 358/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.8594 - val_loss: 0.0832 - val_accuracy: 0.8625\n",
            "Epoch 359/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.8594 - val_loss: 0.0832 - val_accuracy: 0.8620\n",
            "Epoch 360/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8592 - val_loss: 0.0832 - val_accuracy: 0.8626\n",
            "Epoch 361/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8595 - val_loss: 0.0831 - val_accuracy: 0.8625\n",
            "Epoch 362/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8594 - val_loss: 0.0831 - val_accuracy: 0.8625\n",
            "Epoch 363/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8595 - val_loss: 0.0831 - val_accuracy: 0.8625\n",
            "Epoch 364/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0850 - accuracy: 0.8595 - val_loss: 0.0830 - val_accuracy: 0.8625\n",
            "Epoch 365/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8595 - val_loss: 0.0830 - val_accuracy: 0.8624\n",
            "Epoch 366/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8597 - val_loss: 0.0830 - val_accuracy: 0.8625\n",
            "Epoch 367/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8597 - val_loss: 0.0830 - val_accuracy: 0.8630\n",
            "Epoch 368/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8595 - val_loss: 0.0829 - val_accuracy: 0.8626\n",
            "Epoch 369/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8598 - val_loss: 0.0829 - val_accuracy: 0.8626\n",
            "Epoch 370/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0848 - accuracy: 0.8598 - val_loss: 0.0829 - val_accuracy: 0.8627\n",
            "Epoch 371/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8598 - val_loss: 0.0829 - val_accuracy: 0.8629\n",
            "Epoch 372/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8599 - val_loss: 0.0828 - val_accuracy: 0.8628\n",
            "Epoch 373/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8595 - val_loss: 0.0828 - val_accuracy: 0.8633\n",
            "Epoch 374/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8598 - val_loss: 0.0828 - val_accuracy: 0.8633\n",
            "Epoch 375/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8598 - val_loss: 0.0828 - val_accuracy: 0.8633\n",
            "Epoch 376/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0847 - accuracy: 0.8598 - val_loss: 0.0827 - val_accuracy: 0.8633\n",
            "Epoch 377/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8599 - val_loss: 0.0827 - val_accuracy: 0.8634\n",
            "Epoch 378/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8600 - val_loss: 0.0827 - val_accuracy: 0.8632\n",
            "Epoch 379/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8601 - val_loss: 0.0827 - val_accuracy: 0.8623\n",
            "Epoch 380/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8598 - val_loss: 0.0826 - val_accuracy: 0.8632\n",
            "Epoch 381/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8603 - val_loss: 0.0826 - val_accuracy: 0.8633\n",
            "Epoch 382/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0846 - accuracy: 0.8602 - val_loss: 0.0827 - val_accuracy: 0.8626\n",
            "Epoch 383/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8601 - val_loss: 0.0826 - val_accuracy: 0.8630\n",
            "Epoch 384/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8602 - val_loss: 0.0826 - val_accuracy: 0.8627\n",
            "Epoch 385/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8604 - val_loss: 0.0825 - val_accuracy: 0.8639\n",
            "Epoch 386/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8602 - val_loss: 0.0825 - val_accuracy: 0.8634\n",
            "Epoch 387/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8606 - val_loss: 0.0825 - val_accuracy: 0.8638\n",
            "Epoch 388/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0844 - accuracy: 0.8603 - val_loss: 0.0824 - val_accuracy: 0.8637\n",
            "Epoch 389/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8604 - val_loss: 0.0824 - val_accuracy: 0.8633\n",
            "Epoch 390/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8604 - val_loss: 0.0824 - val_accuracy: 0.8639\n",
            "Epoch 391/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8602 - val_loss: 0.0824 - val_accuracy: 0.8637\n",
            "Epoch 392/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8604 - val_loss: 0.0823 - val_accuracy: 0.8638\n",
            "Epoch 393/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8606 - val_loss: 0.0823 - val_accuracy: 0.8636\n",
            "Epoch 394/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.8606 - val_loss: 0.0823 - val_accuracy: 0.8640\n",
            "Epoch 395/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8608 - val_loss: 0.0823 - val_accuracy: 0.8639\n",
            "Epoch 396/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8607 - val_loss: 0.0822 - val_accuracy: 0.8641\n",
            "Epoch 397/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8607 - val_loss: 0.0822 - val_accuracy: 0.8637\n",
            "Epoch 398/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8608 - val_loss: 0.0822 - val_accuracy: 0.8644\n",
            "Epoch 399/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8606 - val_loss: 0.0822 - val_accuracy: 0.8644\n",
            "Epoch 400/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.8609 - val_loss: 0.0822 - val_accuracy: 0.8642\n",
            "Epoch 401/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.8607 - val_loss: 0.0821 - val_accuracy: 0.8638\n",
            "Epoch 402/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8607 - val_loss: 0.0821 - val_accuracy: 0.8641\n",
            "Epoch 403/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8610 - val_loss: 0.0821 - val_accuracy: 0.8643\n",
            "Epoch 404/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8610 - val_loss: 0.0821 - val_accuracy: 0.8640\n",
            "Epoch 405/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8610 - val_loss: 0.0820 - val_accuracy: 0.8644\n",
            "Epoch 406/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0840 - accuracy: 0.8612 - val_loss: 0.0821 - val_accuracy: 0.8637\n",
            "Epoch 407/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8611 - val_loss: 0.0820 - val_accuracy: 0.8637\n",
            "Epoch 408/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8612 - val_loss: 0.0820 - val_accuracy: 0.8640\n",
            "Epoch 409/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8608 - val_loss: 0.0819 - val_accuracy: 0.8647\n",
            "Epoch 410/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8612 - val_loss: 0.0819 - val_accuracy: 0.8645\n",
            "Epoch 411/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8613 - val_loss: 0.0819 - val_accuracy: 0.8647\n",
            "Epoch 412/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8612 - val_loss: 0.0820 - val_accuracy: 0.8636\n",
            "Epoch 413/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.8611 - val_loss: 0.0819 - val_accuracy: 0.8651\n",
            "Epoch 414/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8612 - val_loss: 0.0818 - val_accuracy: 0.8640\n",
            "Epoch 415/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8614 - val_loss: 0.0818 - val_accuracy: 0.8645\n",
            "Epoch 416/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8611 - val_loss: 0.0818 - val_accuracy: 0.8647\n",
            "Epoch 417/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8614 - val_loss: 0.0818 - val_accuracy: 0.8640\n",
            "Epoch 418/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8614 - val_loss: 0.0817 - val_accuracy: 0.8648\n",
            "Epoch 419/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8615 - val_loss: 0.0817 - val_accuracy: 0.8645\n",
            "Epoch 420/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8615 - val_loss: 0.0817 - val_accuracy: 0.8645\n",
            "Epoch 421/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8614 - val_loss: 0.0817 - val_accuracy: 0.8651\n",
            "Epoch 422/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8615 - val_loss: 0.0817 - val_accuracy: 0.8647\n",
            "Epoch 423/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8616 - val_loss: 0.0816 - val_accuracy: 0.8649\n",
            "Epoch 424/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8616 - val_loss: 0.0816 - val_accuracy: 0.8644\n",
            "Epoch 425/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.8619 - val_loss: 0.0816 - val_accuracy: 0.8648\n",
            "Epoch 426/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8616 - val_loss: 0.0816 - val_accuracy: 0.8645\n",
            "Epoch 427/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8617 - val_loss: 0.0815 - val_accuracy: 0.8645\n",
            "Epoch 428/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8617 - val_loss: 0.0815 - val_accuracy: 0.8649\n",
            "Epoch 429/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8616 - val_loss: 0.0815 - val_accuracy: 0.8651\n",
            "Epoch 430/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8618 - val_loss: 0.0815 - val_accuracy: 0.8649\n",
            "Epoch 431/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.8616 - val_loss: 0.0815 - val_accuracy: 0.8648\n",
            "Epoch 432/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8618 - val_loss: 0.0814 - val_accuracy: 0.8648\n",
            "Epoch 433/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8620 - val_loss: 0.0814 - val_accuracy: 0.8648\n",
            "Epoch 434/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8620 - val_loss: 0.0814 - val_accuracy: 0.8651\n",
            "Epoch 435/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8621 - val_loss: 0.0815 - val_accuracy: 0.8647\n",
            "Epoch 436/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8618 - val_loss: 0.0814 - val_accuracy: 0.8651\n",
            "Epoch 437/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.8620 - val_loss: 0.0813 - val_accuracy: 0.8654\n",
            "Epoch 438/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.8621 - val_loss: 0.0814 - val_accuracy: 0.8648\n",
            "Epoch 439/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8619 - val_loss: 0.0814 - val_accuracy: 0.8649\n",
            "Epoch 440/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8621 - val_loss: 0.0813 - val_accuracy: 0.8648\n",
            "Epoch 441/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8619 - val_loss: 0.0813 - val_accuracy: 0.8652\n",
            "Epoch 442/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8620 - val_loss: 0.0812 - val_accuracy: 0.8648\n",
            "Epoch 443/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0832 - accuracy: 0.8623 - val_loss: 0.0812 - val_accuracy: 0.8651\n",
            "Epoch 444/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8620 - val_loss: 0.0812 - val_accuracy: 0.8650\n",
            "Epoch 445/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8622 - val_loss: 0.0812 - val_accuracy: 0.8654\n",
            "Epoch 446/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8622 - val_loss: 0.0811 - val_accuracy: 0.8653\n",
            "Epoch 447/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8620 - val_loss: 0.0811 - val_accuracy: 0.8648\n",
            "Epoch 448/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8622 - val_loss: 0.0811 - val_accuracy: 0.8655\n",
            "Epoch 449/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8622 - val_loss: 0.0811 - val_accuracy: 0.8652\n",
            "Epoch 450/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8626 - val_loss: 0.0811 - val_accuracy: 0.8652\n",
            "Epoch 451/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8622 - val_loss: 0.0810 - val_accuracy: 0.8650\n",
            "Epoch 452/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8625 - val_loss: 0.0810 - val_accuracy: 0.8653\n",
            "Epoch 453/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8623 - val_loss: 0.0810 - val_accuracy: 0.8652\n",
            "Epoch 454/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8623 - val_loss: 0.0810 - val_accuracy: 0.8650\n",
            "Epoch 455/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0830 - accuracy: 0.8623 - val_loss: 0.0810 - val_accuracy: 0.8652\n",
            "Epoch 456/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0830 - accuracy: 0.8622 - val_loss: 0.0809 - val_accuracy: 0.8651\n",
            "Epoch 457/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8624 - val_loss: 0.0809 - val_accuracy: 0.8652\n",
            "Epoch 458/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8625 - val_loss: 0.0809 - val_accuracy: 0.8652\n",
            "Epoch 459/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8626 - val_loss: 0.0809 - val_accuracy: 0.8652\n",
            "Epoch 460/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8626 - val_loss: 0.0809 - val_accuracy: 0.8652\n",
            "Epoch 461/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8626 - val_loss: 0.0809 - val_accuracy: 0.8652\n",
            "Epoch 462/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8627 - val_loss: 0.0808 - val_accuracy: 0.8652\n",
            "Epoch 463/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8630 - val_loss: 0.0808 - val_accuracy: 0.8652\n",
            "Epoch 464/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8629 - val_loss: 0.0808 - val_accuracy: 0.8656\n",
            "Epoch 465/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8627 - val_loss: 0.0808 - val_accuracy: 0.8651\n",
            "Epoch 466/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8627 - val_loss: 0.0808 - val_accuracy: 0.8656\n",
            "Epoch 467/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8629 - val_loss: 0.0807 - val_accuracy: 0.8658\n",
            "Epoch 468/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8630 - val_loss: 0.0807 - val_accuracy: 0.8656\n",
            "Epoch 469/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8630 - val_loss: 0.0807 - val_accuracy: 0.8656\n",
            "Epoch 470/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8631 - val_loss: 0.0807 - val_accuracy: 0.8657\n",
            "Epoch 471/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8628 - val_loss: 0.0807 - val_accuracy: 0.8661\n",
            "Epoch 472/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8627 - val_loss: 0.0806 - val_accuracy: 0.8658\n",
            "Epoch 473/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8631 - val_loss: 0.0806 - val_accuracy: 0.8658\n",
            "Epoch 474/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8629 - val_loss: 0.0806 - val_accuracy: 0.8658\n",
            "Epoch 475/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8630 - val_loss: 0.0806 - val_accuracy: 0.8658\n",
            "Epoch 476/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8631 - val_loss: 0.0806 - val_accuracy: 0.8659\n",
            "Epoch 477/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8629 - val_loss: 0.0805 - val_accuracy: 0.8658\n",
            "Epoch 478/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8633 - val_loss: 0.0805 - val_accuracy: 0.8658\n",
            "Epoch 479/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8632 - val_loss: 0.0805 - val_accuracy: 0.8658\n",
            "Epoch 480/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8632 - val_loss: 0.0805 - val_accuracy: 0.8659\n",
            "Epoch 481/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8632 - val_loss: 0.0805 - val_accuracy: 0.8662\n",
            "Epoch 482/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8629 - val_loss: 0.0804 - val_accuracy: 0.8661\n",
            "Epoch 483/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8633 - val_loss: 0.0805 - val_accuracy: 0.8658\n",
            "Epoch 484/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8633 - val_loss: 0.0804 - val_accuracy: 0.8658\n",
            "Epoch 485/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8632 - val_loss: 0.0804 - val_accuracy: 0.8661\n",
            "Epoch 486/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8631 - val_loss: 0.0804 - val_accuracy: 0.8661\n",
            "Epoch 487/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8635 - val_loss: 0.0804 - val_accuracy: 0.8659\n",
            "Epoch 488/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8632 - val_loss: 0.0803 - val_accuracy: 0.8661\n",
            "Epoch 489/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8633 - val_loss: 0.0803 - val_accuracy: 0.8660\n",
            "Epoch 490/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8635 - val_loss: 0.0803 - val_accuracy: 0.8661\n",
            "Epoch 491/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8636 - val_loss: 0.0803 - val_accuracy: 0.8662\n",
            "Epoch 492/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8635 - val_loss: 0.0803 - val_accuracy: 0.8662\n",
            "Epoch 493/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8635 - val_loss: 0.0803 - val_accuracy: 0.8662\n",
            "Epoch 494/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8635 - val_loss: 0.0802 - val_accuracy: 0.8662\n",
            "Epoch 495/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8634 - val_loss: 0.0802 - val_accuracy: 0.8663\n",
            "Epoch 496/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8635 - val_loss: 0.0802 - val_accuracy: 0.8662\n",
            "Epoch 497/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8633 - val_loss: 0.0802 - val_accuracy: 0.8662\n",
            "Epoch 498/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8633 - val_loss: 0.0802 - val_accuracy: 0.8662\n",
            "Epoch 499/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8636 - val_loss: 0.0802 - val_accuracy: 0.8666\n",
            "Epoch 500/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8637 - val_loss: 0.0802 - val_accuracy: 0.8662\n",
            "Epoch 501/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8636 - val_loss: 0.0802 - val_accuracy: 0.8664\n",
            "Epoch 502/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8638 - val_loss: 0.0801 - val_accuracy: 0.8663\n",
            "Epoch 503/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8636 - val_loss: 0.0801 - val_accuracy: 0.8662\n",
            "Epoch 504/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8638 - val_loss: 0.0801 - val_accuracy: 0.8667\n",
            "Epoch 505/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8638 - val_loss: 0.0801 - val_accuracy: 0.8664\n",
            "Epoch 506/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8638 - val_loss: 0.0800 - val_accuracy: 0.8663\n",
            "Epoch 507/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8640 - val_loss: 0.0800 - val_accuracy: 0.8666\n",
            "Epoch 508/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8638 - val_loss: 0.0800 - val_accuracy: 0.8664\n",
            "Epoch 509/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8639 - val_loss: 0.0800 - val_accuracy: 0.8662\n",
            "Epoch 510/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8640 - val_loss: 0.0800 - val_accuracy: 0.8662\n",
            "Epoch 511/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8638 - val_loss: 0.0799 - val_accuracy: 0.8663\n",
            "Epoch 512/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8643 - val_loss: 0.0799 - val_accuracy: 0.8665\n",
            "Epoch 513/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8638 - val_loss: 0.0799 - val_accuracy: 0.8666\n",
            "Epoch 514/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8639 - val_loss: 0.0799 - val_accuracy: 0.8667\n",
            "Epoch 515/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8638 - val_loss: 0.0799 - val_accuracy: 0.8664\n",
            "Epoch 516/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8639 - val_loss: 0.0799 - val_accuracy: 0.8665\n",
            "Epoch 517/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8640 - val_loss: 0.0798 - val_accuracy: 0.8665\n",
            "Epoch 518/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8641 - val_loss: 0.0798 - val_accuracy: 0.8667\n",
            "Epoch 519/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8640 - val_loss: 0.0798 - val_accuracy: 0.8665\n",
            "Epoch 520/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8640 - val_loss: 0.0798 - val_accuracy: 0.8672\n",
            "Epoch 521/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8642 - val_loss: 0.0798 - val_accuracy: 0.8670\n",
            "Epoch 522/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8640 - val_loss: 0.0797 - val_accuracy: 0.8669\n",
            "Epoch 523/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8639 - val_loss: 0.0797 - val_accuracy: 0.8666\n",
            "Epoch 524/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8639 - val_loss: 0.0798 - val_accuracy: 0.8665\n",
            "Epoch 525/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8641 - val_loss: 0.0797 - val_accuracy: 0.8670\n",
            "Epoch 526/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8641 - val_loss: 0.0797 - val_accuracy: 0.8666\n",
            "Epoch 527/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8644 - val_loss: 0.0797 - val_accuracy: 0.8670\n",
            "Epoch 528/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8642 - val_loss: 0.0797 - val_accuracy: 0.8672\n",
            "Epoch 529/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0817 - accuracy: 0.8644 - val_loss: 0.0797 - val_accuracy: 0.8666\n",
            "Epoch 530/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0817 - accuracy: 0.8643 - val_loss: 0.0796 - val_accuracy: 0.8669\n",
            "Epoch 531/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0817 - accuracy: 0.8643 - val_loss: 0.0796 - val_accuracy: 0.8669\n",
            "Epoch 532/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0817 - accuracy: 0.8644 - val_loss: 0.0796 - val_accuracy: 0.8668\n",
            "Epoch 533/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0817 - accuracy: 0.8641 - val_loss: 0.0796 - val_accuracy: 0.8670\n",
            "Epoch 534/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0817 - accuracy: 0.8644 - val_loss: 0.0796 - val_accuracy: 0.8669\n",
            "Epoch 535/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0816 - accuracy: 0.8643 - val_loss: 0.0796 - val_accuracy: 0.8672\n",
            "Epoch 536/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0816 - accuracy: 0.8644 - val_loss: 0.0795 - val_accuracy: 0.8669\n",
            "Epoch 537/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0816 - accuracy: 0.8645 - val_loss: 0.0795 - val_accuracy: 0.8669\n",
            "Epoch 538/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0816 - accuracy: 0.8645 - val_loss: 0.0795 - val_accuracy: 0.8672\n",
            "Epoch 539/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0816 - accuracy: 0.8646 - val_loss: 0.0795 - val_accuracy: 0.8672\n",
            "Epoch 540/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0816 - accuracy: 0.8645 - val_loss: 0.0795 - val_accuracy: 0.8670\n",
            "Epoch 541/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0816 - accuracy: 0.8645 - val_loss: 0.0794 - val_accuracy: 0.8670\n",
            "Epoch 542/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.8646 - val_loss: 0.0794 - val_accuracy: 0.8669\n",
            "Epoch 543/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.8644 - val_loss: 0.0794 - val_accuracy: 0.8674\n",
            "Epoch 544/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0815 - accuracy: 0.8643 - val_loss: 0.0794 - val_accuracy: 0.8672\n",
            "Epoch 545/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0815 - accuracy: 0.8646 - val_loss: 0.0794 - val_accuracy: 0.8676\n",
            "Epoch 546/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.8648 - val_loss: 0.0794 - val_accuracy: 0.8673\n",
            "Epoch 547/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.8645 - val_loss: 0.0794 - val_accuracy: 0.8673\n",
            "Epoch 548/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.8647 - val_loss: 0.0793 - val_accuracy: 0.8675\n",
            "Epoch 549/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0814 - accuracy: 0.8646 - val_loss: 0.0793 - val_accuracy: 0.8669\n",
            "Epoch 550/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0814 - accuracy: 0.8647 - val_loss: 0.0793 - val_accuracy: 0.8674\n",
            "Epoch 551/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0814 - accuracy: 0.8646 - val_loss: 0.0793 - val_accuracy: 0.8672\n",
            "Epoch 552/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0814 - accuracy: 0.8649 - val_loss: 0.0793 - val_accuracy: 0.8670\n",
            "Epoch 553/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0814 - accuracy: 0.8648 - val_loss: 0.0793 - val_accuracy: 0.8673\n",
            "Epoch 554/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0814 - accuracy: 0.8649 - val_loss: 0.0793 - val_accuracy: 0.8673\n",
            "Epoch 555/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.8647 - val_loss: 0.0793 - val_accuracy: 0.8676\n",
            "Epoch 556/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0813 - accuracy: 0.8650 - val_loss: 0.0792 - val_accuracy: 0.8674\n",
            "Epoch 557/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0813 - accuracy: 0.8646 - val_loss: 0.0792 - val_accuracy: 0.8672\n",
            "Epoch 558/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.8647 - val_loss: 0.0792 - val_accuracy: 0.8677\n",
            "Epoch 559/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.8648 - val_loss: 0.0792 - val_accuracy: 0.8673\n",
            "Epoch 560/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.8649 - val_loss: 0.0792 - val_accuracy: 0.8678\n",
            "Epoch 561/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.8650 - val_loss: 0.0791 - val_accuracy: 0.8674\n",
            "Epoch 562/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.8649 - val_loss: 0.0791 - val_accuracy: 0.8676\n",
            "Epoch 563/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0812 - accuracy: 0.8649 - val_loss: 0.0791 - val_accuracy: 0.8679\n",
            "Epoch 564/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0812 - accuracy: 0.8649 - val_loss: 0.0791 - val_accuracy: 0.8677\n",
            "Epoch 565/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0812 - accuracy: 0.8651 - val_loss: 0.0791 - val_accuracy: 0.8677\n",
            "Epoch 566/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0812 - accuracy: 0.8652 - val_loss: 0.0791 - val_accuracy: 0.8674\n",
            "Epoch 567/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0812 - accuracy: 0.8651 - val_loss: 0.0791 - val_accuracy: 0.8679\n",
            "Epoch 568/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0812 - accuracy: 0.8650 - val_loss: 0.0791 - val_accuracy: 0.8677\n",
            "Epoch 569/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0812 - accuracy: 0.8650 - val_loss: 0.0790 - val_accuracy: 0.8679\n",
            "Epoch 570/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.8652 - val_loss: 0.0790 - val_accuracy: 0.8679\n",
            "Epoch 571/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.8650 - val_loss: 0.0790 - val_accuracy: 0.8681\n",
            "Epoch 572/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.8650 - val_loss: 0.0790 - val_accuracy: 0.8681\n",
            "Epoch 573/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.8652 - val_loss: 0.0790 - val_accuracy: 0.8681\n",
            "Epoch 574/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.8649 - val_loss: 0.0789 - val_accuracy: 0.8680\n",
            "Epoch 575/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0811 - accuracy: 0.8652 - val_loss: 0.0789 - val_accuracy: 0.8680\n",
            "Epoch 576/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.8652 - val_loss: 0.0790 - val_accuracy: 0.8679\n",
            "Epoch 577/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.8652 - val_loss: 0.0789 - val_accuracy: 0.8680\n",
            "Epoch 578/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.8652 - val_loss: 0.0789 - val_accuracy: 0.8677\n",
            "Epoch 579/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.8652 - val_loss: 0.0789 - val_accuracy: 0.8678\n",
            "Epoch 580/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0810 - accuracy: 0.8652 - val_loss: 0.0789 - val_accuracy: 0.8686\n",
            "Epoch 581/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0810 - accuracy: 0.8653 - val_loss: 0.0788 - val_accuracy: 0.8684\n",
            "Epoch 582/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.8652 - val_loss: 0.0788 - val_accuracy: 0.8683\n",
            "Epoch 583/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.8651 - val_loss: 0.0788 - val_accuracy: 0.8677\n",
            "Epoch 584/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.8653 - val_loss: 0.0788 - val_accuracy: 0.8682\n",
            "Epoch 585/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.8655 - val_loss: 0.0788 - val_accuracy: 0.8681\n",
            "Epoch 586/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0809 - accuracy: 0.8655 - val_loss: 0.0788 - val_accuracy: 0.8682\n",
            "Epoch 587/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0809 - accuracy: 0.8656 - val_loss: 0.0788 - val_accuracy: 0.8684\n",
            "Epoch 588/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.8654 - val_loss: 0.0787 - val_accuracy: 0.8681\n",
            "Epoch 589/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.8655 - val_loss: 0.0787 - val_accuracy: 0.8681\n",
            "Epoch 590/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.8655 - val_loss: 0.0787 - val_accuracy: 0.8685\n",
            "Epoch 591/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.8654 - val_loss: 0.0787 - val_accuracy: 0.8685\n",
            "Epoch 592/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0808 - accuracy: 0.8656 - val_loss: 0.0787 - val_accuracy: 0.8683\n",
            "Epoch 593/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0808 - accuracy: 0.8657 - val_loss: 0.0788 - val_accuracy: 0.8676\n",
            "Epoch 594/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.8655 - val_loss: 0.0787 - val_accuracy: 0.8687\n",
            "Epoch 595/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.8656 - val_loss: 0.0787 - val_accuracy: 0.8687\n",
            "Epoch 596/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.8655 - val_loss: 0.0787 - val_accuracy: 0.8684\n",
            "Epoch 597/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.8655 - val_loss: 0.0786 - val_accuracy: 0.8687\n",
            "Epoch 598/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0808 - accuracy: 0.8654 - val_loss: 0.0786 - val_accuracy: 0.8684\n",
            "Epoch 599/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0807 - accuracy: 0.8655 - val_loss: 0.0786 - val_accuracy: 0.8684\n",
            "Epoch 600/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0807 - accuracy: 0.8658 - val_loss: 0.0786 - val_accuracy: 0.8686\n",
            "Epoch 601/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0807 - accuracy: 0.8655 - val_loss: 0.0786 - val_accuracy: 0.8684\n",
            "Epoch 602/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0807 - accuracy: 0.8657 - val_loss: 0.0786 - val_accuracy: 0.8685\n",
            "Epoch 603/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0807 - accuracy: 0.8656 - val_loss: 0.0786 - val_accuracy: 0.8687\n",
            "Epoch 604/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0807 - accuracy: 0.8656 - val_loss: 0.0785 - val_accuracy: 0.8684\n",
            "Epoch 605/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0807 - accuracy: 0.8658 - val_loss: 0.0786 - val_accuracy: 0.8684\n",
            "Epoch 606/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0807 - accuracy: 0.8657 - val_loss: 0.0785 - val_accuracy: 0.8688\n",
            "Epoch 607/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8656 - val_loss: 0.0785 - val_accuracy: 0.8686\n",
            "Epoch 608/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8659 - val_loss: 0.0785 - val_accuracy: 0.8686\n",
            "Epoch 609/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8660 - val_loss: 0.0785 - val_accuracy: 0.8684\n",
            "Epoch 610/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0806 - accuracy: 0.8660 - val_loss: 0.0785 - val_accuracy: 0.8688\n",
            "Epoch 611/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0806 - accuracy: 0.8657 - val_loss: 0.0784 - val_accuracy: 0.8686\n",
            "Epoch 612/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8657 - val_loss: 0.0784 - val_accuracy: 0.8685\n",
            "Epoch 613/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8655 - val_loss: 0.0784 - val_accuracy: 0.8686\n",
            "Epoch 614/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8658 - val_loss: 0.0784 - val_accuracy: 0.8690\n",
            "Epoch 615/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.8658 - val_loss: 0.0784 - val_accuracy: 0.8688\n",
            "Epoch 616/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0805 - accuracy: 0.8658 - val_loss: 0.0784 - val_accuracy: 0.8690\n",
            "Epoch 617/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0805 - accuracy: 0.8659 - val_loss: 0.0784 - val_accuracy: 0.8687\n",
            "Epoch 618/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.8661 - val_loss: 0.0784 - val_accuracy: 0.8691\n",
            "Epoch 619/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.8659 - val_loss: 0.0784 - val_accuracy: 0.8683\n",
            "Epoch 620/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0805 - accuracy: 0.8659 - val_loss: 0.0784 - val_accuracy: 0.8684\n",
            "Epoch 621/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.8658 - val_loss: 0.0783 - val_accuracy: 0.8686\n",
            "Epoch 622/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0804 - accuracy: 0.8658 - val_loss: 0.0783 - val_accuracy: 0.8685\n",
            "Epoch 623/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0804 - accuracy: 0.8658 - val_loss: 0.0783 - val_accuracy: 0.8688\n",
            "Epoch 624/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.8659 - val_loss: 0.0783 - val_accuracy: 0.8687\n",
            "Epoch 625/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.8660 - val_loss: 0.0783 - val_accuracy: 0.8687\n",
            "Epoch 626/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.8659 - val_loss: 0.0783 - val_accuracy: 0.8687\n",
            "Epoch 627/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0804 - accuracy: 0.8662 - val_loss: 0.0783 - val_accuracy: 0.8691\n",
            "Epoch 628/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0804 - accuracy: 0.8658 - val_loss: 0.0782 - val_accuracy: 0.8690\n",
            "Epoch 629/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.8660 - val_loss: 0.0782 - val_accuracy: 0.8690\n",
            "Epoch 630/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.8659 - val_loss: 0.0782 - val_accuracy: 0.8690\n",
            "Epoch 631/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.8663 - val_loss: 0.0782 - val_accuracy: 0.8690\n",
            "Epoch 632/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.8661 - val_loss: 0.0782 - val_accuracy: 0.8690\n",
            "Epoch 633/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0803 - accuracy: 0.8662 - val_loss: 0.0782 - val_accuracy: 0.8691\n",
            "Epoch 634/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0803 - accuracy: 0.8660 - val_loss: 0.0782 - val_accuracy: 0.8691\n",
            "Epoch 635/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.8660 - val_loss: 0.0782 - val_accuracy: 0.8686\n",
            "Epoch 636/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.8662 - val_loss: 0.0781 - val_accuracy: 0.8689\n",
            "Epoch 637/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.8662 - val_loss: 0.0781 - val_accuracy: 0.8690\n",
            "Epoch 638/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.8660 - val_loss: 0.0781 - val_accuracy: 0.8690\n",
            "Epoch 639/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0802 - accuracy: 0.8662 - val_loss: 0.0781 - val_accuracy: 0.8688\n",
            "Epoch 640/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0802 - accuracy: 0.8662 - val_loss: 0.0781 - val_accuracy: 0.8688\n",
            "Epoch 641/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0802 - accuracy: 0.8663 - val_loss: 0.0781 - val_accuracy: 0.8692\n",
            "Epoch 642/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0802 - accuracy: 0.8662 - val_loss: 0.0781 - val_accuracy: 0.8690\n",
            "Epoch 643/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0802 - accuracy: 0.8663 - val_loss: 0.0780 - val_accuracy: 0.8692\n",
            "Epoch 644/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0802 - accuracy: 0.8660 - val_loss: 0.0780 - val_accuracy: 0.8691\n",
            "Epoch 645/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0802 - accuracy: 0.8661 - val_loss: 0.0782 - val_accuracy: 0.8691\n",
            "Epoch 646/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0802 - accuracy: 0.8661 - val_loss: 0.0780 - val_accuracy: 0.8692\n",
            "Epoch 647/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8662 - val_loss: 0.0780 - val_accuracy: 0.8691\n",
            "Epoch 648/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8665 - val_loss: 0.0780 - val_accuracy: 0.8692\n",
            "Epoch 649/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8659 - val_loss: 0.0780 - val_accuracy: 0.8690\n",
            "Epoch 650/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8663 - val_loss: 0.0780 - val_accuracy: 0.8693\n",
            "Epoch 651/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.8665 - val_loss: 0.0780 - val_accuracy: 0.8695\n",
            "Epoch 652/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0801 - accuracy: 0.8665 - val_loss: 0.0780 - val_accuracy: 0.8689\n",
            "Epoch 653/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8664 - val_loss: 0.0780 - val_accuracy: 0.8688\n",
            "Epoch 654/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8664 - val_loss: 0.0780 - val_accuracy: 0.8694\n",
            "Epoch 655/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8663 - val_loss: 0.0779 - val_accuracy: 0.8691\n",
            "Epoch 656/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0800 - accuracy: 0.8664 - val_loss: 0.0780 - val_accuracy: 0.8687\n",
            "Epoch 657/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.8662 - val_loss: 0.0779 - val_accuracy: 0.8691\n",
            "Epoch 658/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.8664 - val_loss: 0.0779 - val_accuracy: 0.8692\n",
            "Epoch 659/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0800 - accuracy: 0.8666 - val_loss: 0.0779 - val_accuracy: 0.8696\n",
            "Epoch 660/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0800 - accuracy: 0.8663 - val_loss: 0.0778 - val_accuracy: 0.8699\n",
            "Epoch 661/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0800 - accuracy: 0.8666 - val_loss: 0.0778 - val_accuracy: 0.8692\n",
            "Epoch 662/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0800 - accuracy: 0.8667 - val_loss: 0.0778 - val_accuracy: 0.8691\n",
            "Epoch 663/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.8666 - val_loss: 0.0778 - val_accuracy: 0.8692\n",
            "Epoch 664/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.8667 - val_loss: 0.0778 - val_accuracy: 0.8688\n",
            "Epoch 665/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8663 - val_loss: 0.0778 - val_accuracy: 0.8692\n",
            "Epoch 666/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8666 - val_loss: 0.0778 - val_accuracy: 0.8689\n",
            "Epoch 667/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8665 - val_loss: 0.0778 - val_accuracy: 0.8691\n",
            "Epoch 668/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8670 - val_loss: 0.0778 - val_accuracy: 0.8697\n",
            "Epoch 669/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0799 - accuracy: 0.8664 - val_loss: 0.0778 - val_accuracy: 0.8694\n",
            "Epoch 670/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8667 - val_loss: 0.0777 - val_accuracy: 0.8697\n",
            "Epoch 671/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0799 - accuracy: 0.8666 - val_loss: 0.0778 - val_accuracy: 0.8699\n",
            "Epoch 672/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8666 - val_loss: 0.0777 - val_accuracy: 0.8700\n",
            "Epoch 673/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8666 - val_loss: 0.0777 - val_accuracy: 0.8699\n",
            "Epoch 674/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0798 - accuracy: 0.8668 - val_loss: 0.0777 - val_accuracy: 0.8699\n",
            "Epoch 675/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0798 - accuracy: 0.8668 - val_loss: 0.0777 - val_accuracy: 0.8699\n",
            "Epoch 676/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.8666 - val_loss: 0.0777 - val_accuracy: 0.8700\n",
            "Epoch 677/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.8668 - val_loss: 0.0776 - val_accuracy: 0.8697\n",
            "Epoch 678/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.8667 - val_loss: 0.0776 - val_accuracy: 0.8700\n",
            "Epoch 679/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.8665 - val_loss: 0.0777 - val_accuracy: 0.8694\n",
            "Epoch 680/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0798 - accuracy: 0.8669 - val_loss: 0.0776 - val_accuracy: 0.8705\n",
            "Epoch 681/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0798 - accuracy: 0.8666 - val_loss: 0.0776 - val_accuracy: 0.8700\n",
            "Epoch 682/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.8667 - val_loss: 0.0776 - val_accuracy: 0.8699\n",
            "Epoch 683/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8670 - val_loss: 0.0776 - val_accuracy: 0.8702\n",
            "Epoch 684/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8667 - val_loss: 0.0776 - val_accuracy: 0.8694\n",
            "Epoch 685/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8669 - val_loss: 0.0776 - val_accuracy: 0.8699\n",
            "Epoch 686/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0797 - accuracy: 0.8666 - val_loss: 0.0776 - val_accuracy: 0.8698\n",
            "Epoch 687/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0797 - accuracy: 0.8670 - val_loss: 0.0776 - val_accuracy: 0.8698\n",
            "Epoch 688/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8669 - val_loss: 0.0775 - val_accuracy: 0.8702\n",
            "Epoch 689/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8669 - val_loss: 0.0775 - val_accuracy: 0.8700\n",
            "Epoch 690/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8669 - val_loss: 0.0776 - val_accuracy: 0.8702\n",
            "Epoch 691/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8670 - val_loss: 0.0775 - val_accuracy: 0.8702\n",
            "Epoch 692/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0796 - accuracy: 0.8669 - val_loss: 0.0775 - val_accuracy: 0.8702\n",
            "Epoch 693/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0796 - accuracy: 0.8669 - val_loss: 0.0775 - val_accuracy: 0.8704\n",
            "Epoch 694/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.8669 - val_loss: 0.0775 - val_accuracy: 0.8702\n",
            "Epoch 695/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.8670 - val_loss: 0.0775 - val_accuracy: 0.8702\n",
            "Epoch 696/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.8669 - val_loss: 0.0775 - val_accuracy: 0.8696\n",
            "Epoch 697/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0796 - accuracy: 0.8669 - val_loss: 0.0774 - val_accuracy: 0.8699\n",
            "Epoch 698/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0796 - accuracy: 0.8672 - val_loss: 0.0775 - val_accuracy: 0.8702\n",
            "Epoch 699/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0796 - accuracy: 0.8671 - val_loss: 0.0774 - val_accuracy: 0.8703\n",
            "Epoch 700/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.8670 - val_loss: 0.0774 - val_accuracy: 0.8702\n",
            "Epoch 701/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.8672 - val_loss: 0.0774 - val_accuracy: 0.8705\n",
            "Epoch 702/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.8670 - val_loss: 0.0774 - val_accuracy: 0.8705\n",
            "Epoch 703/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0795 - accuracy: 0.8670 - val_loss: 0.0774 - val_accuracy: 0.8700\n",
            "Epoch 704/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0795 - accuracy: 0.8672 - val_loss: 0.0774 - val_accuracy: 0.8704\n",
            "Epoch 705/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0795 - accuracy: 0.8671 - val_loss: 0.0774 - val_accuracy: 0.8706\n",
            "Epoch 706/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.8671 - val_loss: 0.0773 - val_accuracy: 0.8701\n",
            "Epoch 707/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.8671 - val_loss: 0.0773 - val_accuracy: 0.8701\n",
            "Epoch 708/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.8673 - val_loss: 0.0773 - val_accuracy: 0.8705\n",
            "Epoch 709/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0795 - accuracy: 0.8672 - val_loss: 0.0773 - val_accuracy: 0.8699\n",
            "Epoch 710/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0795 - accuracy: 0.8672 - val_loss: 0.0773 - val_accuracy: 0.8704\n",
            "Epoch 711/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.8672 - val_loss: 0.0773 - val_accuracy: 0.8705\n",
            "Epoch 712/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8669 - val_loss: 0.0773 - val_accuracy: 0.8704\n",
            "Epoch 713/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8672 - val_loss: 0.0773 - val_accuracy: 0.8705\n",
            "Epoch 714/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8670 - val_loss: 0.0773 - val_accuracy: 0.8708\n",
            "Epoch 715/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0794 - accuracy: 0.8674 - val_loss: 0.0773 - val_accuracy: 0.8701\n",
            "Epoch 716/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0794 - accuracy: 0.8672 - val_loss: 0.0773 - val_accuracy: 0.8702\n",
            "Epoch 717/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8673 - val_loss: 0.0772 - val_accuracy: 0.8706\n",
            "Epoch 718/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8673 - val_loss: 0.0772 - val_accuracy: 0.8702\n",
            "Epoch 719/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8675 - val_loss: 0.0772 - val_accuracy: 0.8704\n",
            "Epoch 720/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8671 - val_loss: 0.0772 - val_accuracy: 0.8704\n",
            "Epoch 721/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0793 - accuracy: 0.8673 - val_loss: 0.0772 - val_accuracy: 0.8707\n",
            "Epoch 722/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0793 - accuracy: 0.8671 - val_loss: 0.0772 - val_accuracy: 0.8707\n",
            "Epoch 723/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8674 - val_loss: 0.0772 - val_accuracy: 0.8708\n",
            "Epoch 724/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8673 - val_loss: 0.0772 - val_accuracy: 0.8704\n",
            "Epoch 725/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8673 - val_loss: 0.0771 - val_accuracy: 0.8705\n",
            "Epoch 726/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8673 - val_loss: 0.0772 - val_accuracy: 0.8706\n",
            "Epoch 727/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0793 - accuracy: 0.8675 - val_loss: 0.0771 - val_accuracy: 0.8707\n",
            "Epoch 728/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0793 - accuracy: 0.8675 - val_loss: 0.0772 - val_accuracy: 0.8706\n",
            "Epoch 729/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8673 - val_loss: 0.0771 - val_accuracy: 0.8706\n",
            "Epoch 730/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8676 - val_loss: 0.0771 - val_accuracy: 0.8706\n",
            "Epoch 731/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.8673 - val_loss: 0.0771 - val_accuracy: 0.8706\n",
            "Epoch 732/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.8675 - val_loss: 0.0771 - val_accuracy: 0.8706\n",
            "Epoch 733/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0792 - accuracy: 0.8674 - val_loss: 0.0771 - val_accuracy: 0.8708\n",
            "Epoch 734/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0792 - accuracy: 0.8671 - val_loss: 0.0771 - val_accuracy: 0.8705\n",
            "Epoch 735/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.8675 - val_loss: 0.0771 - val_accuracy: 0.8706\n",
            "Epoch 736/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.8674 - val_loss: 0.0770 - val_accuracy: 0.8706\n",
            "Epoch 737/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.8673 - val_loss: 0.0770 - val_accuracy: 0.8707\n",
            "Epoch 738/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0792 - accuracy: 0.8676 - val_loss: 0.0770 - val_accuracy: 0.8708\n",
            "Epoch 739/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0792 - accuracy: 0.8676 - val_loss: 0.0770 - val_accuracy: 0.8708\n",
            "Epoch 740/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0792 - accuracy: 0.8676 - val_loss: 0.0770 - val_accuracy: 0.8709\n",
            "Epoch 741/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.8676 - val_loss: 0.0770 - val_accuracy: 0.8705\n",
            "Epoch 742/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8677 - val_loss: 0.0770 - val_accuracy: 0.8709\n",
            "Epoch 743/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8678 - val_loss: 0.0770 - val_accuracy: 0.8708\n",
            "Epoch 744/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8675 - val_loss: 0.0770 - val_accuracy: 0.8706\n",
            "Epoch 745/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0791 - accuracy: 0.8675 - val_loss: 0.0769 - val_accuracy: 0.8708\n",
            "Epoch 746/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0791 - accuracy: 0.8677 - val_loss: 0.0770 - val_accuracy: 0.8709\n",
            "Epoch 747/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8676 - val_loss: 0.0769 - val_accuracy: 0.8709\n",
            "Epoch 748/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8674 - val_loss: 0.0770 - val_accuracy: 0.8709\n",
            "Epoch 749/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8673 - val_loss: 0.0769 - val_accuracy: 0.8707\n",
            "Epoch 750/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8676 - val_loss: 0.0769 - val_accuracy: 0.8710\n",
            "Epoch 751/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0791 - accuracy: 0.8677 - val_loss: 0.0769 - val_accuracy: 0.8705\n",
            "Epoch 752/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0790 - accuracy: 0.8676 - val_loss: 0.0769 - val_accuracy: 0.8711\n",
            "Epoch 753/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8675 - val_loss: 0.0769 - val_accuracy: 0.8709\n",
            "Epoch 754/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8678 - val_loss: 0.0769 - val_accuracy: 0.8709\n",
            "Epoch 755/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8677 - val_loss: 0.0769 - val_accuracy: 0.8709\n",
            "Epoch 756/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8676 - val_loss: 0.0769 - val_accuracy: 0.8711\n",
            "Epoch 757/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0790 - accuracy: 0.8677 - val_loss: 0.0769 - val_accuracy: 0.8711\n",
            "Epoch 758/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0790 - accuracy: 0.8678 - val_loss: 0.0768 - val_accuracy: 0.8709\n",
            "Epoch 759/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8678 - val_loss: 0.0768 - val_accuracy: 0.8706\n",
            "Epoch 760/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8679 - val_loss: 0.0768 - val_accuracy: 0.8709\n",
            "Epoch 761/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8676 - val_loss: 0.0768 - val_accuracy: 0.8708\n",
            "Epoch 762/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.8678 - val_loss: 0.0768 - val_accuracy: 0.8709\n",
            "Epoch 763/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0789 - accuracy: 0.8678 - val_loss: 0.0768 - val_accuracy: 0.8711\n",
            "Epoch 764/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0789 - accuracy: 0.8680 - val_loss: 0.0768 - val_accuracy: 0.8710\n",
            "Epoch 765/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.8678 - val_loss: 0.0768 - val_accuracy: 0.8709\n",
            "Epoch 766/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.8678 - val_loss: 0.0768 - val_accuracy: 0.8708\n",
            "Epoch 767/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.8676 - val_loss: 0.0767 - val_accuracy: 0.8708\n",
            "Epoch 768/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.8678 - val_loss: 0.0767 - val_accuracy: 0.8711\n",
            "Epoch 769/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0789 - accuracy: 0.8678 - val_loss: 0.0767 - val_accuracy: 0.8709\n",
            "Epoch 770/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0789 - accuracy: 0.8677 - val_loss: 0.0767 - val_accuracy: 0.8709\n",
            "Epoch 771/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.8679 - val_loss: 0.0767 - val_accuracy: 0.8712\n",
            "Epoch 772/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8678 - val_loss: 0.0767 - val_accuracy: 0.8712\n",
            "Epoch 773/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8677 - val_loss: 0.0767 - val_accuracy: 0.8712\n",
            "Epoch 774/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8682 - val_loss: 0.0767 - val_accuracy: 0.8711\n",
            "Epoch 775/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0788 - accuracy: 0.8680 - val_loss: 0.0767 - val_accuracy: 0.8712\n",
            "Epoch 776/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0788 - accuracy: 0.8682 - val_loss: 0.0766 - val_accuracy: 0.8712\n",
            "Epoch 777/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8681 - val_loss: 0.0766 - val_accuracy: 0.8711\n",
            "Epoch 778/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8679 - val_loss: 0.0766 - val_accuracy: 0.8710\n",
            "Epoch 779/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8680 - val_loss: 0.0766 - val_accuracy: 0.8711\n",
            "Epoch 780/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8680 - val_loss: 0.0766 - val_accuracy: 0.8712\n",
            "Epoch 781/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0788 - accuracy: 0.8683 - val_loss: 0.0766 - val_accuracy: 0.8711\n",
            "Epoch 782/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0788 - accuracy: 0.8682 - val_loss: 0.0766 - val_accuracy: 0.8711\n",
            "Epoch 783/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8682 - val_loss: 0.0766 - val_accuracy: 0.8711\n",
            "Epoch 784/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8682 - val_loss: 0.0766 - val_accuracy: 0.8711\n",
            "Epoch 785/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8683 - val_loss: 0.0766 - val_accuracy: 0.8713\n",
            "Epoch 786/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8682 - val_loss: 0.0766 - val_accuracy: 0.8711\n",
            "Epoch 787/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0787 - accuracy: 0.8681 - val_loss: 0.0766 - val_accuracy: 0.8712\n",
            "Epoch 788/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0787 - accuracy: 0.8682 - val_loss: 0.0766 - val_accuracy: 0.8711\n",
            "Epoch 789/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8680 - val_loss: 0.0765 - val_accuracy: 0.8715\n",
            "Epoch 790/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8680 - val_loss: 0.0765 - val_accuracy: 0.8713\n",
            "Epoch 791/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8682 - val_loss: 0.0765 - val_accuracy: 0.8709\n",
            "Epoch 792/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8683 - val_loss: 0.0765 - val_accuracy: 0.8712\n",
            "Epoch 793/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0787 - accuracy: 0.8682 - val_loss: 0.0765 - val_accuracy: 0.8713\n",
            "Epoch 794/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0786 - accuracy: 0.8683 - val_loss: 0.0765 - val_accuracy: 0.8712\n",
            "Epoch 795/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8681 - val_loss: 0.0765 - val_accuracy: 0.8714\n",
            "Epoch 796/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8682 - val_loss: 0.0765 - val_accuracy: 0.8711\n",
            "Epoch 797/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8684 - val_loss: 0.0765 - val_accuracy: 0.8712\n",
            "Epoch 798/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8682 - val_loss: 0.0765 - val_accuracy: 0.8712\n",
            "Epoch 799/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0786 - accuracy: 0.8683 - val_loss: 0.0764 - val_accuracy: 0.8712\n",
            "Epoch 800/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0786 - accuracy: 0.8682 - val_loss: 0.0764 - val_accuracy: 0.8713\n",
            "Epoch 801/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8683 - val_loss: 0.0764 - val_accuracy: 0.8712\n",
            "Epoch 802/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8683 - val_loss: 0.0764 - val_accuracy: 0.8712\n",
            "Epoch 803/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8683 - val_loss: 0.0764 - val_accuracy: 0.8713\n",
            "Epoch 804/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8685 - val_loss: 0.0764 - val_accuracy: 0.8712\n",
            "Epoch 805/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0785 - accuracy: 0.8685 - val_loss: 0.0764 - val_accuracy: 0.8713\n",
            "Epoch 806/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0785 - accuracy: 0.8684 - val_loss: 0.0764 - val_accuracy: 0.8712\n",
            "Epoch 807/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8683 - val_loss: 0.0764 - val_accuracy: 0.8717\n",
            "Epoch 808/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8683 - val_loss: 0.0764 - val_accuracy: 0.8713\n",
            "Epoch 809/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8684 - val_loss: 0.0763 - val_accuracy: 0.8715\n",
            "Epoch 810/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8684 - val_loss: 0.0763 - val_accuracy: 0.8716\n",
            "Epoch 811/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0785 - accuracy: 0.8683 - val_loss: 0.0763 - val_accuracy: 0.8717\n",
            "Epoch 812/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0785 - accuracy: 0.8683 - val_loss: 0.0763 - val_accuracy: 0.8717\n",
            "Epoch 813/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8682 - val_loss: 0.0763 - val_accuracy: 0.8713\n",
            "Epoch 814/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8682 - val_loss: 0.0763 - val_accuracy: 0.8715\n",
            "Epoch 815/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8686 - val_loss: 0.0763 - val_accuracy: 0.8715\n",
            "Epoch 816/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8685 - val_loss: 0.0763 - val_accuracy: 0.8712\n",
            "Epoch 817/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8684 - val_loss: 0.0763 - val_accuracy: 0.8716\n",
            "Epoch 818/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0784 - accuracy: 0.8683 - val_loss: 0.0763 - val_accuracy: 0.8718\n",
            "Epoch 819/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8686 - val_loss: 0.0763 - val_accuracy: 0.8715\n",
            "Epoch 820/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8686 - val_loss: 0.0763 - val_accuracy: 0.8713\n",
            "Epoch 821/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8684 - val_loss: 0.0762 - val_accuracy: 0.8715\n",
            "Epoch 822/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8686 - val_loss: 0.0762 - val_accuracy: 0.8719\n",
            "Epoch 823/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0784 - accuracy: 0.8686 - val_loss: 0.0762 - val_accuracy: 0.8714\n",
            "Epoch 824/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0784 - accuracy: 0.8684 - val_loss: 0.0763 - val_accuracy: 0.8717\n",
            "Epoch 825/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8686 - val_loss: 0.0762 - val_accuracy: 0.8715\n",
            "Epoch 826/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8686 - val_loss: 0.0762 - val_accuracy: 0.8716\n",
            "Epoch 827/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8687 - val_loss: 0.0762 - val_accuracy: 0.8715\n",
            "Epoch 828/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8685 - val_loss: 0.0762 - val_accuracy: 0.8717\n",
            "Epoch 829/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0762 - val_accuracy: 0.8713\n",
            "Epoch 830/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0762 - val_accuracy: 0.8716\n",
            "Epoch 831/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0762 - val_accuracy: 0.8719\n",
            "Epoch 832/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8687 - val_loss: 0.0761 - val_accuracy: 0.8717\n",
            "Epoch 833/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8689 - val_loss: 0.0761 - val_accuracy: 0.8716\n",
            "Epoch 834/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8716\n",
            "Epoch 835/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8716\n",
            "Epoch 836/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8720\n",
            "Epoch 837/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8719\n",
            "Epoch 838/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8716\n",
            "Epoch 839/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8720\n",
            "Epoch 840/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8715\n",
            "Epoch 841/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0782 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8716\n",
            "Epoch 842/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0782 - accuracy: 0.8687 - val_loss: 0.0761 - val_accuracy: 0.8716\n",
            "Epoch 843/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8685 - val_loss: 0.0761 - val_accuracy: 0.8719\n",
            "Epoch 844/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8686 - val_loss: 0.0761 - val_accuracy: 0.8716\n",
            "Epoch 845/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8686 - val_loss: 0.0760 - val_accuracy: 0.8716\n",
            "Epoch 846/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8687 - val_loss: 0.0760 - val_accuracy: 0.8720\n",
            "Epoch 847/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0782 - accuracy: 0.8686 - val_loss: 0.0760 - val_accuracy: 0.8721\n",
            "Epoch 848/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0782 - accuracy: 0.8689 - val_loss: 0.0760 - val_accuracy: 0.8718\n",
            "Epoch 849/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0782 - accuracy: 0.8686 - val_loss: 0.0760 - val_accuracy: 0.8716\n",
            "Epoch 850/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8687 - val_loss: 0.0760 - val_accuracy: 0.8719\n",
            "Epoch 851/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0781 - accuracy: 0.8687 - val_loss: 0.0760 - val_accuracy: 0.8719\n",
            "Epoch 852/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.8687 - val_loss: 0.0760 - val_accuracy: 0.8718\n",
            "Epoch 853/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0781 - accuracy: 0.8690 - val_loss: 0.0760 - val_accuracy: 0.8722\n",
            "Epoch 854/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0781 - accuracy: 0.8693 - val_loss: 0.0761 - val_accuracy: 0.8720\n",
            "Epoch 855/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.8687 - val_loss: 0.0760 - val_accuracy: 0.8722\n",
            "Epoch 856/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.8688 - val_loss: 0.0760 - val_accuracy: 0.8716\n",
            "Epoch 857/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.8691 - val_loss: 0.0760 - val_accuracy: 0.8713\n",
            "Epoch 858/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.8692 - val_loss: 0.0759 - val_accuracy: 0.8719\n",
            "Epoch 859/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0781 - accuracy: 0.8688 - val_loss: 0.0759 - val_accuracy: 0.8717\n",
            "Epoch 860/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0781 - accuracy: 0.8690 - val_loss: 0.0759 - val_accuracy: 0.8719\n",
            "Epoch 861/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0781 - accuracy: 0.8689 - val_loss: 0.0759 - val_accuracy: 0.8719\n",
            "Epoch 862/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8690 - val_loss: 0.0759 - val_accuracy: 0.8722\n",
            "Epoch 863/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0780 - accuracy: 0.8688 - val_loss: 0.0759 - val_accuracy: 0.8718\n",
            "Epoch 864/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0780 - accuracy: 0.8688 - val_loss: 0.0759 - val_accuracy: 0.8720\n",
            "Epoch 865/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0780 - accuracy: 0.8690 - val_loss: 0.0759 - val_accuracy: 0.8720\n",
            "Epoch 866/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8688 - val_loss: 0.0759 - val_accuracy: 0.8717\n",
            "Epoch 867/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8691 - val_loss: 0.0758 - val_accuracy: 0.8722\n",
            "Epoch 868/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8688 - val_loss: 0.0758 - val_accuracy: 0.8722\n",
            "Epoch 869/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8689 - val_loss: 0.0758 - val_accuracy: 0.8716\n",
            "Epoch 870/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0780 - accuracy: 0.8688 - val_loss: 0.0758 - val_accuracy: 0.8722\n",
            "Epoch 871/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0780 - accuracy: 0.8690 - val_loss: 0.0758 - val_accuracy: 0.8715\n",
            "Epoch 872/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8690 - val_loss: 0.0758 - val_accuracy: 0.8721\n",
            "Epoch 873/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8689 - val_loss: 0.0758 - val_accuracy: 0.8722\n",
            "Epoch 874/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8688 - val_loss: 0.0758 - val_accuracy: 0.8719\n",
            "Epoch 875/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8691 - val_loss: 0.0758 - val_accuracy: 0.8722\n",
            "Epoch 876/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0779 - accuracy: 0.8690 - val_loss: 0.0758 - val_accuracy: 0.8723\n",
            "Epoch 877/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0779 - accuracy: 0.8689 - val_loss: 0.0758 - val_accuracy: 0.8723\n",
            "Epoch 878/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8690 - val_loss: 0.0758 - val_accuracy: 0.8724\n",
            "Epoch 879/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8691 - val_loss: 0.0757 - val_accuracy: 0.8722\n",
            "Epoch 880/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0779 - accuracy: 0.8691 - val_loss: 0.0757 - val_accuracy: 0.8723\n",
            "Epoch 881/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0779 - accuracy: 0.8690 - val_loss: 0.0758 - val_accuracy: 0.8719\n",
            "Epoch 882/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0779 - accuracy: 0.8690 - val_loss: 0.0757 - val_accuracy: 0.8723\n",
            "Epoch 883/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8690 - val_loss: 0.0757 - val_accuracy: 0.8717\n",
            "Epoch 884/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8689 - val_loss: 0.0757 - val_accuracy: 0.8716\n",
            "Epoch 885/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8693 - val_loss: 0.0757 - val_accuracy: 0.8726\n",
            "Epoch 886/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8691 - val_loss: 0.0757 - val_accuracy: 0.8723\n",
            "Epoch 887/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0778 - accuracy: 0.8691 - val_loss: 0.0757 - val_accuracy: 0.8722\n",
            "Epoch 888/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0778 - accuracy: 0.8691 - val_loss: 0.0757 - val_accuracy: 0.8719\n",
            "Epoch 889/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8692 - val_loss: 0.0757 - val_accuracy: 0.8723\n",
            "Epoch 890/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8693 - val_loss: 0.0757 - val_accuracy: 0.8719\n",
            "Epoch 891/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8692 - val_loss: 0.0757 - val_accuracy: 0.8723\n",
            "Epoch 892/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8690 - val_loss: 0.0757 - val_accuracy: 0.8726\n",
            "Epoch 893/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0778 - accuracy: 0.8693 - val_loss: 0.0756 - val_accuracy: 0.8725\n",
            "Epoch 894/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0778 - accuracy: 0.8693 - val_loss: 0.0756 - val_accuracy: 0.8723\n",
            "Epoch 895/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8690 - val_loss: 0.0756 - val_accuracy: 0.8726\n",
            "Epoch 896/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8691 - val_loss: 0.0756 - val_accuracy: 0.8720\n",
            "Epoch 897/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8691 - val_loss: 0.0756 - val_accuracy: 0.8724\n",
            "Epoch 898/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8693 - val_loss: 0.0756 - val_accuracy: 0.8725\n",
            "Epoch 899/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0777 - accuracy: 0.8691 - val_loss: 0.0756 - val_accuracy: 0.8722\n",
            "Epoch 900/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0777 - accuracy: 0.8689 - val_loss: 0.0756 - val_accuracy: 0.8724\n",
            "Epoch 901/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8692 - val_loss: 0.0756 - val_accuracy: 0.8720\n",
            "Epoch 902/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0777 - accuracy: 0.8691 - val_loss: 0.0756 - val_accuracy: 0.8727\n",
            "Epoch 903/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8692 - val_loss: 0.0756 - val_accuracy: 0.8727\n",
            "Epoch 904/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8692 - val_loss: 0.0756 - val_accuracy: 0.8723\n",
            "Epoch 905/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0777 - accuracy: 0.8694 - val_loss: 0.0755 - val_accuracy: 0.8729\n",
            "Epoch 906/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0777 - accuracy: 0.8692 - val_loss: 0.0756 - val_accuracy: 0.8724\n",
            "Epoch 907/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8693 - val_loss: 0.0755 - val_accuracy: 0.8723\n",
            "Epoch 908/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8690 - val_loss: 0.0755 - val_accuracy: 0.8724\n",
            "Epoch 909/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8694 - val_loss: 0.0755 - val_accuracy: 0.8728\n",
            "Epoch 910/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8692 - val_loss: 0.0755 - val_accuracy: 0.8727\n",
            "Epoch 911/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0776 - accuracy: 0.8695 - val_loss: 0.0755 - val_accuracy: 0.8725\n",
            "Epoch 912/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0776 - accuracy: 0.8694 - val_loss: 0.0755 - val_accuracy: 0.8723\n",
            "Epoch 913/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8694 - val_loss: 0.0755 - val_accuracy: 0.8728\n",
            "Epoch 914/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8694 - val_loss: 0.0755 - val_accuracy: 0.8725\n",
            "Epoch 915/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8692 - val_loss: 0.0755 - val_accuracy: 0.8727\n",
            "Epoch 916/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8692 - val_loss: 0.0755 - val_accuracy: 0.8722\n",
            "Epoch 917/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0776 - accuracy: 0.8693 - val_loss: 0.0755 - val_accuracy: 0.8719\n",
            "Epoch 918/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0776 - accuracy: 0.8694 - val_loss: 0.0754 - val_accuracy: 0.8723\n",
            "Epoch 919/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8692 - val_loss: 0.0754 - val_accuracy: 0.8726\n",
            "Epoch 920/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8695 - val_loss: 0.0754 - val_accuracy: 0.8725\n",
            "Epoch 921/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8692 - val_loss: 0.0754 - val_accuracy: 0.8723\n",
            "Epoch 922/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8694 - val_loss: 0.0754 - val_accuracy: 0.8726\n",
            "Epoch 923/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0775 - accuracy: 0.8696 - val_loss: 0.0754 - val_accuracy: 0.8729\n",
            "Epoch 924/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0775 - accuracy: 0.8692 - val_loss: 0.0754 - val_accuracy: 0.8725\n",
            "Epoch 925/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8694 - val_loss: 0.0754 - val_accuracy: 0.8723\n",
            "Epoch 926/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8692 - val_loss: 0.0754 - val_accuracy: 0.8727\n",
            "Epoch 927/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8693 - val_loss: 0.0754 - val_accuracy: 0.8728\n",
            "Epoch 928/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0775 - accuracy: 0.8694 - val_loss: 0.0754 - val_accuracy: 0.8729\n",
            "Epoch 929/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0775 - accuracy: 0.8694 - val_loss: 0.0754 - val_accuracy: 0.8729\n",
            "Epoch 930/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0775 - accuracy: 0.8694 - val_loss: 0.0754 - val_accuracy: 0.8729\n",
            "Epoch 931/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8695 - val_loss: 0.0754 - val_accuracy: 0.8723\n",
            "Epoch 932/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8694 - val_loss: 0.0753 - val_accuracy: 0.8727\n",
            "Epoch 933/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8696 - val_loss: 0.0753 - val_accuracy: 0.8727\n",
            "Epoch 934/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8695 - val_loss: 0.0753 - val_accuracy: 0.8726\n",
            "Epoch 935/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0774 - accuracy: 0.8695 - val_loss: 0.0753 - val_accuracy: 0.8723\n",
            "Epoch 936/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0774 - accuracy: 0.8695 - val_loss: 0.0753 - val_accuracy: 0.8727\n",
            "Epoch 937/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8694 - val_loss: 0.0753 - val_accuracy: 0.8723\n",
            "Epoch 938/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8694 - val_loss: 0.0753 - val_accuracy: 0.8729\n",
            "Epoch 939/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8696 - val_loss: 0.0753 - val_accuracy: 0.8726\n",
            "Epoch 940/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8694 - val_loss: 0.0753 - val_accuracy: 0.8728\n",
            "Epoch 941/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0774 - accuracy: 0.8697 - val_loss: 0.0753 - val_accuracy: 0.8727\n",
            "Epoch 942/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0774 - accuracy: 0.8694 - val_loss: 0.0753 - val_accuracy: 0.8724\n",
            "Epoch 943/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8694 - val_loss: 0.0753 - val_accuracy: 0.8727\n",
            "Epoch 944/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8695 - val_loss: 0.0753 - val_accuracy: 0.8726\n",
            "Epoch 945/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8694 - val_loss: 0.0752 - val_accuracy: 0.8728\n",
            "Epoch 946/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8697 - val_loss: 0.0753 - val_accuracy: 0.8726\n",
            "Epoch 947/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0774 - accuracy: 0.8695 - val_loss: 0.0752 - val_accuracy: 0.8728\n",
            "Epoch 948/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0773 - accuracy: 0.8694 - val_loss: 0.0752 - val_accuracy: 0.8730\n",
            "Epoch 949/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8698 - val_loss: 0.0752 - val_accuracy: 0.8724\n",
            "Epoch 950/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8696 - val_loss: 0.0752 - val_accuracy: 0.8729\n",
            "Epoch 951/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8696 - val_loss: 0.0752 - val_accuracy: 0.8730\n",
            "Epoch 952/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0773 - accuracy: 0.8697 - val_loss: 0.0752 - val_accuracy: 0.8726\n",
            "Epoch 953/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0773 - accuracy: 0.8696 - val_loss: 0.0752 - val_accuracy: 0.8728\n",
            "Epoch 954/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0773 - accuracy: 0.8696 - val_loss: 0.0752 - val_accuracy: 0.8730\n",
            "Epoch 955/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8696 - val_loss: 0.0752 - val_accuracy: 0.8731\n",
            "Epoch 956/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8695 - val_loss: 0.0751 - val_accuracy: 0.8727\n",
            "Epoch 957/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8697 - val_loss: 0.0752 - val_accuracy: 0.8727\n",
            "Epoch 958/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8698 - val_loss: 0.0752 - val_accuracy: 0.8730\n",
            "Epoch 959/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0773 - accuracy: 0.8695 - val_loss: 0.0751 - val_accuracy: 0.8727\n",
            "Epoch 960/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0773 - accuracy: 0.8695 - val_loss: 0.0751 - val_accuracy: 0.8726\n",
            "Epoch 961/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0772 - accuracy: 0.8695 - val_loss: 0.0751 - val_accuracy: 0.8728\n",
            "Epoch 962/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8696 - val_loss: 0.0751 - val_accuracy: 0.8726\n",
            "Epoch 963/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8697 - val_loss: 0.0751 - val_accuracy: 0.8727\n",
            "Epoch 964/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8699 - val_loss: 0.0751 - val_accuracy: 0.8730\n",
            "Epoch 965/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0772 - accuracy: 0.8696 - val_loss: 0.0751 - val_accuracy: 0.8731\n",
            "Epoch 966/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0772 - accuracy: 0.8697 - val_loss: 0.0751 - val_accuracy: 0.8729\n",
            "Epoch 967/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8698 - val_loss: 0.0751 - val_accuracy: 0.8733\n",
            "Epoch 968/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0772 - accuracy: 0.8696 - val_loss: 0.0751 - val_accuracy: 0.8733\n",
            "Epoch 969/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8699 - val_loss: 0.0750 - val_accuracy: 0.8730\n",
            "Epoch 970/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0772 - accuracy: 0.8696 - val_loss: 0.0751 - val_accuracy: 0.8730\n",
            "Epoch 971/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0772 - accuracy: 0.8697 - val_loss: 0.0750 - val_accuracy: 0.8731\n",
            "Epoch 972/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8697 - val_loss: 0.0750 - val_accuracy: 0.8730\n",
            "Epoch 973/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8695 - val_loss: 0.0750 - val_accuracy: 0.8730\n",
            "Epoch 974/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8697 - val_loss: 0.0750 - val_accuracy: 0.8730\n",
            "Epoch 975/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8695 - val_loss: 0.0750 - val_accuracy: 0.8731\n",
            "Epoch 976/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0771 - accuracy: 0.8696 - val_loss: 0.0750 - val_accuracy: 0.8731\n",
            "Epoch 977/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0771 - accuracy: 0.8698 - val_loss: 0.0750 - val_accuracy: 0.8730\n",
            "Epoch 978/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0771 - accuracy: 0.8696 - val_loss: 0.0750 - val_accuracy: 0.8730\n",
            "Epoch 979/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8697 - val_loss: 0.0750 - val_accuracy: 0.8730\n",
            "Epoch 980/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8697 - val_loss: 0.0750 - val_accuracy: 0.8733\n",
            "Epoch 981/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0771 - accuracy: 0.8698 - val_loss: 0.0750 - val_accuracy: 0.8727\n",
            "Epoch 982/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0771 - accuracy: 0.8697 - val_loss: 0.0749 - val_accuracy: 0.8731\n",
            "Epoch 983/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0771 - accuracy: 0.8700 - val_loss: 0.0749 - val_accuracy: 0.8733\n",
            "Epoch 984/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8698 - val_loss: 0.0750 - val_accuracy: 0.8728\n",
            "Epoch 985/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8698 - val_loss: 0.0749 - val_accuracy: 0.8727\n",
            "Epoch 986/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8699 - val_loss: 0.0749 - val_accuracy: 0.8729\n",
            "Epoch 987/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8697 - val_loss: 0.0749 - val_accuracy: 0.8730\n",
            "Epoch 988/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8697 - val_loss: 0.0749 - val_accuracy: 0.8732\n",
            "Epoch 989/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8701 - val_loss: 0.0749 - val_accuracy: 0.8734\n",
            "Epoch 990/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8700 - val_loss: 0.0749 - val_accuracy: 0.8730\n",
            "Epoch 991/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8698 - val_loss: 0.0749 - val_accuracy: 0.8728\n",
            "Epoch 992/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8698 - val_loss: 0.0749 - val_accuracy: 0.8733\n",
            "Epoch 993/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8699 - val_loss: 0.0749 - val_accuracy: 0.8733\n",
            "Epoch 994/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8699 - val_loss: 0.0749 - val_accuracy: 0.8730\n",
            "Epoch 995/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8698 - val_loss: 0.0749 - val_accuracy: 0.8729\n",
            "Epoch 996/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8698 - val_loss: 0.0748 - val_accuracy: 0.8734\n",
            "Epoch 997/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8700 - val_loss: 0.0748 - val_accuracy: 0.8735\n",
            "Epoch 998/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8697 - val_loss: 0.0748 - val_accuracy: 0.8730\n",
            "Epoch 999/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8699 - val_loss: 0.0748 - val_accuracy: 0.8730\n",
            "Epoch 1000/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0769 - accuracy: 0.8699 - val_loss: 0.0748 - val_accuracy: 0.8732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = network.predict(xtest_std)"
      ],
      "metadata": {
        "id": "RrUIPDfdM5wB",
        "outputId": "43aea6f0-41e3-4e87-af05-f8e07d4ed4d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat.shape)"
      ],
      "metadata": {
        "id": "GJWR1M7LN6rv",
        "outputId": "98c9bc6d-9678-4a96-b5f1-c5afe109b4e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytest.shape)"
      ],
      "metadata": {
        "id": "pFXuFm6HPG0g",
        "outputId": "666dc15a-e048-4a7c-98a9-29e40015ef09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat =np.argmax(yhat, axis = -1)\n",
        "ytest = np.argmax(ytest, axis= -1)"
      ],
      "metadata": {
        "id": "V162us36U6Ij"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = accuracy_score(ytest,yhat)\n",
        "cm = confusion_matrix(ytest,yhat)\n",
        "print(f\"El grado de precisión de los datos son los siguientes {100*precision}\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "yXPBisYxORs_",
        "outputId": "26d8abab-3182-4419-b00e-a4f7da08b695",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El grado de precisión de los datos son los siguientes 87.32\n",
            "[[11122   275   492]\n",
            " [  367  3352    73]\n",
            " [ 1323     6  2990]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función logarítimica\n",
        "\n",
        "#Función logarítimica\n",
        "\n",
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "font1 = {'family':'serif','color':'blue','size':15}\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "plt.title(\"Gráfica de Aprendizaje del Modelo Sigmoide\", fontdict = font1)\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"accuracy\"])\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_accuracy\"], linestyle = \"dotted\")\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "#plt.xlabel(\"Epochs\")\n",
        "\n",
        "ax.set_xlabel(\"Epochs\", fontdict = {'fontsize':14, 'fontweight':'bold',\n",
        "                                    'color':'tab:blue'})\n",
        "\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "JbkIxANdZHMB",
        "outputId": "66b4b08b-6166-4961-c546-38f758fa4ac0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "font1 = {'family':'serif','color':'blue','size':15}\n",
        "\n",
        "plt.title(\"Gráfica de Aprendizaje del Modelo Sigmoide\", fontdict = font1 )\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"loss\"])\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_loss\"])\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "ax.set_xlabel(\"Epochs\", fontdict = {'fontsize':14, 'fontweight':'bold',\n",
        "                                    'color':'tab:blue'})\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "VD_qykwMajLa",
        "outputId": "ae770ce2-4494-4e82-afbc-fc4b42a8d17e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir un mapa de calor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "sns.heatmap(xtrain_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Entrenamiento\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n"
      ],
      "metadata": {
        "id": "lE0LmmEE1LMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un mapa de calor para los datos de prueba\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "sns.heatmap(xtest_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Prueba\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Py3_zIxs4elw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}