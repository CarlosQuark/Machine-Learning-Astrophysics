{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "ProyectoRedesCorregido1.1",
      "authorship_tag": "ABX9TyMn7UQHwIGKtG2bunuJ2mvl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosQuark/Machine-Learning-Astrophysics/blob/main/ProyectoRedesCorregido1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# PROYECTO DE MACHINE LEARNING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvURBlWmT07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZV03xjlnj-NB"
      },
      "outputs": [],
      "source": [
        "#librerias Comunes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#liberias de PCA\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import eig\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder #Change the class to str for another type the int.\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#librerias de sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#librerias de Keras y Redes Neuronales\n",
        "\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = pd.read_csv(\"star_classification.csv\")\n",
        "data_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "OQ6pTIb2mimr",
        "outputId": "344a9d34-522a-4522-a3e5-fac32d5e5968"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237660e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237660e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237660e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237660e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543780e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176010e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030110e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891860e+18   \n",
              "\n",
              "   redshift  plate    MJD  fiber_ID   class  \n",
              "0  0.634794   5812  56354       171  GALAXY  \n",
              "1  0.779136  10445  58158       427  GALAXY  \n",
              "2  0.644195   4576  55592       299  GALAXY  \n",
              "3  0.932346   9149  58039       775  GALAXY  \n",
              "4  0.116123   6121  56187       842  GALAXY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79a1f9ab-ecb1-450d-9dce-1a76a5d38755\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543780e+18</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176010e+19</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030110e+19</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891860e+18</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79a1f9ab-ecb1-450d-9dce-1a76a5d38755')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79a1f9ab-ecb1-450d-9dce-1a76a5d38755 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79a1f9ab-ecb1-450d-9dce-1a76a5d38755');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acdcd68e-064c-4ad4-8936-2892608bbed5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acdcd68e-064c-4ad4-8936-2892608bbed5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acdcd68e-064c-4ad4-8936-2892608bbed5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nlql6Qz1Znk",
        "outputId": "6d8ea192-a0db-4ab0-f4f5-ba2a93dbf222"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 18 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   obj_ID       100000 non-null  float64\n",
            " 1   alpha        100000 non-null  float64\n",
            " 2   delta        100000 non-null  float64\n",
            " 3   u            100000 non-null  float64\n",
            " 4   g            100000 non-null  float64\n",
            " 5   r            100000 non-null  float64\n",
            " 6   i            100000 non-null  float64\n",
            " 7   z            100000 non-null  float64\n",
            " 8   run_ID       100000 non-null  int64  \n",
            " 9   rerun_ID     100000 non-null  int64  \n",
            " 10  cam_col      100000 non-null  int64  \n",
            " 11  field_ID     100000 non-null  int64  \n",
            " 12  spec_obj_ID  100000 non-null  float64\n",
            " 13  redshift     100000 non-null  float64\n",
            " 14  plate        100000 non-null  int64  \n",
            " 15  MJD          100000 non-null  int64  \n",
            " 16  fiber_ID     100000 non-null  int64  \n",
            " 17  class        100000 non-null  object \n",
            "dtypes: float64(10), int64(7), object(1)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enconder = LabelEncoder()\n",
        "\n",
        "data_set[\"class\"] = enconder.fit_transform(data_set[\"class\"])"
      ],
      "metadata": {
        "id": "lVhT4P72weJt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar los datos\n",
        "\n",
        "Y = np.array(data_set[\"class\"])\n",
        "\n",
        "df_new = data_set.drop([\"class\"], axis =1)\n",
        "\n",
        "X = np.array(df_new)\n"
      ],
      "metadata": {
        "id": "5VSRDHJhn75L"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components= 17)\n",
        "PCA_objeto.fit(X)"
      ],
      "metadata": {
        "id": "Akeqp3SySWYi",
        "outputId": "4e1b7bdd-4795-4c9b-ce7c-37284ef6e95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PCA_objeto.explained_variance_)"
      ],
      "metadata": {
        "id": "3jmLTxmoSp0Q",
        "outputId": "9be03d13-e5ef-49e4-d4c3-b702a5d26c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.10491489e+37 5.34345995e+28 3.63783147e+06 1.90094686e+05\n",
            " 6.89069641e+04 2.22875371e+04 8.93542373e+03 3.01724592e+03\n",
            " 3.23491013e+02 6.79740439e+00 3.42870277e+00 2.46778931e+00\n",
            " 1.93784010e+00 4.09255753e-01 3.26988977e-01 4.66492584e-02\n",
            " 3.72772496e-34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components = 17)\n",
        "Z = PCA_objeto.fit_transform(X)"
      ],
      "metadata": {
        "id": "0dytpcETSr5A"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento de los datos\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Z,Y, test_size = 0.2, stratify=Y)"
      ],
      "metadata": {
        "id": "MXeQdyFvxQQ6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estandarizar los datos\n",
        "\n",
        "scaler = MinMaxScaler().fit(xtrain)\n",
        "\n",
        "xtrain_std = scaler.transform(xtrain)\n",
        "\n",
        "xtest_std = scaler.transform(xtest)\n"
      ],
      "metadata": {
        "id": "i6dJHiUQxpVc"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Este apartado se utilizar para poder dar inicio el entrenamiento a una red\n",
        "neuronal\n",
        "\n",
        "   Todo esto viene dentro de la página oficial de Keras.\n",
        "\n",
        "   Dense es una capa de neurona que está conectada con todas las anteriores\n",
        "\n",
        "   Sequential es utilizado para crear secuencias en redes neuronales.\n",
        "\n",
        "   Optimizador: Adam.\n",
        "\n",
        "   units es la candtidad de clases que tienes.\n",
        "\n",
        "   activation: \"Qué tipo de función de activación almacenas\".\n",
        "\n",
        "   input_dim = la dimensionalidad.\n",
        "\n",
        "\"\"\"\n",
        "network = Sequential([\n",
        "\n",
        "    Dense(units=3, activation= \"softmax\" , input_dim = 17)\n",
        "])\n",
        "\n",
        "#Que copilador voy a utilizar, Adam, puede hacer eso.\n",
        "\n",
        "Adam(learning_rate=0.0001) #Taza de aprendizaje pequeña\n",
        "\n",
        "network.compile()\n",
        "\n",
        "#Función de perdida que se utilizará en la sala de entrenamient como su métrica.\n",
        "\n",
        "network.compile(loss= \"mean_squared_error\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QbP87Xplx-fX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"La libreria de keras para to_categorical\n",
        "\n",
        "   se utiliza para poder experesar problemas de clasificación de multiclase.\n",
        "   Para convertir nuestras etiquetas númericas en tipo one-hot.\n",
        "\n",
        "   Supongamso que tienes 3 clases (etiqeutas númericas 0,1,2)\n",
        "\n",
        "   En la primera linea convierte la una matriz en one-hot\n",
        "\n",
        "   Cada fila corresponde a un etiqueta, y cada columna, representa una clase.\n",
        "\n",
        "   AQUÍ INICIAMOS LA ETAPA DE ENTRENAMIENTO DE LA RED\n",
        "\n",
        "   El profe explica que es el batch_size, es para reducir el costo\n",
        "   computacional,\n",
        "   crea grupos para filas de hasta 100,000 dimensiones.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#network.fit(xtrain_std, ytrain, epochs=50, batch_size=128 )\n",
        "\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "epoch_accuracy =network.fit(xtrain_std, ytrain, epochs=1000, batch_size=80,\n",
        "                             validation_data=(xtest_std,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMrjFO3yNnb",
        "outputId": "e57c1833-87d8-410c-b096-b058e20ac699"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1877 - accuracy: 0.5944 - val_loss: 0.1827 - val_accuracy: 0.5946\n",
            "Epoch 2/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1790 - accuracy: 0.5951 - val_loss: 0.1752 - val_accuracy: 0.5958\n",
            "Epoch 3/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1725 - accuracy: 0.5988 - val_loss: 0.1695 - val_accuracy: 0.6047\n",
            "Epoch 4/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1672 - accuracy: 0.6066 - val_loss: 0.1646 - val_accuracy: 0.6104\n",
            "Epoch 5/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1626 - accuracy: 0.6154 - val_loss: 0.1604 - val_accuracy: 0.6241\n",
            "Epoch 6/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1586 - accuracy: 0.6274 - val_loss: 0.1566 - val_accuracy: 0.6359\n",
            "Epoch 7/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1549 - accuracy: 0.6405 - val_loss: 0.1529 - val_accuracy: 0.6452\n",
            "Epoch 8/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1515 - accuracy: 0.6553 - val_loss: 0.1497 - val_accuracy: 0.6744\n",
            "Epoch 9/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1484 - accuracy: 0.6701 - val_loss: 0.1466 - val_accuracy: 0.6727\n",
            "Epoch 10/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1454 - accuracy: 0.6843 - val_loss: 0.1437 - val_accuracy: 0.6879\n",
            "Epoch 11/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1427 - accuracy: 0.6989 - val_loss: 0.1410 - val_accuracy: 0.7059\n",
            "Epoch 12/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1402 - accuracy: 0.7124 - val_loss: 0.1386 - val_accuracy: 0.7143\n",
            "Epoch 13/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1378 - accuracy: 0.7230 - val_loss: 0.1362 - val_accuracy: 0.7347\n",
            "Epoch 14/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1356 - accuracy: 0.7349 - val_loss: 0.1340 - val_accuracy: 0.7376\n",
            "Epoch 15/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1335 - accuracy: 0.7431 - val_loss: 0.1320 - val_accuracy: 0.7429\n",
            "Epoch 16/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1316 - accuracy: 0.7511 - val_loss: 0.1301 - val_accuracy: 0.7485\n",
            "Epoch 17/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1297 - accuracy: 0.7581 - val_loss: 0.1281 - val_accuracy: 0.7584\n",
            "Epoch 18/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1279 - accuracy: 0.7644 - val_loss: 0.1264 - val_accuracy: 0.7699\n",
            "Epoch 19/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1263 - accuracy: 0.7697 - val_loss: 0.1248 - val_accuracy: 0.7699\n",
            "Epoch 20/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1247 - accuracy: 0.7743 - val_loss: 0.1233 - val_accuracy: 0.7738\n",
            "Epoch 21/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1232 - accuracy: 0.7793 - val_loss: 0.1218 - val_accuracy: 0.7786\n",
            "Epoch 22/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1218 - accuracy: 0.7839 - val_loss: 0.1204 - val_accuracy: 0.7788\n",
            "Epoch 23/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1205 - accuracy: 0.7870 - val_loss: 0.1191 - val_accuracy: 0.7850\n",
            "Epoch 24/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1192 - accuracy: 0.7907 - val_loss: 0.1179 - val_accuracy: 0.7929\n",
            "Epoch 25/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1180 - accuracy: 0.7946 - val_loss: 0.1166 - val_accuracy: 0.7970\n",
            "Epoch 26/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1169 - accuracy: 0.7978 - val_loss: 0.1155 - val_accuracy: 0.7982\n",
            "Epoch 27/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1158 - accuracy: 0.8005 - val_loss: 0.1144 - val_accuracy: 0.8009\n",
            "Epoch 28/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1147 - accuracy: 0.8029 - val_loss: 0.1134 - val_accuracy: 0.8085\n",
            "Epoch 29/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1137 - accuracy: 0.8060 - val_loss: 0.1125 - val_accuracy: 0.8073\n",
            "Epoch 30/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1128 - accuracy: 0.8083 - val_loss: 0.1114 - val_accuracy: 0.8116\n",
            "Epoch 31/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1118 - accuracy: 0.8107 - val_loss: 0.1107 - val_accuracy: 0.8076\n",
            "Epoch 32/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1110 - accuracy: 0.8124 - val_loss: 0.1097 - val_accuracy: 0.8156\n",
            "Epoch 33/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1102 - accuracy: 0.8148 - val_loss: 0.1089 - val_accuracy: 0.8161\n",
            "Epoch 34/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1094 - accuracy: 0.8170 - val_loss: 0.1082 - val_accuracy: 0.8155\n",
            "Epoch 35/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1087 - accuracy: 0.8183 - val_loss: 0.1074 - val_accuracy: 0.8181\n",
            "Epoch 36/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1079 - accuracy: 0.8199 - val_loss: 0.1066 - val_accuracy: 0.8185\n",
            "Epoch 37/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1072 - accuracy: 0.8216 - val_loss: 0.1059 - val_accuracy: 0.8209\n",
            "Epoch 38/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1066 - accuracy: 0.8222 - val_loss: 0.1053 - val_accuracy: 0.8259\n",
            "Epoch 39/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1059 - accuracy: 0.8238 - val_loss: 0.1046 - val_accuracy: 0.8245\n",
            "Epoch 40/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1053 - accuracy: 0.8249 - val_loss: 0.1040 - val_accuracy: 0.8272\n",
            "Epoch 41/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1047 - accuracy: 0.8260 - val_loss: 0.1034 - val_accuracy: 0.8275\n",
            "Epoch 42/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1041 - accuracy: 0.8270 - val_loss: 0.1028 - val_accuracy: 0.8275\n",
            "Epoch 43/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1036 - accuracy: 0.8280 - val_loss: 0.1023 - val_accuracy: 0.8304\n",
            "Epoch 44/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1031 - accuracy: 0.8285 - val_loss: 0.1017 - val_accuracy: 0.8300\n",
            "Epoch 45/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1026 - accuracy: 0.8292 - val_loss: 0.1014 - val_accuracy: 0.8275\n",
            "Epoch 46/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1021 - accuracy: 0.8301 - val_loss: 0.1008 - val_accuracy: 0.8318\n",
            "Epoch 47/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1016 - accuracy: 0.8308 - val_loss: 0.1003 - val_accuracy: 0.8317\n",
            "Epoch 48/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1012 - accuracy: 0.8317 - val_loss: 0.0999 - val_accuracy: 0.8324\n",
            "Epoch 49/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1007 - accuracy: 0.8318 - val_loss: 0.0994 - val_accuracy: 0.8339\n",
            "Epoch 50/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1003 - accuracy: 0.8329 - val_loss: 0.0990 - val_accuracy: 0.8340\n",
            "Epoch 51/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0999 - accuracy: 0.8337 - val_loss: 0.0986 - val_accuracy: 0.8370\n",
            "Epoch 52/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0995 - accuracy: 0.8342 - val_loss: 0.0982 - val_accuracy: 0.8365\n",
            "Epoch 53/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0991 - accuracy: 0.8346 - val_loss: 0.0978 - val_accuracy: 0.8370\n",
            "Epoch 54/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0987 - accuracy: 0.8351 - val_loss: 0.0974 - val_accuracy: 0.8374\n",
            "Epoch 55/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0984 - accuracy: 0.8360 - val_loss: 0.0971 - val_accuracy: 0.8376\n",
            "Epoch 56/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0980 - accuracy: 0.8364 - val_loss: 0.0967 - val_accuracy: 0.8404\n",
            "Epoch 57/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0977 - accuracy: 0.8367 - val_loss: 0.0964 - val_accuracy: 0.8383\n",
            "Epoch 58/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0974 - accuracy: 0.8373 - val_loss: 0.0960 - val_accuracy: 0.8408\n",
            "Epoch 59/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0970 - accuracy: 0.8375 - val_loss: 0.0957 - val_accuracy: 0.8417\n",
            "Epoch 60/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0967 - accuracy: 0.8382 - val_loss: 0.0954 - val_accuracy: 0.8396\n",
            "Epoch 61/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0964 - accuracy: 0.8384 - val_loss: 0.0951 - val_accuracy: 0.8418\n",
            "Epoch 62/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0961 - accuracy: 0.8389 - val_loss: 0.0948 - val_accuracy: 0.8424\n",
            "Epoch 63/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0958 - accuracy: 0.8398 - val_loss: 0.0945 - val_accuracy: 0.8439\n",
            "Epoch 64/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0955 - accuracy: 0.8406 - val_loss: 0.0942 - val_accuracy: 0.8418\n",
            "Epoch 65/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0953 - accuracy: 0.8404 - val_loss: 0.0941 - val_accuracy: 0.8445\n",
            "Epoch 66/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0950 - accuracy: 0.8407 - val_loss: 0.0937 - val_accuracy: 0.8447\n",
            "Epoch 67/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.8416 - val_loss: 0.0934 - val_accuracy: 0.8443\n",
            "Epoch 68/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0945 - accuracy: 0.8417 - val_loss: 0.0932 - val_accuracy: 0.8431\n",
            "Epoch 69/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0943 - accuracy: 0.8419 - val_loss: 0.0930 - val_accuracy: 0.8418\n",
            "Epoch 70/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0940 - accuracy: 0.8423 - val_loss: 0.0926 - val_accuracy: 0.8454\n",
            "Epoch 71/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0938 - accuracy: 0.8426 - val_loss: 0.0924 - val_accuracy: 0.8464\n",
            "Epoch 72/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0936 - accuracy: 0.8432 - val_loss: 0.0923 - val_accuracy: 0.8442\n",
            "Epoch 73/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0933 - accuracy: 0.8433 - val_loss: 0.0919 - val_accuracy: 0.8467\n",
            "Epoch 74/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0931 - accuracy: 0.8438 - val_loss: 0.0917 - val_accuracy: 0.8469\n",
            "Epoch 75/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0929 - accuracy: 0.8438 - val_loss: 0.0915 - val_accuracy: 0.8460\n",
            "Epoch 76/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0927 - accuracy: 0.8443 - val_loss: 0.0913 - val_accuracy: 0.8470\n",
            "Epoch 77/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0925 - accuracy: 0.8441 - val_loss: 0.0911 - val_accuracy: 0.8468\n",
            "Epoch 78/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0923 - accuracy: 0.8448 - val_loss: 0.0909 - val_accuracy: 0.8480\n",
            "Epoch 79/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0921 - accuracy: 0.8453 - val_loss: 0.0907 - val_accuracy: 0.8485\n",
            "Epoch 80/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.8455 - val_loss: 0.0906 - val_accuracy: 0.8492\n",
            "Epoch 81/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0917 - accuracy: 0.8461 - val_loss: 0.0904 - val_accuracy: 0.8479\n",
            "Epoch 82/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0915 - accuracy: 0.8460 - val_loss: 0.0901 - val_accuracy: 0.8485\n",
            "Epoch 83/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0913 - accuracy: 0.8465 - val_loss: 0.0899 - val_accuracy: 0.8493\n",
            "Epoch 84/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0911 - accuracy: 0.8464 - val_loss: 0.0898 - val_accuracy: 0.8494\n",
            "Epoch 85/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0910 - accuracy: 0.8471 - val_loss: 0.0896 - val_accuracy: 0.8508\n",
            "Epoch 86/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0908 - accuracy: 0.8470 - val_loss: 0.0894 - val_accuracy: 0.8496\n",
            "Epoch 87/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0906 - accuracy: 0.8474 - val_loss: 0.0892 - val_accuracy: 0.8507\n",
            "Epoch 88/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0905 - accuracy: 0.8479 - val_loss: 0.0891 - val_accuracy: 0.8509\n",
            "Epoch 89/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0903 - accuracy: 0.8479 - val_loss: 0.0889 - val_accuracy: 0.8508\n",
            "Epoch 90/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0902 - accuracy: 0.8483 - val_loss: 0.0888 - val_accuracy: 0.8505\n",
            "Epoch 91/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0900 - accuracy: 0.8483 - val_loss: 0.0886 - val_accuracy: 0.8517\n",
            "Epoch 92/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0898 - accuracy: 0.8487 - val_loss: 0.0884 - val_accuracy: 0.8513\n",
            "Epoch 93/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0897 - accuracy: 0.8489 - val_loss: 0.0883 - val_accuracy: 0.8518\n",
            "Epoch 94/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0895 - accuracy: 0.8491 - val_loss: 0.0881 - val_accuracy: 0.8520\n",
            "Epoch 95/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0894 - accuracy: 0.8492 - val_loss: 0.0880 - val_accuracy: 0.8528\n",
            "Epoch 96/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.8497 - val_loss: 0.0879 - val_accuracy: 0.8519\n",
            "Epoch 97/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0891 - accuracy: 0.8497 - val_loss: 0.0877 - val_accuracy: 0.8526\n",
            "Epoch 98/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.8502 - val_loss: 0.0876 - val_accuracy: 0.8526\n",
            "Epoch 99/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0888 - accuracy: 0.8505 - val_loss: 0.0874 - val_accuracy: 0.8532\n",
            "Epoch 100/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0887 - accuracy: 0.8504 - val_loss: 0.0874 - val_accuracy: 0.8516\n",
            "Epoch 101/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0886 - accuracy: 0.8507 - val_loss: 0.0872 - val_accuracy: 0.8527\n",
            "Epoch 102/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.8509 - val_loss: 0.0870 - val_accuracy: 0.8537\n",
            "Epoch 103/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0883 - accuracy: 0.8511 - val_loss: 0.0870 - val_accuracy: 0.8533\n",
            "Epoch 104/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.8512 - val_loss: 0.0868 - val_accuracy: 0.8537\n",
            "Epoch 105/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.8516 - val_loss: 0.0866 - val_accuracy: 0.8547\n",
            "Epoch 106/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.8514 - val_loss: 0.0865 - val_accuracy: 0.8543\n",
            "Epoch 107/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0878 - accuracy: 0.8521 - val_loss: 0.0864 - val_accuracy: 0.8550\n",
            "Epoch 108/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8523 - val_loss: 0.0863 - val_accuracy: 0.8547\n",
            "Epoch 109/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.8521 - val_loss: 0.0861 - val_accuracy: 0.8551\n",
            "Epoch 110/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.8526 - val_loss: 0.0861 - val_accuracy: 0.8545\n",
            "Epoch 111/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0874 - accuracy: 0.8526 - val_loss: 0.0859 - val_accuracy: 0.8551\n",
            "Epoch 112/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0873 - accuracy: 0.8527 - val_loss: 0.0859 - val_accuracy: 0.8550\n",
            "Epoch 113/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.8529 - val_loss: 0.0857 - val_accuracy: 0.8555\n",
            "Epoch 114/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0870 - accuracy: 0.8536 - val_loss: 0.0856 - val_accuracy: 0.8554\n",
            "Epoch 115/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.8537 - val_loss: 0.0855 - val_accuracy: 0.8558\n",
            "Epoch 116/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.8537 - val_loss: 0.0854 - val_accuracy: 0.8564\n",
            "Epoch 117/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0867 - accuracy: 0.8539 - val_loss: 0.0853 - val_accuracy: 0.8561\n",
            "Epoch 118/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0866 - accuracy: 0.8540 - val_loss: 0.0852 - val_accuracy: 0.8566\n",
            "Epoch 119/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8542 - val_loss: 0.0851 - val_accuracy: 0.8560\n",
            "Epoch 120/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0864 - accuracy: 0.8544 - val_loss: 0.0850 - val_accuracy: 0.8571\n",
            "Epoch 121/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0863 - accuracy: 0.8544 - val_loss: 0.0849 - val_accuracy: 0.8569\n",
            "Epoch 122/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8546 - val_loss: 0.0848 - val_accuracy: 0.8571\n",
            "Epoch 123/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0861 - accuracy: 0.8548 - val_loss: 0.0847 - val_accuracy: 0.8577\n",
            "Epoch 124/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8549 - val_loss: 0.0846 - val_accuracy: 0.8582\n",
            "Epoch 125/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8554 - val_loss: 0.0845 - val_accuracy: 0.8575\n",
            "Epoch 126/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8554 - val_loss: 0.0844 - val_accuracy: 0.8577\n",
            "Epoch 127/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8553 - val_loss: 0.0843 - val_accuracy: 0.8575\n",
            "Epoch 128/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8555 - val_loss: 0.0842 - val_accuracy: 0.8576\n",
            "Epoch 129/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8556 - val_loss: 0.0841 - val_accuracy: 0.8580\n",
            "Epoch 130/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0855 - accuracy: 0.8560 - val_loss: 0.0840 - val_accuracy: 0.8587\n",
            "Epoch 131/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8557 - val_loss: 0.0839 - val_accuracy: 0.8583\n",
            "Epoch 132/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0853 - accuracy: 0.8562 - val_loss: 0.0838 - val_accuracy: 0.8583\n",
            "Epoch 133/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.8559 - val_loss: 0.0838 - val_accuracy: 0.8587\n",
            "Epoch 134/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8562 - val_loss: 0.0837 - val_accuracy: 0.8583\n",
            "Epoch 135/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8565 - val_loss: 0.0836 - val_accuracy: 0.8593\n",
            "Epoch 136/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8567 - val_loss: 0.0835 - val_accuracy: 0.8587\n",
            "Epoch 137/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0849 - accuracy: 0.8568 - val_loss: 0.0834 - val_accuracy: 0.8594\n",
            "Epoch 138/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0848 - accuracy: 0.8570 - val_loss: 0.0834 - val_accuracy: 0.8586\n",
            "Epoch 139/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8569 - val_loss: 0.0832 - val_accuracy: 0.8597\n",
            "Epoch 140/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8572 - val_loss: 0.0832 - val_accuracy: 0.8597\n",
            "Epoch 141/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8573 - val_loss: 0.0831 - val_accuracy: 0.8590\n",
            "Epoch 142/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8575 - val_loss: 0.0831 - val_accuracy: 0.8608\n",
            "Epoch 143/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0844 - accuracy: 0.8574 - val_loss: 0.0830 - val_accuracy: 0.8591\n",
            "Epoch 144/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8575 - val_loss: 0.0829 - val_accuracy: 0.8599\n",
            "Epoch 145/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8576 - val_loss: 0.0828 - val_accuracy: 0.8601\n",
            "Epoch 146/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8579 - val_loss: 0.0827 - val_accuracy: 0.8598\n",
            "Epoch 147/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8580 - val_loss: 0.0826 - val_accuracy: 0.8601\n",
            "Epoch 148/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8584 - val_loss: 0.0826 - val_accuracy: 0.8600\n",
            "Epoch 149/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0840 - accuracy: 0.8582 - val_loss: 0.0826 - val_accuracy: 0.8597\n",
            "Epoch 150/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8582 - val_loss: 0.0825 - val_accuracy: 0.8608\n",
            "Epoch 151/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8582 - val_loss: 0.0824 - val_accuracy: 0.8604\n",
            "Epoch 152/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8587 - val_loss: 0.0823 - val_accuracy: 0.8602\n",
            "Epoch 153/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8588 - val_loss: 0.0823 - val_accuracy: 0.8605\n",
            "Epoch 154/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8587 - val_loss: 0.0822 - val_accuracy: 0.8605\n",
            "Epoch 155/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.8593 - val_loss: 0.0821 - val_accuracy: 0.8607\n",
            "Epoch 156/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8591 - val_loss: 0.0820 - val_accuracy: 0.8611\n",
            "Epoch 157/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8594 - val_loss: 0.0820 - val_accuracy: 0.8608\n",
            "Epoch 158/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8595 - val_loss: 0.0819 - val_accuracy: 0.8611\n",
            "Epoch 159/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8593 - val_loss: 0.0819 - val_accuracy: 0.8615\n",
            "Epoch 160/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8597 - val_loss: 0.0818 - val_accuracy: 0.8607\n",
            "Epoch 161/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8597 - val_loss: 0.0817 - val_accuracy: 0.8612\n",
            "Epoch 162/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8597 - val_loss: 0.0816 - val_accuracy: 0.8616\n",
            "Epoch 163/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8598 - val_loss: 0.0816 - val_accuracy: 0.8609\n",
            "Epoch 164/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8598 - val_loss: 0.0815 - val_accuracy: 0.8619\n",
            "Epoch 165/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8600 - val_loss: 0.0814 - val_accuracy: 0.8618\n",
            "Epoch 166/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8599 - val_loss: 0.0814 - val_accuracy: 0.8619\n",
            "Epoch 167/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8599 - val_loss: 0.0813 - val_accuracy: 0.8621\n",
            "Epoch 168/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8604 - val_loss: 0.0813 - val_accuracy: 0.8618\n",
            "Epoch 169/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8601 - val_loss: 0.0812 - val_accuracy: 0.8626\n",
            "Epoch 170/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8606 - val_loss: 0.0811 - val_accuracy: 0.8624\n",
            "Epoch 171/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8607 - val_loss: 0.0811 - val_accuracy: 0.8624\n",
            "Epoch 172/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8609 - val_loss: 0.0810 - val_accuracy: 0.8630\n",
            "Epoch 173/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8611 - val_loss: 0.0810 - val_accuracy: 0.8621\n",
            "Epoch 174/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8609 - val_loss: 0.0809 - val_accuracy: 0.8626\n",
            "Epoch 175/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8608 - val_loss: 0.0808 - val_accuracy: 0.8632\n",
            "Epoch 176/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8610 - val_loss: 0.0808 - val_accuracy: 0.8627\n",
            "Epoch 177/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8608 - val_loss: 0.0807 - val_accuracy: 0.8637\n",
            "Epoch 178/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8611 - val_loss: 0.0807 - val_accuracy: 0.8629\n",
            "Epoch 179/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8613 - val_loss: 0.0806 - val_accuracy: 0.8633\n",
            "Epoch 180/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8615 - val_loss: 0.0806 - val_accuracy: 0.8629\n",
            "Epoch 181/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8613 - val_loss: 0.0805 - val_accuracy: 0.8632\n",
            "Epoch 182/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8614 - val_loss: 0.0805 - val_accuracy: 0.8630\n",
            "Epoch 183/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8616 - val_loss: 0.0805 - val_accuracy: 0.8630\n",
            "Epoch 184/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8617 - val_loss: 0.0804 - val_accuracy: 0.8638\n",
            "Epoch 185/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8619 - val_loss: 0.0803 - val_accuracy: 0.8637\n",
            "Epoch 186/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8619 - val_loss: 0.0803 - val_accuracy: 0.8632\n",
            "Epoch 187/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0817 - accuracy: 0.8621 - val_loss: 0.0802 - val_accuracy: 0.8637\n",
            "Epoch 188/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0817 - accuracy: 0.8623 - val_loss: 0.0802 - val_accuracy: 0.8636\n",
            "Epoch 189/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0816 - accuracy: 0.8620 - val_loss: 0.0801 - val_accuracy: 0.8638\n",
            "Epoch 190/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0816 - accuracy: 0.8625 - val_loss: 0.0801 - val_accuracy: 0.8643\n",
            "Epoch 191/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.8622 - val_loss: 0.0800 - val_accuracy: 0.8641\n",
            "Epoch 192/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0815 - accuracy: 0.8625 - val_loss: 0.0800 - val_accuracy: 0.8637\n",
            "Epoch 193/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0814 - accuracy: 0.8625 - val_loss: 0.0799 - val_accuracy: 0.8648\n",
            "Epoch 194/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0814 - accuracy: 0.8628 - val_loss: 0.0799 - val_accuracy: 0.8645\n",
            "Epoch 195/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0814 - accuracy: 0.8628 - val_loss: 0.0799 - val_accuracy: 0.8641\n",
            "Epoch 196/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.8628 - val_loss: 0.0798 - val_accuracy: 0.8645\n",
            "Epoch 197/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0812 - accuracy: 0.8627 - val_loss: 0.0798 - val_accuracy: 0.8643\n",
            "Epoch 198/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0812 - accuracy: 0.8631 - val_loss: 0.0797 - val_accuracy: 0.8650\n",
            "Epoch 199/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0812 - accuracy: 0.8630 - val_loss: 0.0796 - val_accuracy: 0.8651\n",
            "Epoch 200/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.8632 - val_loss: 0.0796 - val_accuracy: 0.8652\n",
            "Epoch 201/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0811 - accuracy: 0.8629 - val_loss: 0.0797 - val_accuracy: 0.8642\n",
            "Epoch 202/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.8632 - val_loss: 0.0795 - val_accuracy: 0.8651\n",
            "Epoch 203/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0810 - accuracy: 0.8636 - val_loss: 0.0795 - val_accuracy: 0.8650\n",
            "Epoch 204/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.8633 - val_loss: 0.0795 - val_accuracy: 0.8647\n",
            "Epoch 205/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0809 - accuracy: 0.8634 - val_loss: 0.0794 - val_accuracy: 0.8651\n",
            "Epoch 206/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.8635 - val_loss: 0.0793 - val_accuracy: 0.8655\n",
            "Epoch 207/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.8636 - val_loss: 0.0793 - val_accuracy: 0.8660\n",
            "Epoch 208/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0808 - accuracy: 0.8637 - val_loss: 0.0793 - val_accuracy: 0.8655\n",
            "Epoch 209/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0807 - accuracy: 0.8636 - val_loss: 0.0792 - val_accuracy: 0.8655\n",
            "Epoch 210/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0807 - accuracy: 0.8637 - val_loss: 0.0792 - val_accuracy: 0.8656\n",
            "Epoch 211/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8641 - val_loss: 0.0791 - val_accuracy: 0.8658\n",
            "Epoch 212/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8639 - val_loss: 0.0791 - val_accuracy: 0.8662\n",
            "Epoch 213/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0806 - accuracy: 0.8639 - val_loss: 0.0790 - val_accuracy: 0.8663\n",
            "Epoch 214/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.8640 - val_loss: 0.0790 - val_accuracy: 0.8663\n",
            "Epoch 215/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0805 - accuracy: 0.8641 - val_loss: 0.0790 - val_accuracy: 0.8658\n",
            "Epoch 216/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.8642 - val_loss: 0.0789 - val_accuracy: 0.8656\n",
            "Epoch 217/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.8644 - val_loss: 0.0789 - val_accuracy: 0.8660\n",
            "Epoch 218/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0804 - accuracy: 0.8643 - val_loss: 0.0788 - val_accuracy: 0.8667\n",
            "Epoch 219/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.8644 - val_loss: 0.0788 - val_accuracy: 0.8658\n",
            "Epoch 220/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0803 - accuracy: 0.8645 - val_loss: 0.0788 - val_accuracy: 0.8658\n",
            "Epoch 221/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0802 - accuracy: 0.8643 - val_loss: 0.0787 - val_accuracy: 0.8662\n",
            "Epoch 222/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0802 - accuracy: 0.8646 - val_loss: 0.0787 - val_accuracy: 0.8663\n",
            "Epoch 223/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0802 - accuracy: 0.8643 - val_loss: 0.0786 - val_accuracy: 0.8665\n",
            "Epoch 224/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8645 - val_loss: 0.0786 - val_accuracy: 0.8665\n",
            "Epoch 225/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8647 - val_loss: 0.0787 - val_accuracy: 0.8659\n",
            "Epoch 226/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0801 - accuracy: 0.8648 - val_loss: 0.0785 - val_accuracy: 0.8668\n",
            "Epoch 227/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0800 - accuracy: 0.8646 - val_loss: 0.0785 - val_accuracy: 0.8669\n",
            "Epoch 228/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0800 - accuracy: 0.8649 - val_loss: 0.0785 - val_accuracy: 0.8668\n",
            "Epoch 229/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8650 - val_loss: 0.0785 - val_accuracy: 0.8669\n",
            "Epoch 230/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8652 - val_loss: 0.0784 - val_accuracy: 0.8672\n",
            "Epoch 231/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0799 - accuracy: 0.8650 - val_loss: 0.0784 - val_accuracy: 0.8673\n",
            "Epoch 232/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.8649 - val_loss: 0.0783 - val_accuracy: 0.8671\n",
            "Epoch 233/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0798 - accuracy: 0.8653 - val_loss: 0.0783 - val_accuracy: 0.8669\n",
            "Epoch 234/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8653 - val_loss: 0.0782 - val_accuracy: 0.8674\n",
            "Epoch 235/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8654 - val_loss: 0.0782 - val_accuracy: 0.8676\n",
            "Epoch 236/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8652 - val_loss: 0.0782 - val_accuracy: 0.8674\n",
            "Epoch 237/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.8653 - val_loss: 0.0781 - val_accuracy: 0.8676\n",
            "Epoch 238/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.8653 - val_loss: 0.0781 - val_accuracy: 0.8670\n",
            "Epoch 239/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0796 - accuracy: 0.8654 - val_loss: 0.0781 - val_accuracy: 0.8676\n",
            "Epoch 240/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0796 - accuracy: 0.8654 - val_loss: 0.0780 - val_accuracy: 0.8680\n",
            "Epoch 241/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.8656 - val_loss: 0.0780 - val_accuracy: 0.8678\n",
            "Epoch 242/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.8652 - val_loss: 0.0781 - val_accuracy: 0.8672\n",
            "Epoch 243/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0795 - accuracy: 0.8655 - val_loss: 0.0779 - val_accuracy: 0.8681\n",
            "Epoch 244/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8657 - val_loss: 0.0779 - val_accuracy: 0.8678\n",
            "Epoch 245/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0794 - accuracy: 0.8658 - val_loss: 0.0778 - val_accuracy: 0.8684\n",
            "Epoch 246/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0794 - accuracy: 0.8656 - val_loss: 0.0779 - val_accuracy: 0.8679\n",
            "Epoch 247/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8656 - val_loss: 0.0778 - val_accuracy: 0.8679\n",
            "Epoch 248/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8659 - val_loss: 0.0777 - val_accuracy: 0.8680\n",
            "Epoch 249/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0793 - accuracy: 0.8660 - val_loss: 0.0778 - val_accuracy: 0.8683\n",
            "Epoch 250/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.8658 - val_loss: 0.0777 - val_accuracy: 0.8687\n",
            "Epoch 251/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0792 - accuracy: 0.8659 - val_loss: 0.0778 - val_accuracy: 0.8675\n",
            "Epoch 252/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8663 - val_loss: 0.0777 - val_accuracy: 0.8679\n",
            "Epoch 253/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8661 - val_loss: 0.0776 - val_accuracy: 0.8686\n",
            "Epoch 254/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8663 - val_loss: 0.0776 - val_accuracy: 0.8679\n",
            "Epoch 255/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.8662 - val_loss: 0.0775 - val_accuracy: 0.8686\n",
            "Epoch 256/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8664 - val_loss: 0.0775 - val_accuracy: 0.8688\n",
            "Epoch 257/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0790 - accuracy: 0.8664 - val_loss: 0.0775 - val_accuracy: 0.8689\n",
            "Epoch 258/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8659 - val_loss: 0.0774 - val_accuracy: 0.8692\n",
            "Epoch 259/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0790 - accuracy: 0.8663 - val_loss: 0.0775 - val_accuracy: 0.8681\n",
            "Epoch 260/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.8666 - val_loss: 0.0774 - val_accuracy: 0.8691\n",
            "Epoch 261/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0789 - accuracy: 0.8664 - val_loss: 0.0774 - val_accuracy: 0.8691\n",
            "Epoch 262/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0789 - accuracy: 0.8665 - val_loss: 0.0774 - val_accuracy: 0.8682\n",
            "Epoch 263/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8664 - val_loss: 0.0773 - val_accuracy: 0.8691\n",
            "Epoch 264/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8665 - val_loss: 0.0773 - val_accuracy: 0.8691\n",
            "Epoch 265/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.8668 - val_loss: 0.0772 - val_accuracy: 0.8692\n",
            "Epoch 266/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8668 - val_loss: 0.0773 - val_accuracy: 0.8688\n",
            "Epoch 267/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8669 - val_loss: 0.0773 - val_accuracy: 0.8687\n",
            "Epoch 268/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0787 - accuracy: 0.8666 - val_loss: 0.0772 - val_accuracy: 0.8693\n",
            "Epoch 269/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0787 - accuracy: 0.8669 - val_loss: 0.0771 - val_accuracy: 0.8695\n",
            "Epoch 270/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8665 - val_loss: 0.0771 - val_accuracy: 0.8698\n",
            "Epoch 271/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8672 - val_loss: 0.0771 - val_accuracy: 0.8695\n",
            "Epoch 272/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0786 - accuracy: 0.8670 - val_loss: 0.0770 - val_accuracy: 0.8697\n",
            "Epoch 273/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8671 - val_loss: 0.0771 - val_accuracy: 0.8693\n",
            "Epoch 274/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0785 - accuracy: 0.8672 - val_loss: 0.0770 - val_accuracy: 0.8696\n",
            "Epoch 275/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8673 - val_loss: 0.0770 - val_accuracy: 0.8696\n",
            "Epoch 276/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0785 - accuracy: 0.8672 - val_loss: 0.0769 - val_accuracy: 0.8697\n",
            "Epoch 277/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8671 - val_loss: 0.0769 - val_accuracy: 0.8699\n",
            "Epoch 278/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8673 - val_loss: 0.0769 - val_accuracy: 0.8696\n",
            "Epoch 279/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0784 - accuracy: 0.8674 - val_loss: 0.0769 - val_accuracy: 0.8693\n",
            "Epoch 280/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0784 - accuracy: 0.8675 - val_loss: 0.0768 - val_accuracy: 0.8703\n",
            "Epoch 281/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0783 - accuracy: 0.8676 - val_loss: 0.0768 - val_accuracy: 0.8705\n",
            "Epoch 282/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8672 - val_loss: 0.0769 - val_accuracy: 0.8693\n",
            "Epoch 283/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8676 - val_loss: 0.0767 - val_accuracy: 0.8697\n",
            "Epoch 284/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.8674 - val_loss: 0.0767 - val_accuracy: 0.8704\n",
            "Epoch 285/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8675 - val_loss: 0.0769 - val_accuracy: 0.8691\n",
            "Epoch 286/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0782 - accuracy: 0.8675 - val_loss: 0.0767 - val_accuracy: 0.8703\n",
            "Epoch 287/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8676 - val_loss: 0.0766 - val_accuracy: 0.8702\n",
            "Epoch 288/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0782 - accuracy: 0.8676 - val_loss: 0.0766 - val_accuracy: 0.8698\n",
            "Epoch 289/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.8677 - val_loss: 0.0766 - val_accuracy: 0.8701\n",
            "Epoch 290/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.8675 - val_loss: 0.0766 - val_accuracy: 0.8698\n",
            "Epoch 291/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.8679 - val_loss: 0.0766 - val_accuracy: 0.8705\n",
            "Epoch 292/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0781 - accuracy: 0.8677 - val_loss: 0.0765 - val_accuracy: 0.8705\n",
            "Epoch 293/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8679 - val_loss: 0.0765 - val_accuracy: 0.8710\n",
            "Epoch 294/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8676 - val_loss: 0.0765 - val_accuracy: 0.8708\n",
            "Epoch 295/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8678 - val_loss: 0.0764 - val_accuracy: 0.8706\n",
            "Epoch 296/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0780 - accuracy: 0.8679 - val_loss: 0.0764 - val_accuracy: 0.8707\n",
            "Epoch 297/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8677 - val_loss: 0.0764 - val_accuracy: 0.8702\n",
            "Epoch 298/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0779 - accuracy: 0.8680 - val_loss: 0.0765 - val_accuracy: 0.8701\n",
            "Epoch 299/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8678 - val_loss: 0.0763 - val_accuracy: 0.8711\n",
            "Epoch 300/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0779 - accuracy: 0.8681 - val_loss: 0.0763 - val_accuracy: 0.8706\n",
            "Epoch 301/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8678 - val_loss: 0.0763 - val_accuracy: 0.8709\n",
            "Epoch 302/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8681 - val_loss: 0.0763 - val_accuracy: 0.8713\n",
            "Epoch 303/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0778 - accuracy: 0.8683 - val_loss: 0.0763 - val_accuracy: 0.8705\n",
            "Epoch 304/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0778 - accuracy: 0.8682 - val_loss: 0.0763 - val_accuracy: 0.8715\n",
            "Epoch 305/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8683 - val_loss: 0.0762 - val_accuracy: 0.8712\n",
            "Epoch 306/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8681 - val_loss: 0.0762 - val_accuracy: 0.8714\n",
            "Epoch 307/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8682 - val_loss: 0.0762 - val_accuracy: 0.8716\n",
            "Epoch 308/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8682 - val_loss: 0.0761 - val_accuracy: 0.8718\n",
            "Epoch 309/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0777 - accuracy: 0.8680 - val_loss: 0.0761 - val_accuracy: 0.8709\n",
            "Epoch 310/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0776 - accuracy: 0.8682 - val_loss: 0.0762 - val_accuracy: 0.8704\n",
            "Epoch 311/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8682 - val_loss: 0.0761 - val_accuracy: 0.8709\n",
            "Epoch 312/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8682 - val_loss: 0.0760 - val_accuracy: 0.8717\n",
            "Epoch 313/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0776 - accuracy: 0.8687 - val_loss: 0.0760 - val_accuracy: 0.8722\n",
            "Epoch 314/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8686 - val_loss: 0.0760 - val_accuracy: 0.8717\n",
            "Epoch 315/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8682 - val_loss: 0.0760 - val_accuracy: 0.8717\n",
            "Epoch 316/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0775 - accuracy: 0.8686 - val_loss: 0.0759 - val_accuracy: 0.8713\n",
            "Epoch 317/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0775 - accuracy: 0.8686 - val_loss: 0.0759 - val_accuracy: 0.8719\n",
            "Epoch 318/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8687 - val_loss: 0.0759 - val_accuracy: 0.8717\n",
            "Epoch 319/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8689 - val_loss: 0.0760 - val_accuracy: 0.8705\n",
            "Epoch 320/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8687 - val_loss: 0.0759 - val_accuracy: 0.8716\n",
            "Epoch 321/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.8686 - val_loss: 0.0758 - val_accuracy: 0.8717\n",
            "Epoch 322/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0774 - accuracy: 0.8686 - val_loss: 0.0759 - val_accuracy: 0.8719\n",
            "Epoch 323/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8688 - val_loss: 0.0759 - val_accuracy: 0.8716\n",
            "Epoch 324/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8690 - val_loss: 0.0758 - val_accuracy: 0.8722\n",
            "Epoch 325/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8689 - val_loss: 0.0758 - val_accuracy: 0.8717\n",
            "Epoch 326/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8689 - val_loss: 0.0757 - val_accuracy: 0.8719\n",
            "Epoch 327/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0773 - accuracy: 0.8688 - val_loss: 0.0758 - val_accuracy: 0.8715\n",
            "Epoch 328/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0772 - accuracy: 0.8689 - val_loss: 0.0757 - val_accuracy: 0.8723\n",
            "Epoch 329/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8690 - val_loss: 0.0757 - val_accuracy: 0.8717\n",
            "Epoch 330/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8690 - val_loss: 0.0757 - val_accuracy: 0.8712\n",
            "Epoch 331/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8691 - val_loss: 0.0756 - val_accuracy: 0.8723\n",
            "Epoch 332/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0772 - accuracy: 0.8692 - val_loss: 0.0756 - val_accuracy: 0.8721\n",
            "Epoch 333/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8691 - val_loss: 0.0757 - val_accuracy: 0.8716\n",
            "Epoch 334/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0771 - accuracy: 0.8691 - val_loss: 0.0756 - val_accuracy: 0.8723\n",
            "Epoch 335/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8691 - val_loss: 0.0756 - val_accuracy: 0.8725\n",
            "Epoch 336/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8691 - val_loss: 0.0755 - val_accuracy: 0.8725\n",
            "Epoch 337/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0771 - accuracy: 0.8692 - val_loss: 0.0755 - val_accuracy: 0.8724\n",
            "Epoch 338/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8694 - val_loss: 0.0755 - val_accuracy: 0.8723\n",
            "Epoch 339/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8694 - val_loss: 0.0755 - val_accuracy: 0.8723\n",
            "Epoch 340/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0770 - accuracy: 0.8694 - val_loss: 0.0754 - val_accuracy: 0.8722\n",
            "Epoch 341/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8695 - val_loss: 0.0755 - val_accuracy: 0.8719\n",
            "Epoch 342/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0770 - accuracy: 0.8695 - val_loss: 0.0754 - val_accuracy: 0.8719\n",
            "Epoch 343/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0769 - accuracy: 0.8694 - val_loss: 0.0754 - val_accuracy: 0.8726\n",
            "Epoch 344/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0769 - accuracy: 0.8698 - val_loss: 0.0755 - val_accuracy: 0.8719\n",
            "Epoch 345/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0769 - accuracy: 0.8695 - val_loss: 0.0754 - val_accuracy: 0.8725\n",
            "Epoch 346/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0769 - accuracy: 0.8696 - val_loss: 0.0754 - val_accuracy: 0.8722\n",
            "Epoch 347/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0769 - accuracy: 0.8695 - val_loss: 0.0754 - val_accuracy: 0.8725\n",
            "Epoch 348/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0768 - accuracy: 0.8699 - val_loss: 0.0753 - val_accuracy: 0.8725\n",
            "Epoch 349/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0768 - accuracy: 0.8694 - val_loss: 0.0753 - val_accuracy: 0.8727\n",
            "Epoch 350/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0768 - accuracy: 0.8699 - val_loss: 0.0753 - val_accuracy: 0.8728\n",
            "Epoch 351/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0768 - accuracy: 0.8698 - val_loss: 0.0753 - val_accuracy: 0.8723\n",
            "Epoch 352/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0768 - accuracy: 0.8697 - val_loss: 0.0752 - val_accuracy: 0.8723\n",
            "Epoch 353/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0767 - accuracy: 0.8695 - val_loss: 0.0752 - val_accuracy: 0.8727\n",
            "Epoch 354/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0767 - accuracy: 0.8698 - val_loss: 0.0752 - val_accuracy: 0.8729\n",
            "Epoch 355/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0767 - accuracy: 0.8698 - val_loss: 0.0752 - val_accuracy: 0.8723\n",
            "Epoch 356/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0767 - accuracy: 0.8701 - val_loss: 0.0752 - val_accuracy: 0.8724\n",
            "Epoch 357/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0767 - accuracy: 0.8702 - val_loss: 0.0752 - val_accuracy: 0.8730\n",
            "Epoch 358/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0767 - accuracy: 0.8698 - val_loss: 0.0752 - val_accuracy: 0.8729\n",
            "Epoch 359/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0766 - accuracy: 0.8699 - val_loss: 0.0751 - val_accuracy: 0.8724\n",
            "Epoch 360/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0766 - accuracy: 0.8701 - val_loss: 0.0751 - val_accuracy: 0.8733\n",
            "Epoch 361/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0766 - accuracy: 0.8699 - val_loss: 0.0751 - val_accuracy: 0.8730\n",
            "Epoch 362/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0766 - accuracy: 0.8702 - val_loss: 0.0751 - val_accuracy: 0.8730\n",
            "Epoch 363/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0766 - accuracy: 0.8702 - val_loss: 0.0750 - val_accuracy: 0.8729\n",
            "Epoch 364/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0765 - accuracy: 0.8701 - val_loss: 0.0750 - val_accuracy: 0.8731\n",
            "Epoch 365/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0765 - accuracy: 0.8702 - val_loss: 0.0750 - val_accuracy: 0.8734\n",
            "Epoch 366/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0765 - accuracy: 0.8702 - val_loss: 0.0750 - val_accuracy: 0.8732\n",
            "Epoch 367/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0765 - accuracy: 0.8700 - val_loss: 0.0750 - val_accuracy: 0.8733\n",
            "Epoch 368/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0765 - accuracy: 0.8702 - val_loss: 0.0750 - val_accuracy: 0.8736\n",
            "Epoch 369/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0765 - accuracy: 0.8703 - val_loss: 0.0750 - val_accuracy: 0.8730\n",
            "Epoch 370/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0764 - accuracy: 0.8704 - val_loss: 0.0750 - val_accuracy: 0.8727\n",
            "Epoch 371/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0764 - accuracy: 0.8701 - val_loss: 0.0749 - val_accuracy: 0.8731\n",
            "Epoch 372/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0764 - accuracy: 0.8705 - val_loss: 0.0749 - val_accuracy: 0.8734\n",
            "Epoch 373/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0764 - accuracy: 0.8703 - val_loss: 0.0749 - val_accuracy: 0.8728\n",
            "Epoch 374/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0764 - accuracy: 0.8702 - val_loss: 0.0748 - val_accuracy: 0.8727\n",
            "Epoch 375/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0763 - accuracy: 0.8703 - val_loss: 0.0749 - val_accuracy: 0.8731\n",
            "Epoch 376/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0763 - accuracy: 0.8704 - val_loss: 0.0748 - val_accuracy: 0.8733\n",
            "Epoch 377/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0763 - accuracy: 0.8706 - val_loss: 0.0749 - val_accuracy: 0.8728\n",
            "Epoch 378/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0763 - accuracy: 0.8704 - val_loss: 0.0748 - val_accuracy: 0.8733\n",
            "Epoch 379/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0763 - accuracy: 0.8703 - val_loss: 0.0748 - val_accuracy: 0.8734\n",
            "Epoch 380/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0763 - accuracy: 0.8708 - val_loss: 0.0749 - val_accuracy: 0.8730\n",
            "Epoch 381/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0763 - accuracy: 0.8709 - val_loss: 0.0748 - val_accuracy: 0.8729\n",
            "Epoch 382/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0762 - accuracy: 0.8706 - val_loss: 0.0747 - val_accuracy: 0.8734\n",
            "Epoch 383/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0762 - accuracy: 0.8706 - val_loss: 0.0748 - val_accuracy: 0.8734\n",
            "Epoch 384/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0762 - accuracy: 0.8706 - val_loss: 0.0747 - val_accuracy: 0.8734\n",
            "Epoch 385/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0762 - accuracy: 0.8707 - val_loss: 0.0747 - val_accuracy: 0.8731\n",
            "Epoch 386/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0762 - accuracy: 0.8708 - val_loss: 0.0747 - val_accuracy: 0.8732\n",
            "Epoch 387/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0761 - accuracy: 0.8708 - val_loss: 0.0747 - val_accuracy: 0.8731\n",
            "Epoch 388/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0761 - accuracy: 0.8708 - val_loss: 0.0746 - val_accuracy: 0.8735\n",
            "Epoch 389/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0761 - accuracy: 0.8712 - val_loss: 0.0746 - val_accuracy: 0.8735\n",
            "Epoch 390/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0761 - accuracy: 0.8707 - val_loss: 0.0746 - val_accuracy: 0.8737\n",
            "Epoch 391/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0761 - accuracy: 0.8708 - val_loss: 0.0746 - val_accuracy: 0.8736\n",
            "Epoch 392/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0761 - accuracy: 0.8706 - val_loss: 0.0745 - val_accuracy: 0.8735\n",
            "Epoch 393/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0761 - accuracy: 0.8708 - val_loss: 0.0746 - val_accuracy: 0.8737\n",
            "Epoch 394/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0760 - accuracy: 0.8710 - val_loss: 0.0745 - val_accuracy: 0.8737\n",
            "Epoch 395/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0760 - accuracy: 0.8711 - val_loss: 0.0745 - val_accuracy: 0.8740\n",
            "Epoch 396/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0760 - accuracy: 0.8711 - val_loss: 0.0745 - val_accuracy: 0.8735\n",
            "Epoch 397/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0760 - accuracy: 0.8709 - val_loss: 0.0745 - val_accuracy: 0.8737\n",
            "Epoch 398/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0760 - accuracy: 0.8709 - val_loss: 0.0745 - val_accuracy: 0.8737\n",
            "Epoch 399/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0760 - accuracy: 0.8712 - val_loss: 0.0744 - val_accuracy: 0.8739\n",
            "Epoch 400/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0759 - accuracy: 0.8712 - val_loss: 0.0744 - val_accuracy: 0.8737\n",
            "Epoch 401/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0759 - accuracy: 0.8712 - val_loss: 0.0745 - val_accuracy: 0.8733\n",
            "Epoch 402/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0759 - accuracy: 0.8712 - val_loss: 0.0745 - val_accuracy: 0.8737\n",
            "Epoch 403/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0759 - accuracy: 0.8714 - val_loss: 0.0744 - val_accuracy: 0.8738\n",
            "Epoch 404/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0759 - accuracy: 0.8712 - val_loss: 0.0744 - val_accuracy: 0.8734\n",
            "Epoch 405/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0759 - accuracy: 0.8711 - val_loss: 0.0743 - val_accuracy: 0.8737\n",
            "Epoch 406/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0759 - accuracy: 0.8711 - val_loss: 0.0744 - val_accuracy: 0.8737\n",
            "Epoch 407/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0758 - accuracy: 0.8713 - val_loss: 0.0743 - val_accuracy: 0.8738\n",
            "Epoch 408/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0758 - accuracy: 0.8713 - val_loss: 0.0743 - val_accuracy: 0.8740\n",
            "Epoch 409/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0758 - accuracy: 0.8713 - val_loss: 0.0743 - val_accuracy: 0.8738\n",
            "Epoch 410/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0758 - accuracy: 0.8714 - val_loss: 0.0743 - val_accuracy: 0.8738\n",
            "Epoch 411/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0758 - accuracy: 0.8712 - val_loss: 0.0743 - val_accuracy: 0.8737\n",
            "Epoch 412/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0758 - accuracy: 0.8712 - val_loss: 0.0742 - val_accuracy: 0.8742\n",
            "Epoch 413/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0757 - accuracy: 0.8715 - val_loss: 0.0742 - val_accuracy: 0.8740\n",
            "Epoch 414/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0757 - accuracy: 0.8716 - val_loss: 0.0742 - val_accuracy: 0.8743\n",
            "Epoch 415/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0757 - accuracy: 0.8714 - val_loss: 0.0743 - val_accuracy: 0.8734\n",
            "Epoch 416/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0757 - accuracy: 0.8714 - val_loss: 0.0742 - val_accuracy: 0.8742\n",
            "Epoch 417/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0757 - accuracy: 0.8715 - val_loss: 0.0742 - val_accuracy: 0.8742\n",
            "Epoch 418/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0757 - accuracy: 0.8713 - val_loss: 0.0742 - val_accuracy: 0.8737\n",
            "Epoch 419/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0757 - accuracy: 0.8714 - val_loss: 0.0742 - val_accuracy: 0.8737\n",
            "Epoch 420/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0756 - accuracy: 0.8716 - val_loss: 0.0742 - val_accuracy: 0.8739\n",
            "Epoch 421/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0756 - accuracy: 0.8715 - val_loss: 0.0741 - val_accuracy: 0.8739\n",
            "Epoch 422/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0756 - accuracy: 0.8717 - val_loss: 0.0741 - val_accuracy: 0.8740\n",
            "Epoch 423/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0756 - accuracy: 0.8715 - val_loss: 0.0741 - val_accuracy: 0.8742\n",
            "Epoch 424/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0756 - accuracy: 0.8718 - val_loss: 0.0741 - val_accuracy: 0.8740\n",
            "Epoch 425/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0756 - accuracy: 0.8715 - val_loss: 0.0741 - val_accuracy: 0.8744\n",
            "Epoch 426/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0756 - accuracy: 0.8714 - val_loss: 0.0741 - val_accuracy: 0.8744\n",
            "Epoch 427/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0755 - accuracy: 0.8716 - val_loss: 0.0740 - val_accuracy: 0.8745\n",
            "Epoch 428/1000\n",
            "1000/1000 [==============================] - 4s 3ms/step - loss: 0.0755 - accuracy: 0.8719 - val_loss: 0.0740 - val_accuracy: 0.8744\n",
            "Epoch 429/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0755 - accuracy: 0.8717 - val_loss: 0.0740 - val_accuracy: 0.8742\n",
            "Epoch 430/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0755 - accuracy: 0.8718 - val_loss: 0.0740 - val_accuracy: 0.8744\n",
            "Epoch 431/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0755 - accuracy: 0.8717 - val_loss: 0.0740 - val_accuracy: 0.8745\n",
            "Epoch 432/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0755 - accuracy: 0.8722 - val_loss: 0.0740 - val_accuracy: 0.8744\n",
            "Epoch 433/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0755 - accuracy: 0.8720 - val_loss: 0.0739 - val_accuracy: 0.8745\n",
            "Epoch 434/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0754 - accuracy: 0.8718 - val_loss: 0.0739 - val_accuracy: 0.8745\n",
            "Epoch 435/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0754 - accuracy: 0.8720 - val_loss: 0.0740 - val_accuracy: 0.8740\n",
            "Epoch 436/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0754 - accuracy: 0.8721 - val_loss: 0.0739 - val_accuracy: 0.8745\n",
            "Epoch 437/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0754 - accuracy: 0.8720 - val_loss: 0.0739 - val_accuracy: 0.8742\n",
            "Epoch 438/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0754 - accuracy: 0.8719 - val_loss: 0.0739 - val_accuracy: 0.8742\n",
            "Epoch 439/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0754 - accuracy: 0.8722 - val_loss: 0.0739 - val_accuracy: 0.8748\n",
            "Epoch 440/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0754 - accuracy: 0.8718 - val_loss: 0.0739 - val_accuracy: 0.8744\n",
            "Epoch 441/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0753 - accuracy: 0.8723 - val_loss: 0.0739 - val_accuracy: 0.8745\n",
            "Epoch 442/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0753 - accuracy: 0.8721 - val_loss: 0.0738 - val_accuracy: 0.8746\n",
            "Epoch 443/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0753 - accuracy: 0.8721 - val_loss: 0.0739 - val_accuracy: 0.8741\n",
            "Epoch 444/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0753 - accuracy: 0.8721 - val_loss: 0.0738 - val_accuracy: 0.8746\n",
            "Epoch 445/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0753 - accuracy: 0.8723 - val_loss: 0.0738 - val_accuracy: 0.8741\n",
            "Epoch 446/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0753 - accuracy: 0.8722 - val_loss: 0.0738 - val_accuracy: 0.8741\n",
            "Epoch 447/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0753 - accuracy: 0.8723 - val_loss: 0.0738 - val_accuracy: 0.8752\n",
            "Epoch 448/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0752 - accuracy: 0.8721 - val_loss: 0.0738 - val_accuracy: 0.8745\n",
            "Epoch 449/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0752 - accuracy: 0.8722 - val_loss: 0.0737 - val_accuracy: 0.8751\n",
            "Epoch 450/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0752 - accuracy: 0.8720 - val_loss: 0.0737 - val_accuracy: 0.8749\n",
            "Epoch 451/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0752 - accuracy: 0.8724 - val_loss: 0.0737 - val_accuracy: 0.8745\n",
            "Epoch 452/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0752 - accuracy: 0.8721 - val_loss: 0.0737 - val_accuracy: 0.8748\n",
            "Epoch 453/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0752 - accuracy: 0.8724 - val_loss: 0.0738 - val_accuracy: 0.8738\n",
            "Epoch 454/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0752 - accuracy: 0.8723 - val_loss: 0.0737 - val_accuracy: 0.8750\n",
            "Epoch 455/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0752 - accuracy: 0.8724 - val_loss: 0.0736 - val_accuracy: 0.8749\n",
            "Epoch 456/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0751 - accuracy: 0.8724 - val_loss: 0.0736 - val_accuracy: 0.8748\n",
            "Epoch 457/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0751 - accuracy: 0.8726 - val_loss: 0.0737 - val_accuracy: 0.8747\n",
            "Epoch 458/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0751 - accuracy: 0.8724 - val_loss: 0.0736 - val_accuracy: 0.8752\n",
            "Epoch 459/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0751 - accuracy: 0.8725 - val_loss: 0.0737 - val_accuracy: 0.8745\n",
            "Epoch 460/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0751 - accuracy: 0.8724 - val_loss: 0.0736 - val_accuracy: 0.8752\n",
            "Epoch 461/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0751 - accuracy: 0.8725 - val_loss: 0.0736 - val_accuracy: 0.8752\n",
            "Epoch 462/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0751 - accuracy: 0.8726 - val_loss: 0.0736 - val_accuracy: 0.8748\n",
            "Epoch 463/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0750 - accuracy: 0.8726 - val_loss: 0.0736 - val_accuracy: 0.8749\n",
            "Epoch 464/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0750 - accuracy: 0.8724 - val_loss: 0.0735 - val_accuracy: 0.8749\n",
            "Epoch 465/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0750 - accuracy: 0.8728 - val_loss: 0.0735 - val_accuracy: 0.8754\n",
            "Epoch 466/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0750 - accuracy: 0.8725 - val_loss: 0.0735 - val_accuracy: 0.8749\n",
            "Epoch 467/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0750 - accuracy: 0.8723 - val_loss: 0.0735 - val_accuracy: 0.8750\n",
            "Epoch 468/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0750 - accuracy: 0.8728 - val_loss: 0.0735 - val_accuracy: 0.8754\n",
            "Epoch 469/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0750 - accuracy: 0.8728 - val_loss: 0.0735 - val_accuracy: 0.8754\n",
            "Epoch 470/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0750 - accuracy: 0.8727 - val_loss: 0.0735 - val_accuracy: 0.8753\n",
            "Epoch 471/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0750 - accuracy: 0.8727 - val_loss: 0.0735 - val_accuracy: 0.8752\n",
            "Epoch 472/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0749 - accuracy: 0.8725 - val_loss: 0.0734 - val_accuracy: 0.8752\n",
            "Epoch 473/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0749 - accuracy: 0.8726 - val_loss: 0.0734 - val_accuracy: 0.8755\n",
            "Epoch 474/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0749 - accuracy: 0.8727 - val_loss: 0.0734 - val_accuracy: 0.8748\n",
            "Epoch 475/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0749 - accuracy: 0.8728 - val_loss: 0.0734 - val_accuracy: 0.8754\n",
            "Epoch 476/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0749 - accuracy: 0.8728 - val_loss: 0.0734 - val_accuracy: 0.8743\n",
            "Epoch 477/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0749 - accuracy: 0.8729 - val_loss: 0.0734 - val_accuracy: 0.8752\n",
            "Epoch 478/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0749 - accuracy: 0.8729 - val_loss: 0.0734 - val_accuracy: 0.8748\n",
            "Epoch 479/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0749 - accuracy: 0.8728 - val_loss: 0.0735 - val_accuracy: 0.8744\n",
            "Epoch 480/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0748 - accuracy: 0.8726 - val_loss: 0.0734 - val_accuracy: 0.8745\n",
            "Epoch 481/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0748 - accuracy: 0.8728 - val_loss: 0.0733 - val_accuracy: 0.8755\n",
            "Epoch 482/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0748 - accuracy: 0.8726 - val_loss: 0.0733 - val_accuracy: 0.8755\n",
            "Epoch 483/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0748 - accuracy: 0.8730 - val_loss: 0.0733 - val_accuracy: 0.8755\n",
            "Epoch 484/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0748 - accuracy: 0.8729 - val_loss: 0.0733 - val_accuracy: 0.8749\n",
            "Epoch 485/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0748 - accuracy: 0.8727 - val_loss: 0.0733 - val_accuracy: 0.8752\n",
            "Epoch 486/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0748 - accuracy: 0.8729 - val_loss: 0.0733 - val_accuracy: 0.8752\n",
            "Epoch 487/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0748 - accuracy: 0.8730 - val_loss: 0.0732 - val_accuracy: 0.8758\n",
            "Epoch 488/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0747 - accuracy: 0.8729 - val_loss: 0.0732 - val_accuracy: 0.8755\n",
            "Epoch 489/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0747 - accuracy: 0.8730 - val_loss: 0.0733 - val_accuracy: 0.8754\n",
            "Epoch 490/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0747 - accuracy: 0.8729 - val_loss: 0.0732 - val_accuracy: 0.8757\n",
            "Epoch 491/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0747 - accuracy: 0.8732 - val_loss: 0.0733 - val_accuracy: 0.8751\n",
            "Epoch 492/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0747 - accuracy: 0.8731 - val_loss: 0.0733 - val_accuracy: 0.8751\n",
            "Epoch 493/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0747 - accuracy: 0.8731 - val_loss: 0.0732 - val_accuracy: 0.8754\n",
            "Epoch 494/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0747 - accuracy: 0.8732 - val_loss: 0.0732 - val_accuracy: 0.8755\n",
            "Epoch 495/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0747 - accuracy: 0.8730 - val_loss: 0.0732 - val_accuracy: 0.8760\n",
            "Epoch 496/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0746 - accuracy: 0.8731 - val_loss: 0.0732 - val_accuracy: 0.8755\n",
            "Epoch 497/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0746 - accuracy: 0.8730 - val_loss: 0.0731 - val_accuracy: 0.8759\n",
            "Epoch 498/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0746 - accuracy: 0.8734 - val_loss: 0.0731 - val_accuracy: 0.8761\n",
            "Epoch 499/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0746 - accuracy: 0.8731 - val_loss: 0.0732 - val_accuracy: 0.8750\n",
            "Epoch 500/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0746 - accuracy: 0.8731 - val_loss: 0.0731 - val_accuracy: 0.8757\n",
            "Epoch 501/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0746 - accuracy: 0.8733 - val_loss: 0.0731 - val_accuracy: 0.8759\n",
            "Epoch 502/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0746 - accuracy: 0.8733 - val_loss: 0.0731 - val_accuracy: 0.8755\n",
            "Epoch 503/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0746 - accuracy: 0.8731 - val_loss: 0.0731 - val_accuracy: 0.8759\n",
            "Epoch 504/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0745 - accuracy: 0.8733 - val_loss: 0.0732 - val_accuracy: 0.8752\n",
            "Epoch 505/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0745 - accuracy: 0.8732 - val_loss: 0.0731 - val_accuracy: 0.8755\n",
            "Epoch 506/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0745 - accuracy: 0.8731 - val_loss: 0.0730 - val_accuracy: 0.8763\n",
            "Epoch 507/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0745 - accuracy: 0.8734 - val_loss: 0.0730 - val_accuracy: 0.8759\n",
            "Epoch 508/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0745 - accuracy: 0.8734 - val_loss: 0.0730 - val_accuracy: 0.8758\n",
            "Epoch 509/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0745 - accuracy: 0.8733 - val_loss: 0.0730 - val_accuracy: 0.8759\n",
            "Epoch 510/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0745 - accuracy: 0.8736 - val_loss: 0.0730 - val_accuracy: 0.8759\n",
            "Epoch 511/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0745 - accuracy: 0.8732 - val_loss: 0.0730 - val_accuracy: 0.8762\n",
            "Epoch 512/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0745 - accuracy: 0.8735 - val_loss: 0.0730 - val_accuracy: 0.8765\n",
            "Epoch 513/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0744 - accuracy: 0.8735 - val_loss: 0.0730 - val_accuracy: 0.8755\n",
            "Epoch 514/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0744 - accuracy: 0.8732 - val_loss: 0.0729 - val_accuracy: 0.8760\n",
            "Epoch 515/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0744 - accuracy: 0.8736 - val_loss: 0.0729 - val_accuracy: 0.8762\n",
            "Epoch 516/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0744 - accuracy: 0.8737 - val_loss: 0.0730 - val_accuracy: 0.8760\n",
            "Epoch 517/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0744 - accuracy: 0.8734 - val_loss: 0.0729 - val_accuracy: 0.8762\n",
            "Epoch 518/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0744 - accuracy: 0.8735 - val_loss: 0.0729 - val_accuracy: 0.8762\n",
            "Epoch 519/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0744 - accuracy: 0.8737 - val_loss: 0.0729 - val_accuracy: 0.8759\n",
            "Epoch 520/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0744 - accuracy: 0.8734 - val_loss: 0.0729 - val_accuracy: 0.8762\n",
            "Epoch 521/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0744 - accuracy: 0.8738 - val_loss: 0.0730 - val_accuracy: 0.8748\n",
            "Epoch 522/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.8737 - val_loss: 0.0729 - val_accuracy: 0.8763\n",
            "Epoch 523/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.8737 - val_loss: 0.0728 - val_accuracy: 0.8764\n",
            "Epoch 524/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.8737 - val_loss: 0.0729 - val_accuracy: 0.8755\n",
            "Epoch 525/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0743 - accuracy: 0.8736 - val_loss: 0.0729 - val_accuracy: 0.8755\n",
            "Epoch 526/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0743 - accuracy: 0.8737 - val_loss: 0.0728 - val_accuracy: 0.8765\n",
            "Epoch 527/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.8737 - val_loss: 0.0728 - val_accuracy: 0.8764\n",
            "Epoch 528/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.8737 - val_loss: 0.0728 - val_accuracy: 0.8765\n",
            "Epoch 529/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0743 - accuracy: 0.8738 - val_loss: 0.0728 - val_accuracy: 0.8765\n",
            "Epoch 530/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0743 - accuracy: 0.8737 - val_loss: 0.0728 - val_accuracy: 0.8766\n",
            "Epoch 531/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0742 - accuracy: 0.8739 - val_loss: 0.0728 - val_accuracy: 0.8765\n",
            "Epoch 532/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0742 - accuracy: 0.8736 - val_loss: 0.0727 - val_accuracy: 0.8765\n",
            "Epoch 533/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0742 - accuracy: 0.8739 - val_loss: 0.0727 - val_accuracy: 0.8765\n",
            "Epoch 534/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0742 - accuracy: 0.8734 - val_loss: 0.0727 - val_accuracy: 0.8762\n",
            "Epoch 535/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0742 - accuracy: 0.8738 - val_loss: 0.0728 - val_accuracy: 0.8763\n",
            "Epoch 536/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0742 - accuracy: 0.8738 - val_loss: 0.0727 - val_accuracy: 0.8764\n",
            "Epoch 537/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0742 - accuracy: 0.8737 - val_loss: 0.0727 - val_accuracy: 0.8765\n",
            "Epoch 538/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0742 - accuracy: 0.8737 - val_loss: 0.0727 - val_accuracy: 0.8766\n",
            "Epoch 539/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0742 - accuracy: 0.8740 - val_loss: 0.0727 - val_accuracy: 0.8756\n",
            "Epoch 540/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0742 - accuracy: 0.8737 - val_loss: 0.0727 - val_accuracy: 0.8763\n",
            "Epoch 541/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0741 - accuracy: 0.8740 - val_loss: 0.0727 - val_accuracy: 0.8763\n",
            "Epoch 542/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0741 - accuracy: 0.8741 - val_loss: 0.0727 - val_accuracy: 0.8764\n",
            "Epoch 543/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0741 - accuracy: 0.8740 - val_loss: 0.0727 - val_accuracy: 0.8766\n",
            "Epoch 544/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0741 - accuracy: 0.8741 - val_loss: 0.0726 - val_accuracy: 0.8762\n",
            "Epoch 545/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0741 - accuracy: 0.8738 - val_loss: 0.0726 - val_accuracy: 0.8767\n",
            "Epoch 546/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0741 - accuracy: 0.8741 - val_loss: 0.0726 - val_accuracy: 0.8766\n",
            "Epoch 547/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0741 - accuracy: 0.8740 - val_loss: 0.0726 - val_accuracy: 0.8767\n",
            "Epoch 548/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0741 - accuracy: 0.8740 - val_loss: 0.0726 - val_accuracy: 0.8767\n",
            "Epoch 549/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0741 - accuracy: 0.8739 - val_loss: 0.0726 - val_accuracy: 0.8766\n",
            "Epoch 550/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.8740 - val_loss: 0.0726 - val_accuracy: 0.8762\n",
            "Epoch 551/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0740 - accuracy: 0.8741 - val_loss: 0.0726 - val_accuracy: 0.8766\n",
            "Epoch 552/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0740 - accuracy: 0.8742 - val_loss: 0.0725 - val_accuracy: 0.8766\n",
            "Epoch 553/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.8743 - val_loss: 0.0726 - val_accuracy: 0.8763\n",
            "Epoch 554/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.8741 - val_loss: 0.0725 - val_accuracy: 0.8766\n",
            "Epoch 555/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.8743 - val_loss: 0.0725 - val_accuracy: 0.8770\n",
            "Epoch 556/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.8741 - val_loss: 0.0725 - val_accuracy: 0.8768\n",
            "Epoch 557/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0740 - accuracy: 0.8742 - val_loss: 0.0725 - val_accuracy: 0.8766\n",
            "Epoch 558/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0740 - accuracy: 0.8741 - val_loss: 0.0725 - val_accuracy: 0.8762\n",
            "Epoch 559/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0740 - accuracy: 0.8746 - val_loss: 0.0725 - val_accuracy: 0.8772\n",
            "Epoch 560/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0739 - accuracy: 0.8745 - val_loss: 0.0725 - val_accuracy: 0.8762\n",
            "Epoch 561/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0739 - accuracy: 0.8745 - val_loss: 0.0725 - val_accuracy: 0.8766\n",
            "Epoch 562/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0739 - accuracy: 0.8744 - val_loss: 0.0724 - val_accuracy: 0.8770\n",
            "Epoch 563/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0739 - accuracy: 0.8742 - val_loss: 0.0725 - val_accuracy: 0.8767\n",
            "Epoch 564/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0739 - accuracy: 0.8743 - val_loss: 0.0724 - val_accuracy: 0.8767\n",
            "Epoch 565/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0739 - accuracy: 0.8744 - val_loss: 0.0725 - val_accuracy: 0.8764\n",
            "Epoch 566/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0739 - accuracy: 0.8745 - val_loss: 0.0724 - val_accuracy: 0.8770\n",
            "Epoch 567/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0739 - accuracy: 0.8742 - val_loss: 0.0724 - val_accuracy: 0.8766\n",
            "Epoch 568/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0738 - accuracy: 0.8744 - val_loss: 0.0724 - val_accuracy: 0.8768\n",
            "Epoch 569/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0738 - accuracy: 0.8742 - val_loss: 0.0724 - val_accuracy: 0.8766\n",
            "Epoch 570/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0738 - accuracy: 0.8745 - val_loss: 0.0723 - val_accuracy: 0.8770\n",
            "Epoch 571/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0738 - accuracy: 0.8747 - val_loss: 0.0724 - val_accuracy: 0.8765\n",
            "Epoch 572/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0738 - accuracy: 0.8744 - val_loss: 0.0724 - val_accuracy: 0.8759\n",
            "Epoch 573/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0738 - accuracy: 0.8748 - val_loss: 0.0723 - val_accuracy: 0.8772\n",
            "Epoch 574/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0738 - accuracy: 0.8745 - val_loss: 0.0723 - val_accuracy: 0.8770\n",
            "Epoch 575/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0738 - accuracy: 0.8745 - val_loss: 0.0723 - val_accuracy: 0.8770\n",
            "Epoch 576/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0738 - accuracy: 0.8744 - val_loss: 0.0723 - val_accuracy: 0.8772\n",
            "Epoch 577/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0738 - accuracy: 0.8746 - val_loss: 0.0723 - val_accuracy: 0.8767\n",
            "Epoch 578/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0737 - accuracy: 0.8745 - val_loss: 0.0723 - val_accuracy: 0.8774\n",
            "Epoch 579/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0737 - accuracy: 0.8749 - val_loss: 0.0723 - val_accuracy: 0.8768\n",
            "Epoch 580/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0737 - accuracy: 0.8744 - val_loss: 0.0723 - val_accuracy: 0.8767\n",
            "Epoch 581/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0737 - accuracy: 0.8746 - val_loss: 0.0723 - val_accuracy: 0.8772\n",
            "Epoch 582/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0737 - accuracy: 0.8745 - val_loss: 0.0722 - val_accuracy: 0.8775\n",
            "Epoch 583/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0737 - accuracy: 0.8745 - val_loss: 0.0723 - val_accuracy: 0.8769\n",
            "Epoch 584/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0737 - accuracy: 0.8746 - val_loss: 0.0722 - val_accuracy: 0.8773\n",
            "Epoch 585/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0737 - accuracy: 0.8747 - val_loss: 0.0723 - val_accuracy: 0.8766\n",
            "Epoch 586/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0737 - accuracy: 0.8745 - val_loss: 0.0722 - val_accuracy: 0.8774\n",
            "Epoch 587/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0737 - accuracy: 0.8746 - val_loss: 0.0722 - val_accuracy: 0.8773\n",
            "Epoch 588/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0737 - accuracy: 0.8747 - val_loss: 0.0722 - val_accuracy: 0.8776\n",
            "Epoch 589/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0736 - accuracy: 0.8746 - val_loss: 0.0722 - val_accuracy: 0.8770\n",
            "Epoch 590/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0736 - accuracy: 0.8748 - val_loss: 0.0722 - val_accuracy: 0.8777\n",
            "Epoch 591/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0736 - accuracy: 0.8749 - val_loss: 0.0721 - val_accuracy: 0.8776\n",
            "Epoch 592/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0736 - accuracy: 0.8747 - val_loss: 0.0722 - val_accuracy: 0.8768\n",
            "Epoch 593/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0736 - accuracy: 0.8745 - val_loss: 0.0722 - val_accuracy: 0.8769\n",
            "Epoch 594/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0736 - accuracy: 0.8749 - val_loss: 0.0722 - val_accuracy: 0.8771\n",
            "Epoch 595/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0736 - accuracy: 0.8751 - val_loss: 0.0721 - val_accuracy: 0.8773\n",
            "Epoch 596/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0736 - accuracy: 0.8750 - val_loss: 0.0721 - val_accuracy: 0.8773\n",
            "Epoch 597/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0736 - accuracy: 0.8748 - val_loss: 0.0721 - val_accuracy: 0.8776\n",
            "Epoch 598/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0735 - accuracy: 0.8749 - val_loss: 0.0721 - val_accuracy: 0.8773\n",
            "Epoch 599/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0735 - accuracy: 0.8750 - val_loss: 0.0721 - val_accuracy: 0.8774\n",
            "Epoch 600/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0735 - accuracy: 0.8751 - val_loss: 0.0721 - val_accuracy: 0.8777\n",
            "Epoch 601/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0735 - accuracy: 0.8748 - val_loss: 0.0721 - val_accuracy: 0.8777\n",
            "Epoch 602/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0735 - accuracy: 0.8748 - val_loss: 0.0721 - val_accuracy: 0.8771\n",
            "Epoch 603/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0735 - accuracy: 0.8751 - val_loss: 0.0721 - val_accuracy: 0.8773\n",
            "Epoch 604/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0735 - accuracy: 0.8748 - val_loss: 0.0720 - val_accuracy: 0.8778\n",
            "Epoch 605/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0735 - accuracy: 0.8749 - val_loss: 0.0721 - val_accuracy: 0.8766\n",
            "Epoch 606/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0735 - accuracy: 0.8749 - val_loss: 0.0720 - val_accuracy: 0.8777\n",
            "Epoch 607/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0735 - accuracy: 0.8750 - val_loss: 0.0720 - val_accuracy: 0.8774\n",
            "Epoch 608/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8751 - val_loss: 0.0720 - val_accuracy: 0.8777\n",
            "Epoch 609/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0735 - accuracy: 0.8751 - val_loss: 0.0720 - val_accuracy: 0.8770\n",
            "Epoch 610/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8753 - val_loss: 0.0720 - val_accuracy: 0.8780\n",
            "Epoch 611/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8750 - val_loss: 0.0720 - val_accuracy: 0.8775\n",
            "Epoch 612/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0734 - accuracy: 0.8751 - val_loss: 0.0720 - val_accuracy: 0.8778\n",
            "Epoch 613/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8751 - val_loss: 0.0720 - val_accuracy: 0.8777\n",
            "Epoch 614/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8750 - val_loss: 0.0719 - val_accuracy: 0.8777\n",
            "Epoch 615/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8751 - val_loss: 0.0720 - val_accuracy: 0.8769\n",
            "Epoch 616/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0734 - accuracy: 0.8752 - val_loss: 0.0719 - val_accuracy: 0.8778\n",
            "Epoch 617/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0734 - accuracy: 0.8752 - val_loss: 0.0719 - val_accuracy: 0.8779\n",
            "Epoch 618/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0734 - accuracy: 0.8751 - val_loss: 0.0719 - val_accuracy: 0.8776\n",
            "Epoch 619/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8750 - val_loss: 0.0719 - val_accuracy: 0.8776\n",
            "Epoch 620/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8754 - val_loss: 0.0719 - val_accuracy: 0.8778\n",
            "Epoch 621/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8752 - val_loss: 0.0719 - val_accuracy: 0.8782\n",
            "Epoch 622/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8750 - val_loss: 0.0719 - val_accuracy: 0.8778\n",
            "Epoch 623/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0733 - accuracy: 0.8753 - val_loss: 0.0719 - val_accuracy: 0.8777\n",
            "Epoch 624/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0733 - accuracy: 0.8754 - val_loss: 0.0719 - val_accuracy: 0.8777\n",
            "Epoch 625/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8751 - val_loss: 0.0719 - val_accuracy: 0.8777\n",
            "Epoch 626/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8754 - val_loss: 0.0719 - val_accuracy: 0.8774\n",
            "Epoch 627/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0733 - accuracy: 0.8753 - val_loss: 0.0718 - val_accuracy: 0.8781\n",
            "Epoch 628/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8755 - val_loss: 0.0719 - val_accuracy: 0.8775\n",
            "Epoch 629/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0733 - accuracy: 0.8754 - val_loss: 0.0719 - val_accuracy: 0.8772\n",
            "Epoch 630/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8755 - val_loss: 0.0718 - val_accuracy: 0.8778\n",
            "Epoch 631/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0733 - accuracy: 0.8754 - val_loss: 0.0718 - val_accuracy: 0.8782\n",
            "Epoch 632/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0732 - accuracy: 0.8755 - val_loss: 0.0718 - val_accuracy: 0.8781\n",
            "Epoch 633/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0732 - accuracy: 0.8757 - val_loss: 0.0718 - val_accuracy: 0.8778\n",
            "Epoch 634/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0732 - accuracy: 0.8753 - val_loss: 0.0718 - val_accuracy: 0.8781\n",
            "Epoch 635/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0732 - accuracy: 0.8757 - val_loss: 0.0718 - val_accuracy: 0.8781\n",
            "Epoch 636/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0732 - accuracy: 0.8753 - val_loss: 0.0717 - val_accuracy: 0.8784\n",
            "Epoch 637/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0732 - accuracy: 0.8755 - val_loss: 0.0717 - val_accuracy: 0.8782\n",
            "Epoch 638/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0732 - accuracy: 0.8755 - val_loss: 0.0718 - val_accuracy: 0.8778\n",
            "Epoch 639/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0732 - accuracy: 0.8758 - val_loss: 0.0717 - val_accuracy: 0.8782\n",
            "Epoch 640/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0732 - accuracy: 0.8757 - val_loss: 0.0717 - val_accuracy: 0.8780\n",
            "Epoch 641/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0732 - accuracy: 0.8755 - val_loss: 0.0718 - val_accuracy: 0.8777\n",
            "Epoch 642/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.8755 - val_loss: 0.0717 - val_accuracy: 0.8781\n",
            "Epoch 643/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.8756 - val_loss: 0.0717 - val_accuracy: 0.8785\n",
            "Epoch 644/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.8757 - val_loss: 0.0718 - val_accuracy: 0.8776\n",
            "Epoch 645/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0731 - accuracy: 0.8755 - val_loss: 0.0717 - val_accuracy: 0.8777\n",
            "Epoch 646/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0731 - accuracy: 0.8756 - val_loss: 0.0717 - val_accuracy: 0.8781\n",
            "Epoch 647/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.8757 - val_loss: 0.0717 - val_accuracy: 0.8780\n",
            "Epoch 648/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.8758 - val_loss: 0.0716 - val_accuracy: 0.8782\n",
            "Epoch 649/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.8758 - val_loss: 0.0716 - val_accuracy: 0.8785\n",
            "Epoch 650/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0731 - accuracy: 0.8757 - val_loss: 0.0717 - val_accuracy: 0.8781\n",
            "Epoch 651/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0731 - accuracy: 0.8756 - val_loss: 0.0716 - val_accuracy: 0.8784\n",
            "Epoch 652/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0731 - accuracy: 0.8758 - val_loss: 0.0716 - val_accuracy: 0.8784\n",
            "Epoch 653/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0730 - accuracy: 0.8757 - val_loss: 0.0716 - val_accuracy: 0.8780\n",
            "Epoch 654/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.8755 - val_loss: 0.0716 - val_accuracy: 0.8783\n",
            "Epoch 655/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0730 - accuracy: 0.8757 - val_loss: 0.0716 - val_accuracy: 0.8779\n",
            "Epoch 656/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0730 - accuracy: 0.8758 - val_loss: 0.0716 - val_accuracy: 0.8785\n",
            "Epoch 657/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0730 - accuracy: 0.8759 - val_loss: 0.0716 - val_accuracy: 0.8784\n",
            "Epoch 658/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.8759 - val_loss: 0.0716 - val_accuracy: 0.8784\n",
            "Epoch 659/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.8758 - val_loss: 0.0715 - val_accuracy: 0.8785\n",
            "Epoch 660/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.8759 - val_loss: 0.0716 - val_accuracy: 0.8786\n",
            "Epoch 661/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.8759 - val_loss: 0.0715 - val_accuracy: 0.8785\n",
            "Epoch 662/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0730 - accuracy: 0.8761 - val_loss: 0.0715 - val_accuracy: 0.8781\n",
            "Epoch 663/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0730 - accuracy: 0.8759 - val_loss: 0.0716 - val_accuracy: 0.8783\n",
            "Epoch 664/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0730 - accuracy: 0.8758 - val_loss: 0.0715 - val_accuracy: 0.8784\n",
            "Epoch 665/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0729 - accuracy: 0.8759 - val_loss: 0.0715 - val_accuracy: 0.8787\n",
            "Epoch 666/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0729 - accuracy: 0.8759 - val_loss: 0.0715 - val_accuracy: 0.8781\n",
            "Epoch 667/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0729 - accuracy: 0.8760 - val_loss: 0.0715 - val_accuracy: 0.8787\n",
            "Epoch 668/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0729 - accuracy: 0.8758 - val_loss: 0.0715 - val_accuracy: 0.8788\n",
            "Epoch 669/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0729 - accuracy: 0.8759 - val_loss: 0.0715 - val_accuracy: 0.8788\n",
            "Epoch 670/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0729 - accuracy: 0.8760 - val_loss: 0.0715 - val_accuracy: 0.8788\n",
            "Epoch 671/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0729 - accuracy: 0.8760 - val_loss: 0.0715 - val_accuracy: 0.8785\n",
            "Epoch 672/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0729 - accuracy: 0.8761 - val_loss: 0.0714 - val_accuracy: 0.8787\n",
            "Epoch 673/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0729 - accuracy: 0.8759 - val_loss: 0.0714 - val_accuracy: 0.8787\n",
            "Epoch 674/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0729 - accuracy: 0.8762 - val_loss: 0.0714 - val_accuracy: 0.8787\n",
            "Epoch 675/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0729 - accuracy: 0.8760 - val_loss: 0.0714 - val_accuracy: 0.8789\n",
            "Epoch 676/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.8757 - val_loss: 0.0714 - val_accuracy: 0.8790\n",
            "Epoch 677/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.8760 - val_loss: 0.0714 - val_accuracy: 0.8787\n",
            "Epoch 678/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.8762 - val_loss: 0.0714 - val_accuracy: 0.8790\n",
            "Epoch 679/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0728 - accuracy: 0.8762 - val_loss: 0.0714 - val_accuracy: 0.8784\n",
            "Epoch 680/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0728 - accuracy: 0.8760 - val_loss: 0.0715 - val_accuracy: 0.8781\n",
            "Epoch 681/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.8761 - val_loss: 0.0714 - val_accuracy: 0.8784\n",
            "Epoch 682/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.8763 - val_loss: 0.0714 - val_accuracy: 0.8791\n",
            "Epoch 683/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.8762 - val_loss: 0.0714 - val_accuracy: 0.8789\n",
            "Epoch 684/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.8763 - val_loss: 0.0714 - val_accuracy: 0.8788\n",
            "Epoch 685/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0728 - accuracy: 0.8762 - val_loss: 0.0713 - val_accuracy: 0.8788\n",
            "Epoch 686/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0728 - accuracy: 0.8761 - val_loss: 0.0713 - val_accuracy: 0.8788\n",
            "Epoch 687/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8763 - val_loss: 0.0713 - val_accuracy: 0.8791\n",
            "Epoch 688/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8764 - val_loss: 0.0714 - val_accuracy: 0.8781\n",
            "Epoch 689/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8765 - val_loss: 0.0713 - val_accuracy: 0.8789\n",
            "Epoch 690/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0727 - accuracy: 0.8764 - val_loss: 0.0713 - val_accuracy: 0.8788\n",
            "Epoch 691/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0727 - accuracy: 0.8763 - val_loss: 0.0713 - val_accuracy: 0.8792\n",
            "Epoch 692/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8763 - val_loss: 0.0713 - val_accuracy: 0.8789\n",
            "Epoch 693/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8763 - val_loss: 0.0713 - val_accuracy: 0.8791\n",
            "Epoch 694/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8765 - val_loss: 0.0713 - val_accuracy: 0.8791\n",
            "Epoch 695/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8762 - val_loss: 0.0713 - val_accuracy: 0.8790\n",
            "Epoch 696/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0727 - accuracy: 0.8763 - val_loss: 0.0712 - val_accuracy: 0.8788\n",
            "Epoch 697/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0727 - accuracy: 0.8765 - val_loss: 0.0713 - val_accuracy: 0.8787\n",
            "Epoch 698/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8763 - val_loss: 0.0713 - val_accuracy: 0.8782\n",
            "Epoch 699/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0727 - accuracy: 0.8762 - val_loss: 0.0712 - val_accuracy: 0.8791\n",
            "Epoch 700/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0726 - accuracy: 0.8763 - val_loss: 0.0712 - val_accuracy: 0.8794\n",
            "Epoch 701/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0726 - accuracy: 0.8764 - val_loss: 0.0712 - val_accuracy: 0.8790\n",
            "Epoch 702/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0726 - accuracy: 0.8766 - val_loss: 0.0712 - val_accuracy: 0.8790\n",
            "Epoch 703/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0726 - accuracy: 0.8764 - val_loss: 0.0712 - val_accuracy: 0.8791\n",
            "Epoch 704/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0726 - accuracy: 0.8765 - val_loss: 0.0712 - val_accuracy: 0.8791\n",
            "Epoch 705/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0726 - accuracy: 0.8766 - val_loss: 0.0712 - val_accuracy: 0.8791\n",
            "Epoch 706/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0726 - accuracy: 0.8764 - val_loss: 0.0712 - val_accuracy: 0.8791\n",
            "Epoch 707/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0726 - accuracy: 0.8763 - val_loss: 0.0712 - val_accuracy: 0.8795\n",
            "Epoch 708/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0726 - accuracy: 0.8767 - val_loss: 0.0712 - val_accuracy: 0.8791\n",
            "Epoch 709/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0726 - accuracy: 0.8769 - val_loss: 0.0711 - val_accuracy: 0.8793\n",
            "Epoch 710/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0726 - accuracy: 0.8766 - val_loss: 0.0712 - val_accuracy: 0.8793\n",
            "Epoch 711/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0725 - accuracy: 0.8765 - val_loss: 0.0712 - val_accuracy: 0.8788\n",
            "Epoch 712/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8766 - val_loss: 0.0712 - val_accuracy: 0.8787\n",
            "Epoch 713/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0725 - accuracy: 0.8764 - val_loss: 0.0711 - val_accuracy: 0.8794\n",
            "Epoch 714/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8765 - val_loss: 0.0712 - val_accuracy: 0.8787\n",
            "Epoch 715/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8767 - val_loss: 0.0711 - val_accuracy: 0.8795\n",
            "Epoch 716/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8766 - val_loss: 0.0711 - val_accuracy: 0.8790\n",
            "Epoch 717/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8766 - val_loss: 0.0711 - val_accuracy: 0.8792\n",
            "Epoch 718/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0725 - accuracy: 0.8765 - val_loss: 0.0711 - val_accuracy: 0.8792\n",
            "Epoch 719/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0725 - accuracy: 0.8767 - val_loss: 0.0711 - val_accuracy: 0.8795\n",
            "Epoch 720/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8768 - val_loss: 0.0711 - val_accuracy: 0.8792\n",
            "Epoch 721/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8767 - val_loss: 0.0711 - val_accuracy: 0.8792\n",
            "Epoch 722/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8767 - val_loss: 0.0710 - val_accuracy: 0.8792\n",
            "Epoch 723/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0725 - accuracy: 0.8767 - val_loss: 0.0711 - val_accuracy: 0.8791\n",
            "Epoch 724/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0724 - accuracy: 0.8769 - val_loss: 0.0710 - val_accuracy: 0.8794\n",
            "Epoch 725/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0724 - accuracy: 0.8767 - val_loss: 0.0710 - val_accuracy: 0.8796\n",
            "Epoch 726/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0724 - accuracy: 0.8764 - val_loss: 0.0712 - val_accuracy: 0.8787\n",
            "Epoch 727/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0724 - accuracy: 0.8767 - val_loss: 0.0711 - val_accuracy: 0.8791\n",
            "Epoch 728/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0724 - accuracy: 0.8769 - val_loss: 0.0710 - val_accuracy: 0.8791\n",
            "Epoch 729/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0724 - accuracy: 0.8767 - val_loss: 0.0710 - val_accuracy: 0.8794\n",
            "Epoch 730/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0724 - accuracy: 0.8768 - val_loss: 0.0710 - val_accuracy: 0.8795\n",
            "Epoch 731/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0724 - accuracy: 0.8765 - val_loss: 0.0711 - val_accuracy: 0.8788\n",
            "Epoch 732/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0724 - accuracy: 0.8768 - val_loss: 0.0710 - val_accuracy: 0.8795\n",
            "Epoch 733/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0724 - accuracy: 0.8769 - val_loss: 0.0710 - val_accuracy: 0.8792\n",
            "Epoch 734/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0724 - accuracy: 0.8768 - val_loss: 0.0710 - val_accuracy: 0.8794\n",
            "Epoch 735/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0724 - accuracy: 0.8769 - val_loss: 0.0710 - val_accuracy: 0.8791\n",
            "Epoch 736/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0723 - accuracy: 0.8767 - val_loss: 0.0709 - val_accuracy: 0.8795\n",
            "Epoch 737/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8770 - val_loss: 0.0710 - val_accuracy: 0.8795\n",
            "Epoch 738/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8770 - val_loss: 0.0709 - val_accuracy: 0.8799\n",
            "Epoch 739/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8770 - val_loss: 0.0709 - val_accuracy: 0.8798\n",
            "Epoch 740/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8766 - val_loss: 0.0710 - val_accuracy: 0.8794\n",
            "Epoch 741/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0723 - accuracy: 0.8770 - val_loss: 0.0709 - val_accuracy: 0.8796\n",
            "Epoch 742/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8767 - val_loss: 0.0709 - val_accuracy: 0.8793\n",
            "Epoch 743/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8770 - val_loss: 0.0710 - val_accuracy: 0.8790\n",
            "Epoch 744/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8768 - val_loss: 0.0709 - val_accuracy: 0.8797\n",
            "Epoch 745/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8768 - val_loss: 0.0709 - val_accuracy: 0.8799\n",
            "Epoch 746/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0723 - accuracy: 0.8771 - val_loss: 0.0708 - val_accuracy: 0.8798\n",
            "Epoch 747/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0723 - accuracy: 0.8769 - val_loss: 0.0709 - val_accuracy: 0.8795\n",
            "Epoch 748/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0723 - accuracy: 0.8769 - val_loss: 0.0708 - val_accuracy: 0.8799\n",
            "Epoch 749/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0722 - accuracy: 0.8770 - val_loss: 0.0708 - val_accuracy: 0.8791\n",
            "Epoch 750/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0722 - accuracy: 0.8773 - val_loss: 0.0708 - val_accuracy: 0.8799\n",
            "Epoch 751/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0722 - accuracy: 0.8769 - val_loss: 0.0708 - val_accuracy: 0.8801\n",
            "Epoch 752/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0722 - accuracy: 0.8769 - val_loss: 0.0708 - val_accuracy: 0.8799\n",
            "Epoch 753/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0722 - accuracy: 0.8770 - val_loss: 0.0708 - val_accuracy: 0.8796\n",
            "Epoch 754/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0722 - accuracy: 0.8770 - val_loss: 0.0708 - val_accuracy: 0.8798\n",
            "Epoch 755/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0722 - accuracy: 0.8770 - val_loss: 0.0708 - val_accuracy: 0.8799\n",
            "Epoch 756/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0722 - accuracy: 0.8772 - val_loss: 0.0708 - val_accuracy: 0.8794\n",
            "Epoch 757/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0722 - accuracy: 0.8770 - val_loss: 0.0708 - val_accuracy: 0.8797\n",
            "Epoch 758/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0722 - accuracy: 0.8771 - val_loss: 0.0708 - val_accuracy: 0.8796\n",
            "Epoch 759/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0722 - accuracy: 0.8772 - val_loss: 0.0708 - val_accuracy: 0.8796\n",
            "Epoch 760/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0722 - accuracy: 0.8771 - val_loss: 0.0707 - val_accuracy: 0.8795\n",
            "Epoch 761/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8774 - val_loss: 0.0707 - val_accuracy: 0.8795\n",
            "Epoch 762/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8771 - val_loss: 0.0707 - val_accuracy: 0.8796\n",
            "Epoch 763/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8773 - val_loss: 0.0708 - val_accuracy: 0.8795\n",
            "Epoch 764/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0721 - accuracy: 0.8771 - val_loss: 0.0707 - val_accuracy: 0.8801\n",
            "Epoch 765/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8772 - val_loss: 0.0707 - val_accuracy: 0.8798\n",
            "Epoch 766/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8773 - val_loss: 0.0707 - val_accuracy: 0.8802\n",
            "Epoch 767/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8772 - val_loss: 0.0707 - val_accuracy: 0.8799\n",
            "Epoch 768/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8773 - val_loss: 0.0707 - val_accuracy: 0.8798\n",
            "Epoch 769/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0721 - accuracy: 0.8774 - val_loss: 0.0707 - val_accuracy: 0.8796\n",
            "Epoch 770/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0721 - accuracy: 0.8772 - val_loss: 0.0707 - val_accuracy: 0.8803\n",
            "Epoch 771/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8775 - val_loss: 0.0707 - val_accuracy: 0.8795\n",
            "Epoch 772/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0721 - accuracy: 0.8772 - val_loss: 0.0707 - val_accuracy: 0.8801\n",
            "Epoch 773/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0721 - accuracy: 0.8776 - val_loss: 0.0706 - val_accuracy: 0.8806\n",
            "Epoch 774/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8776 - val_loss: 0.0706 - val_accuracy: 0.8796\n",
            "Epoch 775/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0720 - accuracy: 0.8772 - val_loss: 0.0706 - val_accuracy: 0.8796\n",
            "Epoch 776/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0720 - accuracy: 0.8774 - val_loss: 0.0707 - val_accuracy: 0.8795\n",
            "Epoch 777/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8777 - val_loss: 0.0706 - val_accuracy: 0.8802\n",
            "Epoch 778/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8774 - val_loss: 0.0707 - val_accuracy: 0.8798\n",
            "Epoch 779/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8774 - val_loss: 0.0706 - val_accuracy: 0.8795\n",
            "Epoch 780/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8776 - val_loss: 0.0706 - val_accuracy: 0.8802\n",
            "Epoch 781/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0720 - accuracy: 0.8776 - val_loss: 0.0707 - val_accuracy: 0.8795\n",
            "Epoch 782/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8774 - val_loss: 0.0706 - val_accuracy: 0.8803\n",
            "Epoch 783/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8774 - val_loss: 0.0706 - val_accuracy: 0.8805\n",
            "Epoch 784/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8776 - val_loss: 0.0707 - val_accuracy: 0.8799\n",
            "Epoch 785/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0720 - accuracy: 0.8772 - val_loss: 0.0706 - val_accuracy: 0.8801\n",
            "Epoch 786/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0720 - accuracy: 0.8775 - val_loss: 0.0706 - val_accuracy: 0.8802\n",
            "Epoch 787/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0719 - accuracy: 0.8777 - val_loss: 0.0706 - val_accuracy: 0.8799\n",
            "Epoch 788/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0719 - accuracy: 0.8776 - val_loss: 0.0706 - val_accuracy: 0.8801\n",
            "Epoch 789/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0719 - accuracy: 0.8777 - val_loss: 0.0706 - val_accuracy: 0.8798\n",
            "Epoch 790/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0719 - accuracy: 0.8774 - val_loss: 0.0705 - val_accuracy: 0.8801\n",
            "Epoch 791/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0719 - accuracy: 0.8776 - val_loss: 0.0706 - val_accuracy: 0.8800\n",
            "Epoch 792/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0719 - accuracy: 0.8778 - val_loss: 0.0706 - val_accuracy: 0.8798\n",
            "Epoch 793/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0719 - accuracy: 0.8774 - val_loss: 0.0705 - val_accuracy: 0.8802\n",
            "Epoch 794/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0719 - accuracy: 0.8776 - val_loss: 0.0705 - val_accuracy: 0.8799\n",
            "Epoch 795/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0719 - accuracy: 0.8777 - val_loss: 0.0705 - val_accuracy: 0.8799\n",
            "Epoch 796/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0719 - accuracy: 0.8775 - val_loss: 0.0705 - val_accuracy: 0.8802\n",
            "Epoch 797/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0719 - accuracy: 0.8777 - val_loss: 0.0706 - val_accuracy: 0.8795\n",
            "Epoch 798/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0719 - accuracy: 0.8778 - val_loss: 0.0705 - val_accuracy: 0.8801\n",
            "Epoch 799/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0719 - accuracy: 0.8773 - val_loss: 0.0705 - val_accuracy: 0.8803\n",
            "Epoch 800/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8776 - val_loss: 0.0704 - val_accuracy: 0.8803\n",
            "Epoch 801/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8777 - val_loss: 0.0704 - val_accuracy: 0.8802\n",
            "Epoch 802/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8776 - val_loss: 0.0705 - val_accuracy: 0.8798\n",
            "Epoch 803/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8778 - val_loss: 0.0705 - val_accuracy: 0.8802\n",
            "Epoch 804/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0718 - accuracy: 0.8779 - val_loss: 0.0704 - val_accuracy: 0.8796\n",
            "Epoch 805/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0718 - accuracy: 0.8775 - val_loss: 0.0704 - val_accuracy: 0.8800\n",
            "Epoch 806/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8776 - val_loss: 0.0704 - val_accuracy: 0.8806\n",
            "Epoch 807/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8777 - val_loss: 0.0705 - val_accuracy: 0.8805\n",
            "Epoch 808/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8778 - val_loss: 0.0704 - val_accuracy: 0.8804\n",
            "Epoch 809/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8780 - val_loss: 0.0705 - val_accuracy: 0.8800\n",
            "Epoch 810/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0718 - accuracy: 0.8778 - val_loss: 0.0704 - val_accuracy: 0.8806\n",
            "Epoch 811/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0718 - accuracy: 0.8780 - val_loss: 0.0704 - val_accuracy: 0.8806\n",
            "Epoch 812/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0718 - accuracy: 0.8780 - val_loss: 0.0704 - val_accuracy: 0.8799\n",
            "Epoch 813/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8778 - val_loss: 0.0703 - val_accuracy: 0.8805\n",
            "Epoch 814/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8780 - val_loss: 0.0703 - val_accuracy: 0.8806\n",
            "Epoch 815/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8778 - val_loss: 0.0704 - val_accuracy: 0.8806\n",
            "Epoch 816/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0717 - accuracy: 0.8777 - val_loss: 0.0704 - val_accuracy: 0.8802\n",
            "Epoch 817/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0717 - accuracy: 0.8779 - val_loss: 0.0703 - val_accuracy: 0.8806\n",
            "Epoch 818/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8781 - val_loss: 0.0704 - val_accuracy: 0.8806\n",
            "Epoch 819/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8779 - val_loss: 0.0703 - val_accuracy: 0.8806\n",
            "Epoch 820/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8780 - val_loss: 0.0704 - val_accuracy: 0.8803\n",
            "Epoch 821/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8780 - val_loss: 0.0703 - val_accuracy: 0.8805\n",
            "Epoch 822/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0717 - accuracy: 0.8779 - val_loss: 0.0703 - val_accuracy: 0.8800\n",
            "Epoch 823/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8781 - val_loss: 0.0703 - val_accuracy: 0.8801\n",
            "Epoch 824/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8778 - val_loss: 0.0703 - val_accuracy: 0.8803\n",
            "Epoch 825/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0717 - accuracy: 0.8781 - val_loss: 0.0703 - val_accuracy: 0.8806\n",
            "Epoch 826/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8781 - val_loss: 0.0703 - val_accuracy: 0.8805\n",
            "Epoch 827/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0716 - accuracy: 0.8781 - val_loss: 0.0703 - val_accuracy: 0.8808\n",
            "Epoch 828/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0716 - accuracy: 0.8781 - val_loss: 0.0703 - val_accuracy: 0.8809\n",
            "Epoch 829/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8778 - val_loss: 0.0702 - val_accuracy: 0.8806\n",
            "Epoch 830/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8780 - val_loss: 0.0702 - val_accuracy: 0.8806\n",
            "Epoch 831/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8780 - val_loss: 0.0703 - val_accuracy: 0.8805\n",
            "Epoch 832/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8782 - val_loss: 0.0702 - val_accuracy: 0.8807\n",
            "Epoch 833/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0716 - accuracy: 0.8781 - val_loss: 0.0702 - val_accuracy: 0.8808\n",
            "Epoch 834/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0716 - accuracy: 0.8782 - val_loss: 0.0703 - val_accuracy: 0.8808\n",
            "Epoch 835/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8783 - val_loss: 0.0702 - val_accuracy: 0.8807\n",
            "Epoch 836/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8780 - val_loss: 0.0702 - val_accuracy: 0.8807\n",
            "Epoch 837/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8781 - val_loss: 0.0702 - val_accuracy: 0.8807\n",
            "Epoch 838/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0716 - accuracy: 0.8781 - val_loss: 0.0702 - val_accuracy: 0.8806\n",
            "Epoch 839/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0716 - accuracy: 0.8784 - val_loss: 0.0702 - val_accuracy: 0.8803\n",
            "Epoch 840/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0715 - accuracy: 0.8781 - val_loss: 0.0702 - val_accuracy: 0.8806\n",
            "Epoch 841/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0715 - accuracy: 0.8782 - val_loss: 0.0702 - val_accuracy: 0.8807\n",
            "Epoch 842/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0715 - accuracy: 0.8782 - val_loss: 0.0701 - val_accuracy: 0.8805\n",
            "Epoch 843/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0715 - accuracy: 0.8781 - val_loss: 0.0702 - val_accuracy: 0.8809\n",
            "Epoch 844/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0715 - accuracy: 0.8784 - val_loss: 0.0701 - val_accuracy: 0.8809\n",
            "Epoch 845/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0715 - accuracy: 0.8785 - val_loss: 0.0701 - val_accuracy: 0.8808\n",
            "Epoch 846/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0715 - accuracy: 0.8785 - val_loss: 0.0701 - val_accuracy: 0.8806\n",
            "Epoch 847/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0715 - accuracy: 0.8783 - val_loss: 0.0701 - val_accuracy: 0.8810\n",
            "Epoch 848/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0715 - accuracy: 0.8782 - val_loss: 0.0701 - val_accuracy: 0.8807\n",
            "Epoch 849/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0715 - accuracy: 0.8783 - val_loss: 0.0701 - val_accuracy: 0.8807\n",
            "Epoch 850/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0715 - accuracy: 0.8784 - val_loss: 0.0701 - val_accuracy: 0.8809\n",
            "Epoch 851/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0714 - accuracy: 0.8782 - val_loss: 0.0701 - val_accuracy: 0.8808\n",
            "Epoch 852/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0715 - accuracy: 0.8785 - val_loss: 0.0701 - val_accuracy: 0.8809\n",
            "Epoch 853/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.8785 - val_loss: 0.0701 - val_accuracy: 0.8812\n",
            "Epoch 854/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.8787 - val_loss: 0.0701 - val_accuracy: 0.8809\n",
            "Epoch 855/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0714 - accuracy: 0.8786 - val_loss: 0.0701 - val_accuracy: 0.8809\n",
            "Epoch 856/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0714 - accuracy: 0.8784 - val_loss: 0.0700 - val_accuracy: 0.8809\n",
            "Epoch 857/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0714 - accuracy: 0.8784 - val_loss: 0.0701 - val_accuracy: 0.8805\n",
            "Epoch 858/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0714 - accuracy: 0.8785 - val_loss: 0.0700 - val_accuracy: 0.8809\n",
            "Epoch 859/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.8785 - val_loss: 0.0700 - val_accuracy: 0.8808\n",
            "Epoch 860/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.8785 - val_loss: 0.0700 - val_accuracy: 0.8810\n",
            "Epoch 861/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0714 - accuracy: 0.8788 - val_loss: 0.0701 - val_accuracy: 0.8809\n",
            "Epoch 862/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0714 - accuracy: 0.8785 - val_loss: 0.0700 - val_accuracy: 0.8806\n",
            "Epoch 863/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0714 - accuracy: 0.8785 - val_loss: 0.0700 - val_accuracy: 0.8806\n",
            "Epoch 864/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.8784 - val_loss: 0.0700 - val_accuracy: 0.8810\n",
            "Epoch 865/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0714 - accuracy: 0.8785 - val_loss: 0.0700 - val_accuracy: 0.8813\n",
            "Epoch 866/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.8788 - val_loss: 0.0700 - val_accuracy: 0.8813\n",
            "Epoch 867/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0713 - accuracy: 0.8787 - val_loss: 0.0700 - val_accuracy: 0.8811\n",
            "Epoch 868/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0713 - accuracy: 0.8787 - val_loss: 0.0700 - val_accuracy: 0.8811\n",
            "Epoch 869/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.8786 - val_loss: 0.0701 - val_accuracy: 0.8808\n",
            "Epoch 870/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.8787 - val_loss: 0.0700 - val_accuracy: 0.8808\n",
            "Epoch 871/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0713 - accuracy: 0.8787 - val_loss: 0.0699 - val_accuracy: 0.8812\n",
            "Epoch 872/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0713 - accuracy: 0.8788 - val_loss: 0.0699 - val_accuracy: 0.8807\n",
            "Epoch 873/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0713 - accuracy: 0.8788 - val_loss: 0.0699 - val_accuracy: 0.8807\n",
            "Epoch 874/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.8787 - val_loss: 0.0699 - val_accuracy: 0.8810\n",
            "Epoch 875/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.8790 - val_loss: 0.0699 - val_accuracy: 0.8810\n",
            "Epoch 876/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.8789 - val_loss: 0.0699 - val_accuracy: 0.8811\n",
            "Epoch 877/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0713 - accuracy: 0.8785 - val_loss: 0.0699 - val_accuracy: 0.8810\n",
            "Epoch 878/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0713 - accuracy: 0.8787 - val_loss: 0.0699 - val_accuracy: 0.8814\n",
            "Epoch 879/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.8787 - val_loss: 0.0700 - val_accuracy: 0.8804\n",
            "Epoch 880/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0713 - accuracy: 0.8790 - val_loss: 0.0699 - val_accuracy: 0.8811\n",
            "Epoch 881/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0712 - accuracy: 0.8789 - val_loss: 0.0699 - val_accuracy: 0.8809\n",
            "Epoch 882/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0712 - accuracy: 0.8789 - val_loss: 0.0699 - val_accuracy: 0.8814\n",
            "Epoch 883/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.8788 - val_loss: 0.0699 - val_accuracy: 0.8813\n",
            "Epoch 884/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.8791 - val_loss: 0.0698 - val_accuracy: 0.8811\n",
            "Epoch 885/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0712 - accuracy: 0.8788 - val_loss: 0.0698 - val_accuracy: 0.8812\n",
            "Epoch 886/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.8787 - val_loss: 0.0698 - val_accuracy: 0.8812\n",
            "Epoch 887/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0712 - accuracy: 0.8789 - val_loss: 0.0699 - val_accuracy: 0.8813\n",
            "Epoch 888/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.8791 - val_loss: 0.0698 - val_accuracy: 0.8812\n",
            "Epoch 889/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.8787 - val_loss: 0.0698 - val_accuracy: 0.8812\n",
            "Epoch 890/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.8792 - val_loss: 0.0698 - val_accuracy: 0.8810\n",
            "Epoch 891/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0712 - accuracy: 0.8790 - val_loss: 0.0698 - val_accuracy: 0.8813\n",
            "Epoch 892/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0712 - accuracy: 0.8790 - val_loss: 0.0698 - val_accuracy: 0.8813\n",
            "Epoch 893/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.8791 - val_loss: 0.0698 - val_accuracy: 0.8813\n",
            "Epoch 894/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.8791 - val_loss: 0.0698 - val_accuracy: 0.8814\n",
            "Epoch 895/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.8789 - val_loss: 0.0698 - val_accuracy: 0.8814\n",
            "Epoch 896/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.8791 - val_loss: 0.0698 - val_accuracy: 0.8814\n",
            "Epoch 897/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.8789 - val_loss: 0.0698 - val_accuracy: 0.8813\n",
            "Epoch 898/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.8791 - val_loss: 0.0697 - val_accuracy: 0.8813\n",
            "Epoch 899/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.8788 - val_loss: 0.0697 - val_accuracy: 0.8814\n",
            "Epoch 900/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.8792 - val_loss: 0.0697 - val_accuracy: 0.8814\n",
            "Epoch 901/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.8795 - val_loss: 0.0699 - val_accuracy: 0.8811\n",
            "Epoch 902/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.8793 - val_loss: 0.0697 - val_accuracy: 0.8816\n",
            "Epoch 903/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.8793 - val_loss: 0.0697 - val_accuracy: 0.8816\n",
            "Epoch 904/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0711 - accuracy: 0.8791 - val_loss: 0.0697 - val_accuracy: 0.8817\n",
            "Epoch 905/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.8792 - val_loss: 0.0697 - val_accuracy: 0.8814\n",
            "Epoch 906/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.8794 - val_loss: 0.0698 - val_accuracy: 0.8816\n",
            "Epoch 907/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0711 - accuracy: 0.8788 - val_loss: 0.0697 - val_accuracy: 0.8812\n",
            "Epoch 908/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0710 - accuracy: 0.8790 - val_loss: 0.0697 - val_accuracy: 0.8812\n",
            "Epoch 909/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0710 - accuracy: 0.8792 - val_loss: 0.0697 - val_accuracy: 0.8816\n",
            "Epoch 910/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0710 - accuracy: 0.8792 - val_loss: 0.0697 - val_accuracy: 0.8817\n",
            "Epoch 911/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0710 - accuracy: 0.8793 - val_loss: 0.0697 - val_accuracy: 0.8816\n",
            "Epoch 912/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0710 - accuracy: 0.8796 - val_loss: 0.0697 - val_accuracy: 0.8815\n",
            "Epoch 913/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0710 - accuracy: 0.8793 - val_loss: 0.0697 - val_accuracy: 0.8813\n",
            "Epoch 914/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0710 - accuracy: 0.8795 - val_loss: 0.0697 - val_accuracy: 0.8814\n",
            "Epoch 915/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0710 - accuracy: 0.8794 - val_loss: 0.0697 - val_accuracy: 0.8813\n",
            "Epoch 916/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0710 - accuracy: 0.8794 - val_loss: 0.0696 - val_accuracy: 0.8816\n",
            "Epoch 917/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0710 - accuracy: 0.8795 - val_loss: 0.0697 - val_accuracy: 0.8819\n",
            "Epoch 918/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0710 - accuracy: 0.8795 - val_loss: 0.0696 - val_accuracy: 0.8817\n",
            "Epoch 919/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0710 - accuracy: 0.8794 - val_loss: 0.0696 - val_accuracy: 0.8813\n",
            "Epoch 920/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0709 - accuracy: 0.8794 - val_loss: 0.0696 - val_accuracy: 0.8814\n",
            "Epoch 921/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0709 - accuracy: 0.8794 - val_loss: 0.0696 - val_accuracy: 0.8814\n",
            "Epoch 922/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0709 - accuracy: 0.8796 - val_loss: 0.0696 - val_accuracy: 0.8818\n",
            "Epoch 923/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0709 - accuracy: 0.8793 - val_loss: 0.0696 - val_accuracy: 0.8814\n",
            "Epoch 924/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0709 - accuracy: 0.8795 - val_loss: 0.0696 - val_accuracy: 0.8820\n",
            "Epoch 925/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0709 - accuracy: 0.8796 - val_loss: 0.0697 - val_accuracy: 0.8816\n",
            "Epoch 926/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0709 - accuracy: 0.8794 - val_loss: 0.0696 - val_accuracy: 0.8816\n",
            "Epoch 927/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0709 - accuracy: 0.8791 - val_loss: 0.0696 - val_accuracy: 0.8816\n",
            "Epoch 928/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0709 - accuracy: 0.8796 - val_loss: 0.0696 - val_accuracy: 0.8814\n",
            "Epoch 929/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0709 - accuracy: 0.8793 - val_loss: 0.0696 - val_accuracy: 0.8817\n",
            "Epoch 930/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0709 - accuracy: 0.8794 - val_loss: 0.0695 - val_accuracy: 0.8816\n",
            "Epoch 931/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0709 - accuracy: 0.8792 - val_loss: 0.0695 - val_accuracy: 0.8816\n",
            "Epoch 932/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0709 - accuracy: 0.8795 - val_loss: 0.0695 - val_accuracy: 0.8817\n",
            "Epoch 933/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0709 - accuracy: 0.8795 - val_loss: 0.0695 - val_accuracy: 0.8820\n",
            "Epoch 934/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0708 - accuracy: 0.8795 - val_loss: 0.0695 - val_accuracy: 0.8820\n",
            "Epoch 935/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.8797 - val_loss: 0.0695 - val_accuracy: 0.8820\n",
            "Epoch 936/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0708 - accuracy: 0.8796 - val_loss: 0.0695 - val_accuracy: 0.8814\n",
            "Epoch 937/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.8795 - val_loss: 0.0695 - val_accuracy: 0.8816\n",
            "Epoch 938/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.8799 - val_loss: 0.0695 - val_accuracy: 0.8820\n",
            "Epoch 939/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0708 - accuracy: 0.8798 - val_loss: 0.0695 - val_accuracy: 0.8819\n",
            "Epoch 940/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0708 - accuracy: 0.8795 - val_loss: 0.0695 - val_accuracy: 0.8816\n",
            "Epoch 941/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.8796 - val_loss: 0.0695 - val_accuracy: 0.8820\n",
            "Epoch 942/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.8796 - val_loss: 0.0694 - val_accuracy: 0.8822\n",
            "Epoch 943/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.8800 - val_loss: 0.0695 - val_accuracy: 0.8816\n",
            "Epoch 944/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.8799 - val_loss: 0.0695 - val_accuracy: 0.8817\n",
            "Epoch 945/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0708 - accuracy: 0.8797 - val_loss: 0.0694 - val_accuracy: 0.8815\n",
            "Epoch 946/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0708 - accuracy: 0.8797 - val_loss: 0.0695 - val_accuracy: 0.8816\n",
            "Epoch 947/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0708 - accuracy: 0.8798 - val_loss: 0.0694 - val_accuracy: 0.8818\n",
            "Epoch 948/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8796 - val_loss: 0.0695 - val_accuracy: 0.8821\n",
            "Epoch 949/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8798 - val_loss: 0.0694 - val_accuracy: 0.8819\n",
            "Epoch 950/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0707 - accuracy: 0.8797 - val_loss: 0.0694 - val_accuracy: 0.8818\n",
            "Epoch 951/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0707 - accuracy: 0.8798 - val_loss: 0.0695 - val_accuracy: 0.8819\n",
            "Epoch 952/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0707 - accuracy: 0.8796 - val_loss: 0.0694 - val_accuracy: 0.8814\n",
            "Epoch 953/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8798 - val_loss: 0.0695 - val_accuracy: 0.8821\n",
            "Epoch 954/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8797 - val_loss: 0.0694 - val_accuracy: 0.8823\n",
            "Epoch 955/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8797 - val_loss: 0.0694 - val_accuracy: 0.8821\n",
            "Epoch 956/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0707 - accuracy: 0.8798 - val_loss: 0.0694 - val_accuracy: 0.8817\n",
            "Epoch 957/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0707 - accuracy: 0.8800 - val_loss: 0.0693 - val_accuracy: 0.8824\n",
            "Epoch 958/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0707 - accuracy: 0.8800 - val_loss: 0.0694 - val_accuracy: 0.8816\n",
            "Epoch 959/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8799 - val_loss: 0.0694 - val_accuracy: 0.8819\n",
            "Epoch 960/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8799 - val_loss: 0.0693 - val_accuracy: 0.8820\n",
            "Epoch 961/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0707 - accuracy: 0.8798 - val_loss: 0.0693 - val_accuracy: 0.8819\n",
            "Epoch 962/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0706 - accuracy: 0.8799 - val_loss: 0.0693 - val_accuracy: 0.8820\n",
            "Epoch 963/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0706 - accuracy: 0.8797 - val_loss: 0.0693 - val_accuracy: 0.8823\n",
            "Epoch 964/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0706 - accuracy: 0.8798 - val_loss: 0.0693 - val_accuracy: 0.8820\n",
            "Epoch 965/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0706 - accuracy: 0.8801 - val_loss: 0.0693 - val_accuracy: 0.8820\n",
            "Epoch 966/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0706 - accuracy: 0.8798 - val_loss: 0.0694 - val_accuracy: 0.8820\n",
            "Epoch 967/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0706 - accuracy: 0.8799 - val_loss: 0.0693 - val_accuracy: 0.8819\n",
            "Epoch 968/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0706 - accuracy: 0.8800 - val_loss: 0.0693 - val_accuracy: 0.8821\n",
            "Epoch 969/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0706 - accuracy: 0.8799 - val_loss: 0.0693 - val_accuracy: 0.8824\n",
            "Epoch 970/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0706 - accuracy: 0.8802 - val_loss: 0.0693 - val_accuracy: 0.8823\n",
            "Epoch 971/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0706 - accuracy: 0.8802 - val_loss: 0.0693 - val_accuracy: 0.8824\n",
            "Epoch 972/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0706 - accuracy: 0.8797 - val_loss: 0.0692 - val_accuracy: 0.8822\n",
            "Epoch 973/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0706 - accuracy: 0.8799 - val_loss: 0.0692 - val_accuracy: 0.8824\n",
            "Epoch 974/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0706 - accuracy: 0.8800 - val_loss: 0.0692 - val_accuracy: 0.8823\n",
            "Epoch 975/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0706 - accuracy: 0.8799 - val_loss: 0.0692 - val_accuracy: 0.8821\n",
            "Epoch 976/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8800 - val_loss: 0.0692 - val_accuracy: 0.8823\n",
            "Epoch 977/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8799 - val_loss: 0.0693 - val_accuracy: 0.8824\n",
            "Epoch 978/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8802 - val_loss: 0.0692 - val_accuracy: 0.8820\n",
            "Epoch 979/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0705 - accuracy: 0.8801 - val_loss: 0.0692 - val_accuracy: 0.8824\n",
            "Epoch 980/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0705 - accuracy: 0.8799 - val_loss: 0.0692 - val_accuracy: 0.8820\n",
            "Epoch 981/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8800 - val_loss: 0.0692 - val_accuracy: 0.8819\n",
            "Epoch 982/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8802 - val_loss: 0.0692 - val_accuracy: 0.8821\n",
            "Epoch 983/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8799 - val_loss: 0.0692 - val_accuracy: 0.8824\n",
            "Epoch 984/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8804 - val_loss: 0.0692 - val_accuracy: 0.8824\n",
            "Epoch 985/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0705 - accuracy: 0.8800 - val_loss: 0.0691 - val_accuracy: 0.8826\n",
            "Epoch 986/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0705 - accuracy: 0.8800 - val_loss: 0.0691 - val_accuracy: 0.8824\n",
            "Epoch 987/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8803 - val_loss: 0.0692 - val_accuracy: 0.8824\n",
            "Epoch 988/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0705 - accuracy: 0.8802 - val_loss: 0.0692 - val_accuracy: 0.8824\n",
            "Epoch 989/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0705 - accuracy: 0.8804 - val_loss: 0.0691 - val_accuracy: 0.8824\n",
            "Epoch 990/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0704 - accuracy: 0.8800 - val_loss: 0.0691 - val_accuracy: 0.8823\n",
            "Epoch 991/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0704 - accuracy: 0.8805 - val_loss: 0.0691 - val_accuracy: 0.8824\n",
            "Epoch 992/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0704 - accuracy: 0.8802 - val_loss: 0.0692 - val_accuracy: 0.8824\n",
            "Epoch 993/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0704 - accuracy: 0.8805 - val_loss: 0.0692 - val_accuracy: 0.8824\n",
            "Epoch 994/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0704 - accuracy: 0.8804 - val_loss: 0.0691 - val_accuracy: 0.8824\n",
            "Epoch 995/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0704 - accuracy: 0.8803 - val_loss: 0.0691 - val_accuracy: 0.8823\n",
            "Epoch 996/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0704 - accuracy: 0.8801 - val_loss: 0.0691 - val_accuracy: 0.8823\n",
            "Epoch 997/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0704 - accuracy: 0.8805 - val_loss: 0.0691 - val_accuracy: 0.8824\n",
            "Epoch 998/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0704 - accuracy: 0.8803 - val_loss: 0.0691 - val_accuracy: 0.8824\n",
            "Epoch 999/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0704 - accuracy: 0.8802 - val_loss: 0.0691 - val_accuracy: 0.8824\n",
            "Epoch 1000/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0704 - accuracy: 0.8806 - val_loss: 0.0691 - val_accuracy: 0.8824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = network.predict(xtest_std)"
      ],
      "metadata": {
        "id": "RrUIPDfdM5wB",
        "outputId": "70e1403d-7995-458b-826b-7b5e5606836a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat.shape)"
      ],
      "metadata": {
        "id": "GJWR1M7LN6rv",
        "outputId": "2d247f0c-cf60-400f-cf8f-62f1e38bf8b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytest.shape)"
      ],
      "metadata": {
        "id": "pFXuFm6HPG0g",
        "outputId": "15728589-5195-4711-d87e-a70af762f3ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat =np.argmax(yhat, axis = -1)\n",
        "ytest = np.argmax(ytest, axis= -1)"
      ],
      "metadata": {
        "id": "V162us36U6Ij"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = accuracy_score(ytest,yhat)\n",
        "cm = confusion_matrix(ytest,yhat)\n",
        "print(f\"El grado de precisión de los datos son los siguientes {100*precision}\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "yXPBisYxORs_",
        "outputId": "cba340d6-1954-43ec-81e6-5b1b4611d801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El grado de precisión de los datos son los siguientes 88.24\n",
            "[[11175   199   515]\n",
            " [  404  3351    37]\n",
            " [ 1193     4  3122]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función logarítimica\n",
        "\n",
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "plt.title(\"Grafica de aprendizaje del modelo de 500 Epochs\")\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"accuracy\"])\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_accuracy\"])\n",
        "\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "JbkIxANdZHMB",
        "outputId": "724cc20d-6a6f-49c8-a2da-c9f06978dbe2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"loss\"])\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_loss\"])\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "VD_qykwMajLa",
        "outputId": "45754bab-9e64-4656-ec94-7f847d236caa"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}