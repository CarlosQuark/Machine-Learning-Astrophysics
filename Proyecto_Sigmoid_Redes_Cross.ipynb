{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Proyecto_Sigmoid_Redes_Cross",
      "authorship_tag": "ABX9TyNWd4EFKlRqfAPxWuJ7le8b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosQuark/Machine-Learning-Astrophysics/blob/main/Proyecto_Sigmoid_Redes_Cross.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# PROYECTO DE MACHINE LEARNING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvURBlWmT07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZV03xjlnj-NB"
      },
      "outputs": [],
      "source": [
        "#librerias Comunes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#liberias de PCA\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import eig\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder #Change the class to str for another type the int.\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#librerias de sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#librerias de Keras y Redes Neuronales\n",
        "\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = pd.read_csv(\"star_classification.csv\")\n",
        "data_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "OQ6pTIb2mimr",
        "outputId": "fd348982-a991-4209-9d5f-76a268aa3c3d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237660e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237660e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237660e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237660e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543780e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176010e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030110e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891860e+18   \n",
              "\n",
              "   redshift  plate    MJD  fiber_ID   class  \n",
              "0  0.634794   5812  56354       171  GALAXY  \n",
              "1  0.779136  10445  58158       427  GALAXY  \n",
              "2  0.644195   4576  55592       299  GALAXY  \n",
              "3  0.932346   9149  58039       775  GALAXY  \n",
              "4  0.116123   6121  56187       842  GALAXY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edaed8c8-a595-45e7-a80a-4f5ae2adb63e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543780e+18</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176010e+19</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030110e+19</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891860e+18</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edaed8c8-a595-45e7-a80a-4f5ae2adb63e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edaed8c8-a595-45e7-a80a-4f5ae2adb63e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edaed8c8-a595-45e7-a80a-4f5ae2adb63e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6b56001b-0ec0-4983-a8a5-138345426f29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b56001b-0ec0-4983-a8a5-138345426f29')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6b56001b-0ec0-4983-a8a5-138345426f29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nlql6Qz1Znk",
        "outputId": "029552a2-740e-4813-f197-c27e1ee417e9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 18 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   obj_ID       100000 non-null  float64\n",
            " 1   alpha        100000 non-null  float64\n",
            " 2   delta        100000 non-null  float64\n",
            " 3   u            100000 non-null  float64\n",
            " 4   g            100000 non-null  float64\n",
            " 5   r            100000 non-null  float64\n",
            " 6   i            100000 non-null  float64\n",
            " 7   z            100000 non-null  float64\n",
            " 8   run_ID       100000 non-null  int64  \n",
            " 9   rerun_ID     100000 non-null  int64  \n",
            " 10  cam_col      100000 non-null  int64  \n",
            " 11  field_ID     100000 non-null  int64  \n",
            " 12  spec_obj_ID  100000 non-null  float64\n",
            " 13  redshift     100000 non-null  float64\n",
            " 14  plate        100000 non-null  int64  \n",
            " 15  MJD          100000 non-null  int64  \n",
            " 16  fiber_ID     100000 non-null  int64  \n",
            " 17  class        100000 non-null  object \n",
            "dtypes: float64(10), int64(7), object(1)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enconder = LabelEncoder()\n",
        "\n",
        "data_set[\"class\"] = enconder.fit_transform(data_set[\"class\"])"
      ],
      "metadata": {
        "id": "lVhT4P72weJt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar los datos\n",
        "\n",
        "Y = np.array(data_set[\"class\"])\n",
        "\n",
        "df_new = data_set.drop([\"class\"], axis =1)\n",
        "\n",
        "X = np.array(df_new)\n"
      ],
      "metadata": {
        "id": "5VSRDHJhn75L"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components= 17)\n",
        "PCA_objeto.fit(X)"
      ],
      "metadata": {
        "id": "Akeqp3SySWYi",
        "outputId": "1af18558-6d5e-406c-db88-e6a954f85e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PCA_objeto.explained_variance_)"
      ],
      "metadata": {
        "id": "3jmLTxmoSp0Q",
        "outputId": "8024972b-78b8-4d89-8e24-f4ea1e65e530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.10491489e+37 5.34345995e+28 3.63783147e+06 1.90094686e+05\n",
            " 6.89069641e+04 2.22875371e+04 8.93542373e+03 3.01724592e+03\n",
            " 3.23491013e+02 6.79740439e+00 3.42870277e+00 2.46778931e+00\n",
            " 1.93784010e+00 4.09255753e-01 3.26988977e-01 4.66492584e-02\n",
            " 3.72772496e-34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components = 17)\n",
        "Z = PCA_objeto.fit_transform(X)"
      ],
      "metadata": {
        "id": "0dytpcETSr5A"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento de los datos\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Z,Y, test_size = 0.2, stratify=Y)"
      ],
      "metadata": {
        "id": "MXeQdyFvxQQ6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estandarizar los datos\n",
        "\n",
        "scaler = MinMaxScaler().fit(xtrain)\n",
        "\n",
        "xtrain_std = scaler.transform(xtrain)\n",
        "\n",
        "xtest_std = scaler.transform(xtest)\n"
      ],
      "metadata": {
        "id": "i6dJHiUQxpVc"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Este apartado se utilizar para poder dar inicio el entrenamiento a una red\n",
        "neuronal\n",
        "\n",
        "   Todo esto viene dentro de la página oficial de Keras.\n",
        "\n",
        "   Dense es una capa de neurona que está conectada con todas las anteriores\n",
        "\n",
        "   Sequential es utilizado para crear secuencias en redes neuronales.\n",
        "\n",
        "   Optimizador: Adam.\n",
        "\n",
        "   units es la candtidad de clases que tienes.\n",
        "\n",
        "   activation: \"Qué tipo de función de activación almacenas\".\n",
        "\n",
        "   input_dim = la dimensionalidad.\n",
        "\n",
        "\"\"\"\n",
        "network = Sequential([\n",
        "\n",
        "    Dense(units=3, activation= \"sigmoid\" , input_dim = 17)\n",
        "])\n",
        "\n",
        "#Que copilador voy a utilizar, Adam, puede hacer eso.\n",
        "\n",
        "Adam(learning_rate=0.0001) #Taza de aprendizaje pequeña\n",
        "\n",
        "network.compile()\n",
        "\n",
        "#Función de perdida que se utilizará en la sala de entrenamient como su métrica.\n",
        "\n",
        "network.compile(loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QbP87Xplx-fX"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"La libreria de keras para to_categorical\n",
        "\n",
        "   se utiliza para poder experesar problemas de clasificación de multiclase.\n",
        "   Para convertir nuestras etiquetas númericas en tipo one-hot.\n",
        "\n",
        "   Supongamso que tienes 3 clases (etiqeutas númericas 0,1,2)\n",
        "\n",
        "   En la primera linea convierte la una matriz en one-hot\n",
        "\n",
        "   Cada fila corresponde a un etiqueta, y cada columna, representa una clase.\n",
        "\n",
        "   AQUÍ INICIAMOS LA ETAPA DE ENTRENAMIENTO DE LA RED\n",
        "\n",
        "   El profe explica que es el batch_size, es para reducir el costo\n",
        "   computacional,\n",
        "   crea grupos para filas de hasta 100,000 dimensiones.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#network.fit(xtrain_std, ytrain, epochs=50, batch_size=128 )\n",
        "\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "epoch_accuracy =network.fit(xtrain_std, ytrain, epochs=1000, batch_size=80,\n",
        "                             validation_data=(xtest_std,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMrjFO3yNnb",
        "outputId": "6beaadf2-4b16-4030-c6f1-a628b5af4e7d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9645 - accuracy: 0.5936 - val_loss: 0.9338 - val_accuracy: 0.5944\n",
            "Epoch 2/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.9125 - accuracy: 0.5949 - val_loss: 0.8938 - val_accuracy: 0.5958\n",
            "Epoch 3/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8792 - accuracy: 0.5983 - val_loss: 0.8671 - val_accuracy: 0.6010\n",
            "Epoch 4/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8558 - accuracy: 0.6042 - val_loss: 0.8466 - val_accuracy: 0.6070\n",
            "Epoch 5/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8374 - accuracy: 0.6097 - val_loss: 0.8298 - val_accuracy: 0.6104\n",
            "Epoch 6/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.8215 - accuracy: 0.6141 - val_loss: 0.8148 - val_accuracy: 0.6175\n",
            "Epoch 7/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8070 - accuracy: 0.6193 - val_loss: 0.8007 - val_accuracy: 0.6284\n",
            "Epoch 8/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7935 - accuracy: 0.6266 - val_loss: 0.7873 - val_accuracy: 0.6320\n",
            "Epoch 9/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7812 - accuracy: 0.6348 - val_loss: 0.7753 - val_accuracy: 0.6401\n",
            "Epoch 10/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7697 - accuracy: 0.6438 - val_loss: 0.7643 - val_accuracy: 0.6552\n",
            "Epoch 11/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7592 - accuracy: 0.6539 - val_loss: 0.7539 - val_accuracy: 0.6521\n",
            "Epoch 12/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7490 - accuracy: 0.6632 - val_loss: 0.7436 - val_accuracy: 0.6676\n",
            "Epoch 13/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7397 - accuracy: 0.6732 - val_loss: 0.7345 - val_accuracy: 0.6758\n",
            "Epoch 14/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.7308 - accuracy: 0.6832 - val_loss: 0.7258 - val_accuracy: 0.6776\n",
            "Epoch 15/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7223 - accuracy: 0.6924 - val_loss: 0.7172 - val_accuracy: 0.6984\n",
            "Epoch 16/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7144 - accuracy: 0.7023 - val_loss: 0.7094 - val_accuracy: 0.6988\n",
            "Epoch 17/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7068 - accuracy: 0.7110 - val_loss: 0.7021 - val_accuracy: 0.7161\n",
            "Epoch 18/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6997 - accuracy: 0.7189 - val_loss: 0.6948 - val_accuracy: 0.7222\n",
            "Epoch 19/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6930 - accuracy: 0.7275 - val_loss: 0.6883 - val_accuracy: 0.7214\n",
            "Epoch 20/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6866 - accuracy: 0.7341 - val_loss: 0.6820 - val_accuracy: 0.7304\n",
            "Epoch 21/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6806 - accuracy: 0.7395 - val_loss: 0.6759 - val_accuracy: 0.7427\n",
            "Epoch 22/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6749 - accuracy: 0.7459 - val_loss: 0.6702 - val_accuracy: 0.7421\n",
            "Epoch 23/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6693 - accuracy: 0.7522 - val_loss: 0.6654 - val_accuracy: 0.7416\n",
            "Epoch 24/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6641 - accuracy: 0.7560 - val_loss: 0.6596 - val_accuracy: 0.7560\n",
            "Epoch 25/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6593 - accuracy: 0.7603 - val_loss: 0.6548 - val_accuracy: 0.7681\n",
            "Epoch 26/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6544 - accuracy: 0.7655 - val_loss: 0.6502 - val_accuracy: 0.7578\n",
            "Epoch 27/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6497 - accuracy: 0.7688 - val_loss: 0.6452 - val_accuracy: 0.7753\n",
            "Epoch 28/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6452 - accuracy: 0.7725 - val_loss: 0.6408 - val_accuracy: 0.7812\n",
            "Epoch 29/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6410 - accuracy: 0.7761 - val_loss: 0.6364 - val_accuracy: 0.7824\n",
            "Epoch 30/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6369 - accuracy: 0.7787 - val_loss: 0.6325 - val_accuracy: 0.7865\n",
            "Epoch 31/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6332 - accuracy: 0.7817 - val_loss: 0.6284 - val_accuracy: 0.7877\n",
            "Epoch 32/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.6294 - accuracy: 0.7849 - val_loss: 0.6253 - val_accuracy: 0.7793\n",
            "Epoch 33/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6258 - accuracy: 0.7873 - val_loss: 0.6212 - val_accuracy: 0.7929\n",
            "Epoch 34/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6223 - accuracy: 0.7908 - val_loss: 0.6179 - val_accuracy: 0.7971\n",
            "Epoch 35/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6190 - accuracy: 0.7927 - val_loss: 0.6147 - val_accuracy: 0.7933\n",
            "Epoch 36/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6159 - accuracy: 0.7952 - val_loss: 0.6115 - val_accuracy: 0.7944\n",
            "Epoch 37/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6128 - accuracy: 0.7966 - val_loss: 0.6089 - val_accuracy: 0.8038\n",
            "Epoch 38/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6099 - accuracy: 0.7992 - val_loss: 0.6052 - val_accuracy: 0.8045\n",
            "Epoch 39/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6069 - accuracy: 0.8005 - val_loss: 0.6023 - val_accuracy: 0.8057\n",
            "Epoch 40/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6041 - accuracy: 0.8031 - val_loss: 0.5997 - val_accuracy: 0.8101\n",
            "Epoch 41/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6015 - accuracy: 0.8049 - val_loss: 0.5968 - val_accuracy: 0.8073\n",
            "Epoch 42/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5989 - accuracy: 0.8062 - val_loss: 0.5942 - val_accuracy: 0.8092\n",
            "Epoch 43/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5964 - accuracy: 0.8075 - val_loss: 0.5919 - val_accuracy: 0.8150\n",
            "Epoch 44/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5939 - accuracy: 0.8086 - val_loss: 0.5895 - val_accuracy: 0.8103\n",
            "Epoch 45/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5916 - accuracy: 0.8100 - val_loss: 0.5869 - val_accuracy: 0.8123\n",
            "Epoch 46/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5894 - accuracy: 0.8115 - val_loss: 0.5847 - val_accuracy: 0.8117\n",
            "Epoch 47/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5871 - accuracy: 0.8127 - val_loss: 0.5825 - val_accuracy: 0.8170\n",
            "Epoch 48/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5849 - accuracy: 0.8135 - val_loss: 0.5803 - val_accuracy: 0.8162\n",
            "Epoch 49/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5829 - accuracy: 0.8148 - val_loss: 0.5783 - val_accuracy: 0.8174\n",
            "Epoch 50/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5809 - accuracy: 0.8162 - val_loss: 0.5762 - val_accuracy: 0.8205\n",
            "Epoch 51/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5790 - accuracy: 0.8168 - val_loss: 0.5743 - val_accuracy: 0.8220\n",
            "Epoch 52/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5770 - accuracy: 0.8176 - val_loss: 0.5723 - val_accuracy: 0.8198\n",
            "Epoch 53/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5752 - accuracy: 0.8188 - val_loss: 0.5706 - val_accuracy: 0.8191\n",
            "Epoch 54/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5733 - accuracy: 0.8193 - val_loss: 0.5686 - val_accuracy: 0.8237\n",
            "Epoch 55/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5715 - accuracy: 0.8206 - val_loss: 0.5670 - val_accuracy: 0.8234\n",
            "Epoch 56/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5699 - accuracy: 0.8209 - val_loss: 0.5652 - val_accuracy: 0.8268\n",
            "Epoch 57/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5682 - accuracy: 0.8216 - val_loss: 0.5637 - val_accuracy: 0.8218\n",
            "Epoch 58/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5666 - accuracy: 0.8222 - val_loss: 0.5617 - val_accuracy: 0.8261\n",
            "Epoch 59/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5649 - accuracy: 0.8229 - val_loss: 0.5601 - val_accuracy: 0.8272\n",
            "Epoch 60/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5633 - accuracy: 0.8238 - val_loss: 0.5586 - val_accuracy: 0.8285\n",
            "Epoch 61/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5618 - accuracy: 0.8241 - val_loss: 0.5571 - val_accuracy: 0.8303\n",
            "Epoch 62/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5603 - accuracy: 0.8248 - val_loss: 0.5556 - val_accuracy: 0.8287\n",
            "Epoch 63/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5588 - accuracy: 0.8253 - val_loss: 0.5541 - val_accuracy: 0.8316\n",
            "Epoch 64/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5574 - accuracy: 0.8257 - val_loss: 0.5528 - val_accuracy: 0.8279\n",
            "Epoch 65/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5560 - accuracy: 0.8261 - val_loss: 0.5519 - val_accuracy: 0.8354\n",
            "Epoch 66/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5547 - accuracy: 0.8272 - val_loss: 0.5500 - val_accuracy: 0.8316\n",
            "Epoch 67/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5533 - accuracy: 0.8278 - val_loss: 0.5490 - val_accuracy: 0.8281\n",
            "Epoch 68/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5521 - accuracy: 0.8277 - val_loss: 0.5478 - val_accuracy: 0.8366\n",
            "Epoch 69/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5508 - accuracy: 0.8288 - val_loss: 0.5460 - val_accuracy: 0.8323\n",
            "Epoch 70/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5495 - accuracy: 0.8291 - val_loss: 0.5447 - val_accuracy: 0.8344\n",
            "Epoch 71/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5483 - accuracy: 0.8292 - val_loss: 0.5435 - val_accuracy: 0.8357\n",
            "Epoch 72/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5470 - accuracy: 0.8296 - val_loss: 0.5422 - val_accuracy: 0.8338\n",
            "Epoch 73/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5459 - accuracy: 0.8301 - val_loss: 0.5411 - val_accuracy: 0.8353\n",
            "Epoch 74/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5448 - accuracy: 0.8309 - val_loss: 0.5401 - val_accuracy: 0.8371\n",
            "Epoch 75/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5436 - accuracy: 0.8313 - val_loss: 0.5388 - val_accuracy: 0.8350\n",
            "Epoch 76/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5425 - accuracy: 0.8317 - val_loss: 0.5379 - val_accuracy: 0.8380\n",
            "Epoch 77/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5414 - accuracy: 0.8321 - val_loss: 0.5365 - val_accuracy: 0.8361\n",
            "Epoch 78/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5403 - accuracy: 0.8324 - val_loss: 0.5355 - val_accuracy: 0.8375\n",
            "Epoch 79/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5393 - accuracy: 0.8325 - val_loss: 0.5345 - val_accuracy: 0.8386\n",
            "Epoch 80/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5382 - accuracy: 0.8329 - val_loss: 0.5335 - val_accuracy: 0.8391\n",
            "Epoch 81/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5372 - accuracy: 0.8333 - val_loss: 0.5324 - val_accuracy: 0.8397\n",
            "Epoch 82/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5362 - accuracy: 0.8334 - val_loss: 0.5318 - val_accuracy: 0.8414\n",
            "Epoch 83/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5352 - accuracy: 0.8341 - val_loss: 0.5308 - val_accuracy: 0.8355\n",
            "Epoch 84/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.8342 - val_loss: 0.5295 - val_accuracy: 0.8405\n",
            "Epoch 85/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5333 - accuracy: 0.8344 - val_loss: 0.5285 - val_accuracy: 0.8393\n",
            "Epoch 86/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5324 - accuracy: 0.8351 - val_loss: 0.5280 - val_accuracy: 0.8421\n",
            "Epoch 87/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5314 - accuracy: 0.8356 - val_loss: 0.5273 - val_accuracy: 0.8353\n",
            "Epoch 88/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5306 - accuracy: 0.8358 - val_loss: 0.5258 - val_accuracy: 0.8396\n",
            "Epoch 89/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5296 - accuracy: 0.8362 - val_loss: 0.5251 - val_accuracy: 0.8421\n",
            "Epoch 90/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5287 - accuracy: 0.8364 - val_loss: 0.5241 - val_accuracy: 0.8395\n",
            "Epoch 91/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5279 - accuracy: 0.8366 - val_loss: 0.5234 - val_accuracy: 0.8382\n",
            "Epoch 92/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5270 - accuracy: 0.8367 - val_loss: 0.5223 - val_accuracy: 0.8401\n",
            "Epoch 93/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5262 - accuracy: 0.8372 - val_loss: 0.5217 - val_accuracy: 0.8392\n",
            "Epoch 94/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5253 - accuracy: 0.8372 - val_loss: 0.5207 - val_accuracy: 0.8405\n",
            "Epoch 95/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5245 - accuracy: 0.8373 - val_loss: 0.5198 - val_accuracy: 0.8431\n",
            "Epoch 96/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5237 - accuracy: 0.8378 - val_loss: 0.5191 - val_accuracy: 0.8408\n",
            "Epoch 97/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5229 - accuracy: 0.8380 - val_loss: 0.5183 - val_accuracy: 0.8444\n",
            "Epoch 98/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5221 - accuracy: 0.8383 - val_loss: 0.5182 - val_accuracy: 0.8449\n",
            "Epoch 99/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5214 - accuracy: 0.8387 - val_loss: 0.5166 - val_accuracy: 0.8435\n",
            "Epoch 100/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5206 - accuracy: 0.8390 - val_loss: 0.5159 - val_accuracy: 0.8428\n",
            "Epoch 101/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5199 - accuracy: 0.8390 - val_loss: 0.5153 - val_accuracy: 0.8445\n",
            "Epoch 102/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5191 - accuracy: 0.8390 - val_loss: 0.5148 - val_accuracy: 0.8453\n",
            "Epoch 103/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5184 - accuracy: 0.8397 - val_loss: 0.5138 - val_accuracy: 0.8443\n",
            "Epoch 104/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5177 - accuracy: 0.8398 - val_loss: 0.5131 - val_accuracy: 0.8418\n",
            "Epoch 105/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5170 - accuracy: 0.8403 - val_loss: 0.5125 - val_accuracy: 0.8414\n",
            "Epoch 106/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5163 - accuracy: 0.8401 - val_loss: 0.5116 - val_accuracy: 0.8442\n",
            "Epoch 107/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5155 - accuracy: 0.8407 - val_loss: 0.5112 - val_accuracy: 0.8418\n",
            "Epoch 108/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5149 - accuracy: 0.8404 - val_loss: 0.5103 - val_accuracy: 0.8425\n",
            "Epoch 109/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5142 - accuracy: 0.8403 - val_loss: 0.5096 - val_accuracy: 0.8439\n",
            "Epoch 110/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5135 - accuracy: 0.8407 - val_loss: 0.5090 - val_accuracy: 0.8455\n",
            "Epoch 111/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5128 - accuracy: 0.8411 - val_loss: 0.5084 - val_accuracy: 0.8442\n",
            "Epoch 112/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5122 - accuracy: 0.8410 - val_loss: 0.5075 - val_accuracy: 0.8470\n",
            "Epoch 113/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5116 - accuracy: 0.8418 - val_loss: 0.5069 - val_accuracy: 0.8468\n",
            "Epoch 114/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5109 - accuracy: 0.8417 - val_loss: 0.5064 - val_accuracy: 0.8478\n",
            "Epoch 115/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5103 - accuracy: 0.8415 - val_loss: 0.5058 - val_accuracy: 0.8477\n",
            "Epoch 116/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5096 - accuracy: 0.8420 - val_loss: 0.5050 - val_accuracy: 0.8479\n",
            "Epoch 117/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5090 - accuracy: 0.8424 - val_loss: 0.5044 - val_accuracy: 0.8480\n",
            "Epoch 118/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5084 - accuracy: 0.8422 - val_loss: 0.5039 - val_accuracy: 0.8471\n",
            "Epoch 119/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5078 - accuracy: 0.8421 - val_loss: 0.5033 - val_accuracy: 0.8468\n",
            "Epoch 120/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5072 - accuracy: 0.8429 - val_loss: 0.5026 - val_accuracy: 0.8479\n",
            "Epoch 121/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5065 - accuracy: 0.8427 - val_loss: 0.5020 - val_accuracy: 0.8481\n",
            "Epoch 122/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5060 - accuracy: 0.8425 - val_loss: 0.5015 - val_accuracy: 0.8479\n",
            "Epoch 123/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5054 - accuracy: 0.8424 - val_loss: 0.5009 - val_accuracy: 0.8485\n",
            "Epoch 124/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5048 - accuracy: 0.8431 - val_loss: 0.5004 - val_accuracy: 0.8481\n",
            "Epoch 125/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5042 - accuracy: 0.8433 - val_loss: 0.4998 - val_accuracy: 0.8494\n",
            "Epoch 126/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5037 - accuracy: 0.8436 - val_loss: 0.4993 - val_accuracy: 0.8486\n",
            "Epoch 127/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5031 - accuracy: 0.8435 - val_loss: 0.4987 - val_accuracy: 0.8475\n",
            "Epoch 128/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5025 - accuracy: 0.8436 - val_loss: 0.4988 - val_accuracy: 0.8439\n",
            "Epoch 129/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5020 - accuracy: 0.8436 - val_loss: 0.4976 - val_accuracy: 0.8493\n",
            "Epoch 130/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5015 - accuracy: 0.8440 - val_loss: 0.4971 - val_accuracy: 0.8494\n",
            "Epoch 131/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5009 - accuracy: 0.8442 - val_loss: 0.4965 - val_accuracy: 0.8493\n",
            "Epoch 132/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5004 - accuracy: 0.8444 - val_loss: 0.4959 - val_accuracy: 0.8502\n",
            "Epoch 133/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4998 - accuracy: 0.8446 - val_loss: 0.4954 - val_accuracy: 0.8499\n",
            "Epoch 134/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4993 - accuracy: 0.8444 - val_loss: 0.4949 - val_accuracy: 0.8496\n",
            "Epoch 135/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4988 - accuracy: 0.8450 - val_loss: 0.4945 - val_accuracy: 0.8511\n",
            "Epoch 136/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4983 - accuracy: 0.8448 - val_loss: 0.4940 - val_accuracy: 0.8475\n",
            "Epoch 137/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4978 - accuracy: 0.8450 - val_loss: 0.4933 - val_accuracy: 0.8500\n",
            "Epoch 138/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4972 - accuracy: 0.8452 - val_loss: 0.4928 - val_accuracy: 0.8498\n",
            "Epoch 139/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4967 - accuracy: 0.8455 - val_loss: 0.4924 - val_accuracy: 0.8507\n",
            "Epoch 140/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4963 - accuracy: 0.8452 - val_loss: 0.4921 - val_accuracy: 0.8490\n",
            "Epoch 141/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4957 - accuracy: 0.8453 - val_loss: 0.4914 - val_accuracy: 0.8504\n",
            "Epoch 142/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4953 - accuracy: 0.8458 - val_loss: 0.4911 - val_accuracy: 0.8516\n",
            "Epoch 143/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.8456 - val_loss: 0.4905 - val_accuracy: 0.8501\n",
            "Epoch 144/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4942 - accuracy: 0.8454 - val_loss: 0.4900 - val_accuracy: 0.8512\n",
            "Epoch 145/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4937 - accuracy: 0.8461 - val_loss: 0.4895 - val_accuracy: 0.8508\n",
            "Epoch 146/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4933 - accuracy: 0.8464 - val_loss: 0.4890 - val_accuracy: 0.8509\n",
            "Epoch 147/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4929 - accuracy: 0.8458 - val_loss: 0.4889 - val_accuracy: 0.8526\n",
            "Epoch 148/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4924 - accuracy: 0.8465 - val_loss: 0.4882 - val_accuracy: 0.8520\n",
            "Epoch 149/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4919 - accuracy: 0.8466 - val_loss: 0.4876 - val_accuracy: 0.8521\n",
            "Epoch 150/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4914 - accuracy: 0.8470 - val_loss: 0.4873 - val_accuracy: 0.8493\n",
            "Epoch 151/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4910 - accuracy: 0.8464 - val_loss: 0.4867 - val_accuracy: 0.8522\n",
            "Epoch 152/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4905 - accuracy: 0.8469 - val_loss: 0.4862 - val_accuracy: 0.8520\n",
            "Epoch 153/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4901 - accuracy: 0.8466 - val_loss: 0.4866 - val_accuracy: 0.8471\n",
            "Epoch 154/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4896 - accuracy: 0.8472 - val_loss: 0.4855 - val_accuracy: 0.8511\n",
            "Epoch 155/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4892 - accuracy: 0.8473 - val_loss: 0.4850 - val_accuracy: 0.8529\n",
            "Epoch 156/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4887 - accuracy: 0.8476 - val_loss: 0.4847 - val_accuracy: 0.8511\n",
            "Epoch 157/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4883 - accuracy: 0.8473 - val_loss: 0.4844 - val_accuracy: 0.8503\n",
            "Epoch 158/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4878 - accuracy: 0.8479 - val_loss: 0.4838 - val_accuracy: 0.8529\n",
            "Epoch 159/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4874 - accuracy: 0.8476 - val_loss: 0.4832 - val_accuracy: 0.8529\n",
            "Epoch 160/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4870 - accuracy: 0.8476 - val_loss: 0.4829 - val_accuracy: 0.8520\n",
            "Epoch 161/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4865 - accuracy: 0.8476 - val_loss: 0.4823 - val_accuracy: 0.8529\n",
            "Epoch 162/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4861 - accuracy: 0.8481 - val_loss: 0.4822 - val_accuracy: 0.8523\n",
            "Epoch 163/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4857 - accuracy: 0.8480 - val_loss: 0.4815 - val_accuracy: 0.8527\n",
            "Epoch 164/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4853 - accuracy: 0.8485 - val_loss: 0.4811 - val_accuracy: 0.8521\n",
            "Epoch 165/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4849 - accuracy: 0.8482 - val_loss: 0.4809 - val_accuracy: 0.8531\n",
            "Epoch 166/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4845 - accuracy: 0.8485 - val_loss: 0.4803 - val_accuracy: 0.8534\n",
            "Epoch 167/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4841 - accuracy: 0.8486 - val_loss: 0.4800 - val_accuracy: 0.8535\n",
            "Epoch 168/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4836 - accuracy: 0.8487 - val_loss: 0.4800 - val_accuracy: 0.8541\n",
            "Epoch 169/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4833 - accuracy: 0.8483 - val_loss: 0.4791 - val_accuracy: 0.8539\n",
            "Epoch 170/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4828 - accuracy: 0.8491 - val_loss: 0.4787 - val_accuracy: 0.8529\n",
            "Epoch 171/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4825 - accuracy: 0.8487 - val_loss: 0.4784 - val_accuracy: 0.8522\n",
            "Epoch 172/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4820 - accuracy: 0.8490 - val_loss: 0.4780 - val_accuracy: 0.8525\n",
            "Epoch 173/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4817 - accuracy: 0.8491 - val_loss: 0.4776 - val_accuracy: 0.8546\n",
            "Epoch 174/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4813 - accuracy: 0.8489 - val_loss: 0.4774 - val_accuracy: 0.8517\n",
            "Epoch 175/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4809 - accuracy: 0.8492 - val_loss: 0.4768 - val_accuracy: 0.8545\n",
            "Epoch 176/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4805 - accuracy: 0.8495 - val_loss: 0.4767 - val_accuracy: 0.8518\n",
            "Epoch 177/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4800 - accuracy: 0.8497 - val_loss: 0.4761 - val_accuracy: 0.8550\n",
            "Epoch 178/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4797 - accuracy: 0.8496 - val_loss: 0.4758 - val_accuracy: 0.8543\n",
            "Epoch 179/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4793 - accuracy: 0.8498 - val_loss: 0.4753 - val_accuracy: 0.8534\n",
            "Epoch 180/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4790 - accuracy: 0.8500 - val_loss: 0.4752 - val_accuracy: 0.8536\n",
            "Epoch 181/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4785 - accuracy: 0.8501 - val_loss: 0.4747 - val_accuracy: 0.8529\n",
            "Epoch 182/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4781 - accuracy: 0.8499 - val_loss: 0.4744 - val_accuracy: 0.8551\n",
            "Epoch 183/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4778 - accuracy: 0.8500 - val_loss: 0.4738 - val_accuracy: 0.8540\n",
            "Epoch 184/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4774 - accuracy: 0.8497 - val_loss: 0.4734 - val_accuracy: 0.8545\n",
            "Epoch 185/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4771 - accuracy: 0.8509 - val_loss: 0.4731 - val_accuracy: 0.8540\n",
            "Epoch 186/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4767 - accuracy: 0.8507 - val_loss: 0.4728 - val_accuracy: 0.8550\n",
            "Epoch 187/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4763 - accuracy: 0.8505 - val_loss: 0.4726 - val_accuracy: 0.8551\n",
            "Epoch 188/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4760 - accuracy: 0.8507 - val_loss: 0.4722 - val_accuracy: 0.8554\n",
            "Epoch 189/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4757 - accuracy: 0.8506 - val_loss: 0.4718 - val_accuracy: 0.8539\n",
            "Epoch 190/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4753 - accuracy: 0.8505 - val_loss: 0.4716 - val_accuracy: 0.8550\n",
            "Epoch 191/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4749 - accuracy: 0.8510 - val_loss: 0.4712 - val_accuracy: 0.8540\n",
            "Epoch 192/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4746 - accuracy: 0.8506 - val_loss: 0.4708 - val_accuracy: 0.8554\n",
            "Epoch 193/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4742 - accuracy: 0.8507 - val_loss: 0.4703 - val_accuracy: 0.8553\n",
            "Epoch 194/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4738 - accuracy: 0.8511 - val_loss: 0.4701 - val_accuracy: 0.8562\n",
            "Epoch 195/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4736 - accuracy: 0.8511 - val_loss: 0.4698 - val_accuracy: 0.8547\n",
            "Epoch 196/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4732 - accuracy: 0.8516 - val_loss: 0.4694 - val_accuracy: 0.8558\n",
            "Epoch 197/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4728 - accuracy: 0.8516 - val_loss: 0.4691 - val_accuracy: 0.8563\n",
            "Epoch 198/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4725 - accuracy: 0.8517 - val_loss: 0.4688 - val_accuracy: 0.8541\n",
            "Epoch 199/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4721 - accuracy: 0.8519 - val_loss: 0.4683 - val_accuracy: 0.8556\n",
            "Epoch 200/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4719 - accuracy: 0.8514 - val_loss: 0.4681 - val_accuracy: 0.8543\n",
            "Epoch 201/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4715 - accuracy: 0.8517 - val_loss: 0.4680 - val_accuracy: 0.8536\n",
            "Epoch 202/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4712 - accuracy: 0.8518 - val_loss: 0.4674 - val_accuracy: 0.8551\n",
            "Epoch 203/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4708 - accuracy: 0.8517 - val_loss: 0.4670 - val_accuracy: 0.8558\n",
            "Epoch 204/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4705 - accuracy: 0.8520 - val_loss: 0.4667 - val_accuracy: 0.8565\n",
            "Epoch 205/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4701 - accuracy: 0.8523 - val_loss: 0.4664 - val_accuracy: 0.8565\n",
            "Epoch 206/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4698 - accuracy: 0.8522 - val_loss: 0.4660 - val_accuracy: 0.8561\n",
            "Epoch 207/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4695 - accuracy: 0.8521 - val_loss: 0.4659 - val_accuracy: 0.8576\n",
            "Epoch 208/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4691 - accuracy: 0.8524 - val_loss: 0.4658 - val_accuracy: 0.8540\n",
            "Epoch 209/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4688 - accuracy: 0.8524 - val_loss: 0.4651 - val_accuracy: 0.8564\n",
            "Epoch 210/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4685 - accuracy: 0.8524 - val_loss: 0.4648 - val_accuracy: 0.8550\n",
            "Epoch 211/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4682 - accuracy: 0.8525 - val_loss: 0.4644 - val_accuracy: 0.8557\n",
            "Epoch 212/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4679 - accuracy: 0.8529 - val_loss: 0.4643 - val_accuracy: 0.8581\n",
            "Epoch 213/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4675 - accuracy: 0.8529 - val_loss: 0.4639 - val_accuracy: 0.8554\n",
            "Epoch 214/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4671 - accuracy: 0.8526 - val_loss: 0.4638 - val_accuracy: 0.8545\n",
            "Epoch 215/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4669 - accuracy: 0.8531 - val_loss: 0.4632 - val_accuracy: 0.8568\n",
            "Epoch 216/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4666 - accuracy: 0.8530 - val_loss: 0.4629 - val_accuracy: 0.8557\n",
            "Epoch 217/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4663 - accuracy: 0.8530 - val_loss: 0.4626 - val_accuracy: 0.8555\n",
            "Epoch 218/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4659 - accuracy: 0.8533 - val_loss: 0.4625 - val_accuracy: 0.8569\n",
            "Epoch 219/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4656 - accuracy: 0.8532 - val_loss: 0.4619 - val_accuracy: 0.8575\n",
            "Epoch 220/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4653 - accuracy: 0.8532 - val_loss: 0.4616 - val_accuracy: 0.8561\n",
            "Epoch 221/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4650 - accuracy: 0.8535 - val_loss: 0.4614 - val_accuracy: 0.8555\n",
            "Epoch 222/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4647 - accuracy: 0.8535 - val_loss: 0.4610 - val_accuracy: 0.8565\n",
            "Epoch 223/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4644 - accuracy: 0.8533 - val_loss: 0.4607 - val_accuracy: 0.8573\n",
            "Epoch 224/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4641 - accuracy: 0.8539 - val_loss: 0.4606 - val_accuracy: 0.8565\n",
            "Epoch 225/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4637 - accuracy: 0.8536 - val_loss: 0.4601 - val_accuracy: 0.8573\n",
            "Epoch 226/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4634 - accuracy: 0.8540 - val_loss: 0.4599 - val_accuracy: 0.8586\n",
            "Epoch 227/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4631 - accuracy: 0.8542 - val_loss: 0.4596 - val_accuracy: 0.8558\n",
            "Epoch 228/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4628 - accuracy: 0.8539 - val_loss: 0.4592 - val_accuracy: 0.8582\n",
            "Epoch 229/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4625 - accuracy: 0.8541 - val_loss: 0.4590 - val_accuracy: 0.8583\n",
            "Epoch 230/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4622 - accuracy: 0.8541 - val_loss: 0.4587 - val_accuracy: 0.8558\n",
            "Epoch 231/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4619 - accuracy: 0.8542 - val_loss: 0.4584 - val_accuracy: 0.8566\n",
            "Epoch 232/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4616 - accuracy: 0.8540 - val_loss: 0.4582 - val_accuracy: 0.8589\n",
            "Epoch 233/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4613 - accuracy: 0.8544 - val_loss: 0.4579 - val_accuracy: 0.8565\n",
            "Epoch 234/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4610 - accuracy: 0.8544 - val_loss: 0.4576 - val_accuracy: 0.8568\n",
            "Epoch 235/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4608 - accuracy: 0.8544 - val_loss: 0.4573 - val_accuracy: 0.8568\n",
            "Epoch 236/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4605 - accuracy: 0.8542 - val_loss: 0.4571 - val_accuracy: 0.8592\n",
            "Epoch 237/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4602 - accuracy: 0.8544 - val_loss: 0.4566 - val_accuracy: 0.8574\n",
            "Epoch 238/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4599 - accuracy: 0.8544 - val_loss: 0.4563 - val_accuracy: 0.8580\n",
            "Epoch 239/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4596 - accuracy: 0.8547 - val_loss: 0.4561 - val_accuracy: 0.8580\n",
            "Epoch 240/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4593 - accuracy: 0.8547 - val_loss: 0.4559 - val_accuracy: 0.8594\n",
            "Epoch 241/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4591 - accuracy: 0.8548 - val_loss: 0.4558 - val_accuracy: 0.8604\n",
            "Epoch 242/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4587 - accuracy: 0.8548 - val_loss: 0.4553 - val_accuracy: 0.8583\n",
            "Epoch 243/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4585 - accuracy: 0.8548 - val_loss: 0.4550 - val_accuracy: 0.8579\n",
            "Epoch 244/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4582 - accuracy: 0.8549 - val_loss: 0.4547 - val_accuracy: 0.8575\n",
            "Epoch 245/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4579 - accuracy: 0.8550 - val_loss: 0.4545 - val_accuracy: 0.8591\n",
            "Epoch 246/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4577 - accuracy: 0.8550 - val_loss: 0.4541 - val_accuracy: 0.8582\n",
            "Epoch 247/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4574 - accuracy: 0.8554 - val_loss: 0.4541 - val_accuracy: 0.8597\n",
            "Epoch 248/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4571 - accuracy: 0.8554 - val_loss: 0.4538 - val_accuracy: 0.8572\n",
            "Epoch 249/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4568 - accuracy: 0.8550 - val_loss: 0.4533 - val_accuracy: 0.8589\n",
            "Epoch 250/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4565 - accuracy: 0.8559 - val_loss: 0.4535 - val_accuracy: 0.8565\n",
            "Epoch 251/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4562 - accuracy: 0.8550 - val_loss: 0.4528 - val_accuracy: 0.8591\n",
            "Epoch 252/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4560 - accuracy: 0.8557 - val_loss: 0.4529 - val_accuracy: 0.8612\n",
            "Epoch 253/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4557 - accuracy: 0.8559 - val_loss: 0.4523 - val_accuracy: 0.8586\n",
            "Epoch 254/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.8551 - val_loss: 0.4521 - val_accuracy: 0.8577\n",
            "Epoch 255/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4552 - accuracy: 0.8553 - val_loss: 0.4518 - val_accuracy: 0.8591\n",
            "Epoch 256/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4549 - accuracy: 0.8555 - val_loss: 0.4519 - val_accuracy: 0.8612\n",
            "Epoch 257/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4547 - accuracy: 0.8556 - val_loss: 0.4512 - val_accuracy: 0.8595\n",
            "Epoch 258/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4543 - accuracy: 0.8555 - val_loss: 0.4510 - val_accuracy: 0.8592\n",
            "Epoch 259/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4541 - accuracy: 0.8559 - val_loss: 0.4510 - val_accuracy: 0.8569\n",
            "Epoch 260/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4538 - accuracy: 0.8557 - val_loss: 0.4505 - val_accuracy: 0.8606\n",
            "Epoch 261/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4536 - accuracy: 0.8558 - val_loss: 0.4502 - val_accuracy: 0.8592\n",
            "Epoch 262/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.8563 - val_loss: 0.4504 - val_accuracy: 0.8618\n",
            "Epoch 263/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.8559 - val_loss: 0.4497 - val_accuracy: 0.8605\n",
            "Epoch 264/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4527 - accuracy: 0.8561 - val_loss: 0.4498 - val_accuracy: 0.8575\n",
            "Epoch 265/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4525 - accuracy: 0.8558 - val_loss: 0.4494 - val_accuracy: 0.8590\n",
            "Epoch 266/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4522 - accuracy: 0.8563 - val_loss: 0.4489 - val_accuracy: 0.8594\n",
            "Epoch 267/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4520 - accuracy: 0.8563 - val_loss: 0.4487 - val_accuracy: 0.8594\n",
            "Epoch 268/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4517 - accuracy: 0.8563 - val_loss: 0.4485 - val_accuracy: 0.8594\n",
            "Epoch 269/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.8564 - val_loss: 0.4485 - val_accuracy: 0.8583\n",
            "Epoch 270/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.8565 - val_loss: 0.4491 - val_accuracy: 0.8544\n",
            "Epoch 271/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4509 - accuracy: 0.8559 - val_loss: 0.4477 - val_accuracy: 0.8597\n",
            "Epoch 272/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4507 - accuracy: 0.8567 - val_loss: 0.4474 - val_accuracy: 0.8604\n",
            "Epoch 273/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.8565 - val_loss: 0.4472 - val_accuracy: 0.8609\n",
            "Epoch 274/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4502 - accuracy: 0.8562 - val_loss: 0.4469 - val_accuracy: 0.8598\n",
            "Epoch 275/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4499 - accuracy: 0.8565 - val_loss: 0.4467 - val_accuracy: 0.8596\n",
            "Epoch 276/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.8568 - val_loss: 0.4464 - val_accuracy: 0.8594\n",
            "Epoch 277/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4495 - accuracy: 0.8566 - val_loss: 0.4462 - val_accuracy: 0.8598\n",
            "Epoch 278/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4492 - accuracy: 0.8566 - val_loss: 0.4461 - val_accuracy: 0.8590\n",
            "Epoch 279/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4489 - accuracy: 0.8568 - val_loss: 0.4459 - val_accuracy: 0.8597\n",
            "Epoch 280/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4486 - accuracy: 0.8567 - val_loss: 0.4456 - val_accuracy: 0.8590\n",
            "Epoch 281/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4484 - accuracy: 0.8567 - val_loss: 0.4453 - val_accuracy: 0.8601\n",
            "Epoch 282/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4481 - accuracy: 0.8568 - val_loss: 0.4451 - val_accuracy: 0.8590\n",
            "Epoch 283/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4479 - accuracy: 0.8570 - val_loss: 0.4448 - val_accuracy: 0.8600\n",
            "Epoch 284/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4476 - accuracy: 0.8569 - val_loss: 0.4448 - val_accuracy: 0.8584\n",
            "Epoch 285/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4473 - accuracy: 0.8571 - val_loss: 0.4446 - val_accuracy: 0.8625\n",
            "Epoch 286/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4472 - accuracy: 0.8570 - val_loss: 0.4448 - val_accuracy: 0.8565\n",
            "Epoch 287/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4469 - accuracy: 0.8573 - val_loss: 0.4444 - val_accuracy: 0.8575\n",
            "Epoch 288/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4467 - accuracy: 0.8570 - val_loss: 0.4436 - val_accuracy: 0.8598\n",
            "Epoch 289/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4465 - accuracy: 0.8574 - val_loss: 0.4433 - val_accuracy: 0.8609\n",
            "Epoch 290/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4462 - accuracy: 0.8575 - val_loss: 0.4431 - val_accuracy: 0.8612\n",
            "Epoch 291/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4460 - accuracy: 0.8571 - val_loss: 0.4428 - val_accuracy: 0.8609\n",
            "Epoch 292/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4457 - accuracy: 0.8572 - val_loss: 0.4429 - val_accuracy: 0.8595\n",
            "Epoch 293/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4455 - accuracy: 0.8574 - val_loss: 0.4424 - val_accuracy: 0.8622\n",
            "Epoch 294/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4453 - accuracy: 0.8574 - val_loss: 0.4422 - val_accuracy: 0.8618\n",
            "Epoch 295/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4450 - accuracy: 0.8574 - val_loss: 0.4420 - val_accuracy: 0.8622\n",
            "Epoch 296/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4447 - accuracy: 0.8572 - val_loss: 0.4416 - val_accuracy: 0.8615\n",
            "Epoch 297/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4445 - accuracy: 0.8578 - val_loss: 0.4414 - val_accuracy: 0.8609\n",
            "Epoch 298/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4443 - accuracy: 0.8573 - val_loss: 0.4414 - val_accuracy: 0.8615\n",
            "Epoch 299/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4440 - accuracy: 0.8576 - val_loss: 0.4410 - val_accuracy: 0.8611\n",
            "Epoch 300/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4438 - accuracy: 0.8574 - val_loss: 0.4408 - val_accuracy: 0.8608\n",
            "Epoch 301/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4436 - accuracy: 0.8581 - val_loss: 0.4409 - val_accuracy: 0.8592\n",
            "Epoch 302/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4434 - accuracy: 0.8581 - val_loss: 0.4403 - val_accuracy: 0.8618\n",
            "Epoch 303/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4431 - accuracy: 0.8582 - val_loss: 0.4402 - val_accuracy: 0.8608\n",
            "Epoch 304/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4429 - accuracy: 0.8580 - val_loss: 0.4399 - val_accuracy: 0.8613\n",
            "Epoch 305/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4426 - accuracy: 0.8582 - val_loss: 0.4396 - val_accuracy: 0.8617\n",
            "Epoch 306/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4423 - accuracy: 0.8581 - val_loss: 0.4396 - val_accuracy: 0.8593\n",
            "Epoch 307/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4422 - accuracy: 0.8580 - val_loss: 0.4392 - val_accuracy: 0.8626\n",
            "Epoch 308/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4420 - accuracy: 0.8583 - val_loss: 0.4390 - val_accuracy: 0.8615\n",
            "Epoch 309/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4417 - accuracy: 0.8586 - val_loss: 0.4388 - val_accuracy: 0.8616\n",
            "Epoch 310/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4415 - accuracy: 0.8585 - val_loss: 0.4385 - val_accuracy: 0.8619\n",
            "Epoch 311/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4413 - accuracy: 0.8586 - val_loss: 0.4387 - val_accuracy: 0.8643\n",
            "Epoch 312/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4411 - accuracy: 0.8583 - val_loss: 0.4381 - val_accuracy: 0.8630\n",
            "Epoch 313/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4408 - accuracy: 0.8587 - val_loss: 0.4378 - val_accuracy: 0.8619\n",
            "Epoch 314/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4406 - accuracy: 0.8589 - val_loss: 0.4378 - val_accuracy: 0.8608\n",
            "Epoch 315/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4404 - accuracy: 0.8584 - val_loss: 0.4374 - val_accuracy: 0.8617\n",
            "Epoch 316/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4402 - accuracy: 0.8586 - val_loss: 0.4376 - val_accuracy: 0.8586\n",
            "Epoch 317/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4399 - accuracy: 0.8585 - val_loss: 0.4370 - val_accuracy: 0.8622\n",
            "Epoch 318/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4397 - accuracy: 0.8584 - val_loss: 0.4368 - val_accuracy: 0.8620\n",
            "Epoch 319/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4395 - accuracy: 0.8589 - val_loss: 0.4366 - val_accuracy: 0.8619\n",
            "Epoch 320/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4392 - accuracy: 0.8587 - val_loss: 0.4366 - val_accuracy: 0.8626\n",
            "Epoch 321/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4390 - accuracy: 0.8589 - val_loss: 0.4361 - val_accuracy: 0.8625\n",
            "Epoch 322/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4388 - accuracy: 0.8590 - val_loss: 0.4360 - val_accuracy: 0.8616\n",
            "Epoch 323/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4386 - accuracy: 0.8586 - val_loss: 0.4359 - val_accuracy: 0.8622\n",
            "Epoch 324/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4384 - accuracy: 0.8590 - val_loss: 0.4355 - val_accuracy: 0.8625\n",
            "Epoch 325/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4381 - accuracy: 0.8591 - val_loss: 0.4353 - val_accuracy: 0.8625\n",
            "Epoch 326/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4379 - accuracy: 0.8588 - val_loss: 0.4353 - val_accuracy: 0.8605\n",
            "Epoch 327/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4378 - accuracy: 0.8591 - val_loss: 0.4350 - val_accuracy: 0.8605\n",
            "Epoch 328/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4375 - accuracy: 0.8596 - val_loss: 0.4348 - val_accuracy: 0.8612\n",
            "Epoch 329/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4373 - accuracy: 0.8593 - val_loss: 0.4346 - val_accuracy: 0.8634\n",
            "Epoch 330/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4371 - accuracy: 0.8595 - val_loss: 0.4342 - val_accuracy: 0.8620\n",
            "Epoch 331/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4369 - accuracy: 0.8592 - val_loss: 0.4340 - val_accuracy: 0.8619\n",
            "Epoch 332/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4367 - accuracy: 0.8594 - val_loss: 0.4338 - val_accuracy: 0.8626\n",
            "Epoch 333/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4364 - accuracy: 0.8600 - val_loss: 0.4338 - val_accuracy: 0.8609\n",
            "Epoch 334/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4362 - accuracy: 0.8594 - val_loss: 0.4338 - val_accuracy: 0.8594\n",
            "Epoch 335/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4360 - accuracy: 0.8599 - val_loss: 0.4342 - val_accuracy: 0.8573\n",
            "Epoch 336/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4358 - accuracy: 0.8597 - val_loss: 0.4330 - val_accuracy: 0.8625\n",
            "Epoch 337/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4356 - accuracy: 0.8597 - val_loss: 0.4328 - val_accuracy: 0.8633\n",
            "Epoch 338/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4354 - accuracy: 0.8594 - val_loss: 0.4326 - val_accuracy: 0.8625\n",
            "Epoch 339/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4352 - accuracy: 0.8596 - val_loss: 0.4324 - val_accuracy: 0.8637\n",
            "Epoch 340/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4349 - accuracy: 0.8599 - val_loss: 0.4332 - val_accuracy: 0.8572\n",
            "Epoch 341/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4348 - accuracy: 0.8594 - val_loss: 0.4320 - val_accuracy: 0.8619\n",
            "Epoch 342/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4345 - accuracy: 0.8597 - val_loss: 0.4320 - val_accuracy: 0.8620\n",
            "Epoch 343/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4343 - accuracy: 0.8600 - val_loss: 0.4317 - val_accuracy: 0.8618\n",
            "Epoch 344/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4341 - accuracy: 0.8598 - val_loss: 0.4314 - val_accuracy: 0.8632\n",
            "Epoch 345/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4339 - accuracy: 0.8599 - val_loss: 0.4312 - val_accuracy: 0.8637\n",
            "Epoch 346/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4337 - accuracy: 0.8603 - val_loss: 0.4315 - val_accuracy: 0.8601\n",
            "Epoch 347/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4335 - accuracy: 0.8601 - val_loss: 0.4308 - val_accuracy: 0.8629\n",
            "Epoch 348/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4333 - accuracy: 0.8599 - val_loss: 0.4305 - val_accuracy: 0.8632\n",
            "Epoch 349/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4330 - accuracy: 0.8599 - val_loss: 0.4303 - val_accuracy: 0.8631\n",
            "Epoch 350/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4328 - accuracy: 0.8595 - val_loss: 0.4306 - val_accuracy: 0.8665\n",
            "Epoch 351/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4327 - accuracy: 0.8598 - val_loss: 0.4299 - val_accuracy: 0.8634\n",
            "Epoch 352/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4324 - accuracy: 0.8601 - val_loss: 0.4298 - val_accuracy: 0.8635\n",
            "Epoch 353/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4323 - accuracy: 0.8598 - val_loss: 0.4297 - val_accuracy: 0.8623\n",
            "Epoch 354/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4321 - accuracy: 0.8602 - val_loss: 0.4294 - val_accuracy: 0.8626\n",
            "Epoch 355/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4319 - accuracy: 0.8604 - val_loss: 0.4294 - val_accuracy: 0.8609\n",
            "Epoch 356/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4316 - accuracy: 0.8601 - val_loss: 0.4291 - val_accuracy: 0.8619\n",
            "Epoch 357/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4315 - accuracy: 0.8603 - val_loss: 0.4289 - val_accuracy: 0.8627\n",
            "Epoch 358/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4312 - accuracy: 0.8602 - val_loss: 0.4287 - val_accuracy: 0.8622\n",
            "Epoch 359/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4311 - accuracy: 0.8607 - val_loss: 0.4284 - val_accuracy: 0.8637\n",
            "Epoch 360/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4309 - accuracy: 0.8605 - val_loss: 0.4283 - val_accuracy: 0.8648\n",
            "Epoch 361/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4307 - accuracy: 0.8609 - val_loss: 0.4280 - val_accuracy: 0.8632\n",
            "Epoch 362/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4305 - accuracy: 0.8611 - val_loss: 0.4279 - val_accuracy: 0.8626\n",
            "Epoch 363/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4303 - accuracy: 0.8608 - val_loss: 0.4277 - val_accuracy: 0.8648\n",
            "Epoch 364/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4299 - accuracy: 0.8610 - val_loss: 0.4277 - val_accuracy: 0.8626\n",
            "Epoch 365/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4298 - accuracy: 0.8609 - val_loss: 0.4273 - val_accuracy: 0.8628\n",
            "Epoch 366/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4297 - accuracy: 0.8611 - val_loss: 0.4271 - val_accuracy: 0.8630\n",
            "Epoch 367/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4295 - accuracy: 0.8609 - val_loss: 0.4269 - val_accuracy: 0.8634\n",
            "Epoch 368/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4292 - accuracy: 0.8611 - val_loss: 0.4275 - val_accuracy: 0.8583\n",
            "Epoch 369/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4291 - accuracy: 0.8608 - val_loss: 0.4266 - val_accuracy: 0.8626\n",
            "Epoch 370/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4288 - accuracy: 0.8612 - val_loss: 0.4265 - val_accuracy: 0.8660\n",
            "Epoch 371/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4286 - accuracy: 0.8608 - val_loss: 0.4261 - val_accuracy: 0.8629\n",
            "Epoch 372/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4285 - accuracy: 0.8607 - val_loss: 0.4260 - val_accuracy: 0.8626\n",
            "Epoch 373/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4283 - accuracy: 0.8612 - val_loss: 0.4258 - val_accuracy: 0.8651\n",
            "Epoch 374/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4281 - accuracy: 0.8612 - val_loss: 0.4256 - val_accuracy: 0.8627\n",
            "Epoch 375/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4279 - accuracy: 0.8609 - val_loss: 0.4255 - val_accuracy: 0.8619\n",
            "Epoch 376/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4277 - accuracy: 0.8610 - val_loss: 0.4252 - val_accuracy: 0.8638\n",
            "Epoch 377/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4275 - accuracy: 0.8612 - val_loss: 0.4249 - val_accuracy: 0.8641\n",
            "Epoch 378/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4273 - accuracy: 0.8609 - val_loss: 0.4249 - val_accuracy: 0.8640\n",
            "Epoch 379/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4271 - accuracy: 0.8611 - val_loss: 0.4247 - val_accuracy: 0.8641\n",
            "Epoch 380/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4269 - accuracy: 0.8615 - val_loss: 0.4244 - val_accuracy: 0.8639\n",
            "Epoch 381/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4267 - accuracy: 0.8613 - val_loss: 0.4243 - val_accuracy: 0.8630\n",
            "Epoch 382/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4265 - accuracy: 0.8614 - val_loss: 0.4240 - val_accuracy: 0.8637\n",
            "Epoch 383/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4263 - accuracy: 0.8615 - val_loss: 0.4239 - val_accuracy: 0.8630\n",
            "Epoch 384/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4262 - accuracy: 0.8614 - val_loss: 0.4237 - val_accuracy: 0.8630\n",
            "Epoch 385/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4260 - accuracy: 0.8616 - val_loss: 0.4236 - val_accuracy: 0.8658\n",
            "Epoch 386/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4257 - accuracy: 0.8611 - val_loss: 0.4233 - val_accuracy: 0.8655\n",
            "Epoch 387/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4256 - accuracy: 0.8618 - val_loss: 0.4234 - val_accuracy: 0.8615\n",
            "Epoch 388/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.4253 - accuracy: 0.8616 - val_loss: 0.4229 - val_accuracy: 0.8637\n",
            "Epoch 389/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4252 - accuracy: 0.8615 - val_loss: 0.4230 - val_accuracy: 0.8618\n",
            "Epoch 390/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4250 - accuracy: 0.8613 - val_loss: 0.4226 - val_accuracy: 0.8639\n",
            "Epoch 391/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4248 - accuracy: 0.8618 - val_loss: 0.4223 - val_accuracy: 0.8638\n",
            "Epoch 392/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4246 - accuracy: 0.8615 - val_loss: 0.4222 - val_accuracy: 0.8647\n",
            "Epoch 393/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4244 - accuracy: 0.8613 - val_loss: 0.4220 - val_accuracy: 0.8643\n",
            "Epoch 394/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4243 - accuracy: 0.8621 - val_loss: 0.4219 - val_accuracy: 0.8644\n",
            "Epoch 395/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4241 - accuracy: 0.8620 - val_loss: 0.4217 - val_accuracy: 0.8632\n",
            "Epoch 396/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4238 - accuracy: 0.8619 - val_loss: 0.4216 - val_accuracy: 0.8630\n",
            "Epoch 397/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4237 - accuracy: 0.8622 - val_loss: 0.4218 - val_accuracy: 0.8678\n",
            "Epoch 398/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4235 - accuracy: 0.8620 - val_loss: 0.4214 - val_accuracy: 0.8670\n",
            "Epoch 399/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4233 - accuracy: 0.8623 - val_loss: 0.4209 - val_accuracy: 0.8640\n",
            "Epoch 400/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4232 - accuracy: 0.8621 - val_loss: 0.4208 - val_accuracy: 0.8633\n",
            "Epoch 401/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4229 - accuracy: 0.8621 - val_loss: 0.4205 - val_accuracy: 0.8644\n",
            "Epoch 402/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4228 - accuracy: 0.8622 - val_loss: 0.4204 - val_accuracy: 0.8641\n",
            "Epoch 403/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4226 - accuracy: 0.8621 - val_loss: 0.4204 - val_accuracy: 0.8660\n",
            "Epoch 404/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4224 - accuracy: 0.8623 - val_loss: 0.4201 - val_accuracy: 0.8637\n",
            "Epoch 405/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4222 - accuracy: 0.8622 - val_loss: 0.4199 - val_accuracy: 0.8661\n",
            "Epoch 406/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4221 - accuracy: 0.8619 - val_loss: 0.4199 - val_accuracy: 0.8670\n",
            "Epoch 407/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4219 - accuracy: 0.8624 - val_loss: 0.4195 - val_accuracy: 0.8641\n",
            "Epoch 408/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4217 - accuracy: 0.8623 - val_loss: 0.4194 - val_accuracy: 0.8655\n",
            "Epoch 409/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4215 - accuracy: 0.8623 - val_loss: 0.4193 - val_accuracy: 0.8668\n",
            "Epoch 410/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4213 - accuracy: 0.8623 - val_loss: 0.4191 - val_accuracy: 0.8634\n",
            "Epoch 411/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4212 - accuracy: 0.8624 - val_loss: 0.4188 - val_accuracy: 0.8659\n",
            "Epoch 412/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4210 - accuracy: 0.8622 - val_loss: 0.4186 - val_accuracy: 0.8640\n",
            "Epoch 413/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4208 - accuracy: 0.8624 - val_loss: 0.4184 - val_accuracy: 0.8650\n",
            "Epoch 414/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4206 - accuracy: 0.8622 - val_loss: 0.4183 - val_accuracy: 0.8647\n",
            "Epoch 415/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4204 - accuracy: 0.8627 - val_loss: 0.4182 - val_accuracy: 0.8641\n",
            "Epoch 416/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4202 - accuracy: 0.8625 - val_loss: 0.4180 - val_accuracy: 0.8663\n",
            "Epoch 417/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4201 - accuracy: 0.8628 - val_loss: 0.4179 - val_accuracy: 0.8636\n",
            "Epoch 418/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4199 - accuracy: 0.8623 - val_loss: 0.4177 - val_accuracy: 0.8643\n",
            "Epoch 419/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4197 - accuracy: 0.8622 - val_loss: 0.4182 - val_accuracy: 0.8683\n",
            "Epoch 420/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4195 - accuracy: 0.8628 - val_loss: 0.4174 - val_accuracy: 0.8636\n",
            "Epoch 421/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4194 - accuracy: 0.8626 - val_loss: 0.4173 - val_accuracy: 0.8665\n",
            "Epoch 422/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4192 - accuracy: 0.8629 - val_loss: 0.4171 - val_accuracy: 0.8630\n",
            "Epoch 423/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4190 - accuracy: 0.8629 - val_loss: 0.4168 - val_accuracy: 0.8638\n",
            "Epoch 424/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4188 - accuracy: 0.8630 - val_loss: 0.4166 - val_accuracy: 0.8663\n",
            "Epoch 425/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4186 - accuracy: 0.8631 - val_loss: 0.4168 - val_accuracy: 0.8682\n",
            "Epoch 426/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4185 - accuracy: 0.8626 - val_loss: 0.4162 - val_accuracy: 0.8658\n",
            "Epoch 427/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4183 - accuracy: 0.8628 - val_loss: 0.4161 - val_accuracy: 0.8644\n",
            "Epoch 428/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4181 - accuracy: 0.8629 - val_loss: 0.4160 - val_accuracy: 0.8661\n",
            "Epoch 429/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4179 - accuracy: 0.8631 - val_loss: 0.4157 - val_accuracy: 0.8660\n",
            "Epoch 430/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4178 - accuracy: 0.8635 - val_loss: 0.4158 - val_accuracy: 0.8631\n",
            "Epoch 431/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4176 - accuracy: 0.8635 - val_loss: 0.4154 - val_accuracy: 0.8662\n",
            "Epoch 432/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4174 - accuracy: 0.8634 - val_loss: 0.4154 - val_accuracy: 0.8637\n",
            "Epoch 433/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4173 - accuracy: 0.8634 - val_loss: 0.4150 - val_accuracy: 0.8650\n",
            "Epoch 434/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4171 - accuracy: 0.8632 - val_loss: 0.4149 - val_accuracy: 0.8643\n",
            "Epoch 435/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4169 - accuracy: 0.8633 - val_loss: 0.4148 - val_accuracy: 0.8673\n",
            "Epoch 436/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4167 - accuracy: 0.8635 - val_loss: 0.4148 - val_accuracy: 0.8633\n",
            "Epoch 437/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4166 - accuracy: 0.8635 - val_loss: 0.4143 - val_accuracy: 0.8652\n",
            "Epoch 438/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4164 - accuracy: 0.8635 - val_loss: 0.4142 - val_accuracy: 0.8662\n",
            "Epoch 439/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4163 - accuracy: 0.8632 - val_loss: 0.4140 - val_accuracy: 0.8653\n",
            "Epoch 440/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4160 - accuracy: 0.8637 - val_loss: 0.4139 - val_accuracy: 0.8644\n",
            "Epoch 441/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4159 - accuracy: 0.8636 - val_loss: 0.4138 - val_accuracy: 0.8637\n",
            "Epoch 442/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4158 - accuracy: 0.8631 - val_loss: 0.4136 - val_accuracy: 0.8650\n",
            "Epoch 443/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4156 - accuracy: 0.8634 - val_loss: 0.4134 - val_accuracy: 0.8668\n",
            "Epoch 444/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4154 - accuracy: 0.8637 - val_loss: 0.4132 - val_accuracy: 0.8663\n",
            "Epoch 445/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4152 - accuracy: 0.8636 - val_loss: 0.4132 - val_accuracy: 0.8638\n",
            "Epoch 446/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4150 - accuracy: 0.8639 - val_loss: 0.4130 - val_accuracy: 0.8650\n",
            "Epoch 447/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4148 - accuracy: 0.8639 - val_loss: 0.4127 - val_accuracy: 0.8648\n",
            "Epoch 448/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4147 - accuracy: 0.8636 - val_loss: 0.4131 - val_accuracy: 0.8632\n",
            "Epoch 449/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4145 - accuracy: 0.8636 - val_loss: 0.4124 - val_accuracy: 0.8665\n",
            "Epoch 450/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4144 - accuracy: 0.8637 - val_loss: 0.4122 - val_accuracy: 0.8656\n",
            "Epoch 451/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4142 - accuracy: 0.8639 - val_loss: 0.4121 - val_accuracy: 0.8655\n",
            "Epoch 452/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4140 - accuracy: 0.8640 - val_loss: 0.4119 - val_accuracy: 0.8653\n",
            "Epoch 453/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4138 - accuracy: 0.8641 - val_loss: 0.4118 - val_accuracy: 0.8659\n",
            "Epoch 454/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4137 - accuracy: 0.8641 - val_loss: 0.4115 - val_accuracy: 0.8662\n",
            "Epoch 455/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4135 - accuracy: 0.8639 - val_loss: 0.4114 - val_accuracy: 0.8656\n",
            "Epoch 456/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4134 - accuracy: 0.8637 - val_loss: 0.4113 - val_accuracy: 0.8654\n",
            "Epoch 457/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4132 - accuracy: 0.8638 - val_loss: 0.4114 - val_accuracy: 0.8686\n",
            "Epoch 458/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4131 - accuracy: 0.8644 - val_loss: 0.4109 - val_accuracy: 0.8652\n",
            "Epoch 459/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4129 - accuracy: 0.8636 - val_loss: 0.4108 - val_accuracy: 0.8665\n",
            "Epoch 460/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4127 - accuracy: 0.8644 - val_loss: 0.4106 - val_accuracy: 0.8652\n",
            "Epoch 461/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4125 - accuracy: 0.8643 - val_loss: 0.4106 - val_accuracy: 0.8647\n",
            "Epoch 462/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4124 - accuracy: 0.8642 - val_loss: 0.4107 - val_accuracy: 0.8674\n",
            "Epoch 463/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4123 - accuracy: 0.8642 - val_loss: 0.4103 - val_accuracy: 0.8684\n",
            "Epoch 464/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4121 - accuracy: 0.8644 - val_loss: 0.4101 - val_accuracy: 0.8643\n",
            "Epoch 465/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4119 - accuracy: 0.8640 - val_loss: 0.4098 - val_accuracy: 0.8659\n",
            "Epoch 466/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4117 - accuracy: 0.8643 - val_loss: 0.4098 - val_accuracy: 0.8666\n",
            "Epoch 467/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4116 - accuracy: 0.8643 - val_loss: 0.4096 - val_accuracy: 0.8666\n",
            "Epoch 468/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4114 - accuracy: 0.8642 - val_loss: 0.4095 - val_accuracy: 0.8654\n",
            "Epoch 469/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4112 - accuracy: 0.8645 - val_loss: 0.4092 - val_accuracy: 0.8654\n",
            "Epoch 470/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4111 - accuracy: 0.8644 - val_loss: 0.4094 - val_accuracy: 0.8638\n",
            "Epoch 471/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4110 - accuracy: 0.8645 - val_loss: 0.4090 - val_accuracy: 0.8666\n",
            "Epoch 472/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4108 - accuracy: 0.8644 - val_loss: 0.4089 - val_accuracy: 0.8663\n",
            "Epoch 473/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4106 - accuracy: 0.8648 - val_loss: 0.4090 - val_accuracy: 0.8632\n",
            "Epoch 474/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4104 - accuracy: 0.8643 - val_loss: 0.4085 - val_accuracy: 0.8658\n",
            "Epoch 475/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4103 - accuracy: 0.8644 - val_loss: 0.4083 - val_accuracy: 0.8658\n",
            "Epoch 476/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4101 - accuracy: 0.8650 - val_loss: 0.4082 - val_accuracy: 0.8648\n",
            "Epoch 477/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4100 - accuracy: 0.8649 - val_loss: 0.4083 - val_accuracy: 0.8636\n",
            "Epoch 478/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4098 - accuracy: 0.8646 - val_loss: 0.4078 - val_accuracy: 0.8672\n",
            "Epoch 479/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4096 - accuracy: 0.8645 - val_loss: 0.4079 - val_accuracy: 0.8692\n",
            "Epoch 480/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4095 - accuracy: 0.8645 - val_loss: 0.4076 - val_accuracy: 0.8669\n",
            "Epoch 481/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4094 - accuracy: 0.8646 - val_loss: 0.4074 - val_accuracy: 0.8668\n",
            "Epoch 482/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4092 - accuracy: 0.8646 - val_loss: 0.4075 - val_accuracy: 0.8643\n",
            "Epoch 483/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4091 - accuracy: 0.8650 - val_loss: 0.4071 - val_accuracy: 0.8662\n",
            "Epoch 484/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4089 - accuracy: 0.8649 - val_loss: 0.4069 - val_accuracy: 0.8669\n",
            "Epoch 485/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4087 - accuracy: 0.8649 - val_loss: 0.4069 - val_accuracy: 0.8664\n",
            "Epoch 486/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4085 - accuracy: 0.8652 - val_loss: 0.4068 - val_accuracy: 0.8659\n",
            "Epoch 487/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4085 - accuracy: 0.8650 - val_loss: 0.4065 - val_accuracy: 0.8663\n",
            "Epoch 488/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4083 - accuracy: 0.8651 - val_loss: 0.4064 - val_accuracy: 0.8652\n",
            "Epoch 489/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4081 - accuracy: 0.8650 - val_loss: 0.4062 - val_accuracy: 0.8659\n",
            "Epoch 490/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4080 - accuracy: 0.8650 - val_loss: 0.4061 - val_accuracy: 0.8656\n",
            "Epoch 491/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4078 - accuracy: 0.8650 - val_loss: 0.4062 - val_accuracy: 0.8709\n",
            "Epoch 492/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4076 - accuracy: 0.8653 - val_loss: 0.4057 - val_accuracy: 0.8659\n",
            "Epoch 493/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4075 - accuracy: 0.8648 - val_loss: 0.4058 - val_accuracy: 0.8646\n",
            "Epoch 494/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4074 - accuracy: 0.8651 - val_loss: 0.4056 - val_accuracy: 0.8662\n",
            "Epoch 495/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4071 - accuracy: 0.8650 - val_loss: 0.4053 - val_accuracy: 0.8680\n",
            "Epoch 496/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4070 - accuracy: 0.8650 - val_loss: 0.4055 - val_accuracy: 0.8633\n",
            "Epoch 497/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4069 - accuracy: 0.8653 - val_loss: 0.4050 - val_accuracy: 0.8676\n",
            "Epoch 498/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4067 - accuracy: 0.8653 - val_loss: 0.4052 - val_accuracy: 0.8641\n",
            "Epoch 499/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4066 - accuracy: 0.8655 - val_loss: 0.4048 - val_accuracy: 0.8658\n",
            "Epoch 500/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4065 - accuracy: 0.8655 - val_loss: 0.4045 - val_accuracy: 0.8663\n",
            "Epoch 501/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4062 - accuracy: 0.8653 - val_loss: 0.4046 - val_accuracy: 0.8669\n",
            "Epoch 502/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4061 - accuracy: 0.8655 - val_loss: 0.4042 - val_accuracy: 0.8663\n",
            "Epoch 503/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4059 - accuracy: 0.8658 - val_loss: 0.4043 - val_accuracy: 0.8652\n",
            "Epoch 504/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4058 - accuracy: 0.8655 - val_loss: 0.4041 - val_accuracy: 0.8663\n",
            "Epoch 505/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4057 - accuracy: 0.8656 - val_loss: 0.4038 - val_accuracy: 0.8663\n",
            "Epoch 506/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4055 - accuracy: 0.8657 - val_loss: 0.4038 - val_accuracy: 0.8655\n",
            "Epoch 507/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4053 - accuracy: 0.8658 - val_loss: 0.4035 - val_accuracy: 0.8672\n",
            "Epoch 508/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4052 - accuracy: 0.8659 - val_loss: 0.4033 - val_accuracy: 0.8676\n",
            "Epoch 509/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4050 - accuracy: 0.8655 - val_loss: 0.4032 - val_accuracy: 0.8673\n",
            "Epoch 510/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4049 - accuracy: 0.8658 - val_loss: 0.4032 - val_accuracy: 0.8652\n",
            "Epoch 511/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4047 - accuracy: 0.8655 - val_loss: 0.4031 - val_accuracy: 0.8699\n",
            "Epoch 512/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4046 - accuracy: 0.8659 - val_loss: 0.4028 - val_accuracy: 0.8670\n",
            "Epoch 513/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4044 - accuracy: 0.8661 - val_loss: 0.4029 - val_accuracy: 0.8654\n",
            "Epoch 514/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4043 - accuracy: 0.8656 - val_loss: 0.4026 - val_accuracy: 0.8654\n",
            "Epoch 515/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4041 - accuracy: 0.8661 - val_loss: 0.4025 - val_accuracy: 0.8706\n",
            "Epoch 516/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4040 - accuracy: 0.8659 - val_loss: 0.4025 - val_accuracy: 0.8708\n",
            "Epoch 517/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4039 - accuracy: 0.8662 - val_loss: 0.4022 - val_accuracy: 0.8711\n",
            "Epoch 518/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4037 - accuracy: 0.8659 - val_loss: 0.4019 - val_accuracy: 0.8682\n",
            "Epoch 519/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4036 - accuracy: 0.8662 - val_loss: 0.4018 - val_accuracy: 0.8666\n",
            "Epoch 520/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4034 - accuracy: 0.8661 - val_loss: 0.4016 - val_accuracy: 0.8668\n",
            "Epoch 521/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4032 - accuracy: 0.8660 - val_loss: 0.4014 - val_accuracy: 0.8677\n",
            "Epoch 522/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4031 - accuracy: 0.8661 - val_loss: 0.4014 - val_accuracy: 0.8658\n",
            "Epoch 523/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4030 - accuracy: 0.8661 - val_loss: 0.4014 - val_accuracy: 0.8708\n",
            "Epoch 524/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.8663 - val_loss: 0.4010 - val_accuracy: 0.8680\n",
            "Epoch 525/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4027 - accuracy: 0.8663 - val_loss: 0.4009 - val_accuracy: 0.8695\n",
            "Epoch 526/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4025 - accuracy: 0.8662 - val_loss: 0.4010 - val_accuracy: 0.8641\n",
            "Epoch 527/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4024 - accuracy: 0.8665 - val_loss: 0.4007 - val_accuracy: 0.8659\n",
            "Epoch 528/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4022 - accuracy: 0.8666 - val_loss: 0.4007 - val_accuracy: 0.8648\n",
            "Epoch 529/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4020 - accuracy: 0.8662 - val_loss: 0.4004 - val_accuracy: 0.8681\n",
            "Epoch 530/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4019 - accuracy: 0.8663 - val_loss: 0.4004 - val_accuracy: 0.8708\n",
            "Epoch 531/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4017 - accuracy: 0.8673 - val_loss: 0.4000 - val_accuracy: 0.8666\n",
            "Epoch 532/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4016 - accuracy: 0.8663 - val_loss: 0.3999 - val_accuracy: 0.8661\n",
            "Epoch 533/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4015 - accuracy: 0.8668 - val_loss: 0.3998 - val_accuracy: 0.8689\n",
            "Epoch 534/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4014 - accuracy: 0.8666 - val_loss: 0.3997 - val_accuracy: 0.8695\n",
            "Epoch 535/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4012 - accuracy: 0.8670 - val_loss: 0.3995 - val_accuracy: 0.8674\n",
            "Epoch 536/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.8668 - val_loss: 0.3995 - val_accuracy: 0.8656\n",
            "Epoch 537/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4009 - accuracy: 0.8667 - val_loss: 0.3993 - val_accuracy: 0.8683\n",
            "Epoch 538/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4008 - accuracy: 0.8668 - val_loss: 0.3991 - val_accuracy: 0.8664\n",
            "Epoch 539/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4006 - accuracy: 0.8668 - val_loss: 0.3989 - val_accuracy: 0.8669\n",
            "Epoch 540/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4005 - accuracy: 0.8672 - val_loss: 0.3989 - val_accuracy: 0.8712\n",
            "Epoch 541/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4004 - accuracy: 0.8667 - val_loss: 0.3986 - val_accuracy: 0.8691\n",
            "Epoch 542/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4002 - accuracy: 0.8669 - val_loss: 0.3985 - val_accuracy: 0.8683\n",
            "Epoch 543/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4001 - accuracy: 0.8669 - val_loss: 0.3984 - val_accuracy: 0.8688\n",
            "Epoch 544/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3999 - accuracy: 0.8671 - val_loss: 0.3982 - val_accuracy: 0.8666\n",
            "Epoch 545/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3998 - accuracy: 0.8668 - val_loss: 0.3981 - val_accuracy: 0.8698\n",
            "Epoch 546/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3996 - accuracy: 0.8666 - val_loss: 0.3981 - val_accuracy: 0.8711\n",
            "Epoch 547/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3995 - accuracy: 0.8668 - val_loss: 0.3979 - val_accuracy: 0.8660\n",
            "Epoch 548/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3994 - accuracy: 0.8670 - val_loss: 0.3978 - val_accuracy: 0.8695\n",
            "Epoch 549/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3992 - accuracy: 0.8670 - val_loss: 0.3976 - val_accuracy: 0.8681\n",
            "Epoch 550/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3991 - accuracy: 0.8671 - val_loss: 0.3974 - val_accuracy: 0.8681\n",
            "Epoch 551/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3989 - accuracy: 0.8671 - val_loss: 0.3977 - val_accuracy: 0.8643\n",
            "Epoch 552/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3988 - accuracy: 0.8673 - val_loss: 0.3972 - val_accuracy: 0.8687\n",
            "Epoch 553/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3986 - accuracy: 0.8671 - val_loss: 0.3971 - val_accuracy: 0.8658\n",
            "Epoch 554/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3985 - accuracy: 0.8671 - val_loss: 0.3970 - val_accuracy: 0.8707\n",
            "Epoch 555/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3984 - accuracy: 0.8673 - val_loss: 0.3968 - val_accuracy: 0.8677\n",
            "Epoch 556/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3982 - accuracy: 0.8672 - val_loss: 0.3967 - val_accuracy: 0.8677\n",
            "Epoch 557/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3981 - accuracy: 0.8675 - val_loss: 0.3965 - val_accuracy: 0.8696\n",
            "Epoch 558/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3979 - accuracy: 0.8676 - val_loss: 0.3966 - val_accuracy: 0.8652\n",
            "Epoch 559/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3978 - accuracy: 0.8679 - val_loss: 0.3962 - val_accuracy: 0.8702\n",
            "Epoch 560/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3977 - accuracy: 0.8674 - val_loss: 0.3961 - val_accuracy: 0.8703\n",
            "Epoch 561/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3975 - accuracy: 0.8677 - val_loss: 0.3962 - val_accuracy: 0.8722\n",
            "Epoch 562/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3974 - accuracy: 0.8677 - val_loss: 0.3958 - val_accuracy: 0.8677\n",
            "Epoch 563/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3973 - accuracy: 0.8679 - val_loss: 0.3956 - val_accuracy: 0.8692\n",
            "Epoch 564/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3971 - accuracy: 0.8680 - val_loss: 0.3955 - val_accuracy: 0.8698\n",
            "Epoch 565/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3969 - accuracy: 0.8675 - val_loss: 0.3954 - val_accuracy: 0.8701\n",
            "Epoch 566/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3969 - accuracy: 0.8678 - val_loss: 0.3952 - val_accuracy: 0.8691\n",
            "Epoch 567/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3968 - accuracy: 0.8677 - val_loss: 0.3952 - val_accuracy: 0.8671\n",
            "Epoch 568/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3966 - accuracy: 0.8677 - val_loss: 0.3950 - val_accuracy: 0.8694\n",
            "Epoch 569/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3965 - accuracy: 0.8676 - val_loss: 0.3949 - val_accuracy: 0.8708\n",
            "Epoch 570/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3963 - accuracy: 0.8679 - val_loss: 0.3948 - val_accuracy: 0.8696\n",
            "Epoch 571/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3962 - accuracy: 0.8676 - val_loss: 0.3947 - val_accuracy: 0.8701\n",
            "Epoch 572/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3960 - accuracy: 0.8682 - val_loss: 0.3947 - val_accuracy: 0.8707\n",
            "Epoch 573/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3959 - accuracy: 0.8680 - val_loss: 0.3944 - val_accuracy: 0.8699\n",
            "Epoch 574/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3957 - accuracy: 0.8679 - val_loss: 0.3943 - val_accuracy: 0.8692\n",
            "Epoch 575/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3956 - accuracy: 0.8681 - val_loss: 0.3942 - val_accuracy: 0.8679\n",
            "Epoch 576/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3955 - accuracy: 0.8680 - val_loss: 0.3940 - val_accuracy: 0.8705\n",
            "Epoch 577/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3953 - accuracy: 0.8681 - val_loss: 0.3939 - val_accuracy: 0.8672\n",
            "Epoch 578/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3952 - accuracy: 0.8678 - val_loss: 0.3938 - val_accuracy: 0.8695\n",
            "Epoch 579/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3951 - accuracy: 0.8680 - val_loss: 0.3936 - val_accuracy: 0.8709\n",
            "Epoch 580/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3949 - accuracy: 0.8680 - val_loss: 0.3936 - val_accuracy: 0.8692\n",
            "Epoch 581/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8679 - val_loss: 0.3933 - val_accuracy: 0.8691\n",
            "Epoch 582/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3947 - accuracy: 0.8682 - val_loss: 0.3932 - val_accuracy: 0.8710\n",
            "Epoch 583/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8682 - val_loss: 0.3933 - val_accuracy: 0.8668\n",
            "Epoch 584/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3944 - accuracy: 0.8683 - val_loss: 0.3929 - val_accuracy: 0.8683\n",
            "Epoch 585/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3943 - accuracy: 0.8680 - val_loss: 0.3932 - val_accuracy: 0.8656\n",
            "Epoch 586/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3942 - accuracy: 0.8685 - val_loss: 0.3928 - val_accuracy: 0.8697\n",
            "Epoch 587/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3940 - accuracy: 0.8687 - val_loss: 0.3926 - val_accuracy: 0.8701\n",
            "Epoch 588/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3939 - accuracy: 0.8684 - val_loss: 0.3924 - val_accuracy: 0.8691\n",
            "Epoch 589/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3938 - accuracy: 0.8684 - val_loss: 0.3922 - val_accuracy: 0.8699\n",
            "Epoch 590/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3936 - accuracy: 0.8686 - val_loss: 0.3928 - val_accuracy: 0.8654\n",
            "Epoch 591/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3935 - accuracy: 0.8685 - val_loss: 0.3920 - val_accuracy: 0.8705\n",
            "Epoch 592/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3934 - accuracy: 0.8684 - val_loss: 0.3919 - val_accuracy: 0.8707\n",
            "Epoch 593/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3932 - accuracy: 0.8681 - val_loss: 0.3918 - val_accuracy: 0.8681\n",
            "Epoch 594/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3931 - accuracy: 0.8687 - val_loss: 0.3917 - val_accuracy: 0.8714\n",
            "Epoch 595/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3930 - accuracy: 0.8690 - val_loss: 0.3916 - val_accuracy: 0.8675\n",
            "Epoch 596/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3928 - accuracy: 0.8690 - val_loss: 0.3914 - val_accuracy: 0.8685\n",
            "Epoch 597/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3927 - accuracy: 0.8686 - val_loss: 0.3918 - val_accuracy: 0.8653\n",
            "Epoch 598/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3926 - accuracy: 0.8688 - val_loss: 0.3913 - val_accuracy: 0.8674\n",
            "Epoch 599/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3925 - accuracy: 0.8688 - val_loss: 0.3911 - val_accuracy: 0.8669\n",
            "Epoch 600/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3923 - accuracy: 0.8688 - val_loss: 0.3908 - val_accuracy: 0.8706\n",
            "Epoch 601/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3922 - accuracy: 0.8689 - val_loss: 0.3908 - val_accuracy: 0.8697\n",
            "Epoch 602/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3921 - accuracy: 0.8690 - val_loss: 0.3908 - val_accuracy: 0.8679\n",
            "Epoch 603/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3919 - accuracy: 0.8693 - val_loss: 0.3907 - val_accuracy: 0.8670\n",
            "Epoch 604/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3918 - accuracy: 0.8691 - val_loss: 0.3903 - val_accuracy: 0.8691\n",
            "Epoch 605/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3917 - accuracy: 0.8692 - val_loss: 0.3903 - val_accuracy: 0.8673\n",
            "Epoch 606/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3915 - accuracy: 0.8690 - val_loss: 0.3903 - val_accuracy: 0.8668\n",
            "Epoch 607/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3914 - accuracy: 0.8689 - val_loss: 0.3901 - val_accuracy: 0.8671\n",
            "Epoch 608/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3912 - accuracy: 0.8692 - val_loss: 0.3900 - val_accuracy: 0.8709\n",
            "Epoch 609/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3911 - accuracy: 0.8693 - val_loss: 0.3899 - val_accuracy: 0.8734\n",
            "Epoch 610/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3910 - accuracy: 0.8691 - val_loss: 0.3896 - val_accuracy: 0.8694\n",
            "Epoch 611/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3909 - accuracy: 0.8692 - val_loss: 0.3898 - val_accuracy: 0.8670\n",
            "Epoch 612/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3908 - accuracy: 0.8695 - val_loss: 0.3894 - val_accuracy: 0.8717\n",
            "Epoch 613/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3906 - accuracy: 0.8694 - val_loss: 0.3893 - val_accuracy: 0.8725\n",
            "Epoch 614/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3905 - accuracy: 0.8695 - val_loss: 0.3891 - val_accuracy: 0.8709\n",
            "Epoch 615/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3904 - accuracy: 0.8695 - val_loss: 0.3890 - val_accuracy: 0.8719\n",
            "Epoch 616/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3902 - accuracy: 0.8697 - val_loss: 0.3889 - val_accuracy: 0.8703\n",
            "Epoch 617/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3902 - accuracy: 0.8695 - val_loss: 0.3890 - val_accuracy: 0.8729\n",
            "Epoch 618/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3900 - accuracy: 0.8693 - val_loss: 0.3891 - val_accuracy: 0.8734\n",
            "Epoch 619/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3899 - accuracy: 0.8696 - val_loss: 0.3885 - val_accuracy: 0.8698\n",
            "Epoch 620/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3897 - accuracy: 0.8695 - val_loss: 0.3884 - val_accuracy: 0.8680\n",
            "Epoch 621/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3897 - accuracy: 0.8696 - val_loss: 0.3883 - val_accuracy: 0.8698\n",
            "Epoch 622/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3895 - accuracy: 0.8697 - val_loss: 0.3884 - val_accuracy: 0.8676\n",
            "Epoch 623/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3894 - accuracy: 0.8699 - val_loss: 0.3880 - val_accuracy: 0.8695\n",
            "Epoch 624/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3892 - accuracy: 0.8696 - val_loss: 0.3880 - val_accuracy: 0.8721\n",
            "Epoch 625/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3892 - accuracy: 0.8697 - val_loss: 0.3878 - val_accuracy: 0.8716\n",
            "Epoch 626/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3890 - accuracy: 0.8701 - val_loss: 0.3877 - val_accuracy: 0.8694\n",
            "Epoch 627/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3888 - accuracy: 0.8701 - val_loss: 0.3878 - val_accuracy: 0.8675\n",
            "Epoch 628/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3887 - accuracy: 0.8698 - val_loss: 0.3874 - val_accuracy: 0.8717\n",
            "Epoch 629/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3886 - accuracy: 0.8702 - val_loss: 0.3873 - val_accuracy: 0.8723\n",
            "Epoch 630/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3884 - accuracy: 0.8703 - val_loss: 0.3874 - val_accuracy: 0.8679\n",
            "Epoch 631/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3884 - accuracy: 0.8698 - val_loss: 0.3871 - val_accuracy: 0.8737\n",
            "Epoch 632/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3882 - accuracy: 0.8699 - val_loss: 0.3869 - val_accuracy: 0.8708\n",
            "Epoch 633/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3880 - accuracy: 0.8700 - val_loss: 0.3869 - val_accuracy: 0.8680\n",
            "Epoch 634/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3880 - accuracy: 0.8700 - val_loss: 0.3868 - val_accuracy: 0.8741\n",
            "Epoch 635/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3878 - accuracy: 0.8703 - val_loss: 0.3867 - val_accuracy: 0.8730\n",
            "Epoch 636/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3877 - accuracy: 0.8701 - val_loss: 0.3864 - val_accuracy: 0.8717\n",
            "Epoch 637/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3876 - accuracy: 0.8702 - val_loss: 0.3863 - val_accuracy: 0.8715\n",
            "Epoch 638/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3875 - accuracy: 0.8702 - val_loss: 0.3863 - val_accuracy: 0.8730\n",
            "Epoch 639/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3873 - accuracy: 0.8703 - val_loss: 0.3860 - val_accuracy: 0.8715\n",
            "Epoch 640/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3872 - accuracy: 0.8705 - val_loss: 0.3862 - val_accuracy: 0.8676\n",
            "Epoch 641/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3871 - accuracy: 0.8703 - val_loss: 0.3859 - val_accuracy: 0.8693\n",
            "Epoch 642/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3870 - accuracy: 0.8702 - val_loss: 0.3859 - val_accuracy: 0.8716\n",
            "Epoch 643/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3869 - accuracy: 0.8703 - val_loss: 0.3859 - val_accuracy: 0.8681\n",
            "Epoch 644/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3867 - accuracy: 0.8703 - val_loss: 0.3855 - val_accuracy: 0.8720\n",
            "Epoch 645/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3866 - accuracy: 0.8704 - val_loss: 0.3857 - val_accuracy: 0.8679\n",
            "Epoch 646/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3865 - accuracy: 0.8704 - val_loss: 0.3854 - val_accuracy: 0.8702\n",
            "Epoch 647/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3864 - accuracy: 0.8706 - val_loss: 0.3852 - val_accuracy: 0.8694\n",
            "Epoch 648/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3863 - accuracy: 0.8704 - val_loss: 0.3850 - val_accuracy: 0.8724\n",
            "Epoch 649/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3862 - accuracy: 0.8707 - val_loss: 0.3850 - val_accuracy: 0.8737\n",
            "Epoch 650/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3860 - accuracy: 0.8707 - val_loss: 0.3847 - val_accuracy: 0.8719\n",
            "Epoch 651/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3859 - accuracy: 0.8707 - val_loss: 0.3846 - val_accuracy: 0.8723\n",
            "Epoch 652/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3858 - accuracy: 0.8712 - val_loss: 0.3845 - val_accuracy: 0.8697\n",
            "Epoch 653/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3856 - accuracy: 0.8707 - val_loss: 0.3845 - val_accuracy: 0.8691\n",
            "Epoch 654/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3855 - accuracy: 0.8707 - val_loss: 0.3844 - val_accuracy: 0.8740\n",
            "Epoch 655/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3854 - accuracy: 0.8709 - val_loss: 0.3842 - val_accuracy: 0.8738\n",
            "Epoch 656/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3853 - accuracy: 0.8708 - val_loss: 0.3840 - val_accuracy: 0.8726\n",
            "Epoch 657/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3851 - accuracy: 0.8709 - val_loss: 0.3840 - val_accuracy: 0.8695\n",
            "Epoch 658/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3850 - accuracy: 0.8708 - val_loss: 0.3838 - val_accuracy: 0.8726\n",
            "Epoch 659/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3849 - accuracy: 0.8708 - val_loss: 0.3839 - val_accuracy: 0.8734\n",
            "Epoch 660/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3848 - accuracy: 0.8711 - val_loss: 0.3836 - val_accuracy: 0.8706\n",
            "Epoch 661/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3847 - accuracy: 0.8710 - val_loss: 0.3836 - val_accuracy: 0.8687\n",
            "Epoch 662/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3846 - accuracy: 0.8707 - val_loss: 0.3834 - val_accuracy: 0.8745\n",
            "Epoch 663/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3844 - accuracy: 0.8709 - val_loss: 0.3832 - val_accuracy: 0.8730\n",
            "Epoch 664/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3843 - accuracy: 0.8713 - val_loss: 0.3831 - val_accuracy: 0.8716\n",
            "Epoch 665/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3842 - accuracy: 0.8710 - val_loss: 0.3831 - val_accuracy: 0.8742\n",
            "Epoch 666/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3841 - accuracy: 0.8712 - val_loss: 0.3830 - val_accuracy: 0.8740\n",
            "Epoch 667/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3840 - accuracy: 0.8710 - val_loss: 0.3828 - val_accuracy: 0.8737\n",
            "Epoch 668/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3838 - accuracy: 0.8712 - val_loss: 0.3827 - val_accuracy: 0.8741\n",
            "Epoch 669/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3837 - accuracy: 0.8711 - val_loss: 0.3826 - val_accuracy: 0.8738\n",
            "Epoch 670/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3836 - accuracy: 0.8716 - val_loss: 0.3826 - val_accuracy: 0.8695\n",
            "Epoch 671/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3835 - accuracy: 0.8715 - val_loss: 0.3823 - val_accuracy: 0.8710\n",
            "Epoch 672/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3834 - accuracy: 0.8715 - val_loss: 0.3823 - val_accuracy: 0.8743\n",
            "Epoch 673/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3833 - accuracy: 0.8715 - val_loss: 0.3821 - val_accuracy: 0.8712\n",
            "Epoch 674/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3831 - accuracy: 0.8716 - val_loss: 0.3820 - val_accuracy: 0.8742\n",
            "Epoch 675/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3830 - accuracy: 0.8711 - val_loss: 0.3819 - val_accuracy: 0.8709\n",
            "Epoch 676/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3829 - accuracy: 0.8713 - val_loss: 0.3820 - val_accuracy: 0.8741\n",
            "Epoch 677/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3828 - accuracy: 0.8718 - val_loss: 0.3821 - val_accuracy: 0.8697\n",
            "Epoch 678/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8714 - val_loss: 0.3815 - val_accuracy: 0.8743\n",
            "Epoch 679/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3825 - accuracy: 0.8713 - val_loss: 0.3814 - val_accuracy: 0.8734\n",
            "Epoch 680/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3824 - accuracy: 0.8716 - val_loss: 0.3812 - val_accuracy: 0.8730\n",
            "Epoch 681/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3823 - accuracy: 0.8717 - val_loss: 0.3812 - val_accuracy: 0.8709\n",
            "Epoch 682/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3822 - accuracy: 0.8715 - val_loss: 0.3811 - val_accuracy: 0.8720\n",
            "Epoch 683/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8716 - val_loss: 0.3812 - val_accuracy: 0.8748\n",
            "Epoch 684/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8720 - val_loss: 0.3809 - val_accuracy: 0.8748\n",
            "Epoch 685/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3818 - accuracy: 0.8722 - val_loss: 0.3809 - val_accuracy: 0.8748\n",
            "Epoch 686/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3817 - accuracy: 0.8719 - val_loss: 0.3808 - val_accuracy: 0.8695\n",
            "Epoch 687/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3816 - accuracy: 0.8717 - val_loss: 0.3806 - val_accuracy: 0.8713\n",
            "Epoch 688/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3814 - accuracy: 0.8719 - val_loss: 0.3805 - val_accuracy: 0.8735\n",
            "Epoch 689/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3814 - accuracy: 0.8719 - val_loss: 0.3803 - val_accuracy: 0.8744\n",
            "Epoch 690/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3812 - accuracy: 0.8719 - val_loss: 0.3805 - val_accuracy: 0.8694\n",
            "Epoch 691/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3811 - accuracy: 0.8720 - val_loss: 0.3802 - val_accuracy: 0.8708\n",
            "Epoch 692/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3810 - accuracy: 0.8722 - val_loss: 0.3799 - val_accuracy: 0.8744\n",
            "Epoch 693/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3810 - accuracy: 0.8719 - val_loss: 0.3799 - val_accuracy: 0.8711\n",
            "Epoch 694/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3808 - accuracy: 0.8720 - val_loss: 0.3800 - val_accuracy: 0.8692\n",
            "Epoch 695/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3806 - accuracy: 0.8723 - val_loss: 0.3796 - val_accuracy: 0.8729\n",
            "Epoch 696/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3806 - accuracy: 0.8723 - val_loss: 0.3794 - val_accuracy: 0.8727\n",
            "Epoch 697/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3804 - accuracy: 0.8719 - val_loss: 0.3795 - val_accuracy: 0.8724\n",
            "Epoch 698/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3803 - accuracy: 0.8720 - val_loss: 0.3792 - val_accuracy: 0.8737\n",
            "Epoch 699/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3802 - accuracy: 0.8723 - val_loss: 0.3792 - val_accuracy: 0.8739\n",
            "Epoch 700/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3801 - accuracy: 0.8723 - val_loss: 0.3791 - val_accuracy: 0.8746\n",
            "Epoch 701/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3800 - accuracy: 0.8725 - val_loss: 0.3789 - val_accuracy: 0.8730\n",
            "Epoch 702/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3799 - accuracy: 0.8724 - val_loss: 0.3794 - val_accuracy: 0.8684\n",
            "Epoch 703/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3798 - accuracy: 0.8723 - val_loss: 0.3787 - val_accuracy: 0.8716\n",
            "Epoch 704/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3796 - accuracy: 0.8723 - val_loss: 0.3787 - val_accuracy: 0.8730\n",
            "Epoch 705/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3795 - accuracy: 0.8728 - val_loss: 0.3785 - val_accuracy: 0.8715\n",
            "Epoch 706/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3794 - accuracy: 0.8726 - val_loss: 0.3784 - val_accuracy: 0.8730\n",
            "Epoch 707/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3793 - accuracy: 0.8726 - val_loss: 0.3784 - val_accuracy: 0.8716\n",
            "Epoch 708/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3792 - accuracy: 0.8727 - val_loss: 0.3785 - val_accuracy: 0.8702\n",
            "Epoch 709/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3791 - accuracy: 0.8726 - val_loss: 0.3781 - val_accuracy: 0.8740\n",
            "Epoch 710/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3790 - accuracy: 0.8727 - val_loss: 0.3780 - val_accuracy: 0.8730\n",
            "Epoch 711/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3789 - accuracy: 0.8727 - val_loss: 0.3779 - val_accuracy: 0.8716\n",
            "Epoch 712/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3788 - accuracy: 0.8728 - val_loss: 0.3779 - val_accuracy: 0.8711\n",
            "Epoch 713/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3786 - accuracy: 0.8728 - val_loss: 0.3784 - val_accuracy: 0.8763\n",
            "Epoch 714/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3786 - accuracy: 0.8728 - val_loss: 0.3776 - val_accuracy: 0.8719\n",
            "Epoch 715/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3784 - accuracy: 0.8728 - val_loss: 0.3776 - val_accuracy: 0.8703\n",
            "Epoch 716/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3783 - accuracy: 0.8731 - val_loss: 0.3774 - val_accuracy: 0.8752\n",
            "Epoch 717/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3782 - accuracy: 0.8728 - val_loss: 0.3772 - val_accuracy: 0.8722\n",
            "Epoch 718/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3781 - accuracy: 0.8731 - val_loss: 0.3771 - val_accuracy: 0.8735\n",
            "Epoch 719/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3780 - accuracy: 0.8728 - val_loss: 0.3770 - val_accuracy: 0.8746\n",
            "Epoch 720/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3779 - accuracy: 0.8731 - val_loss: 0.3769 - val_accuracy: 0.8745\n",
            "Epoch 721/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3778 - accuracy: 0.8733 - val_loss: 0.3769 - val_accuracy: 0.8713\n",
            "Epoch 722/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3776 - accuracy: 0.8729 - val_loss: 0.3771 - val_accuracy: 0.8759\n",
            "Epoch 723/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3775 - accuracy: 0.8732 - val_loss: 0.3767 - val_accuracy: 0.8723\n",
            "Epoch 724/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8733 - val_loss: 0.3764 - val_accuracy: 0.8737\n",
            "Epoch 725/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3773 - accuracy: 0.8734 - val_loss: 0.3763 - val_accuracy: 0.8749\n",
            "Epoch 726/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3772 - accuracy: 0.8732 - val_loss: 0.3764 - val_accuracy: 0.8760\n",
            "Epoch 727/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8734 - val_loss: 0.3763 - val_accuracy: 0.8721\n",
            "Epoch 728/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3770 - accuracy: 0.8736 - val_loss: 0.3761 - val_accuracy: 0.8763\n",
            "Epoch 729/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3769 - accuracy: 0.8736 - val_loss: 0.3759 - val_accuracy: 0.8737\n",
            "Epoch 730/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3768 - accuracy: 0.8734 - val_loss: 0.3761 - val_accuracy: 0.8766\n",
            "Epoch 731/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3766 - accuracy: 0.8732 - val_loss: 0.3757 - val_accuracy: 0.8751\n",
            "Epoch 732/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3765 - accuracy: 0.8735 - val_loss: 0.3756 - val_accuracy: 0.8734\n",
            "Epoch 733/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3764 - accuracy: 0.8733 - val_loss: 0.3755 - val_accuracy: 0.8744\n",
            "Epoch 734/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3764 - accuracy: 0.8740 - val_loss: 0.3754 - val_accuracy: 0.8726\n",
            "Epoch 735/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3762 - accuracy: 0.8737 - val_loss: 0.3752 - val_accuracy: 0.8750\n",
            "Epoch 736/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3761 - accuracy: 0.8735 - val_loss: 0.3752 - val_accuracy: 0.8759\n",
            "Epoch 737/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3760 - accuracy: 0.8735 - val_loss: 0.3752 - val_accuracy: 0.8720\n",
            "Epoch 738/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3759 - accuracy: 0.8738 - val_loss: 0.3749 - val_accuracy: 0.8739\n",
            "Epoch 739/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3758 - accuracy: 0.8735 - val_loss: 0.3748 - val_accuracy: 0.8731\n",
            "Epoch 740/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3757 - accuracy: 0.8733 - val_loss: 0.3747 - val_accuracy: 0.8748\n",
            "Epoch 741/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3755 - accuracy: 0.8738 - val_loss: 0.3747 - val_accuracy: 0.8724\n",
            "Epoch 742/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3755 - accuracy: 0.8739 - val_loss: 0.3747 - val_accuracy: 0.8760\n",
            "Epoch 743/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3753 - accuracy: 0.8740 - val_loss: 0.3746 - val_accuracy: 0.8720\n",
            "Epoch 744/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3752 - accuracy: 0.8742 - val_loss: 0.3744 - val_accuracy: 0.8749\n",
            "Epoch 745/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3751 - accuracy: 0.8741 - val_loss: 0.3745 - val_accuracy: 0.8715\n",
            "Epoch 746/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8742 - val_loss: 0.3741 - val_accuracy: 0.8730\n",
            "Epoch 747/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3749 - accuracy: 0.8737 - val_loss: 0.3741 - val_accuracy: 0.8764\n",
            "Epoch 748/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3748 - accuracy: 0.8744 - val_loss: 0.3740 - val_accuracy: 0.8725\n",
            "Epoch 749/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3747 - accuracy: 0.8738 - val_loss: 0.3739 - val_accuracy: 0.8756\n",
            "Epoch 750/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3746 - accuracy: 0.8744 - val_loss: 0.3739 - val_accuracy: 0.8720\n",
            "Epoch 751/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3745 - accuracy: 0.8742 - val_loss: 0.3738 - val_accuracy: 0.8770\n",
            "Epoch 752/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3744 - accuracy: 0.8745 - val_loss: 0.3735 - val_accuracy: 0.8755\n",
            "Epoch 753/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3743 - accuracy: 0.8742 - val_loss: 0.3734 - val_accuracy: 0.8761\n",
            "Epoch 754/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3742 - accuracy: 0.8745 - val_loss: 0.3733 - val_accuracy: 0.8742\n",
            "Epoch 755/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3740 - accuracy: 0.8744 - val_loss: 0.3731 - val_accuracy: 0.8752\n",
            "Epoch 756/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3739 - accuracy: 0.8744 - val_loss: 0.3732 - val_accuracy: 0.8769\n",
            "Epoch 757/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8743 - val_loss: 0.3730 - val_accuracy: 0.8767\n",
            "Epoch 758/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8744 - val_loss: 0.3728 - val_accuracy: 0.8756\n",
            "Epoch 759/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3736 - accuracy: 0.8744 - val_loss: 0.3727 - val_accuracy: 0.8748\n",
            "Epoch 760/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3735 - accuracy: 0.8744 - val_loss: 0.3727 - val_accuracy: 0.8760\n",
            "Epoch 761/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3734 - accuracy: 0.8748 - val_loss: 0.3726 - val_accuracy: 0.8747\n",
            "Epoch 762/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3733 - accuracy: 0.8744 - val_loss: 0.3725 - val_accuracy: 0.8765\n",
            "Epoch 763/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3732 - accuracy: 0.8748 - val_loss: 0.3724 - val_accuracy: 0.8765\n",
            "Epoch 764/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3731 - accuracy: 0.8749 - val_loss: 0.3722 - val_accuracy: 0.8754\n",
            "Epoch 765/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3730 - accuracy: 0.8744 - val_loss: 0.3724 - val_accuracy: 0.8774\n",
            "Epoch 766/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3729 - accuracy: 0.8748 - val_loss: 0.3721 - val_accuracy: 0.8750\n",
            "Epoch 767/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3728 - accuracy: 0.8746 - val_loss: 0.3721 - val_accuracy: 0.8726\n",
            "Epoch 768/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3727 - accuracy: 0.8747 - val_loss: 0.3721 - val_accuracy: 0.8726\n",
            "Epoch 769/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3726 - accuracy: 0.8750 - val_loss: 0.3721 - val_accuracy: 0.8769\n",
            "Epoch 770/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3725 - accuracy: 0.8748 - val_loss: 0.3717 - val_accuracy: 0.8750\n",
            "Epoch 771/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3723 - accuracy: 0.8745 - val_loss: 0.3716 - val_accuracy: 0.8770\n",
            "Epoch 772/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3722 - accuracy: 0.8751 - val_loss: 0.3718 - val_accuracy: 0.8719\n",
            "Epoch 773/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3722 - accuracy: 0.8751 - val_loss: 0.3714 - val_accuracy: 0.8762\n",
            "Epoch 774/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3721 - accuracy: 0.8751 - val_loss: 0.3713 - val_accuracy: 0.8763\n",
            "Epoch 775/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3719 - accuracy: 0.8750 - val_loss: 0.3712 - val_accuracy: 0.8741\n",
            "Epoch 776/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3718 - accuracy: 0.8753 - val_loss: 0.3712 - val_accuracy: 0.8734\n",
            "Epoch 777/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3717 - accuracy: 0.8749 - val_loss: 0.3709 - val_accuracy: 0.8755\n",
            "Epoch 778/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3716 - accuracy: 0.8746 - val_loss: 0.3709 - val_accuracy: 0.8767\n",
            "Epoch 779/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3715 - accuracy: 0.8753 - val_loss: 0.3708 - val_accuracy: 0.8742\n",
            "Epoch 780/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3714 - accuracy: 0.8751 - val_loss: 0.3707 - val_accuracy: 0.8776\n",
            "Epoch 781/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3714 - accuracy: 0.8753 - val_loss: 0.3706 - val_accuracy: 0.8755\n",
            "Epoch 782/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3712 - accuracy: 0.8750 - val_loss: 0.3705 - val_accuracy: 0.8776\n",
            "Epoch 783/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3711 - accuracy: 0.8752 - val_loss: 0.3703 - val_accuracy: 0.8766\n",
            "Epoch 784/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3710 - accuracy: 0.8754 - val_loss: 0.3703 - val_accuracy: 0.8749\n",
            "Epoch 785/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3709 - accuracy: 0.8751 - val_loss: 0.3702 - val_accuracy: 0.8759\n",
            "Epoch 786/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3708 - accuracy: 0.8752 - val_loss: 0.3700 - val_accuracy: 0.8765\n",
            "Epoch 787/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3707 - accuracy: 0.8753 - val_loss: 0.3699 - val_accuracy: 0.8761\n",
            "Epoch 788/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3706 - accuracy: 0.8755 - val_loss: 0.3701 - val_accuracy: 0.8727\n",
            "Epoch 789/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3705 - accuracy: 0.8756 - val_loss: 0.3698 - val_accuracy: 0.8744\n",
            "Epoch 790/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3704 - accuracy: 0.8752 - val_loss: 0.3697 - val_accuracy: 0.8773\n",
            "Epoch 791/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3703 - accuracy: 0.8756 - val_loss: 0.3699 - val_accuracy: 0.8730\n",
            "Epoch 792/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3702 - accuracy: 0.8758 - val_loss: 0.3694 - val_accuracy: 0.8771\n",
            "Epoch 793/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3701 - accuracy: 0.8755 - val_loss: 0.3694 - val_accuracy: 0.8782\n",
            "Epoch 794/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3700 - accuracy: 0.8758 - val_loss: 0.3694 - val_accuracy: 0.8754\n",
            "Epoch 795/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3699 - accuracy: 0.8762 - val_loss: 0.3692 - val_accuracy: 0.8742\n",
            "Epoch 796/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3698 - accuracy: 0.8756 - val_loss: 0.3691 - val_accuracy: 0.8782\n",
            "Epoch 797/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3697 - accuracy: 0.8755 - val_loss: 0.3690 - val_accuracy: 0.8753\n",
            "Epoch 798/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3696 - accuracy: 0.8758 - val_loss: 0.3689 - val_accuracy: 0.8762\n",
            "Epoch 799/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3695 - accuracy: 0.8758 - val_loss: 0.3689 - val_accuracy: 0.8759\n",
            "Epoch 800/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3694 - accuracy: 0.8758 - val_loss: 0.3686 - val_accuracy: 0.8770\n",
            "Epoch 801/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3694 - accuracy: 0.8758 - val_loss: 0.3687 - val_accuracy: 0.8742\n",
            "Epoch 802/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3692 - accuracy: 0.8762 - val_loss: 0.3685 - val_accuracy: 0.8780\n",
            "Epoch 803/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3691 - accuracy: 0.8759 - val_loss: 0.3685 - val_accuracy: 0.8755\n",
            "Epoch 804/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3690 - accuracy: 0.8762 - val_loss: 0.3684 - val_accuracy: 0.8778\n",
            "Epoch 805/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8763 - val_loss: 0.3687 - val_accuracy: 0.8712\n",
            "Epoch 806/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3688 - accuracy: 0.8762 - val_loss: 0.3682 - val_accuracy: 0.8765\n",
            "Epoch 807/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3687 - accuracy: 0.8760 - val_loss: 0.3681 - val_accuracy: 0.8785\n",
            "Epoch 808/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3686 - accuracy: 0.8765 - val_loss: 0.3679 - val_accuracy: 0.8783\n",
            "Epoch 809/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3685 - accuracy: 0.8763 - val_loss: 0.3682 - val_accuracy: 0.8794\n",
            "Epoch 810/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3684 - accuracy: 0.8763 - val_loss: 0.3677 - val_accuracy: 0.8765\n",
            "Epoch 811/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3683 - accuracy: 0.8762 - val_loss: 0.3676 - val_accuracy: 0.8762\n",
            "Epoch 812/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3682 - accuracy: 0.8763 - val_loss: 0.3678 - val_accuracy: 0.8737\n",
            "Epoch 813/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3681 - accuracy: 0.8764 - val_loss: 0.3678 - val_accuracy: 0.8727\n",
            "Epoch 814/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3680 - accuracy: 0.8766 - val_loss: 0.3673 - val_accuracy: 0.8770\n",
            "Epoch 815/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3679 - accuracy: 0.8765 - val_loss: 0.3672 - val_accuracy: 0.8767\n",
            "Epoch 816/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3678 - accuracy: 0.8763 - val_loss: 0.3671 - val_accuracy: 0.8768\n",
            "Epoch 817/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3677 - accuracy: 0.8767 - val_loss: 0.3672 - val_accuracy: 0.8752\n",
            "Epoch 818/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3676 - accuracy: 0.8763 - val_loss: 0.3670 - val_accuracy: 0.8770\n",
            "Epoch 819/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3675 - accuracy: 0.8766 - val_loss: 0.3671 - val_accuracy: 0.8793\n",
            "Epoch 820/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3674 - accuracy: 0.8767 - val_loss: 0.3667 - val_accuracy: 0.8781\n",
            "Epoch 821/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3673 - accuracy: 0.8762 - val_loss: 0.3667 - val_accuracy: 0.8782\n",
            "Epoch 822/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3672 - accuracy: 0.8768 - val_loss: 0.3666 - val_accuracy: 0.8764\n",
            "Epoch 823/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3671 - accuracy: 0.8766 - val_loss: 0.3666 - val_accuracy: 0.8751\n",
            "Epoch 824/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3670 - accuracy: 0.8768 - val_loss: 0.3664 - val_accuracy: 0.8769\n",
            "Epoch 825/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3670 - accuracy: 0.8766 - val_loss: 0.3662 - val_accuracy: 0.8773\n",
            "Epoch 826/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3669 - accuracy: 0.8768 - val_loss: 0.3662 - val_accuracy: 0.8786\n",
            "Epoch 827/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3667 - accuracy: 0.8766 - val_loss: 0.3663 - val_accuracy: 0.8789\n",
            "Epoch 828/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3666 - accuracy: 0.8767 - val_loss: 0.3662 - val_accuracy: 0.8751\n",
            "Epoch 829/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3665 - accuracy: 0.8765 - val_loss: 0.3660 - val_accuracy: 0.8777\n",
            "Epoch 830/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3664 - accuracy: 0.8766 - val_loss: 0.3658 - val_accuracy: 0.8773\n",
            "Epoch 831/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3663 - accuracy: 0.8767 - val_loss: 0.3658 - val_accuracy: 0.8788\n",
            "Epoch 832/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3663 - accuracy: 0.8773 - val_loss: 0.3656 - val_accuracy: 0.8771\n",
            "Epoch 833/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3661 - accuracy: 0.8768 - val_loss: 0.3657 - val_accuracy: 0.8786\n",
            "Epoch 834/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3661 - accuracy: 0.8771 - val_loss: 0.3656 - val_accuracy: 0.8799\n",
            "Epoch 835/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3660 - accuracy: 0.8770 - val_loss: 0.3654 - val_accuracy: 0.8781\n",
            "Epoch 836/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3659 - accuracy: 0.8775 - val_loss: 0.3652 - val_accuracy: 0.8780\n",
            "Epoch 837/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3657 - accuracy: 0.8767 - val_loss: 0.3651 - val_accuracy: 0.8783\n",
            "Epoch 838/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3657 - accuracy: 0.8774 - val_loss: 0.3652 - val_accuracy: 0.8755\n",
            "Epoch 839/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3655 - accuracy: 0.8772 - val_loss: 0.3653 - val_accuracy: 0.8751\n",
            "Epoch 840/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3655 - accuracy: 0.8773 - val_loss: 0.3649 - val_accuracy: 0.8789\n",
            "Epoch 841/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3654 - accuracy: 0.8777 - val_loss: 0.3652 - val_accuracy: 0.8809\n",
            "Epoch 842/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3653 - accuracy: 0.8772 - val_loss: 0.3648 - val_accuracy: 0.8759\n",
            "Epoch 843/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3652 - accuracy: 0.8771 - val_loss: 0.3646 - val_accuracy: 0.8780\n",
            "Epoch 844/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3651 - accuracy: 0.8775 - val_loss: 0.3647 - val_accuracy: 0.8754\n",
            "Epoch 845/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3650 - accuracy: 0.8776 - val_loss: 0.3644 - val_accuracy: 0.8776\n",
            "Epoch 846/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3649 - accuracy: 0.8774 - val_loss: 0.3645 - val_accuracy: 0.8807\n",
            "Epoch 847/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3647 - accuracy: 0.8774 - val_loss: 0.3644 - val_accuracy: 0.8808\n",
            "Epoch 848/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3647 - accuracy: 0.8774 - val_loss: 0.3642 - val_accuracy: 0.8765\n",
            "Epoch 849/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3646 - accuracy: 0.8774 - val_loss: 0.3643 - val_accuracy: 0.8751\n",
            "Epoch 850/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3645 - accuracy: 0.8774 - val_loss: 0.3640 - val_accuracy: 0.8805\n",
            "Epoch 851/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3644 - accuracy: 0.8777 - val_loss: 0.3638 - val_accuracy: 0.8778\n",
            "Epoch 852/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3643 - accuracy: 0.8775 - val_loss: 0.3637 - val_accuracy: 0.8781\n",
            "Epoch 853/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3642 - accuracy: 0.8775 - val_loss: 0.3637 - val_accuracy: 0.8773\n",
            "Epoch 854/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3641 - accuracy: 0.8777 - val_loss: 0.3637 - val_accuracy: 0.8809\n",
            "Epoch 855/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3640 - accuracy: 0.8778 - val_loss: 0.3637 - val_accuracy: 0.8755\n",
            "Epoch 856/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3639 - accuracy: 0.8777 - val_loss: 0.3635 - val_accuracy: 0.8794\n",
            "Epoch 857/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3638 - accuracy: 0.8777 - val_loss: 0.3633 - val_accuracy: 0.8788\n",
            "Epoch 858/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3637 - accuracy: 0.8777 - val_loss: 0.3632 - val_accuracy: 0.8794\n",
            "Epoch 859/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3637 - accuracy: 0.8774 - val_loss: 0.3632 - val_accuracy: 0.8765\n",
            "Epoch 860/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3636 - accuracy: 0.8779 - val_loss: 0.3630 - val_accuracy: 0.8782\n",
            "Epoch 861/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3634 - accuracy: 0.8782 - val_loss: 0.3629 - val_accuracy: 0.8784\n",
            "Epoch 862/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3633 - accuracy: 0.8777 - val_loss: 0.3631 - val_accuracy: 0.8762\n",
            "Epoch 863/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3633 - accuracy: 0.8776 - val_loss: 0.3628 - val_accuracy: 0.8778\n",
            "Epoch 864/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3632 - accuracy: 0.8782 - val_loss: 0.3628 - val_accuracy: 0.8814\n",
            "Epoch 865/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3631 - accuracy: 0.8783 - val_loss: 0.3627 - val_accuracy: 0.8781\n",
            "Epoch 866/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3630 - accuracy: 0.8783 - val_loss: 0.3625 - val_accuracy: 0.8770\n",
            "Epoch 867/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3629 - accuracy: 0.8777 - val_loss: 0.3623 - val_accuracy: 0.8786\n",
            "Epoch 868/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3628 - accuracy: 0.8780 - val_loss: 0.3623 - val_accuracy: 0.8794\n",
            "Epoch 869/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3627 - accuracy: 0.8784 - val_loss: 0.3624 - val_accuracy: 0.8763\n",
            "Epoch 870/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3626 - accuracy: 0.8781 - val_loss: 0.3621 - val_accuracy: 0.8779\n",
            "Epoch 871/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3625 - accuracy: 0.8784 - val_loss: 0.3624 - val_accuracy: 0.8820\n",
            "Epoch 872/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3625 - accuracy: 0.8781 - val_loss: 0.3620 - val_accuracy: 0.8795\n",
            "Epoch 873/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3624 - accuracy: 0.8784 - val_loss: 0.3618 - val_accuracy: 0.8782\n",
            "Epoch 874/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3622 - accuracy: 0.8782 - val_loss: 0.3620 - val_accuracy: 0.8763\n",
            "Epoch 875/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3622 - accuracy: 0.8786 - val_loss: 0.3618 - val_accuracy: 0.8801\n",
            "Epoch 876/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3620 - accuracy: 0.8781 - val_loss: 0.3615 - val_accuracy: 0.8788\n",
            "Epoch 877/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3620 - accuracy: 0.8784 - val_loss: 0.3616 - val_accuracy: 0.8773\n",
            "Epoch 878/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3619 - accuracy: 0.8787 - val_loss: 0.3621 - val_accuracy: 0.8737\n",
            "Epoch 879/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3618 - accuracy: 0.8783 - val_loss: 0.3615 - val_accuracy: 0.8814\n",
            "Epoch 880/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3617 - accuracy: 0.8785 - val_loss: 0.3616 - val_accuracy: 0.8805\n",
            "Epoch 881/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3617 - accuracy: 0.8783 - val_loss: 0.3612 - val_accuracy: 0.8785\n",
            "Epoch 882/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3616 - accuracy: 0.8784 - val_loss: 0.3610 - val_accuracy: 0.8806\n",
            "Epoch 883/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3614 - accuracy: 0.8783 - val_loss: 0.3610 - val_accuracy: 0.8798\n",
            "Epoch 884/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3614 - accuracy: 0.8786 - val_loss: 0.3609 - val_accuracy: 0.8781\n",
            "Epoch 885/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3612 - accuracy: 0.8785 - val_loss: 0.3610 - val_accuracy: 0.8765\n",
            "Epoch 886/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3612 - accuracy: 0.8785 - val_loss: 0.3607 - val_accuracy: 0.8789\n",
            "Epoch 887/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3611 - accuracy: 0.8782 - val_loss: 0.3608 - val_accuracy: 0.8824\n",
            "Epoch 888/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3610 - accuracy: 0.8787 - val_loss: 0.3606 - val_accuracy: 0.8797\n",
            "Epoch 889/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3609 - accuracy: 0.8787 - val_loss: 0.3605 - val_accuracy: 0.8817\n",
            "Epoch 890/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3608 - accuracy: 0.8789 - val_loss: 0.3604 - val_accuracy: 0.8776\n",
            "Epoch 891/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3607 - accuracy: 0.8790 - val_loss: 0.3605 - val_accuracy: 0.8799\n",
            "Epoch 892/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3606 - accuracy: 0.8787 - val_loss: 0.3602 - val_accuracy: 0.8812\n",
            "Epoch 893/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3605 - accuracy: 0.8792 - val_loss: 0.3601 - val_accuracy: 0.8816\n",
            "Epoch 894/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3604 - accuracy: 0.8789 - val_loss: 0.3602 - val_accuracy: 0.8770\n",
            "Epoch 895/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3604 - accuracy: 0.8792 - val_loss: 0.3599 - val_accuracy: 0.8816\n",
            "Epoch 896/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3603 - accuracy: 0.8790 - val_loss: 0.3598 - val_accuracy: 0.8785\n",
            "Epoch 897/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3602 - accuracy: 0.8791 - val_loss: 0.3600 - val_accuracy: 0.8763\n",
            "Epoch 898/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3601 - accuracy: 0.8788 - val_loss: 0.3597 - val_accuracy: 0.8827\n",
            "Epoch 899/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3600 - accuracy: 0.8795 - val_loss: 0.3601 - val_accuracy: 0.8752\n",
            "Epoch 900/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3599 - accuracy: 0.8794 - val_loss: 0.3595 - val_accuracy: 0.8788\n",
            "Epoch 901/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3599 - accuracy: 0.8794 - val_loss: 0.3594 - val_accuracy: 0.8792\n",
            "Epoch 902/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3597 - accuracy: 0.8792 - val_loss: 0.3595 - val_accuracy: 0.8824\n",
            "Epoch 903/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3597 - accuracy: 0.8792 - val_loss: 0.3592 - val_accuracy: 0.8803\n",
            "Epoch 904/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3596 - accuracy: 0.8788 - val_loss: 0.3591 - val_accuracy: 0.8806\n",
            "Epoch 905/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3594 - accuracy: 0.8792 - val_loss: 0.3591 - val_accuracy: 0.8827\n",
            "Epoch 906/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3593 - accuracy: 0.8795 - val_loss: 0.3589 - val_accuracy: 0.8801\n",
            "Epoch 907/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3593 - accuracy: 0.8789 - val_loss: 0.3589 - val_accuracy: 0.8819\n",
            "Epoch 908/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3592 - accuracy: 0.8796 - val_loss: 0.3588 - val_accuracy: 0.8826\n",
            "Epoch 909/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3591 - accuracy: 0.8798 - val_loss: 0.3590 - val_accuracy: 0.8763\n",
            "Epoch 910/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3590 - accuracy: 0.8797 - val_loss: 0.3587 - val_accuracy: 0.8806\n",
            "Epoch 911/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3589 - accuracy: 0.8798 - val_loss: 0.3585 - val_accuracy: 0.8799\n",
            "Epoch 912/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3589 - accuracy: 0.8797 - val_loss: 0.3585 - val_accuracy: 0.8778\n",
            "Epoch 913/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3587 - accuracy: 0.8796 - val_loss: 0.3583 - val_accuracy: 0.8808\n",
            "Epoch 914/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3587 - accuracy: 0.8798 - val_loss: 0.3583 - val_accuracy: 0.8824\n",
            "Epoch 915/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3586 - accuracy: 0.8797 - val_loss: 0.3581 - val_accuracy: 0.8798\n",
            "Epoch 916/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3585 - accuracy: 0.8798 - val_loss: 0.3583 - val_accuracy: 0.8820\n",
            "Epoch 917/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3584 - accuracy: 0.8797 - val_loss: 0.3582 - val_accuracy: 0.8834\n",
            "Epoch 918/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3583 - accuracy: 0.8798 - val_loss: 0.3582 - val_accuracy: 0.8770\n",
            "Epoch 919/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3582 - accuracy: 0.8800 - val_loss: 0.3579 - val_accuracy: 0.8793\n",
            "Epoch 920/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3581 - accuracy: 0.8798 - val_loss: 0.3577 - val_accuracy: 0.8804\n",
            "Epoch 921/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3580 - accuracy: 0.8797 - val_loss: 0.3577 - val_accuracy: 0.8800\n",
            "Epoch 922/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3579 - accuracy: 0.8802 - val_loss: 0.3581 - val_accuracy: 0.8758\n",
            "Epoch 923/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3579 - accuracy: 0.8796 - val_loss: 0.3575 - val_accuracy: 0.8802\n",
            "Epoch 924/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3577 - accuracy: 0.8795 - val_loss: 0.3576 - val_accuracy: 0.8794\n",
            "Epoch 925/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3577 - accuracy: 0.8804 - val_loss: 0.3574 - val_accuracy: 0.8828\n",
            "Epoch 926/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3575 - accuracy: 0.8803 - val_loss: 0.3574 - val_accuracy: 0.8780\n",
            "Epoch 927/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3575 - accuracy: 0.8797 - val_loss: 0.3571 - val_accuracy: 0.8809\n",
            "Epoch 928/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3574 - accuracy: 0.8802 - val_loss: 0.3571 - val_accuracy: 0.8806\n",
            "Epoch 929/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3574 - accuracy: 0.8803 - val_loss: 0.3570 - val_accuracy: 0.8832\n",
            "Epoch 930/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3573 - accuracy: 0.8801 - val_loss: 0.3569 - val_accuracy: 0.8809\n",
            "Epoch 931/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3572 - accuracy: 0.8800 - val_loss: 0.3571 - val_accuracy: 0.8777\n",
            "Epoch 932/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3571 - accuracy: 0.8804 - val_loss: 0.3567 - val_accuracy: 0.8824\n",
            "Epoch 933/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3570 - accuracy: 0.8807 - val_loss: 0.3569 - val_accuracy: 0.8773\n",
            "Epoch 934/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3569 - accuracy: 0.8802 - val_loss: 0.3569 - val_accuracy: 0.8779\n",
            "Epoch 935/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3568 - accuracy: 0.8806 - val_loss: 0.3568 - val_accuracy: 0.8770\n",
            "Epoch 936/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3567 - accuracy: 0.8803 - val_loss: 0.3566 - val_accuracy: 0.8784\n",
            "Epoch 937/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3566 - accuracy: 0.8800 - val_loss: 0.3564 - val_accuracy: 0.8841\n",
            "Epoch 938/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3565 - accuracy: 0.8806 - val_loss: 0.3564 - val_accuracy: 0.8783\n",
            "Epoch 939/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3565 - accuracy: 0.8805 - val_loss: 0.3563 - val_accuracy: 0.8799\n",
            "Epoch 940/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3564 - accuracy: 0.8807 - val_loss: 0.3560 - val_accuracy: 0.8807\n",
            "Epoch 941/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3562 - accuracy: 0.8803 - val_loss: 0.3561 - val_accuracy: 0.8791\n",
            "Epoch 942/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3562 - accuracy: 0.8803 - val_loss: 0.3560 - val_accuracy: 0.8839\n",
            "Epoch 943/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3561 - accuracy: 0.8810 - val_loss: 0.3558 - val_accuracy: 0.8816\n",
            "Epoch 944/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3561 - accuracy: 0.8809 - val_loss: 0.3559 - val_accuracy: 0.8845\n",
            "Epoch 945/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3559 - accuracy: 0.8804 - val_loss: 0.3556 - val_accuracy: 0.8831\n",
            "Epoch 946/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3559 - accuracy: 0.8812 - val_loss: 0.3555 - val_accuracy: 0.8817\n",
            "Epoch 947/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3558 - accuracy: 0.8809 - val_loss: 0.3556 - val_accuracy: 0.8844\n",
            "Epoch 948/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3557 - accuracy: 0.8808 - val_loss: 0.3557 - val_accuracy: 0.8848\n",
            "Epoch 949/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3556 - accuracy: 0.8812 - val_loss: 0.3553 - val_accuracy: 0.8810\n",
            "Epoch 950/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3556 - accuracy: 0.8808 - val_loss: 0.3552 - val_accuracy: 0.8834\n",
            "Epoch 951/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3555 - accuracy: 0.8808 - val_loss: 0.3551 - val_accuracy: 0.8819\n",
            "Epoch 952/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3554 - accuracy: 0.8810 - val_loss: 0.3551 - val_accuracy: 0.8847\n",
            "Epoch 953/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3553 - accuracy: 0.8814 - val_loss: 0.3550 - val_accuracy: 0.8807\n",
            "Epoch 954/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3552 - accuracy: 0.8809 - val_loss: 0.3550 - val_accuracy: 0.8799\n",
            "Epoch 955/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3551 - accuracy: 0.8810 - val_loss: 0.3548 - val_accuracy: 0.8823\n",
            "Epoch 956/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3550 - accuracy: 0.8812 - val_loss: 0.3548 - val_accuracy: 0.8844\n",
            "Epoch 957/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3549 - accuracy: 0.8816 - val_loss: 0.3549 - val_accuracy: 0.8819\n",
            "Epoch 958/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3548 - accuracy: 0.8810 - val_loss: 0.3545 - val_accuracy: 0.8828\n",
            "Epoch 959/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3548 - accuracy: 0.8813 - val_loss: 0.3545 - val_accuracy: 0.8809\n",
            "Epoch 960/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3547 - accuracy: 0.8815 - val_loss: 0.3545 - val_accuracy: 0.8794\n",
            "Epoch 961/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3546 - accuracy: 0.8813 - val_loss: 0.3544 - val_accuracy: 0.8813\n",
            "Epoch 962/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3545 - accuracy: 0.8815 - val_loss: 0.3543 - val_accuracy: 0.8823\n",
            "Epoch 963/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3544 - accuracy: 0.8813 - val_loss: 0.3543 - val_accuracy: 0.8813\n",
            "Epoch 964/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3544 - accuracy: 0.8813 - val_loss: 0.3541 - val_accuracy: 0.8827\n",
            "Epoch 965/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3543 - accuracy: 0.8815 - val_loss: 0.3541 - val_accuracy: 0.8849\n",
            "Epoch 966/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3542 - accuracy: 0.8815 - val_loss: 0.3540 - val_accuracy: 0.8850\n",
            "Epoch 967/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3540 - accuracy: 0.8819 - val_loss: 0.3538 - val_accuracy: 0.8816\n",
            "Epoch 968/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3541 - accuracy: 0.8814 - val_loss: 0.3540 - val_accuracy: 0.8792\n",
            "Epoch 969/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3539 - accuracy: 0.8815 - val_loss: 0.3536 - val_accuracy: 0.8821\n",
            "Epoch 970/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3539 - accuracy: 0.8815 - val_loss: 0.3536 - val_accuracy: 0.8837\n",
            "Epoch 971/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3538 - accuracy: 0.8817 - val_loss: 0.3535 - val_accuracy: 0.8817\n",
            "Epoch 972/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3537 - accuracy: 0.8816 - val_loss: 0.3534 - val_accuracy: 0.8828\n",
            "Epoch 973/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3536 - accuracy: 0.8817 - val_loss: 0.3538 - val_accuracy: 0.8783\n",
            "Epoch 974/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8814 - val_loss: 0.3536 - val_accuracy: 0.8857\n",
            "Epoch 975/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3535 - accuracy: 0.8818 - val_loss: 0.3532 - val_accuracy: 0.8850\n",
            "Epoch 976/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3534 - accuracy: 0.8817 - val_loss: 0.3535 - val_accuracy: 0.8791\n",
            "Epoch 977/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3533 - accuracy: 0.8816 - val_loss: 0.3531 - val_accuracy: 0.8839\n",
            "Epoch 978/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3532 - accuracy: 0.8821 - val_loss: 0.3529 - val_accuracy: 0.8823\n",
            "Epoch 979/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3531 - accuracy: 0.8818 - val_loss: 0.3529 - val_accuracy: 0.8829\n",
            "Epoch 980/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3531 - accuracy: 0.8821 - val_loss: 0.3528 - val_accuracy: 0.8837\n",
            "Epoch 981/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3530 - accuracy: 0.8819 - val_loss: 0.3527 - val_accuracy: 0.8824\n",
            "Epoch 982/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3529 - accuracy: 0.8822 - val_loss: 0.3527 - val_accuracy: 0.8845\n",
            "Epoch 983/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3528 - accuracy: 0.8820 - val_loss: 0.3527 - val_accuracy: 0.8861\n",
            "Epoch 984/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3527 - accuracy: 0.8824 - val_loss: 0.3527 - val_accuracy: 0.8800\n",
            "Epoch 985/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3526 - accuracy: 0.8826 - val_loss: 0.3528 - val_accuracy: 0.8788\n",
            "Epoch 986/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3525 - accuracy: 0.8824 - val_loss: 0.3528 - val_accuracy: 0.8781\n",
            "Epoch 987/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3525 - accuracy: 0.8823 - val_loss: 0.3523 - val_accuracy: 0.8840\n",
            "Epoch 988/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3524 - accuracy: 0.8823 - val_loss: 0.3524 - val_accuracy: 0.8859\n",
            "Epoch 989/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3523 - accuracy: 0.8826 - val_loss: 0.3521 - val_accuracy: 0.8838\n",
            "Epoch 990/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3522 - accuracy: 0.8823 - val_loss: 0.3522 - val_accuracy: 0.8860\n",
            "Epoch 991/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3521 - accuracy: 0.8827 - val_loss: 0.3520 - val_accuracy: 0.8812\n",
            "Epoch 992/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3520 - accuracy: 0.8823 - val_loss: 0.3519 - val_accuracy: 0.8809\n",
            "Epoch 993/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3520 - accuracy: 0.8826 - val_loss: 0.3517 - val_accuracy: 0.8845\n",
            "Epoch 994/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3519 - accuracy: 0.8825 - val_loss: 0.3517 - val_accuracy: 0.8818\n",
            "Epoch 995/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3518 - accuracy: 0.8824 - val_loss: 0.3523 - val_accuracy: 0.8771\n",
            "Epoch 996/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3517 - accuracy: 0.8824 - val_loss: 0.3516 - val_accuracy: 0.8824\n",
            "Epoch 997/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3517 - accuracy: 0.8826 - val_loss: 0.3514 - val_accuracy: 0.8834\n",
            "Epoch 998/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3516 - accuracy: 0.8828 - val_loss: 0.3513 - val_accuracy: 0.8836\n",
            "Epoch 999/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3515 - accuracy: 0.8827 - val_loss: 0.3513 - val_accuracy: 0.8822\n",
            "Epoch 1000/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3514 - accuracy: 0.8825 - val_loss: 0.3512 - val_accuracy: 0.8826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = network.predict(xtest_std)"
      ],
      "metadata": {
        "id": "RrUIPDfdM5wB",
        "outputId": "e49087d4-45f8-4323-b036-eee83064678d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat.shape)"
      ],
      "metadata": {
        "id": "GJWR1M7LN6rv",
        "outputId": "419f9f44-814c-46af-f136-a361b5983942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytest.shape)"
      ],
      "metadata": {
        "id": "pFXuFm6HPG0g",
        "outputId": "666dc15a-e048-4a7c-98a9-29e40015ef09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat =np.argmax(yhat, axis = -1)\n",
        "ytest = np.argmax(ytest, axis= -1)"
      ],
      "metadata": {
        "id": "V162us36U6Ij"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = accuracy_score(ytest,yhat)\n",
        "cm = confusion_matrix(ytest,yhat)\n",
        "print(f\"El grado de precisión de los datos son los siguientes {100*precision}\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "yXPBisYxORs_",
        "outputId": "81610ea4-3a02-4b5c-8005-f2ab5e88b3ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El grado de precisión de los datos son los siguientes 88.26\n",
            "[[11275   222   392]\n",
            " [  511  3257    24]\n",
            " [ 1194     5  3120]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función logarítimica\n",
        "\n",
        "#Función logarítimica\n",
        "\n",
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "font1 = {'family':'serif','color':'blue','size':15}\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "plt.title(\"Gráfica de Aprendizaje del Modelo Sigmoide\", fontdict = font1)\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"accuracy\"])\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_accuracy\"], linestyle = \"dotted\")\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "#plt.xlabel(\"Epochs\")\n",
        "\n",
        "ax.set_xlabel(\"Epochs\", fontdict = {'fontsize':14, 'fontweight':'bold',\n",
        "                                    'color':'tab:blue'})\n",
        "\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "JbkIxANdZHMB",
        "outputId": "46d4ae9b-5b9d-4bde-b1e7-e023640f49bd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHPCAYAAAC7lGWmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACEO0lEQVR4nO3dd3hURdsG8Ht7eoH0ECD03iGEItKbCNgBARFRET5RbKAUsYCvvi9iRxSwC6JY6YYmEnrvndDSCOltszvfH8MmWXYTkpDsSbL377pyJXvK7HNmd88+mTMzRyWEECAiIiJyImqlAyAiIiJyNCZARERE5HSYABEREZHTYQJERERETocJEBERETkdJkBERETkdJgAERERkdNhAkREREROhwkQEREROR0mQNXI9OmASgUsWaJ0JERERJWbirfCqB727QMiIoCXXgLmzlU6GiIiosqNLUAVJCcH+PxzYPBgIDQUMBgANzegXj3gnnuAefOAAwfK57ny8oDHHwfuvx94++3it/33X6B/fyAwEHBxAcLDgTFjgIQEoH59oFMnwGgsn7gqyqOPypYuy48j7dsnnzM0FDCZHPvclUVennX9P/aY7TZDhgDBwcDJk46N7d13AU9PYNkyxz5vSeqkNMpS1ubN1vupVMDHH5ds3w8+sN23vP39t3X5X31V9rJuPdY7Kaukdu+W557wcHnu9PQEGjYE+vYFZs4E1qyx3Uep92NFOX4cCAoChg4t2fZffmn9Om3eXKHhlRoToAqwcyfQqJFMRoYOBaKjgbQ04OxZmRTl5gKvvgq0bStPPHfqnXcAd3d5EijuxHXmDNCvH3DjBrBjB5CSImP89lsgMxOIjQUuXpTxVWbffQcIAdSp4/jnXrxY/r561f4JzxlotbL+N20qeptz52RSnZTkuLgA+f5NTwcuXXLs85akTkqjLGXdfbftfu+8I/8ZK05OjvyiLvzcFXFdoE8fWe7s2XdeluVYy6Oskvj2W6BzZ+DyZeCbb+S58to1YOVKoFkz4K23gEGDbPdT6v1YUZKTgcRE+V1SEk88IV+nsWMrNKwyYwJUzvbsAXr2BFxdgb17gSefBGrXBvR6+R9x377AunXAI4/I7cujtWXGDNmy4+JS/Hbr1slEZ/Ro+V+MwQCMHCmz+jp15If77FmZTJGt7Gzghx+AmjXlY0syRLb27pVfEJGRjn3ejz+WXzYvveTY562MwsOBK1eAL74ofrsvvpDnJ7IvMxOYNAnw8gL++gvo3h3w8QE8PICWLeU/sU89ZX/f6vZ+jIyUn+u9e5WOpHwwASpHeXkyscnKAj79FPD3t7+dSgUsWABoNA4NDwkJ8renp/XyJk3kb19f+aEm+375Rf62XFb46y8gLk65eCozF5ei3/8VSaUCatVy/PNWRq++Kn8X1wqUmwv85z/AtGmOi6uqOXJEtuA3aFD0+XHsWNmt4FbV8f3o73/7f7arCiZA5einn2QLSp06QK9exW8bGAh88gnQpUvBsqeftr5eeuaMvETVsCGg01n3Bzh3Dnj9ddks6+8vW3MaNACef15e4irMcr18zhz5eNy4gud4/XX5U/h5L1ywjTcxEXjxRfkcBoOMv1MnuezIkYLthACWLwcefljG7eIiE6s+fYDVq0tTmwU++wxo0UKWFRQEjB8v4ynOhQuy+TUsTMYbHAyMGAEcPVq2GADZ4vPII7Kvlb+/THi/+cb+tnXrFtTn3XfL/l733gvUqCFbB9u1k5fyClu2zLZfw88/y3p2d5fL6tYt2F4IYOlS+V+Zp6fcpl07mVzn5VmX7eJiHc+5c8CwYfI/WXd3+foUfh0Li4+XLZmWfmPNm8sE357i+mZcuGDbz+TWn86dC7aPjZWXZu66S75+er38bE2YIFsrC0tMvH2/GaMReP99eenZzU3+R9+lC/D11/aPpTilqZPC/vhDnht8fOT7oFkz+bnMyCh9DLczduztW4EWL5Z127//7ctbvVpeQq9RQx5zo0bAyy8D16/b3/7AAXlZyMtLvj+7dweioop/jvJ8jQD5GeveXZbj6ipbbN56S7bqlJSXl/x98mTRxxoZKd+vhZXk/Th3bsE5NSREvqfi4633HTZMbm/vMzxkiKzbwED5uUhLk9t++y3QtKncp1kzeamuKNHRwPDhQECAjKNuXflddOtlu8ceu30fsU2bgB495DnFxwcYMADYv7/o5wbkJcLZswvi9fEBeveW/2BWOEHlZtQoefX8oYfurJwePWQ5AwcK8dZbQly7JkRMjBDNmgkxdqzc5pVXhNDrhfjiCyFu3BAiOVmIP/8UolYtIZo2FSI93bbc2bNluUuXFv+8589bLz93TojatYUICRFizRohsrKEuHJFxgYI0bp1wbZZWXJZ795CHD4sH589K8STT8rlixeXri6ef17uN2KEEBcvyvJ+/VWIbt2ECAyU6261e7cQvr5C1KsnxD//CJGTI8ShQ0JERgrh5ibEli2li0EIeQwqlRA7d8rHzz0nn7tJk6L3OX9ebhMWJl+Tv/8WIjtbiDNnhBg0SK6bO9d2P8vr1L+/EA8+KMSpU0KkpAgxcqQQdeoUbDd6tNzu5ZeFSEiQ23z0kRAajRBDhghhNtuPp0ULIXr2FCI6Woi0NCH++ksIT08hQkOFyMy03uf6dSEaNJDvtaVL5fsqNlYef+/esjzLe9LeMRR+r1me/1ZXrwoRECDrd+3aguWffSaXzZ0rRHy8jHXTJiGaNxciKEi+B2+1aZP9mHJyZLxqtRD/+5+sq4QEIWbOlNtPmmRbVlHKWiczZsh1o0cLcfmyEBkZQvz4oxDu7kJ07Ghb90Udy+1Y9hNCnh8A+dpmZ1tvl5srP9d//FHw2hT1jfD663Ldk08KcemS/ByuWiU/g3XrCnHhgvX20dHys1anjvy8ZWcLcfy4EH37CnH33fbPQ2V5jYo7p40bJ9fNmiXfP+npQnz/vazvtm3lObMkjEZ5XrWc61atEsJkKtm+xb2G990n102dKkRcnHx/L14sRJs2cnnhz7qF5XVq2VJ+P+zfL+vp44/l8qFDhfj2WyHefVeIxERZ561ayXPCgQO25S1eLNcNHSrE6dPyddq2TYhGjYSoWVOIvXtt96lTx/77ZOVKWVbr1kLs2yfL2rNHiC5dhOjcWe6zaZP1PklJMj4XFyG++UZ+Ji5fFmLCBLn9e+8VV7t3jglQOWrfXr5oL7xwZ+VYEpExY6yXf/edEJ9+Kv/+4AMh5syx3XflSrnvggW268qaAHXtKpf//bftPo8+ap0A5eTID3BcnPV2ZrPczs9PiLw8+89/q+3b5fM2bChPQoV9+qn9E3ZurhDh4XL55s3W62JihNBq5Qf41vJu57XXZAJqcfBgwfP/84/9fQp/qaxebb0uI0N+eWg0Qhw7Zr3O8jqFh1vX1b59QkyeLP/+8ku5zd132z7vU0/JdV98UXQ8u3ZZr5s4US7//Xf7Zdl7r3XqVLoE6OJFIby9rbczmWQyBggxbZr1uhUr5PPfat8+uf1zz9muK+oLx5J8PPaY7T79+8t1GzbYrrOnLHWyYYNcXr++7ft/3jy57rXXSnYst1M4ASr8efjwQ+vtFi2Sn1Uhik+AoqLk8q5dbdetWSPX3XVXwTKzWSb8gO0/G4mJQri62j8PleU1KuqctnixXD5ypG1Zn31m//xanFWrhDAYCuooIEDGuWyZTECKUtRr+OOPcnnPnrb7vPzy7RMgwDahadFC/sMwbpz18uXLCxKtwo4fF0KnkwlsTo71uqNHZVn169ueK+0lQOnpMmHSaOQ/i4UdOSLLspcAPfqoXP7669bLzWb5z6VWK+OsKEyAylGDBvLFnDHjzsqxJCJr1pR+37Nn5b7332+7riwJ0N69cllwsP19tm+3/0Vgj6XF4vDhkm1v+S/g1Vdt16Wm2j9h//KLXNa4sf0yLf+hr1pVshiEkF9YoaHyv6rC2rYt+oQtRMHJys/P/vqnny5owSnM8jq98krRMbVsKbf58Ufbdf/8I9d17Gg/ntBQ230+/ND2P67cXPlfPCBboYrap6QJkD2W7bp2LXlSajLJfdq3t11n7wsnL0+2CAKyZeJW334r1z344O2fu6x1MmSIXD5vnu0+ly4VfKne7lhKonACJERBK1BISEErkNEov/h+/lk+Li4Buvdeufyzz2zXmc0FLbH79sll//5b8Hz2WFo+Cr83yvoaFfU+a9Wq6HNoaqr8otZoZAtTSZ0+LcQTTwjh41NQV4BMjB57rHQtkn37yuWLFtnuc+jQ7ROgsDDbdZZ6vbWV3fLP2uDB1suffbb480zHjnL9ypXWy+0lQN9/L5d16WK/rHbtbBOg+Hj5GgDyKset3nxTrnvpJftllgf2ASpH3t7yd3HXlwtfx73dfBu1axe9LjdXzrEQGSmv/1rKql9fri+v4cc7dsjflo7St4qMBGbNsl52/LjsZ9Sokbzubont229LF5tlpIG95/b0lH0Rioq3bVv7ZVrqdNeuksUAAGvXyuv7o0dbLx83Tv5esaLg2ntxz3mrpk3l7337SrdfRgZw+LD8295xWvY7cMD+KMPQUNtlls6dhfuinDgh38tareyncKvC/ZHKYtMm4M035ev444/yeQoTQtZtz54yZo1Gvo8sgwdK+j46eVL2i1OrgdatbdeX5j1R1jop7n0ZEiLLi4+33//uTln6Al29CixaJJd9843sp3HffbffPzpa/m7WzHadSlXwPrZsV9znFrBfR+X5GmVkAIcOFR2zp6fsG2gyle480KCB7EsVHy/7Mln6RObkyL5uHTsW3UfoVsXVUUk+V8HBtsssg1tuXWfpw3RrP7PiXldA9msrvF1xyvKa794tX4OgIPlzq7Kcq0uLCVA5srz4Fy8WvU12tjyxnz9/+/Lc3IpeN3y47PTWsKEcAp+XZ12u2VzyuItj6VBd0tFh//wjT/KrVskOrLGxBf8rWeaCKGlsKSnyd1HD8m8dzVY43ls7FFt+li6V60szemvxYtmZ79YP6ciRsmNuRkbxE53ZixMoOK7kZPvri3r9C2/fpIntMVrmRzIa7ScJrq62yyyJuBAFyyz1b0lib1XUcZVEfDwwapR8L3z1lfxCutWkScBDD8l/Gtatk6MrLe8loOTvI8t7wmyWdXprffXoIdeX5D1R1jqxxDBggO3zazQFndYrYlShTmc9IiwjQ3a+fe21kk14eLtzgGW5Zbs7+dyWx2tU+PNR0phLQ6eTHdnfew84fVr+gxQQIBPM998vWRnF1VFJPlf2PsO3W1f4sw2U/nUtzp285rGx9s/Vlu+LihxpywSoHA0eLH9HR5dfAmJPdLQckeHvL7+cGzSouCH1vr7yd3p6ybZ/6y35H9Frr8nRC5ZWsbLw8ZG/ixohY6/VxRLv448XbqS2/fnss5LFEB8vRyOsWmX7AfXzK5g0srg5gYpqHbIcl+U4S6rw9jExxR+nvaG5pX2erCz77+fiWr2KI4RsTbt2TY5aHDLEdpurV4GFC2WLwA8/yFGAZZ2rxvKe0Onkf5xF1VVW1u3LKmudWGLYurX41ysiotSHVyKFW4EGDZLni4cfLtm+tzsHWJZbtruTz215vkalibk42dlydGNRz92/vxxJCwAHD96+vMIx2qujsn6uSqu0r2tx7uQ1r1ev+M/E8eO3f/6yYgJUjh58UCYjV68Cf/5Zcc9jaeUJD5cnjMJKcoIoDcuw5KLehIcPy2HXlue1xNaoke22pY2tffuinzs93X7rhiXeolrYjEb5H1tJZ2b95hvZ8mNpYbv1Z8sWud3OnUUPsY+Jsb/82DH523KcJeXuLofzAkUf5/Hjdz4rcePG8rny8uzP/FpcS2dx5s0D1q+Xw/v/85+C5SZTwVDiCxdk/fr52Z6AS/s+atxYlmE02g6ft9i3r+Ay1e3KKkud3O59eeGCbOWqqH+cCrcCbd0q/1aX8Oxvid3e+7vwF5Rl0kvL+/nECfvl2auj8nyNCn8+7MWcliY//xqNfA/eTmysvAxb3KUYy2Vlg+H25QHFn9vK+rkqreJe18LLSzKZaXHHA9g/po4d5Wtw+bLttB0W//5b8qSyLJgAlSOtVvZlcHUFnn22+C/ZO7mPlOXa6OnTtv2N/vmn7OXa064d0K2bPAnYm8PjtddkkmBpdrXEduubNjdXJgml8fjj8vfPP9t+QG6dQ8diyBCZGG7dav8L6ptvZEtdSWfgXrxYzolRVAvbXXcBrVoVbGtPYqL8cissMxP47TdZblnuGzVlStHPmZMj66GoOYpKSqeT94kD5Pv6VkW9BsX5918554e3t7xsWDiBv3SpoP+C5X2UkCBbigor7Xtco5GX0wD79XX9urykcetrZE9Z6+TZZ+XvJUts1wkhy3znnZInJWUxdqz8LHfrJi8/lpQl9m++sb2MsnatvETRrVtB/6bOnWX/katXC/5BsEhKsn8LmfJ8jYCCz4e9+YO++06ef0eMkAl2SRV3mdtyTP36lays8ePl7/L6XJXFxIny/bx8ue1EmceOybsahIfLe1feztChsi537ZLzExV2/Lj9fo7+/vI1yM0t6B9a2MmT8tJned0z066K61/tvKKj5bwRgYFyVMi5c3L0SFqanKPmjTfkCAlAiO7dbfcvaji6hdkse9sDQgwfLkcnpKXJ3vo1a8rlPXrY7ncn8wCFhcnRQ2vXyjlALl2SwypdXOSoD4vVq+WQRy8vIX76SY64OHdOiIcfLnooZHFefFHuM3Jkwfwjv/8u54KxjBq5lWUeoAYNZLw3bsgRB599Jofg2pt7x55//5UjPOLji9/u888LRnsVHk5qGbHRrJmcg2jjRrn+7Fk5IgMQ4u23bcsr6QiqMWNknb74ohyRlJkpR+316SPnQLp0yXp7Szz23htLl8p1s2dbL09KknOCGAxCfPWVHL4fFydf++bNSzcKLDGxYD6VL7+Ur0vhH8toFYtHHpGPu3WTI2PS0+WQbMuwbnujZG43D5BeL8Q778h5azIyhNi6VY5Q6dix+OHM5VEnhecBOnpUvl7HjsnjrFlTHmNJjuV2bh0FVhK3mwfIEvv48fJ9lZ0tP+tBQXIuoVvPGTt3yvl2LPMA5eQIcfKkfG82a2b//V2W16i4z4pl1OmMGfIznJEhxA8/COHhIUeJJSWVvm6efrpg7p3UVDkUfdIkua53b9uRjMW9hg8+KNdNnVowT9HSpQXnhuJGgdn7DI8da//8Wtw+ixbJeZeGDJHfIzk58rzXuLE8h+7ebbtPUfMA/f67HNXVpo2so5wceT7q2FF+XuzFZpkHyNNTxnLliqzXVavkOWzwYPndWVGYAFWQzEwhPvlEiH79ZCKk08kv39BQIXr1kpN7WYaNWlg+zLf+2EsYUlPlvCmWE3HNmkIMG1YwDNzys3RpwYfw1h/LB6yo5y0sIUF+UOvXlyeo4GD5fLcegxBy/p1evWRMBoM84c2bJ5OYW5+7JBYulF8ser0s84EH5GSClg8iYDsk+sIFOV9L7dqy7oOC5NDTP/4o2XNakkHLz62JgUXhGCw/lpNd4RPP+fPyhGepkzZt5NDewop6nYp6biHk5GFdu8oTiJubnDvj5ZflxHy3i9PypWHvOQt/ocXHywnwAgLka9CggZz6YP16630++qjoY9i0Sc5dVfzVfuv3XU6OEP/5j3z/uLjIOYT69i2Yl8Ze/RT3hZObK2No317WlZeXnE7grbdKnvyUpU4K++sveQw+PvKY6teXczCdO2e9XWnfB0JYf1EX9Tm253avg8Wff8oExsdHHnP9+nLOs6KGkh84ICf89PCQ9d2hg5y24dbzTeFpMUr6GhX3PrMwm4X4+mv5z6KHh/zcNW8uXyd7E8UWxWSSkwO+/ro8rzVoID9vOp08t/ftK4ee3zq/0+1ew9xc+c+Y5Zxaq5ac+DU5WW7bsKF1eUV9hu3VheX8eut5zN77aNs2OdVBzZrymMLC5BQkt05uaUmw7D2PxaZNck4oV1dZ5927y7mbbt03La1gn/R02SjQvLn8TPj6yvfKhx/azk9U3lRCCFGBDUxETuvCBdmE3KOH7ERJFS8qSt7W4/HHebNaqpos541evW5/6xC6M+wDRERVVv/+si+chaXfnWUqAKLKqlMn2c/lVpZ7YA0d6th4nBETICKqsk6eBN54Q879cu6cHJHo7V22juVEjnTsmHyf7tkjh9pfuyY7yc+YAXTtCjz1lNIRVn9MgIgqQN26shkbkCNhirojNN2Z556TIw5DQ+Vdw8PD5VDp4mZRJ6oMPvtMTrHx0ENAzZpyPpwFC4CXXpKXvko6pJ7Kjn2AiIiIyOko3gL0ySefoG7dunBxcUFERAR2FTPblNFoxBtvvIH69evDxcUFrVu3xtq1a++oTCIiInI+iiZAy5cvx9SpUzF79mzs27cPrVu3Rv/+/REfH293+xkzZuDzzz/HRx99hGPHjuHpp5/G8OHDsX///jKXSURERM5H0UtgERER6NixIz7++GMAgNlsRlhYGP7v//4P06ZNs9k+JCQEr732GiZZpgwFcP/998PV1RXf3Zw+s7Rl2mM2m3H16lV4enpCVZK7BRIREZHihBBIS0tDSEgI1LeZWl3roJhs5ObmYu/evZg+fXr+MrVajT59+iA6OtruPjk5OXBxcbFa5urqim3btpW5TEu5OYXmAr9y5QqaNWtWpuMiIiIiZV26dAm1atUqdhvFEqDExESYTCYE3nK76sDAQJwo4i56/fv3x/z583HXXXehfv36iIqKwsqVK2G6eWOtspQJAPPmzcOcOXNsln/55Zdwc3Mr7aERERGRAjIzM/HEE0/A09PzttsqlgCVxQcffIAJEyagSZMmUKlUqF+/PsaNG4cl9u4wWArTp0/H1KlT8x+npqYiLCwMw4YNg5eX152Gnc9oNGLDhg3o27cvdLfexp3KDevZcVjXjsF6dgzWs2NUZD2npqbiiSeeKFH3FcUSID8/P2g0GsTFxVktj4uLQ1BQkN19/P398dtvvyE7OxvXr19HSEgIpk2bhnr16pW5TAAwGAww2Jl0QafTVciHoKLKJWusZ8dhXTsG69kxWM+OURH1XJryFBsFptfr0b59e0QVutmJ2WxGVFQUIiMji93XxcUFoaGhyMvLwy+//IKhN+cMv5MyiYiIyHkoegls6tSpGDt2LDp06IBOnTphwYIFyMjIwLhx4wAAY8aMQWhoKObNmwcA2LlzJ65cuYI2bdrgypUreP3112E2m/Hyyy+XuEwiIiIiRROghx9+GAkJCZg1axZiY2PRpk0brF27Nr8Tc0xMjNUwtuzsbMyYMQPnzp2Dh4cHBg0ahG+//RY+Pj4lLpOIiIhI8U7QkydPxuTJk+2u27x5s9XjHj164NixY3dUJhEREZHit8IgIiIicjQmQEREROR0mAARERGR02ECRERERE6HCRARERE5HSZARERE5HSYABEREZHTYQJERERE5cuYBZjN8m+zueDvSoQJEBEREd05IeTvlCvAew2BX8YDJiOwsBvw1aCC9ZUEEyAiIiKSjFlAejxgzC75PmYTsPcr4NPOQFYycO0gkJsGHF0JLB0ExB+VSVFMdKVKgpgAEREREXDtEPB2EPDfhsC74UBmUgl3VAFb3gMSTgC/TwI0OmDgu0DbR4HLu+QmKTHA0oHA4RVA0llAKH9JTPF7gREREZGCdn0BZCQCB34oWGbMBJaPBlo/AuRmADXrA+Y8oH5v4N8FQPwxoO1ooE4XQOcK9HoN+G0icOIv4OQaYMA8oP04wOANk09taNa+IstdOQE6AOH+wwDc4/hjLYQJEBERUWWQehWIPQw07AeoVNbrLkYDG2YCfV4H6naTy4Sw3a4k0hOAC1uBX54A+s8Dtr4HZCYCdbvLlhq9JxD5DHB+K/DHLTcW7zkDOL0euLwbOPorzM3vg8rgiTyDL3SWbYQJR9cswv2mt+Cm74m7s/5Gc/VA/Gtujse169BNfRi/XfPEqvWnMX1ws9LHX06YABERETlKdirg4mV/3Re9gLRrwMPfAU3uATa+BdRsALQZAUR/LJOOrwYDoe2BK3vlPk3uATpNALzDALeagKuPXL5zEXDgO8AzBGg8EGg6RPbV0eiAnQuBf/4rt1v/GtDpSSAvG2g+HBcj30IMAqE6/ie6xUTbhPjmpnjEuY/Ax9gNAFAfXQkA0AHIFRosN/XEMM2/qIWraJh3BmeMIbhXF427NQdx3Fgbj+ZOzy9rhqe+PGq0zJgAERERVQSzGVg2QnYKfvh7ID1OPu73FtDl/+Q2WclAyiXAp45MfgCZJF3eU5Ck7P8OMBsLyrUkP4C85HTir4LHOjdg5E/AiT/l8147CJxagySPhsiJ/hzBF367JcY8bPh3J2LUoXhzWxqANABXsNPwNnCzcemqqIE95sbwRCZqiYuIueGBTuZP8LH+Q3RSn5SHIfRYahqAb/L64pO8odjo8jL+NMxAdM/lcEkajgsZrTEltDEm+nggtFkklvyyBsPahJRTRZcNEyAiIqI7ZTYBao38OzkGOPAjoNECgS2A7BTgz2dlPxpAts4ENgfCewBf3QPEHQZ6zwamHAJ86wCL7gZuXATq9QTObQIubgMG/Vd2HI47ClOjQdAc/dl+HMZM4Ot7sEbfDwMLLR7x1UEs1m/LT2oAICL7Y7RRn8Xn+vdx0XwJnfSHcF14Y5zxJTye+xImaX/Hf/MewjkRAk+DFqO0UZhm+hx3e93Akd4T0CzqfSAVSG90H9zO/IlnVH/gqY6+0Az9EFj8HXBpJyI3PQwM/xwIGwp82BbQusLY4hJC3QFvV51N+I7EBIiIiMjeRH1CAGmxgNYAuNUofv9fxgNJ54G+bwB6D2DzXMArFOg/V16+yssG4o7IS1Yn/gK+HQ7RYTxUBg+5f9QcnI9PQXLr8Wh7dT8A4H3D0xjUqBE8cuKxNi0Cp3wicNaYjj17k6DGMIzUROEt3VIAQLbQ4ZCol98iMzB3Pd4xPoIlpoFwQzbu0ezARlNbjNFuAABMzX0aDQzJiDf54wsxFBGaE2gl5L6zB7RA76a94e85Eb0AuOhuJnYxPsARgfCAZghvHQLU/gVIOg+Pn8bmt1Bp1DczrPHrgS/7yMt2enfA3V8uz8uCevuHABqU+iUqb0yAiIjIue1ZCqyfCdXDP1gv/+UJ4MjPsqNw5DMFy7++V3YY7vGSTJz+fBY4+isA4OKNbASk7oHZvTbcU2OwK0GNWn0+hd+WV6DPSsCW9BD0uFmMas9iq6fbvP843t69H4PUk3EDHvhnvwkfWLY+eQnhqmuYov0F92rdcUTURbDqOjabWmOvuSE+Vz2A3Dwz6quu4H/+q9EmdROGNdCgR2MfhF/4CUGnvgcA7Oj0EbLqD8B7R2dBc2hhQRZgmZ6n+X14rGu4/XqqHSF/LHzryp+2jwJX98l5fmp1Klj/2GrZ+qV3B/RuQKOBwKk1EC7eJXlVKhwTICIiqjxyM+Ww6pKMbrpxETixCmhxH+AZJCfx07nKdUd+ARLPAD1eti6r8Mipy3vkJaaNbwEAtN8OQXP//oC5HxB3GkY3f2hVaiD+OFLW/we56TegTzgEt8TD0J/fgvhdKxAb2g+tTn0LAJhlHIs3/nzIKkTfjdMwwvgCboi3ccjlSfS4vAj9cv6D9YZXrLbLEAaM067DOO06AMC7xofgq05HnDYYLi6ueFCzGbqsBPRHQcdks84d+4asxfPNmmF0Vh7iU3NQ+8jH8IreBLS4H00e+BSI/hS4mfwAQGccBhqPAbaesq5LzxBgyAI5Aq20Bsy1v1yrBzz8Cx4/9DWQmQShNgCx/5T+ecoZEyAiIlKWEMCeJcCqqfJx79lAh3EyQWnQR14yMmYDrR4s2Gfv17LlBQD+/UDOQ7P/OyD5khz1ZGld2TwXGLcGOLcFOPC9XNdoAERQK5iP/ArNjo9x0b0l/q7/KsYfGoEGCevw/Dvz8b54FzoAbbI/xzMH/sbj5neghoBaVTCTcUDGSQSckpeNvs7ri29M/fG89hf4qtLzt2movoL+2gP42XwXjpnroL4mFl3atsSQyyvQOHM/6gV4oH7tWvC4GIUu176BCgLCtQZe9D8EdcIJoPlweSkt+g9ZYKuHgfjjQOwhqI0Z6LCyO4AvENBsKAI8vYGzBnm5qcbN/kZZN+Rvr1ry2Bv0kY+Hfw583EH+/dRWILh1Ob2YxdAaAK9gwGi8/bYOwASIiIiUdXpDQfIDAFFzZEKUckmOnlr+qFwef1S2VHgEFCQ/Lj5Ag97I2/YRtEk3WzUKXVqK92iKbzacRqOEo7g35xKwaxEO7N2O4yIcI8x/AgBOpeqwbvcxNNC2Qg/NIbwv3s3fPxmeMBuzodWakSzcsSyvF77K64cUuOMVwy94TLUKx1APs/PG4YH2tTDh0hdo07AOnu0RAiwfA8/rB/Fq9jd4VfMNMGk38ElHvH5skPzbv1Bry94bQNRfwL0fQ9V4IFRzfORytRZocT9w7A+g/1tAs6Hy/lrH/wR+Hie3WTkBaDxIJhh3vSh/LLo+CwS1BBr2LWgdAwC/hsDrKdadt50MEyAiImcnBJB5Xc4jo1IBW96Vl5MCmsovXK1BbpeTLu/vpNIAbUZaX1q6cUHeDypiIuAZaP950mKBU+sAYQLycoCoN4HQdnJWYQvXGhBtRkIV/bEMLTs5f+BS3vZPoTXn5G/6jXo4tof+H/7v0EQ0N5/Csry7sdLUHZO0v6OWKgGbzW0wIG0XXkx/1iqMWnkxaKM6kv+4r2YfVBBwU1nf/2pF0w/wZcsOcNNHID3sK2Rm5uA+rQZNr6WhZag3aojuwJXRaOZTGxcCm9/cq1BLygSZYOH1m31eYg8BAc1kvxjfutZ102YU0GiAvJQHyKQl9jDQeoSso+cPF2yr0cnLfsGtgY/ayWWWztS3MngCze61vw5w2uQHYAJERFT1nFwrfzceIH+X5L/44mYNXj9DjlRq/5icaXjT2wXrks4X9KNZOlB+iQOAzgVoOhTITpaXZKLmyBE/5jzZKtP20YIvc4vYIwUtNxYXZF+QBNdwfOX1DGJ04fgo+gEAwAB8ijG/rEBvjQ+mG59AN/URPK5dm7/rrMwHgKOxiFeNwFf6/+CkCMMM3Xeor7qKzjmfIA1u0HvWxOis7/L3Wed5H/qnrbSpgh6hKmSP3oo/1/+FgS39oA3vhgc1OjmcfdMCoEEfePSX9RLg6XJzrwB5Wel2nvpHdpJuOgRoeq8czq69ZRJAjc66vh5dCRi8ZD0XpWZ94JEfi044qVhMgIiIqpLsFODHh+Xfr14DEk8BK58Ehi+ULQWWROf6WeCf+TIhMWbKBOnBr6zLMhnlbQ3qdgdSLssWnP7zAP+mQMJxuU2j/sC3w4FrBwr6kwDAz4/bDS/z6gm4XdiAhPOHsCL0FZxJMiI+NQf1EYOnrs1GUVPfzUm5BztvuCEFGTiqr4MAVTLWqp7J/5Zaov+v1fZfmwbgsS7h8HbVwcu1GdYY7sdAPw80/ikChqwcbOt3GblGE/wDu0KousN8eCU0vV9D/+DWQNyLwNX9wNpX5W0l6veEzjcc0GthVush6nSTCQkgL0ElnAC0xSQitxPcSv6UhkdAybZrMqj08RAAJkBERGVT1vswlZQxG8hIAHzCrJcnx8jf7v5ATiqw6OYw6S3vAve8Lx+HRQDH/7DeT6MHLm6XX+SrX5RDkmOigbNRcn3fN4Dwu2RypTUgd1ostHoXpGXnAdfOwPtm8nPSMwLH64zGsCPW94gyQoM/TJFYeaoDHtckovf539H0zAUMVV9GnPDFbnNjhGivAAD2mRtgj7kxTolamKv9EnvUrfCx/iMAQLT/g3jHsAiRNdIw5uQkeOTEId69IQIyTls939g3l9uvt0e+Adz94L39Q2DfN0DnSVANmAtN60cKtglsLn/aPnpLncvOuaqTq4ELm+VEhE3vAe79CGjxgP3noyqLCRARUWnlpMvZemtHAIPft72cYbHuNcCnthy5Y7lHk4UpDzDlyDlS7Pn1SeDY78DE7YDaABfjzdaXoJbAjAQgPVa2/ACAxiDvB3V+i7zdwi3Jj9C6QuVbF1g6EKYaDaBOvQyRcBpx3i3hr9LhFZdZuHGyExqZz2La5a24Dh+0f30jAGCK5hc8r7uUX9bhZAOmJXhhjfp59NXshRZ5SBJe+NMUicNCzh/TWX0ccXm+GKmVZYSqrqO15jzivdsgtvFotNv5Atqpz+DYE+dgDpiLCJELbP0PsO8bRI6ahUif2kB6PHDGBLQZhYCwTsCfU+T9rup2l8dalDqR8rfvzblsMhOL3rYI6u0fAFf3ylaiZvcC7caUugyq/JgAEVH1lXIFSDwphwD7N7r99kd/A3Ytkl+yPacXvd35LcD10/LHmAUknAT6zAEa9pH3cUq+KO/efbMjL1o+KO/0ff4foH5P4NIuYPkowLUG8ORmwNVXdlb9579y/z5zgIzrct+L26GNmoN+OenIGzgU0PnKhCvxtIwDQNq9X8Lo1QSxMfHIqDkUWVlZWJdSC+31MbhP/A1VXhYWJbbA/eIyaiadAQCokI3ghH+xNK8/auUeQKe0KDys3QwAqIlkvKv9HC/nPYV66mv5h50uXDBAvQtBuut4L/Bd7A8YgLeODYQK5vy+ObEPrsIV/VsI0aQA29WyFevaQWiECQHJBxBw92+A/hqQm45mtWreLFkL9J0jh7+r1XKRRwDw/FHZAVulkn1nbjcbc2FdpwC1I4GQNiXf5yZz5GSoV08Fes8q9b5UdTABIqLq68zfstNtowHAyCIumRSWdQO4+K9tq0zSefmFfHqDHBXVeBDwRJS8DPVFL9nK8P39csj237OB6zLJQL275eiq6I+Bf/5n5/mSgB8eAnLS5HMmnoLQuUHV8gGYTbkw6mtgR6wOPXLSAACn/9cPv4a+AF3GNbyc9DoA4C3jKPivWIantKPxW94AvJFX0FoRbvw2/yz/btYQfIo+2GOYCK3KjPPmQGTAFem+zfB82vs2oTUN8caCyDaonfF/yHAfD/ewNjCf3AyvDS+gm/Y4uk3uJictbPQpsO9rOZIrOwVBKwYjqNUjwH2fA3+ekaPD7p4ObJ4HdHpKJnu9Z9qvf0vyY1G4A3Bpkh9A9nmytAaVkmgyBGgxvGIvcZLimAARUcU5uxE4EyX/sy/qMlFF0rkBAc0LJoWzx2SUw7rzsmQfmPsXAzXCC4Yud30O+HdBwfaNBwGP/ADU6iBbfwa8A6x8Qq5bPsq67HOb5e/YgiHMF1o9D/WlaHgaE+GbfgZIOIEMXQ0cywlDoqkjYvNqouvCkWikugwDgNzdX2Ng3jz0Uu/HS7qf0OzSU1ZPsc7cAZ1UcjK+x7Vr4YlMHPIfjCGmvwFjFo7o78bp8EextHkXdIx+Btpz8p5XdToPhbrbVLTQuwHL98nRWN5hQKcngWb3oqVah5ZewQBC85/Ly+AJnP5NjhYD5O0N2oyQP6Y84KO2so9S3W5yfVhnmSS2HQ20GyuH2VcVTH6qPSZARFRx/pkvv1hD28tWGL3bnZW3+0vZGtN5IuBdy3pd4hngzAb5hdvyZofVZkNly0RWkuxUfOuQ4kM/yUnkChvyIbC70D2a9n1ttToTBujNArsvJKHVlifgHrMRZvcAJDQagcD9HwAAzvl2RWxqLky5WaivvopE4Y0fTL2x19wIp3fVAtARbVRn8IHuY9RRx8PdmISO2IHeee/hD/0MuKsK5rrpq9kHlc4F11U1AVNBHMkeDZDafRbWtR2MnIw0pJ5oCq91U/BgcAIeTCh0mwVdKFoMuzmD8vqY/MXqXYtkq9ZdLwHdnpd3G7/dZULPQOCxv+yv02jlcO8re2TnYUC2AhFVUkyAiKjshJ07aBdmGTp8dKW8W3bD/sCIH4ErewH/JnLytvQEefnn79eBG+eB+76QnX9D2sqhwydWAzs+BcI6yb8TjgOZScDwzwqeJzkG+CwSMOXKx/V7yUsmGp28TYIwySHensHAPQvk+rMbbeepAXApQ4WwAwX3TkLWDfykGYQ6xnOIMrXF8oM98f6JPmiMC9hnDkZ3DaDOiIfrvkXYLRqho/oU6t34F//NfRbZ0GOnsSky4GrzPNd9W2Jwxsfw0AI/i6moZbqMp+snw/1yjs22fczbsa3BdOR1eRraoz8DWgN8IifBx6c2AMBN7wu0vhf4503Z58UyhN2rFvDwtwUFPbMDSDonW+WO/Q50vNlyVb9n8a9jSbn6FNxqgaiSYwJERKWXeBr47n5ozXlA/XlymckInN8KfHcfMGyhvJzU9Vk5gubidpksGTzk0Ouv75XDux9YAnwzFHAPkB2KAeDSzoLJ8mYnA8tGyL9z04GW98sbV147UDD53+b/yPs9FbblXaS2nQCvP8bL5Mci7Rr+PXQCCX9vRrvkdXi15vsYbuqO+qorWG2KwAZzB1xb7YGmqjmYpvsRGcIFvTQH8JBpNermfg9fpOGgy5P5xb1gmohnjM/hDd1SZMEV59xao13OfJzWN8MC9RfQm7Owb2gUwhq0xLWULPi46qHTquDrpoeLrtDEhal/A/Ob4MHLb8sETe8BhHeXE+F9/yBwcRt0pkyIsAigXjf7r4lbDdlpWK2RlxyzkuRQ78JUKjl5Xs36QMST9sshchJMgIiqs7wceXNI79CC+wBlpwBb35Pz2IS0LbhcVBKn/5b3Z1o7HcjLggpA24uLoFnyPnDjnCwbAH57Wv52DwDuWwR0e05O0vfPfDnrsNkoWyIW3V0Qk1eobDH64ebdtOv3lonWTSLuOFRX9wMAzKnXsP/MZaTGX4L/3i2oBU/4IA0naj2IJpdXwLxzIeb8I/A/vdx+Sd6A/FFKGw+cwjjtOtRSJcIjZhNeME+0Ocz9oiEez5uORh5Z6JUrj6Wbyzm41m4H3LyKlNj9Tcxu9hjCarjhZGxvNIv9A65rpgAN+qLJiGXyODKvo13TRoCLAf6ehqLr1Su44O+AZnJ4vcW4VTDmZCF27frbvjz5l/i8gq3LJCIbTICIqjJx887URXXYTDgJfN5d/j1imZy2/4//k5c/LGpHylFKZ6IKEhPfukDtLnK+lXOb5Vw2ag3wywTAxVt2GAYgdO6onbTN9nk9AuV8NBnxwLfD5LKmQwouzdziYpupyG37BLD5bTRMOgsAeN19Jg58dRxPGgYgPsOMxyATgJG5r+JGjiee/HYihmv+zS/jXeND+OrMAHRVhyFMlYBcaJErNFhu6omVpm75CdBM3ffYYuiBTG0GevR+CL4JZpyMTcX97WvBz8OAjnVrwNNFC53m5oik6BuAqw++azZUXqqLWQcYM+FXvxf8bj53+zo1gNxagNYVUKllf5jRtrdbKNaTm4GEU9bJj4Wap2qi8sZPFVFVknpNdlxVa+RcMksGyPlTuvyfbF05/qfsY3N5t/wy1hT6iP/4iLyk1Py+ggQoqKWcn2bHp9bPk3EdqN0ZuLBN3uPJwrs2kBIDPPoLoPdAHrRQLx0AjZAz6KJhP2DUCpjNAmf//RkNo57I33VXghYe+lZolivvJfVU7nOYqv0Zx0VtPLejA7DjAIBBeFDjjm2mlri26yoALZ6BHNb9q6kbmqkvYru5OQCVVfLzovEpnAgago7uBkBbB5qabni4UQBOuL6EZiYznrxyBVePDULI5dVAWAR6PP47oFKhEYARt6vzyGesH9fubH+7+r2A166VffRQSFv5Q0QOwQSISCnxJ4D938oROO5+tuu/vzly566X5Q0n/3xO9uuYFgNAA2Qly/4tW96VCZAwA1f3AT/dnAfm8h5gzO/A2D/lqKb7FsnlzYcBzW9eqoo7CnxZqNNqxNOyY2xGouxMa84DNhTM2ZLZchQ2B47FP4cSsedCEgI9BbTaeTiF2riRlo6GCb5InBeFqynZGKA+ghe1IWigvgoA+OZqLfxlfhC/6mchRJWII+Zw9M991+qQtWo14uo/iKBsI7r4eaBnE38cvJSMDcfiUNO/CyYPexJP5cmO10mpm1AjYQ/Q8Qn899b5Y27Rvk4NoMuPctg6VBUzxPk2MRBR5cIEiKgsTHnArs/l0O6a9eWlqNx0OZtvUVKvAge+l/dk8mssO/cKs7xzdo+XZKfey3tk606tDkBarLzz9un1smWl+TA5eirhhBwNdWknoNYB49cDZjNQp4ssO7QDkHpZXq7xqQ341pEzG187AKx8Cug6BalNH8LmkwmokZmMbsZMAMDfLd7FPlUPuB9W4Uy8K84m7IVKpUIH46Popj4MD1UWPtgIbDPvyz+k0/EAEAIgD4ALDsVm5a9ba+6EtbmdYEAuhmu2Ic6vM2oZXfF3+HsY28SMZbW6IDPXhNo13HAtJQuXbmShVag3fN2t5wu6p1UIXhvczLY+/doB9dqV7nXT2Y7GIiLnxASIqCz2fwts+Y8c3XTi5rwoLR4AHlhsvZ3lhpk3LsgWn41v2ZZ1dZ9MYP7bqOC+RbUjZZ+Z2ENAcGsgpJ3s4Fq7s0ye/u0H+DUEhn4M+DVC1tWjcHWrCQx6D0g8jfT2k3AjsDfS/voQYXeNRpJHQ+T8tQCNEk/iyB/v457lPgAAA3LRTv0abghPnNhTC8BZm/AOYhAWm2zvOB1WwxWtQ71hvHEVXoFhuJqSjV5NAuHtqsPlG5no0cgfABCXmoP+zYdBVUyrSz1/D9Tz97hdrRMRlRsmQES3YzbJjq0qlWz5+Wk0cHK1XGdJfgDgyM9Al8myH0fcMZkgmXKBwfOBhd3lnbubDZWtPj515Kio5vfJcg/8YH3Txphoue2LZ4DP75KtOV2fLQipdiSOunbEKxsDMeDnCXhW8wuyhQ6Jaj/UEtfwztYMvKVbCgD4+uRFzM4bh77qehiraY5peQUT/+WpDYgxNEJsVsHlG08XLdKy89CzsT+6N/THtZQsJKbnok/TQCRl5MDXXY8+TQPhotPAaDRi9erLGDSoOXQ6XcXUPxFRBWACRBR3VA4Vb9hXXn6yEELOUXN5N9D5GXmfqJhoObMwIJOX4NbyflM6V3mpavdi2Sqj1gKn1spk6NIOmfwAsvNxv7dlolRYSDug2VCY6/eByjsUmRf3YWNKOP5YeRFBWY9gxoY3sH3jGjxnfh4pWUbUxAOoqUrFKZGJQHU9QAO4qIyoJeSNK2dqv8X/5U7GA5qteD9PDnPfYO6ADeYO6FDHF/1q+eC5vg3hadBCtWwkcHINMgd+ANFmFNwNPC0QUfXHMx05N5MR+KyL/HvAO/IWCwBw4V+Z+OSkAVDJu3QX1nUK0HmSvOmlX0PZufbcZpkMHfhRtubct0gOLXcPAGbEA590Am5cQJ4pDxfi06BVq6FRqxB97jpWHUrFjnMjYNxvhllkA2gGed+DOIzSJMOgM6KnaTtSsmXidB3euC7kvar2atvgQ5encK9uN0wqLeqn7kKST0u8PmEWarjr8enZ60jNNqJHowC46jWwcf0sAAE3V1eAyQ8ROQme7ah6O7UeMGYC9XrIu1DfyljQaRdrpwGHlsvWoMKXo8ZvAPZ+DRz4rmBZ/V6yo/FXg+S9p146I2+SmXkdphXjoLmyG3EDv8TWkJeguq6CMT4O8J+Cnin/wbQ16di6ajPMKH7UkLteg1q+blif1h9tPfKwU9UKQ5uEoGGAB0J9XVHf3wMtQ71v9q25R+6UlwOkxSLYnAd4yIn3ujSwM8KssPZjZctUowHFb0dEVI0wAaLqIeM6sPYVoNXDQN27C5bv/Qo4uUomLKEd5D2PQtrKxOfor3LCv+eOyLt97/4SuDnTcL4pB+U2YZ2Age/g8ubFuGHUIz4lBN0aB8IAABkJ6DlvLc6nmNBYE4t1ut0AgLG/JeKEOFSosEBccInFV/r3sDzvbryS9yRUqoK5DAHgjaHN0TzEG75uOtSu4QatZTI+DECJ5mvWGuSor9KInCR/iIicCBMgqh52LQIOrwAOr4Cm0UC4a3vJ5TXCZX+ctDhg67vyBwBq1AduzjiMx9cBg/8H9H0TWNhVzoQcORmizxxcTTMi+WoK9sUk44O/TyExveHNJzwN4DT6qqfCACPOZ8v7TXmbbwAAzpmDcELIG1WG+riihrseDQI8sCfnGYRf34rwPv/BSu9ANAr0RFauCT5uuoKZh4mIqMIxAaKqxWyWnZFXPS9v8zD6N9kPp+0oYMs7AAD1qTXwrltPNq10eBxIuybn2ok/WlBORgKgc4cIaY1479ZYufks8kxmHK/5JW64GJF5Og/XD2zF5RtZdsOw2GDukP93s2AvDG9xF2KTxuNcZg18HdkJLUK8UNOj8D2g2gAAahZa4sF+N0REDsczL1UeljlzhAD2LpWXrIJaApveBvybAEGtgOWPAokn5fZN7gEWtJCzFQe3Bkb/CqTFwbzvG3S88Akw9xPgpbPAkV/k9iOWI6dGI5zJrYHjsek4fCEW3+y+BjFvY5EhadUqeLnqUKemG/w9DIhLy4GPqw5NgjzRqpYPejcNsL6rNwCgE4IqpoaIiKicKJ4AffLJJ3jvvfcQGxuL1q1b46OPPkKnTp2K3H7BggX47LPPEBMTAz8/PzzwwAOYN28eXFzkXZBff/11zJkzx2qfxo0b48SJExV6HFQKNy4Cu78AIibKu5Rb/LtA9sFpPBj463k5y3HvWfLO5YD8O/Ek0LA/cOO8nCyw+XBg3avAgP8AdSIBAGbv2lB/PQhm/6Y4naqHa9hQZOca8exqV5yIu/VmnAWXncL93KHTqNAi1BuNAj0R4uOKXk0C2EJDRFQNKXpmX758OaZOnYqFCxciIiICCxYsQP/+/XHy5EkEBATYbP/DDz9g2rRpWLJkCbp06YJTp07hscceg0qlwvz58/O3a968Of7+++/8x1otv8AqlXObge0fyZ+ntgKBLYD448Dfr8v1XZ6VCU3yRaDdGJkUHV0JRL0h1/eeBQS1KCivpewenG004cddMVh7RIW0nLkwJtTA6Q/+AfDwzQ3T83ep6a5Hq1reCKvhhpruBjzerS48XTiRHxGRs1A0M5g/fz4mTJiAcePGAQAWLlyIVatWYcmSJZg2bZrN9tu3b0fXrl0xcuRIAEDdunUxYsQI7Ny502o7rVaLoCBehKhUzm4EPINlq45/Y3nPKlOuHHmVclmuB2SHZWMW0Pnpgn2bDJYJEAC0HgEEtUByZi7eW3cSHi5aJKXn4ti1VBy9mlroCesC2fIvLxctGgV6olmIFxoHeaJP00AEerk44qiJiKiSUiwBys3Nxd69ezF9+vT8ZWq1Gn369EF0dLTdfbp06YLvvvsOu3btQqdOnXDu3DmsXr0ao0ePttru9OnTCAkJgYuLCyIjIzFv3jzUrl27yFhycnKQk5OT/zg1VX6RGo1GGI3GOzlMK5ayyrPMSi0tFpot82BuMwqqE2uh2f05AMDceDBMz52A7n/1gH3fQLj6QgXA1HMWzB0eB/QeQOE6ajgQqkHzcT3LjN+NnbDlix349+z1Ip82vKYb8rIzMKxjPQxoEYRGgbY3KHWa16CCOd17WiGsZ8dgPTtGRdZzacpUCVF4FhLHuXr1KkJDQ7F9+3ZERkbmL3/55ZexZcsWm1Ydiw8//BAvvvgihBDIy8vD008/jc8++yx//Zo1a5Ceno7GjRvj2rVrmDNnDq5cuYIjR47A09P+nbrt9RsC5CU3Nze3OzxS51Ej/STaXfwcR0JHIdanPUJu7ETHC58g3RAE19xEaEQeAOCyT2ccqD0eTa+tQP2E9QCAmBrdsb/OBKvysvKAf+NUOJmiQlyWCim59m+mGeAiEJ+tQtdAM+4ONiOAN/wmInJKmZmZGDlyJFJSUuDl5VXstlWqc8zmzZsxd+5cfPrpp4iIiMCZM2cwZcoUvPnmm5g5cyYAYODAgfnbt2rVChEREahTpw5++uknjB8/3m6506dPx9SpU/Mfp6amIiwsDP369bttBZaG0WjEhg0b0Ldv32p540jtwjehyk1ER91pmAbNhOqUCiJlNVy6vwTV4Z9gFmaYW49EYKOB6K93B3L6AP8NBwCERAwH6vdCWrYRz/10CKfjM+w+R4i3C/o2C0BSRi50GjXeuLcZDFrr+XOqez1XJqxrx2A9Owbr2TEqsp4tV3BKQrEEyM/PDxqNBnFxcVbL4+Liiuy/M3PmTIwePRpPPPEEAKBly5bIyMjAk08+iddeew1qte1Ecj4+PmjUqBHOnDlTZCwGgwEGg8FmuU6nq5APQUWVq4jMJGD/t0D7x4BHfgBOrYE6+lOoP2kPDP8cUKmh/eMZ2fenz+tQt3oQ0Mi3XbrJE+j+CnbHAY//6otsbC3yaXo1CcAjHcPQr3nJ+3ZVq3qu5FjXjsF6dgzWs2NURD2XpjzFEiC9Xo/27dsjKioKw4YNAwCYzWZERUVh8uTJdvfJzMy0SXI0GjkHS1FX8tLT03H27FmbfkJ0B0x58q7pKhWwdBCQcFzeD6vNSMC/kezYnHxRdmhu9TCwea681UKXyRBC4O9jcfhi6znsupAEoLXdp2gT5oPX720OIQTahPncvN8VERFR+VD0EtjUqVMxduxYdOjQAZ06dcKCBQuQkZGRPypszJgxCA0Nxbx58wAAQ4YMwfz589G2bdv8S2AzZ87EkCFD8hOhF198EUOGDEGdOnVw9epVzJ49GxqNBiNGjFDsOKud7R8A2xYAEU8BA+YBv00Ezm+VCRAgZ2fOvA4ENAVC2sJcvzd+j6uJv7/fh1WHr9ktsmNdXzzauQ5a1/JBnZpuTHiIiKhCKZoAPfzww0hISMCsWbMQGxuLNm3aYO3atQgMDAQAxMTEWLX4zJgxAyqVCjNmzMCVK1fg7++PIUOG4O23387f5vLlyxgxYgSuX78Of39/dOvWDTt27IC/v7/Dj6/aSjoH5KTKy1r1ewIvFJpk8vQG4I9ngYAmiO7yJV74aSduZBqRZYyzKaZjXV90a+CPuxv7o3WYj+PiJyIip6d4J+jJkycXeclr8+bNVo+1Wi1mz56N2bNnF1nesmXLyjM8sog/DnzaWf7deRLw4FdALdsZuxOyVfBPu4qrWWqMOLrDap1eq0Y9P3fc0yoYvZoEommwJ1t6iIhIEYonQFSJJZ0D1rwCnF5vvXzHJ0Do4vzbWFxKysT2s4k4FZeOFdtTUEe8hdjsGlCpAH8PA9rW9sEbQ1tw8kEiIqo0mACRtHMRkHoFcPEC2j0GrJ8BnFoLZCVZbxfUCghohqSATjh3IQlvrjqOg5eSC23gggSvZmgc4IFvBjdF0+Dym0aAiIiovDABcnY7FwHHfgcubitYdmUfcOIv+bfBG2j9CNDvTUArpwq4fCMT3f6zyW5xYyLr4I2hLeyuIyIiqiyYADmzvFxgzUu2y33rAi4+QHYyMOwToOkQpGQZMf6L7dgXcwPmW2YceLxrOB5oXwshPi7wduXcGUREVPkxAXJmWj3Q8zVg09vyDuxNhwDeYfJGpf0LRtadiU/H2CW7cCU5K3+Zn4cBMwY3RfeGfqjpYTuJJBERUWVmO3UyOZe2j8rf0Z8AoR2Abe8D79UDNs1DttGE55cfQJ/5W/KTn/r+7nhlQBNsfuluDGsbyuSHiIiqJLYAOSsh5EzOZhNQvxdwdiPwhi8Q2BLwro1r2hCM++RfnIhNAwB4u+rwy8RINAiwf0NZIiKiqoQJkLP67Rkg9TIQMRHo9zbwWaRcHncYlwwNcM8qF6QgDT5uOvzn/lbo0cgfLjqNsjETERGVEyZAziY3A1g7HTj4g3yckw5c3Ze/+k/RDf+X8gwAoHmIF5aO64gAT87fQ0RE1QsTIGeRlwPERAN/PS8nOASADo8DnsFA8kVs8RqCsRf6ARCoU9MNL/ZrjMEtg6FWc6ZmIiKqfpgAVXcxO4D4YzLxKazTk0CfOTBpXfEl7se8NfJ+Xs/3aYzJvRpAw8SHiIiqMSZA1d3OhcDRXwseu9UEHvoGqNtNjvL6YR/WHIkFADzauTam9GmoUKBERESOwwSouvNrVPB3/d7A0I8BrxBcvpGJF346iJ3n5a0unu3dEM/2aqBQkERERI7FBKg6y04BblwoeHzvh4BXCI5eTcHYJbuQmJ4LN70Gbw9vgeFtaykWJhERkaMxAarOVr8MHFou/zZ4AV6hOHo1BY8s2oG07Dw0CfLE/x5qjeYh3srGSURE5GBMgKqra4eAQ8vk34Etgaf/gQAwd/VxpGXnoWNdXyx+rCO8XHjvLiIicj5MgKqrfd8U/B13GDmrpmFBQjv8e8YDWrUK8x9qw+SHiIicFu8FVl31nQNM2pX/0LBnIfLObIZGrcJbw1ogrIabgsEREREpiwlQdWQ2AXp3OQLssdVI0/gAALJgwI8TOuORTrWVjY+IiEhhTICqm11fAG/6AxejAZUKp1xbYVjma3jP+BCu1xuGTuE1lI6QiIhIcewDVN1smAUIE7B0AMxj/sT//nXDWRGKk43aYtHoDkpHR0REVCmwBai66fla/p8rdpzGuqNx0GlUmHh3A97Xi4iI6Ca2AFU3XSYDjfrjwNGjmLcmGwDw3wdbo30dX4UDIyIiqjzYAlTdGLOQm5eHuVuTkAxPDGkdgqFtQpWOioiIqFJhC1B18tdUYM9i6AG8Zq6HCZ7v4Z37WiodFRERUaXDFqDqJDkm/08vZODFfo3hbmCOS0REdCt+O1YXm+ZBnN+K9Yb+8Mm6iGNed2Fse97glIiIyB4mQNVFVhJUphzsza6Br1TjsGp0N476IiIiKgIvgVUHm98Bdi3CCUNLLDLdg3tbh6BhoKfSUREREVVaTICqg8RTAIBf0ltCo1bjybvqKRwQERFR5cZLYNVB/7n4OrcX1hzOQ7eGfmjE1h8iIqJiMQGq6vZ+jeQbCfjmaE1cFgF4u1u40hERERFVekyAqrrdX8In9hDCxMvwr9cEPRr5Kx0RERFRpccEqKprOgRbkv0QkxOA8a1DlI6GiIioSmACVJUJgRttnsa4tc1hFkDPxgFKR0RERFQlMAGqqn6dCBz8Ab4AVOJbNAv2RYiPq9JRERERVQkcBl9VHVqW/+dr2u/xWJe6ysVCRERUxTABqqq6Ppf/5+PatejfIki5WIiIiKoYXgKrqvrMxpeG0Vi7+lfUCauN/7nqlI6IiIioymALUFWUkw4Igb+Px2GPaILmrTooHREREVGVwhagqsZsBuaFQqjUuJDzMQAf9GkaqHRUREREVQpbgKqa7GQAgEqYsVz7OhoFeqB2TTdlYyIiIqpimABVNW41gMjJAACdKo+tP0RERGXAS2BVUN5d0/C/6DT8mdsWHzABIiIiKjUmQFXQ0UQTPsvuDy8XLdqE+SgdDhERUZXDBKgqMZuA5aNhzA5BTbRD2/BG0KhVSkdFRERU5TABqkquHQROrkJLlQuM6Igu9WsqHREREVGVpHgn6E8++QR169aFi4sLIiIisGvXrmK3X7BgARo3bgxXV1eEhYXh+eefR3Z29h2VWWV4hQL3foQ5eBKp8EDHujWUjoiIiKhKUjQBWr58OaZOnYrZs2dj3759aN26Nfr374/4+Hi72//www+YNm0aZs+ejePHj2Px4sVYvnw5Xn311TKXWaV4BuJG40fwQ1ZnAED9AHeFAyIiIqqaFE2A5s+fjwkTJmDcuHFo1qwZFi5cCDc3NyxZssTu9tu3b0fXrl0xcuRI1K1bF/369cOIESOsWnhKW2ZVcy4xHQAQ4u0CNz2vYBIREZWFYt+gubm52Lt3L6ZPn56/TK1Wo0+fPoiOjra7T5cuXfDdd99h165d6NSpE86dO4fVq1dj9OjRZS4TAHJycpCTk5P/ODU1FQBgNBphNBrv6DgLs5RV5jIzEnD60AH44wYaBjYs19iqkzuuZyox1rVjsJ4dg/XsGBVZz6UpU7EEKDExESaTCYGB1vPYBAYG4sSJE3b3GTlyJBITE9GtWzcIIZCXl4enn346/xJYWcoEgHnz5mHOnDk2y9evXw83t/KfZXnDhg1l2q9e/Do8cuV7uOkisSX3GaxevbqcI6teylrPVHqsa8dgPTsG69kxKqKeMzMzS7xtlbqGsnnzZsydOxeffvopIiIicObMGUyZMgVvvvkmZs6cWeZyp0+fjqlTp+Y/Tk1NRVhYGPr16wcvL6/yCB2AzEw3bNiAvn37Qqcr/d3b1Xuu4fqVv5AsPDCyfxe0quVdbrFVJ3daz1RyrGvHYD07BuvZMSqyni1XcEpCsQTIz88PGo0GcXFxVsvj4uIQFBRkd5+ZM2di9OjReOKJJwAALVu2REZGBp588km89tprZSoTAAwGAwwGg81ynU5XIR+CMpV7/h+YDv6IcTkv4pCoj8PB3vyA3kZFvX5ki3XtGKxnx2A9O0ZF1HNpylOsE7Rer0f79u0RFRWVv8xsNiMqKgqRkZF298nMzIRabR2yRqMBAAghylRmlfH1PdDEHsCX+v/B39MATxd+OImIiMpK0UtgU6dOxdixY9GhQwd06tQJCxYsQEZGBsaNGwcAGDNmDEJDQzFv3jwAwJAhQzB//ny0bds2/xLYzJkzMWTIkPxE6HZlVlnjNyBqyya8e9QL7Rv4Kh0NERFRlaZoAvTwww8jISEBs2bNQmxsLNq0aYO1a9fmd2KOiYmxavGZMWMGVCoVZsyYgStXrsDf3x9DhgzB22+/XeIyq6ywTohL/AWTtJvg5uMNoL3SEREREVVZineCnjx5MiZPnmx33ebNm60ea7VazJ49G7Nnzy5zmVWWEIhMWYVwzSWcdX1A6WiIiIiqNMUTICoBsxm5OxdjpbEz/NAEQ9rcq3REREREVRoToKrAmAn9uhfxghboov4eY/0ClI6IiIioSmMCVCUIXPHriotxN9AwjHeAJyIiulNMgKoCgyc+Df0Pvr8cg4mhHAFGRER0pxS9GSqV3NXkLABA7Rrlf2sOIiIiZ8MEqIq4lpINAAj2dlE4EiIioqqPl8CqgvgTWJj8JC7raiDAZ53S0RAREVV5TICqgPTUG6iLa1Cr8lDDx1XpcIiIiKo8XgKr7HLSYPznA2QLHX7U3QcPA3NWIiKiO8Vv08pu+8fwvbgGUAEq3zpKR0NERFQtsAWosstMBACcNwdCFdRM4WCIiIiqB7YAVXaD/ot5CV2QdHoHuhluKB0NERFRtcAEqLJTqeCedAzTdYuQcOkogPuUjoiIiKjK4yWwKiAtIxNZQg+tO2eBJiIiKg9sAarMzm2GecdCPJa3G66qXJgDGykdERERUbXABKgyS4uD+tQahKqAq6Imgt08lI6IiIioWmACVJkFtcTFNi/h/V0ZOFSjPzbedbfSEREREVULTIAqs8Bm2FnLE7/tOITuvpwBmoiIqLywE3Qld+WGvAt8KG+BQUREVG6YAFVmaXFISbwCLfJQiy1ARERE5YaXwCqzv57H6ydXIVczHqG+7ZWOhoiIqNpgC1BllpcNM1RIF64I9XFTOhoiIqJqgwlQJWYe9QsaG7/HH+ZIhPISGBERUblhAlSJxaflwGgCNGo1Aj0NSodDRERUbTABqsSuJGcCAIK8XKDV8KUiIiIqL/xWrcTco/+L2dqv0c6Td4EnIiIqT0yAKrGgi39gnHYdGrplKh0KERFRtcJh8JXYNt/hOJ8WAxe/OkqHQkREVK2wBaiySjgFVXocFucNhFdgXaWjISIiqlbYAlRZbX0Pg1N/wnaNO0J9eysdDRERUbXCFqBKSuRlAwA8kIVQbw6BJyIiKk9MgCqp9GaPAACm635EiDpJ4WiIiIiqFyZAldQl74J7f7kYXBSMhIiIqPopdQJUt25dvPHGG4iJiamIeOgmt72fAwD+1t0NuAcoGwwREVE1U+oE6LnnnsPKlStRr1499O3bF8uWLUNOTk5FxObUTOkJAACDVgWo2VBHRERUnsqUAB04cAC7du1C06ZN8X//938IDg7G5MmTsW/fvoqI0SnViIsGAOzzHaRwJERERNVPmZsW2rVrhw8//BBXr17F7Nmz8eWXX6Jjx45o06YNlixZAiFEecbpdITJCAC4N+U7gHVJRERUrsqcABmNRvz000+499578cILL6BDhw748ssvcf/99+PVV1/FqFGjyjNOp7Ok3gcAgDoZRwCVSuFoiIiIqpdST4S4b98+LF26FD/++CPUajXGjBmD999/H02aNMnfZvjw4ejYsWO5BupsVKmXAQBqmBSOhIiIqPopdQLUsWNH9O3bF5999hmGDRsGnU5ns014eDgeeeSRcgnQWaVnZAAAUj3rw0vhWIiIiKqbUidA586dQ506xd+c093dHUuXLi1zUAQMTvkBAHCj/nAmQEREROWs1H2A4uPjsXPnTpvlO3fuxJ49e8olKKcnBDqYDso/245WOBgiIqLqp9QJ0KRJk3Dp0iWb5VeuXMGkSZPKJShnl5lrxFzjCPzX+CBq1qihdDhERETVTqkvgR07dgzt2rWzWd62bVscO3asXIJydgnpRiwyDYGLTo0XPDyVDoeIiKjaKXULkMFgQFxcnM3ya9euQastdT5FdsSnyZm1AzxdoOIQeCIionJX6gSoX79+mD59OlJSUvKXJScn49VXX0Xfvn3LNThnlZCcgUAkoZ47bzFCRERUEUqdAP33v//FpUuXUKdOHfTs2RM9e/ZEeHg4YmNj8b///a9MQXzyySeoW7cuXFxcEBERgV27dhW57d133w2VSmXzM3jw4PxtHnvsMZv1AwYMKFNsSsiKP4udLpPx2fXHlQ6FiIioWir1NavQ0FAcOnQI33//PQ4ePAhXV1eMGzcOI0aMsDsn0O0sX74cU6dOxcKFCxEREYEFCxagf//+OHnyJAICbO+CvnLlSuTm5uY/vn79Olq3bo0HH3zQarsBAwZYDcU3GAyljk0pyemZMAoNTOrS1ycRERHdXpk67bi7u+PJJ58slwDmz5+PCRMmYNy4cQCAhQsXYtWqVViyZAmmTZtms32NW0ZFLVu2DG5ubjYJkMFgQFBQULnE6GjnVGFomPMtnu9WD1OUDoaIiKgaKnOv5WPHjiEmJsaqNQYA7r333hKXkZubi71792L69On5y9RqNfr06YPo6OgSlbF48WI88sgjcHd3t1q+efNmBAQEwNfXF7169cJbb72FmjVr2i0jJycHOTkF/W1SU1MByPudGY3GEh/P7VjKul2ZyZmyTt0MunJ9fmdR0nqmO8e6dgzWs2Ownh2jIuu5NGWqRClv237u3DkMHz4chw8fhkqlyr/ru2W0kslU8ntXXb16FaGhodi+fTsiIyPzl7/88svYsmWL3QkXC9u1axciIiKwc+dOdOrUKX+5pVUoPDwcZ8+exauvvgoPDw9ER0dDo9HYlPP6669jzpw5Nst/+OEHuLm5lfh4ysvC42ocT1ZjVH0TOgXwTvBEREQlkZmZiZEjRyIlJQVeXsXfR6HULUBTpkxBeHg4oqKiEB4ejl27duH69et44YUX8N///rfMQZfF4sWL0bJlS6vkB4DVfchatmyJVq1aoX79+ti8eTN69+5tU8706dMxderU/MepqakICwtDv379bluBpWE0GrFhwwb07du32P5SGy8sw4j039GxZns0GPRiuT2/syhpPdOdY107BuvZMVjPjlGR9Wy5glMSpU6AoqOjsXHjRvj5+UGtVkOtVqNbt26YN28enn32Wezfv7/EZfn5+UGj0djMKxQXF3fb/jsZGRlYtmwZ3njjjds+T7169eDn54czZ87YTYAMBoPdTtI6na5CPgS3K9c36xLGaDcg9VoSdLrpRW5Hxauo149ssa4dg/XsGKxnx6iIei5NeaUeBm8ymeDpKWcn9vPzw9WrVwEAderUwcmTJ0tVll6vR/v27REVFZW/zGw2IyoqyuqSmD0rVqxATk4OHn300ds+z+XLl3H9+nUEBweXKj6lHM8Lwgd59yG9yUNKh0JERFQtlboFqEWLFjh48CDCw8MRERGBd999F3q9HosWLUK9evVKHcDUqVMxduxYdOjQAZ06dcKCBQuQkZGRPypszJgxCA0Nxbx586z2W7x4MYYNG2bTsTk9PR1z5szB/fffj6CgIJw9exYvv/wyGjRogP79+5c6PiUcyA7GzrwHcH+7nkqHQkREVC2VOgGaMWMGMjIyAABvvPEG7rnnHnTv3h01a9bE8uXLSx3Aww8/jISEBMyaNQuxsbFo06YN1q5di8DAQABATEwM1GrrhqqTJ09i27ZtWL9+vU15Go0Ghw4dwtdff43k5GSEhISgX79+ePPNN6vEXEDZRhNy8swAAC9XNsESERFVhFInQIVbURo0aIATJ04gKSkJvr6+Zb5v1eTJkzF58mS76zZv3myzrHHjxihq8JqrqyvWrVtXpjgqg5QsI1yQA4PKBA+NWelwiIiIqqVS9QEyGo3QarU4cuSI1fIaNWrwpp3lJCXLiHGadThoeALqVVNvvwMRERGVWqkSIJ1Oh9q1a5dqrh8qnZQsIwyqm5NLaiv/JTsiIqKqqNSjwF577TW8+uqrSEpKqoh4nJ7p6iFcMAfhJe//Av3nKh0OERFRtVTqPkAff/wxzpw5g5CQENSpU8fmFhT79u0rt+CckdeFtVig/wx/m4YAuglKh0NERFQtlToBGjZsWAWEQRaJ2iD8Y2qBJNdwpUMhIiKqtkqdAM2ePbsi4qCb9voOwgfGhhgZUhucBpGIiKhilLoPEFWslCx5J1tvzgFERERUYUrdAqRWq4sd8s4RYncmlQkQERFRhSt1AvTrr79aPTYajdi/fz++/vprzJkzp9wCc1aDLr+Pp/W7kXDjOQD1lQ6HiIioWip1AjR06FCbZQ888ACaN2+O5cuXY/z48eUSmLPyzrmGRuoryFFnKx0KERFRtVVufYA6d+5sdVd3KpuFujEYkfsacur2UjoUIiKiaqvULUD2ZGVl4cMPP0RoaGh5FOfUjhiDEGf2hUvNMKVDISIiqrZKnQDdetNTIQTS0tLg5uaG7777rlyDc0bp2XkAAA9DueSmREREZEepv2Xff/99qwRIrVbD398fERER8PX1LdfgnI3ZLNAhbx/0aiM8zO0AuN92HyIiIiq9UidAjz32WAWEQQCQaTThde1XCFfHISe9LxAQrHRIRERE1VKpO0EvXboUK1assFm+YsUKfP311+USlLPKyMnDERGO/eYG0HuwNY2IiKiilDoBmjdvHvz8/GyWBwQEYO5c3r38TqTn5OH/jM9ijHouVAFNlQ6HiIio2ip1AhQTE4PwcNsbddapUwcxMTHlEpSzyshhB2giIiJHKHUCFBAQgEOHDtksP3jwIGrWrFkuQTmr9JsJkDsTICIiogpV6m/aESNG4Nlnn4WnpyfuuusuAMCWLVswZcoUPPLII+UeoDPJTk/BWv0rUGW6AaZ/AQ3vB0ZERFQRSp0Avfnmm7hw4QJ69+4NrVbubjabMWbMGPYBukO5GSloor4EU54aULMViIiIqKKU+ltWr9dj+fLleOutt3DgwAG4urqiZcuWqFOnTkXE51SShAdG5U5H5zB3/F+huZaIiIiofJW5maFhw4Zo2LBhecbi9NLyNPjX3BKBNXhLESIioopU6k7Q999/P/7zn//YLH/33Xfx4IMPlktQziqDnaCJiIgcotQJ0NatWzFo0CCb5QMHDsTWrVvLJShnJdLj0Uu9D/WNp5UOhYiIqFordVNDeno69Hq9zXKdTofU1NRyCcpZNUjYgBf0HwBHATw4XOlwiIiIqq1StwC1bNkSy5cvt1m+bNkyNGvWrFyCclbnNXWRLXQ4XGeM0qEQERFVa6VuAZo5cybuu+8+nD17Fr169QIAREVF4YcffsDPP/9c7gE6kwOaFmiX8zleb9ERLZUOhoiIqBordQI0ZMgQ/Pbbb5g7dy5+/vlnuLq6onXr1ti4cSNq1KhRETE6B1MeXro6FVd0egjtF0pHQ0REVK2VabjR4MGDMXjwYABAamoqfvzxR7z44ovYu3cvTCZTuQboNLJT0Nx4GM01wBZXN6WjISIiqtZK3QfIYuvWrRg7dixCQkLwv//9D7169cKOHTvKMzbnonPF6/oX8YpxAjxcDUpHQ0REVK2VqgUoNjYWX331FRYvXozU1FQ89NBDyMnJwW+//cYO0HdK74Y/TJ2RZMrFOM4DREREVKFK3AI0ZMgQNG7cGIcOHcKCBQtw9epVfPTRRxUZm9PJvxu8ngkQERFRRSrxN+2aNWvw7LPPYuLEibwFRgUwpiehiek00lRu8HRhAkRERFSRStwCtG3bNqSlpaF9+/aIiIjAxx9/jMTExIqMzanknPsXfxhm4n3dp7wVBhERUQUrcQLUuXNnfPHFF7h27RqeeuopLFu2DCEhITCbzdiwYQPS0tIqMs5qL8usxmXhh0T4Qqcpc990IiIiKoFSf9O6u7vj8ccfx7Zt23D48GG88MILeOeddxAQEIB77723ImJ0CklBd6Fbzod4WTdN6VCIiIiqvTtqamjcuDHeffddXL58GT/++GN5xeSU8jtAGzQKR0JERFT9lcu1Fo1Gg2HDhuGPP/4oj+KcUmYuR4ARERE5Cr9tKwn3i1H4XPcFrua1AXCX0uEQERFVa0yAKgld8nn01+zBvyYPpUMhIiKq9pgAVRKXfTriB+N4+AU1QlelgyEiIqrmON66krjmUh8/mnrjvFcnpUMhIiKq9pgAVRJZRhMAwE3PUWBEREQVjQlQJaFOj0MD1WXURKrSoRAREVV7TIAqiTaXv8XfhpfR4/pypUMhIiKq9ipFAvTJJ5+gbt26cHFxQUREBHbt2lXktnfffTdUKpXNz+DBg/O3EUJg1qxZCA4OhqurK/r06YPTp0874lDKLEvokCQ8YNa5Kx0KERFRtad4ArR8+XJMnToVs2fPxr59+9C6dWv0798f8fHxdrdfuXIlrl27lv9z5MgRaDQaPPjgg/nbvPvuu/jwww+xcOFC7Ny5E+7u7ujfvz+ys7MddVil9mfN8WiXswhHGzyldChERETVnuIJ0Pz58zFhwgSMGzcOzZo1w8KFC+Hm5oYlS5bY3b5GjRoICgrK/9mwYQPc3NzyEyAhBBYsWIAZM2Zg6NChaNWqFb755htcvXoVv/32mwOPrHQsM0G7sBM0ERFRhVM0AcrNzcXevXvRp0+f/GVqtRp9+vRBdHR0icpYvHgxHnnkEbi7y0tH58+fR2xsrFWZ3t7eiIiIKHGZSsgymgEAbjomQERERBVN0YkQExMTYTKZEBgYaLU8MDAQJ06cuO3+u3btwpEjR7B48eL8ZbGxsfll3FqmZd2tcnJykJOTk/84NVWOxDIajTAajSU7mBKwlGWvzF5JP2G47hiCkh6H0Ti03J7TGRVXz1S+WNeOwXp2DNazY1RkPZemzCo9E/TixYvRsmVLdOp0Z5MHzps3D3PmzLFZvn79eri5ud1R2fZs2LDBZllQxnEM0PyLNScaYXWmrtyf0xnZq2eqGKxrx2A9Owbr2TEqop4zMzNLvK2iCZCfnx80Gg3i4uKslsfFxSEoKKjYfTMyMrBs2TK88cYbVsst+8XFxSE4ONiqzDZt2tgta/r06Zg6dWr+49TUVISFhaFfv37w8vIqzSEVy2g0YsOGDejbty90OuskZ/ApV7ilpiCkw0A069Cr3J7TGRVXz1S+WNeOwXp2DNazY1RkPVuu4JSEogmQXq9H+/btERUVhWHDhgEAzGYzoqKiMHny5GL3XbFiBXJycvDoo49aLQ8PD0dQUBCioqLyE57U1FTs3LkTEydOtFuWwWCAwWCwWa7T6SrkQ2Cv3LQ8DcYZX8avYRH84JWTinr9yBbr2jFYz47BenaMiqjn0pSn+CWwqVOnYuzYsejQoQM6deqEBQsWICMjA+PGjQMAjBkzBqGhoZg3b57VfosXL8awYcNQs2ZNq+UqlQrPPfcc3nrrLTRs2BDh4eGYOXMmQkJC8pOsyijLaIIJGt4Kg4iIyAEUT4AefvhhJCQkYNasWYiNjUWbNm2wdu3a/E7MMTExUKutB6udPHkS27Ztw/r16+2W+fLLLyMjIwNPPvkkkpOT0a1bN6xduxYuLi4VfjxlkpmEHsZtuKF2gYuup9LREBERVXuKJ0AAMHny5CIveW3evNlmWePGjSGEKLI8lUqFN954w6Z/UGVlSjiFDzQf4IIqEG76F5UOh4iIqNpTfCJEAnLUrthhboqDoj5cOQ8QERFRhasULUDOLsOnCR7JnQkAOK9jTkpERFTR+G1bCWTlmgAArjoNVCqVwtEQERFVf0yAKoEso0yAOAKMiIjIMXgJrBLQnN+M1frXcAYNAfRVOhwiIqJqjwlQJWDKuI5m6ovIRfnNOk1ERERFYwJUCcTX6IC3cqchyN8fbZQOhoiIyAmwD1AlkKypgX/MrRDj1lzpUIiIiJwCE6BKgJ2giYiIHIsJUCWgSb6Iu9X70UBcUDoUIiIip8AEqBIIit2Ir/TvYWDycqVDISIicgpMgCqBFJU3DprrIcU1VOlQiIiInAJHgVUCB3z74ZncBniyTj3wXvBEREQVjy1AlUBmbh4AwIU3QiUiInIIJkCVQFauGQBHgRERETkKE6BKoGPCz/hZ/zraXFuhdChEREROgQlQJeCTfQUd1KfgkxurdChEREROgZ2gK4G/DX3x6/XaGBl+N5ooHQwREZETYAtQJXAKYVhn7og8v6ZKh0JEROQUmABVAlm58lYYruwETURE5BBMgCqB3plr0VJ1Dq7Mf4iIiByCfYCUlpOGaXmfAgbgtOo+paMhIiJyCkyAlGYyYq9oDL3Igbe7j9LREBEROQUmQAoTrr64P2c2AGC3gS8HERGRI7APkMKyjeb8v9kJmoiIyDGYACksy2jK/9uV9wIjIiJyCF5zUVjeua34XT8DR1EPGvVgpcMhIiJyCkyAFGZOjUNr9TnkwFXpUIiIiJwGEyCFJfl3wPTcl+Di7o1OSgdDRETkJJgAKSxV64dN5rao5+KudChEREROg52gFWbpBO3GEWBEREQOwxYghamvn0Y39WH4qBooHQoREZHTYAuQwoLP/ITv9PMwMGed0qEQERE5DSZACkvT1cBxc22k6/2UDoWIiMhpMAFS2L7Q0RiY+w52BDysdChEREROgwmQwjJzZSdoF84CTURE5DBMgBTGUWBERESOx1FgCuty4RP00O1BbPp4AM2UDoeIiMgpsAVIYX4ZZxCpOQZvc7LSoRARETkNtgApbI3vCHya1B49/COUDoWIiMhpsAVIYcc0TfGXORIm7zpKh0JEROQ0mAApzNIJ2pWdoImIiByGCZDCgjNOoJ3qFDyRqXQoREREToN9gBT2f6n/Q11DDA6n1QfQUOlwiIiInAITIIXFwg8qcza0rp5Kh0JEROQ0mAApbLL6NSTm5mB1SHulQyEiInIaTICUlHIZLY2HkKU2wU1/t9LREBEROQ3FO0F/8sknqFu3LlxcXBAREYFdu3YVu31ycjImTZqE4OBgGAwGNGrUCKtXr85f//rrr0OlUln9NGnSpKIPo0zEtgVYqpqDZfq34MpUlIiIyGEU/dpdvnw5pk6dioULFyIiIgILFixA//79cfLkSQQEBNhsn5ubi759+yIgIAA///wzQkNDcfHiRfj4+Fht17x5c/z999/5j7Xaypld5PnWh+7m3265CQDclQyHiIjIaSiaGcyfPx8TJkzAuHHjAAALFy7EqlWrsGTJEkybNs1m+yVLliApKQnbt2+HTidTh7p169psp9VqERQUVKGxl4eMNuPx9qpzCMF1TK5ZW+lwiIiInIZiCVBubi727t2L6dOn5y9Tq9Xo06cPoqOj7e7zxx9/IDIyEpMmTcLvv/8Of39/jBw5Eq+88go0moKJBE+fPo2QkBC4uLggMjIS8+bNQ+3aRScYOTk5yMnJyX+cmpoKADAajTAajXd6qPksZVl+p2bmYIXpbug0Kkw2m2A0m8rtuZzZrfVMFYd17RisZ8dgPTtGRdZzacpULAFKTEyEyWRCYGCg1fLAwECcOHHC7j7nzp3Dxo0bMWrUKKxevRpnzpzBM888A6PRiNmzZwMAIiIi8NVXX6Fx48a4du0a5syZg+7du+PIkSPw9LQ/1HzevHmYM2eOzfL169fDzc3tDo/U1oYNGwAAcVkAoIUWZqt+TFQ+LPVMFY917RisZ8dgPTtGRdRzZmbJJxVWCSFEuUdQAlevXkVoaCi2b9+OyMjI/OUvv/wytmzZgp07d9rs06hRI2RnZ+P8+fP5LT7z58/He++9h2vXrtl9nuTkZNSpUwfz58/H+PHj7W5jrwUoLCwMiYmJ8PLyupPDtGI0GrFhwwb07dsXOp0O8RsW4GT0X9ig7403pk2/fQFUIrfWM1Uc1rVjsJ4dg/XsGBVZz6mpqfDz80NKSsptv78VawHy8/ODRqNBXFyc1fK4uLgi++8EBwdDp9NZXe5q2rQpYmNjkZubC71eb7OPj48PGjVqhDNnzhQZi8FggMFgsFmu0+kq5ENgKVd//Th6aQ7gtKY1P2wVoKJeP7LFunYM1rNjsJ4doyLquTTlKTYMXq/Xo3379oiKispfZjabERUVZdUiVFjXrl1x5swZmM3m/GWnTp1CcHCw3eQHANLT03H27FkEBweX7wGUg8v1HsJLxidx0NBB6VCIiIiciqLzAE2dOhVffPEFvv76axw/fhwTJ05ERkZG/qiwMWPGWHWSnjhxIpKSkjBlyhScOnUKq1atwty5czFp0qT8bV588UVs2bIFFy5cwPbt2zF8+HBoNBqMGDHC4cd3O3HerbHCdDfi3BooHQoREZFTUXQY/MMPP4yEhATMmjULsbGxaNOmDdauXZvfMTomJgZqdUGOFhYWhnXr1uH5559Hq1atEBoaiilTpuCVV17J3+by5csYMWIErl+/Dn9/f3Tr1g07duyAv7+/w4/vdrKMctSXm15zmy2JiIioPCk+Q+DkyZMxefJku+s2b95ssywyMhI7duwosrxly5aVV2gVTpN0Bk1VF+Gr4QSIREREjqT4rTCcWcfDr2ONYTra5O5XOhQiIiKnwgRIQVkaLyQIb6gMHkqHQkRE5FSYACloRcN30THnM8TU6KJ0KERERE6FCZCCsnLZCZqIiEgJTIAUZEmAXHVMgIiIiBxJ8VFgzuyBi3PQVZeBDPPrABoqHQ4REZHTYAKkoFbp29BRk43fNebbb0xERETlhgmQgr72eQbX4hPQzqPyTdJIRERUnTEBUtBaXR/sMyWjs5un0qEQERE5FXaCVlAmO0ETEREpgi1ASjFmISjnHFKh4jB4IiIiB2MCpJT44/gqawquGmogWT9c6WiIiIicCi+BKcVswnXhhRvCEx4G5qFERESOxG9eheSFtEf7nIUAgL0GXgIjIiJyJLYAKSTjZgdoAPBwYR5KRETkSEyAFJKRkwcA0GlUMGjZAkRERORITIAUot/xIT7QfYye+uNKh0JEROR0mAApRH/pHwzVbEcdzQ2lQyEiInI67HyikMv1R2LFhbq44NFC6VCIiIicDhMghcQE9MJSkzfaufkoHQoREZHT4SUwhVg6QbtzDiAiIiKHYwKkEM2NMwhTxcFLr3QkREREzocJkEIG7BiNfwzPo7YqTulQiIiInA6vvygkV+0Kk8iB3uCmdChEREROhy1ACpnf4lc0z1mKPK9aSodCRETkdJgAKSSdnaCJiIgUwwRIIZZRYLwTPBERkePx21cJmdfx6NW30EWrhpv+A6WjISIicjpMgJSQdQNdMzeipcYV0bwTPBERkcPx21cJrjXwsW4cbmQaMdCdEwERERE5GhMgJbjVwMLcgUg35WEUEyAiIiKHYydoBeTkmfNHgdV0NygcDRERkfNhAqSA5OtxqKVKgKc6B16ubIQjIiJyNCZAClAdWo5thin4r+FLqFQqpcMhIiJyOkyAFJCVnY0coUOuzlvpUIiIiJwSr78o4EDtseizqx26hvpgiNLBEBEROSG2ACkgKSMXAODr4apwJERERM6JCZACbtxMgGpwCDwREZEieAlMAZ3OfYRQbRxMqqcBtFA6HCIiIqfDFiAFtEzeiEe1UfDXZSsdChERkVNiC5ACVro/iMzrV9C0Rl2lQyEiInJKTIAUsBJ9cSIvHd/4BisdChERkVPiJTAFpGTL22B4u+oUjoSIiMg5MQFyMLU5Fx5ZV+COLPi4MQEiIiJSAi+BOZhn+nlsUL+N8/pA+LgOVTocIiIip8QWIAfLy8tBttAhBR7wdGH+SUREpATFE6BPPvkEdevWhYuLCyIiIrBr165it09OTsakSZMQHBwMg8GARo0aYfXq1XdUpiOddWmFJjlfY7z6TajVvBEqERGREhRNgJYvX46pU6di9uzZ2LdvH1q3bo3+/fsjPj7e7va5ubno27cvLly4gJ9//hknT57EF198gdDQ0DKX6WhZJvnb3c1N2UCIiIicmKIJ0Pz58zFhwgSMGzcOzZo1w8KFC+Hm5oYlS5bY3X7JkiVISkrCb7/9hq5du6Ju3bro0aMHWrduXeYyHS0jT7b6sAM0ERGRchRLgHJzc7F371706dOnIBi1Gn369EF0dLTdff744w9ERkZi0qRJCAwMRIsWLTB37lyYTKYyl+lozZM34W3tYkSqjigdChERkdNSrBduYmIiTCYTAgMDrZYHBgbixIkTdvc5d+4cNm7ciFGjRmH16tU4c+YMnnnmGRiNRsyePbtMZQJATk4OcnJy8h+npqYCAIxGI4xGY1kP0YbRaETdrMNoo92Nn0Szci2bCljqlfVb8VjXjsF6dgzWs2NUZD2XpswqNQzJbDYjICAAixYtgkajQfv27XHlyhW89957mD17dpnLnTdvHubMmWOzfP369XAr5746V/VdsCm9NhKzA2C4pfM2la8NGzYoHYLTYF07BuvZMVjPjlER9ZyZmVnibRVLgPz8/KDRaBAXF2e1PC4uDkFBQXb3CQ4Ohk6ng0ajyV/WtGlTxMbGIjc3t0xlAsD06dMxderU/MepqakICwtDv3794OXlVZbDs8toNOKpc2r8Y4rAxObhGNSnYbmVTQWMRiM2bNiAvn37QqdjX6uKxLp2DNazY7CeHaMi69lyBackFEuA9Ho92rdvj6ioKAwbNgyAbOGJiorC5MmT7e7TtWtX/PDDDzCbzVCrZfelU6dOITg4GHq9HgBKXSYAGAwGGAwGm+U6na7cX5wbufJ3qK87P2AVrCJeP7KPde0YrGfHYD07RkXUc2nKU3QU2NSpU/HFF1/g66+/xvHjxzFx4kRkZGRg3LhxAIAxY8Zg+vTp+dtPnDgRSUlJmDJlCk6dOoVVq1Zh7ty5mDRpUonLVJprTgI8kYkQb9uEi4iIiBxD0T5ADz/8MBISEjBr1izExsaiTZs2WLt2bX4n5piYmPyWHgAICwvDunXr8Pzzz6NVq1YIDQ3FlClT8Morr5S4TEWlXcMK8/MwG1Q47XFc6WiIiIicluKdoCdPnlzk5anNmzfbLIuMjMSOHTvKXKaSkq+cAoQ3Lgt/1Pf3UzocIiIip6V4AuRM1qfXx4ycT9A9WOAbF15fJiIiUgoTIAdKysiFTq1C26Yc/UVERKQkJkAO9HSPeghKPYHekbWVDoWIiMipKX43eGej1wCevPxFRESkKCZARERE5HSYABEREZHTYQJERERETocJEBERETkdJkBERETkdJgAERERkdNhAkREREROhwkQEREROR0mQEREROR0mAARERGR02ECRERERE6HCRARERE5HSZARERE5HS0SgdQGQkhAACpqanlWq7RaERmZiZSU1Oh0/GO8BWF9ew4rGvHYD07BuvZMSqyni3f25bv8eIwAbIjLS0NABAWFqZwJERERFRaaWlp8Pb2LnYblShJmuRkzGYzrl69Ck9PT6hUqnIrNzU1FWFhYbh06RK8vLzKrVyyxnp2HNa1Y7CeHYP17BgVWc9CCKSlpSEkJARqdfG9fNgCZIdarUatWrUqrHwvLy9+uByA9ew4rGvHYD07BuvZMSqqnm/X8mPBTtBERETkdJgAERERkdNhAuRABoMBs2fPhsFgUDqUao317Disa8dgPTsG69kxKks9sxM0EREROR22ABEREZHTYQJERERETocJEBERETkdJkBERETkdJgAOdAnn3yCunXrwsXFBREREdi1a5fSIVUZ8+bNQ8eOHeHp6YmAgAAMGzYMJ0+etNomOzsbkyZNQs2aNeHh4YH7778fcXFxVtvExMRg8ODBcHNzQ0BAAF566SXk5eU58lCqlHfeeQcqlQrPPfdc/jLWc/m5cuUKHn30UdSsWROurq5o2bIl9uzZk79eCIFZs2YhODgYrq6u6NOnD06fPm1VRlJSEkaNGgUvLy/4+Phg/PjxSE9Pd/ShVFomkwkzZ85EeHg4XF1dUb9+fbz55ptW94piPZfe1q1bMWTIEISEhEClUuG3336zWl9edXro0CF0794dLi4uCAsLw7vvvlt+ByHIIZYtWyb0er1YsmSJOHr0qJgwYYLw8fERcXFxSodWJfTv318sXbpUHDlyRBw4cEAMGjRI1K5dW6Snp+dv8/TTT4uwsDARFRUl9uzZIzp37iy6dOmSvz4vL0+0aNFC9OnTR+zfv1+sXr1a+Pn5ienTpytxSJXerl27RN26dUWrVq3ElClT8peznstHUlKSqFOnjnjsscfEzp07xblz58S6devEmTNn8rd55513hLe3t/jtt9/EwYMHxb333ivCw8NFVlZW/jYDBgwQrVu3Fjt27BD//POPaNCggRgxYoQSh1Qpvf3226JmzZrir7/+EufPnxcrVqwQHh4e4oMPPsjfhvVceqtXrxavvfaaWLlypQAgfv31V6v15VGnKSkpIjAwUIwaNUocOXJE/Pjjj8LV1VV8/vnn5XIMTIAcpFOnTmLSpEn5j00mkwgJCRHz5s1TMKqqKz4+XgAQW7ZsEUIIkZycLHQ6nVixYkX+NsePHxcARHR0tBBCfmDVarWIjY3N3+azzz4TXl5eIicnx7EHUMmlpaWJhg0big0bNogePXrkJ0Cs5/LzyiuviG7duhW53mw2i6CgIPHee+/lL0tOThYGg0H8+OOPQgghjh07JgCI3bt352+zZs0aoVKpxJUrVyou+Cpk8ODB4vHHH7dadt9994lRo0YJIVjP5eHWBKi86vTTTz8Vvr6+VueNV155RTRu3Lhc4uYlMAfIzc3F3r170adPn/xlarUaffr0QXR0tIKRVV0pKSkAgBo1agAA9u7dC6PRaFXHTZo0Qe3atfPrODo6Gi1btkRgYGD+Nv3790dqaiqOHj3qwOgrv0mTJmHw4MFW9QmwnsvTH3/8gQ4dOuDBBx9EQEAA2rZtiy+++CJ//fnz5xEbG2tV197e3oiIiLCqax8fH3To0CF/mz59+kCtVmPnzp2OO5hKrEuXLoiKisKpU6cAAAcPHsS2bdswcOBAAKznilBedRodHY277roLer0+f5v+/fvj5MmTuHHjxh3HyZuhOkBiYiJMJpPVFwIABAYG4sSJEwpFVXWZzWY899xz6Nq1K1q0aAEAiI2NhV6vh4+Pj9W2gYGBiI2Nzd/G3mtgWUfSsmXLsG/fPuzevdtmHeu5/Jw7dw6fffYZpk6dildffRW7d+/Gs88+C71ej7Fjx+bXlb26LFzXAQEBVuu1Wi1q1KjBur5p2rRpSE1NRZMmTaDRaGAymfD2229j1KhRAMB6rgDlVaexsbEIDw+3KcOyztfX947iZAJEVc6kSZNw5MgRbNu2TelQqp1Lly5hypQp2LBhA1xcXJQOp1ozm83o0KED5s6dCwBo27Ytjhw5goULF2Ls2LEKR1d9/PTTT/j+++/xww8/oHnz5jhw4ACee+45hISEsJ6dHC+BOYCfnx80Go3NSJm4uDgEBQUpFFXVNHnyZPz111/YtGkTatWqlb88KCgIubm5SE5Ottq+cB0HBQXZfQ0s60he4oqPj0e7du2g1Wqh1WqxZcsWfPjhh9BqtQgMDGQ9l5Pg4GA0a9bMalnTpk0RExMDoKCuijtvBAUFIT4+3mp9Xl4ekpKSWNc3vfTSS5g2bRoeeeQRtGzZEqNHj8bzzz+PefPmAWA9V4TyqtOKPpcwAXIAvV6P9u3bIyoqKn+Z2WxGVFQUIiMjFYys6hBCYPLkyfj111+xceNGm2bR9u3bQ6fTWdXxyZMnERMTk1/HkZGROHz4sNWHbsOGDfDy8rL5InJWvXv3xuHDh3HgwIH8nw4dOmDUqFH5f7Oey0fXrl1tpnI4deoU6tSpAwAIDw9HUFCQVV2npqZi586dVnWdnJyMvXv35m+zceNGmM1mREREOOAoKr/MzEyo1dZfdRqNBmazGQDruSKUV51GRkZi69atMBqN+dts2LABjRs3vuPLXwA4DN5Rli1bJgwGg/jqq6/EsWPHxJNPPil8fHysRspQ0SZOnCi8vb3F5s2bxbVr1/J/MjMz87d5+umnRe3atcXGjRvFnj17RGRkpIiMjMxfbxme3a9fP3HgwAGxdu1a4e/vz+HZt1F4FJgQrOfysmvXLqHVasXbb78tTp8+Lb7//nvh5uYmvvvuu/xt3nnnHeHj4yN+//13cejQITF06FC7Q4nbtm0rdu7cKbZt2yYaNmzo1MOzbzV27FgRGhqaPwx+5cqVws/PT7z88sv527CeSy8tLU3s379f7N+/XwAQ8+fPF/v37xcXL14UQpRPnSYnJ4vAwEAxevRoceTIEbFs2TLh5ubGYfBV0UcffSRq164t9Hq96NSpk9ixY4fSIVUZAOz+LF26NH+brKws8cwzzwhfX1/h5uYmhg8fLq5du2ZVzoULF8TAgQOFq6ur8PPzEy+88IIwGo0OPpqq5dYEiPVcfv7880/RokULYTAYRJMmTcSiRYus1pvNZjFz5kwRGBgoDAaD6N27tzh58qTVNtevXxcjRowQHh4ewsvLS4wbN06kpaU58jAqtdTUVDFlyhRRu3Zt4eLiIurVqydee+01q6HVrOfS27Rpk91z8tixY4UQ5VenBw8eFN26dRMGg0GEhoaKd955p9yOQSVEoekwiYiIiJwA+wARERGR02ECRERERE6HCRARERE5HSZARERE5HSYABEREZHTYQJERERETocJEBERETkd3gyViKiELiVlovu7m/If/zihMyLr11QwIiIqKyZARFShos9ex4gvdtx2u/vb1cL/HmrtgIiIiHgJjIiIiJwQW4CIyKHuaRWMVrW8bZY3CvRUIBoiclZMgIjIoXo08seDHcKKXG+vn821lCws+fc8Tselw8OgRa8mAXh5QBP4exps9j98OQVL/z2PXReSEJ+WA61ahVq+rriroT/Gdw9HsLerzT55JjNW7ruCPw9dxfFrqUjJMsLTRYfaNdxwd2N/PNenUZHxrj0Si8+3nsXxa6nQa9To1tAPMwY3Q4iP9fNsOBaHb3dcxLGrKUjONMJFp0ENdz0aB3miTZgPJvaoD7VaVZIqJKJywASIiCq1jzaexvaz1/Mf5+TlYsXey9h5Pgm/PtMFNT0KkqDF287j7VXHYC50i+dcAKfi0nEqLh3L91zCotEdrDouJ2fmYuySXTh4OcXqeZMycpGUkYuzCelFJkCfbTmLracS8h9nG81YfTgWx6+lYc2U7nDRaQAAK/Zcwks/H7LaNz0nD+k5eYhJysSGY3EY3y0cLmpNqeuHiMqGCRAROdSWUwm4kZlrs/yeViE2rSYAsP3sdUTWq4mO4TWw92IS/j0jk6GYpEy8s+YE3ntQdpzeee463lp1DOJm8hPq44ohrUOQmZuHFXsuI8toQlp2HiZ+vxdbXuwJbzcdAOD55Qeskp8GAR7o2dgfeq0aR6+m4sCl5CKPZeupBLSu5Y27Gvkj+ux17Ll4AwBwPjED64/F4d7WIQCA73bG5O/TupY3ejUJhMlsxtWUbBy4lIwz8emlqEEiKg9MgIjIof46dA1/Hbpms7xlqI/dBKh7Qz9883gnqFQqCCEwZsku/HM6EQDw+4GreGNoC7jqNfhy2/n85MfDoMXvk7vC72brUM8mARi3dDcAIDnTiJ/3Xcb4buE4EZuKTScLWnB6NvbHojEdoNMUjA+JuZ5Z5LG0DvPBz09HQqdRw2gyI3JeFBLTZXJ36FJyfgKUYzTl7zP73uZoV9vXqpxLSZnQazgmhciR+IkjokpteNtQqFSyb4xKpcKwNqH563JNZpyITQUA7I+5kb+8RyP//OQHAHo2DkBNd33+4303t919oWAfAJjSp5FV8gMAtWu6FRnbIx3D8rfXadSo5VuwbUqWMf/vTuE18v8e/eVOjF68EzN/O4Jvoi/gRGwqwmq4sf8PkYOxBYiIHOq9B1oV2wn6VoX7+ACA3y0dn1Oz8wDIlp38bTz0uJWfhwHXM2TrTOrN5CTllktxYb62LVDFqXXL9nptQfJUuB/SS/0bIyYpE5tPJiAj14R/Tifmt2IBQER4DSwd1xFuep6SiRyFnzYiqtSup+dYPU5Ms37s5SJPYz5uuvzLT5bfVvsVKsfLVfb/8XazTpQu3ciySbiKo1VbtxYV1Ybj6aLDV+M64VpKFvbHJON8YgZOx6Vh3dE4ZBlN2Hk+CQu3nMPUvkWPNiOi8sVLYERUqf26/wrEzc49Qgj8duBK/jq9Ro0mQV4AYNWvZsupBKuEZ9PJ+PzWHwBof3PbjnWt++J8FHUaeSaz1bLLN4ruA1RSJ2PTYDSZEeztikEtgzGpZwMseKQtHu5Y0BJ29EpKMSUQUXljCxAROVRRo8A8XXQY0am2zfJ/Tidi5Bc70Sm8BvYUGgUGAPe2CYGrXg4dH98tHBuOx0EIOcR86Mf/4t42IcjMycNPey7n7+PjpsP97WsBAJoEeaFnY//8jtBRJ+Ix8IN/0LNJAAxaNU7FpWHX+STsn9Xvjo757dXHcfBSMro2qIlgb1fUcNcjPjUbK/YWxGVplSIix2ACREQOVdQosFAfV7sJUK8mAdh4Ih7R565bLa/l64ppA5vkP46oVxMzBjfLnwfoSnIWPtt81mofTxctPhvVHt6Fko35D7XBY0sL5gE6HZ+O04WGpXu6lM9pMiXLiNWHY+2uM2jVeKxL3XJ5HiIqGSZARFSpTeheD8PahuKLredwKi4NbnoNejUJxCsDGluN9AJkK1DHur746t8L2Hk+CQlpOVCrgVq+bujRyB/ju4XbDLX3ddfj54ldsHLfZfx58Fr+TNDuBi1q13BDryYBd3wMT91VD/X93XHgUjKuJWcjKSMXUAFBXi7oWLcGJtwVnn8pj4gcQyUsF9eJiCoBe7fCKDxzMxFReWAnaCIiInI6TICIiIjI6TABIiIiIqfDPkBERETkdNgCRERERE6HCRARERE5HSZARERE5HSYABEREZHTYQJERERETocJEBERETkdJkBERETkdJgAERERkdNhAkRERERO5/8Bm0fOHn9pk8YAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "font1 = {'family':'serif','color':'blue','size':15}\n",
        "\n",
        "plt.title(\"Gráfica de Aprendizaje del Modelo Sigmoide\", fontdict = font1 )\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"loss\"])\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_loss\"])\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "ax.set_xlabel(\"Epochs\", fontdict = {'fontsize':14, 'fontweight':'bold',\n",
        "                                    'color':'tab:blue'})\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "VD_qykwMajLa",
        "outputId": "ec0e7227-2765-42f1-929c-2a1f98e79c15"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir un mapa de calor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "sns.heatmap(xtrain_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Entrenamiento\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n"
      ],
      "metadata": {
        "id": "lE0LmmEE1LMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un mapa de calor para los datos de prueba\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "sns.heatmap(xtest_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Prueba\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Py3_zIxs4elw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}