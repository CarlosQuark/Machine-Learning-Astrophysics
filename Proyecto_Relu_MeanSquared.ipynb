{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDpIwEJXr7l2unvdsCTZQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosQuark/Machine-Learning-Astrophysics/blob/main/Proyecto_Relu_MeanSquared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# PROYECTO DE MACHINE LEARNING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvURBlWmT07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ZV03xjlnj-NB"
      },
      "outputs": [],
      "source": [
        "#librerias Comunes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#liberias de PCA\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import eig\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder #Change the class to str for another type the int.\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#librerias de sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#librerias de Keras y Redes Neuronales\n",
        "\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = pd.read_csv(\"star_classification.csv\")\n",
        "data_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "OQ6pTIb2mimr",
        "outputId": "5618e40b-ae53-45f6-87b9-b3266a8228a6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237660e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237660e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237660e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237660e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543780e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176010e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030110e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891860e+18   \n",
              "\n",
              "   redshift  plate    MJD  fiber_ID   class  \n",
              "0  0.634794   5812  56354       171  GALAXY  \n",
              "1  0.779136  10445  58158       427  GALAXY  \n",
              "2  0.644195   4576  55592       299  GALAXY  \n",
              "3  0.932346   9149  58039       775  GALAXY  \n",
              "4  0.116123   6121  56187       842  GALAXY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee3a6081-c793-4864-ac49-2dfdcdb8feb0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543780e+18</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176010e+19</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030110e+19</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891860e+18</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee3a6081-c793-4864-ac49-2dfdcdb8feb0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee3a6081-c793-4864-ac49-2dfdcdb8feb0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee3a6081-c793-4864-ac49-2dfdcdb8feb0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b977508-6ec1-489e-9af2-1bfd50c5011a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b977508-6ec1-489e-9af2-1bfd50c5011a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b977508-6ec1-489e-9af2-1bfd50c5011a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nlql6Qz1Znk",
        "outputId": "14ee4780-cff1-413f-d8ce-754483143c08"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 18 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   obj_ID       100000 non-null  float64\n",
            " 1   alpha        100000 non-null  float64\n",
            " 2   delta        100000 non-null  float64\n",
            " 3   u            100000 non-null  float64\n",
            " 4   g            100000 non-null  float64\n",
            " 5   r            100000 non-null  float64\n",
            " 6   i            100000 non-null  float64\n",
            " 7   z            100000 non-null  float64\n",
            " 8   run_ID       100000 non-null  int64  \n",
            " 9   rerun_ID     100000 non-null  int64  \n",
            " 10  cam_col      100000 non-null  int64  \n",
            " 11  field_ID     100000 non-null  int64  \n",
            " 12  spec_obj_ID  100000 non-null  float64\n",
            " 13  redshift     100000 non-null  float64\n",
            " 14  plate        100000 non-null  int64  \n",
            " 15  MJD          100000 non-null  int64  \n",
            " 16  fiber_ID     100000 non-null  int64  \n",
            " 17  class        100000 non-null  object \n",
            "dtypes: float64(10), int64(7), object(1)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enconder = LabelEncoder()\n",
        "\n",
        "data_set[\"class\"] = enconder.fit_transform(data_set[\"class\"])"
      ],
      "metadata": {
        "id": "lVhT4P72weJt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar los datos\n",
        "\n",
        "Y = np.array(data_set[\"class\"])\n",
        "\n",
        "df_new = data_set.drop([\"class\"], axis =1)\n",
        "\n",
        "X = np.array(df_new)\n"
      ],
      "metadata": {
        "id": "5VSRDHJhn75L"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components= 17)\n",
        "PCA_objeto.fit(X)"
      ],
      "metadata": {
        "id": "Akeqp3SySWYi",
        "outputId": "afc23013-a283-4757-c53f-a54fc9947159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PCA_objeto.explained_variance_)"
      ],
      "metadata": {
        "id": "3jmLTxmoSp0Q",
        "outputId": "99365322-e1f2-40f3-8012-fe955588e6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.10491489e+37 5.34345995e+28 3.63783147e+06 1.90094686e+05\n",
            " 6.89069641e+04 2.22875371e+04 8.93542373e+03 3.01724592e+03\n",
            " 3.23491013e+02 6.79740439e+00 3.42870277e+00 2.46778931e+00\n",
            " 1.93784010e+00 4.09255753e-01 3.26988977e-01 4.66492584e-02\n",
            " 3.72772496e-34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components = 17)\n",
        "Z = PCA_objeto.fit_transform(X)"
      ],
      "metadata": {
        "id": "0dytpcETSr5A"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento de los datos\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Z,Y, test_size = 0.2, stratify=Y)"
      ],
      "metadata": {
        "id": "MXeQdyFvxQQ6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estandarizar los datos\n",
        "\n",
        "scaler = MinMaxScaler().fit(xtrain)\n",
        "\n",
        "xtrain_std = scaler.transform(xtrain)\n",
        "\n",
        "xtest_std = scaler.transform(xtest)\n"
      ],
      "metadata": {
        "id": "i6dJHiUQxpVc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Este apartado se utilizar para poder dar inicio el entrenamiento a una red\n",
        "neuronal\n",
        "\n",
        "   Todo esto viene dentro de la página oficial de Keras.\n",
        "\n",
        "   Dense es una capa de neurona que está conectada con todas las anteriores\n",
        "\n",
        "   Sequential es utilizado para crear secuencias en redes neuronales.\n",
        "\n",
        "   Optimizador: Adam.\n",
        "\n",
        "   units es la candtidad de clases que tienes.\n",
        "\n",
        "   activation: \"Qué tipo de función de activación almacenas\".\n",
        "\n",
        "   input_dim = la dimensionalidad.\n",
        "\n",
        "\"\"\"\n",
        "network = Sequential([\n",
        "\n",
        "    Dense(units=3, activation= \"relu\" , input_dim = 17)\n",
        "])\n",
        "\n",
        "#Que copilador voy a utilizar, Adam, puede hacer eso.\n",
        "\n",
        "Adam(learning_rate=0.0001) #Taza de aprendizaje pequeña\n",
        "\n",
        "network.compile()\n",
        "\n",
        "#Función de perdida que se utilizará en la sala de entrenamient como su métrica.\n",
        "\n",
        "network.compile(loss= \"mean_squared_error\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QbP87Xplx-fX"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"La libreria de keras para to_categorical\n",
        "\n",
        "   se utiliza para poder experesar problemas de clasificación de multiclase.\n",
        "   Para convertir nuestras etiquetas númericas en tipo one-hot.\n",
        "\n",
        "   Supongamso que tienes 3 clases (etiqeutas númericas 0,1,2)\n",
        "\n",
        "   En la primera linea convierte la una matriz en one-hot\n",
        "\n",
        "   Cada fila corresponde a un etiqueta, y cada columna, representa una clase.\n",
        "\n",
        "   AQUÍ INICIAMOS LA ETAPA DE ENTRENAMIENTO DE LA RED\n",
        "\n",
        "   El profe explica que es el batch_size, es para reducir el costo\n",
        "   computacional,\n",
        "   crea grupos para filas de hasta 100,000 dimensiones.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#network.fit(xtrain_std, ytrain, epochs=50, batch_size=128 )\n",
        "\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "epoch_accuracy =network.fit(xtrain_std, ytrain, epochs=1000, batch_size=80,\n",
        "                             validation_data=(xtest_std,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMrjFO3yNnb",
        "outputId": "db217ab5-df42-421d-8df4-89f874b95d4c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.2045 - accuracy: 0.5834 - val_loss: 0.1808 - val_accuracy: 0.5950\n",
            "Epoch 2/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1710 - accuracy: 0.6000 - val_loss: 0.1634 - val_accuracy: 0.6076\n",
            "Epoch 3/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1584 - accuracy: 0.6157 - val_loss: 0.1538 - val_accuracy: 0.6231\n",
            "Epoch 4/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1499 - accuracy: 0.6368 - val_loss: 0.1464 - val_accuracy: 0.6594\n",
            "Epoch 5/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1432 - accuracy: 0.6697 - val_loss: 0.1404 - val_accuracy: 0.6898\n",
            "Epoch 6/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1378 - accuracy: 0.7025 - val_loss: 0.1355 - val_accuracy: 0.7074\n",
            "Epoch 7/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1331 - accuracy: 0.7307 - val_loss: 0.1312 - val_accuracy: 0.7362\n",
            "Epoch 8/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1293 - accuracy: 0.7544 - val_loss: 0.1278 - val_accuracy: 0.7463\n",
            "Epoch 9/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1259 - accuracy: 0.7706 - val_loss: 0.1247 - val_accuracy: 0.7776\n",
            "Epoch 10/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1232 - accuracy: 0.7846 - val_loss: 0.1222 - val_accuracy: 0.7986\n",
            "Epoch 11/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1209 - accuracy: 0.7954 - val_loss: 0.1200 - val_accuracy: 0.7916\n",
            "Epoch 12/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1188 - accuracy: 0.8033 - val_loss: 0.1181 - val_accuracy: 0.8037\n",
            "Epoch 13/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1171 - accuracy: 0.8109 - val_loss: 0.1165 - val_accuracy: 0.8077\n",
            "Epoch 14/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1155 - accuracy: 0.8151 - val_loss: 0.1152 - val_accuracy: 0.8224\n",
            "Epoch 15/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1141 - accuracy: 0.8200 - val_loss: 0.1138 - val_accuracy: 0.8239\n",
            "Epoch 16/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1130 - accuracy: 0.8223 - val_loss: 0.1129 - val_accuracy: 0.8256\n",
            "Epoch 17/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1119 - accuracy: 0.8247 - val_loss: 0.1117 - val_accuracy: 0.8220\n",
            "Epoch 18/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1110 - accuracy: 0.8274 - val_loss: 0.1109 - val_accuracy: 0.8264\n",
            "Epoch 19/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1102 - accuracy: 0.8283 - val_loss: 0.1105 - val_accuracy: 0.8219\n",
            "Epoch 20/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1094 - accuracy: 0.8304 - val_loss: 0.1099 - val_accuracy: 0.8322\n",
            "Epoch 21/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1087 - accuracy: 0.8314 - val_loss: 0.1088 - val_accuracy: 0.8288\n",
            "Epoch 22/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1081 - accuracy: 0.8331 - val_loss: 0.1082 - val_accuracy: 0.8284\n",
            "Epoch 23/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1076 - accuracy: 0.8329 - val_loss: 0.1076 - val_accuracy: 0.8303\n",
            "Epoch 24/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1071 - accuracy: 0.8344 - val_loss: 0.1072 - val_accuracy: 0.8321\n",
            "Epoch 25/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1066 - accuracy: 0.8356 - val_loss: 0.1067 - val_accuracy: 0.8324\n",
            "Epoch 26/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1061 - accuracy: 0.8358 - val_loss: 0.1063 - val_accuracy: 0.8325\n",
            "Epoch 27/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1057 - accuracy: 0.8366 - val_loss: 0.1059 - val_accuracy: 0.8334\n",
            "Epoch 28/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1053 - accuracy: 0.8376 - val_loss: 0.1061 - val_accuracy: 0.8296\n",
            "Epoch 29/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1050 - accuracy: 0.8377 - val_loss: 0.1053 - val_accuracy: 0.8342\n",
            "Epoch 30/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1046 - accuracy: 0.8388 - val_loss: 0.1053 - val_accuracy: 0.8305\n",
            "Epoch 31/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1043 - accuracy: 0.8396 - val_loss: 0.1047 - val_accuracy: 0.8365\n",
            "Epoch 32/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1040 - accuracy: 0.8395 - val_loss: 0.1044 - val_accuracy: 0.8352\n",
            "Epoch 33/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1038 - accuracy: 0.8402 - val_loss: 0.1041 - val_accuracy: 0.8357\n",
            "Epoch 34/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1035 - accuracy: 0.8402 - val_loss: 0.1038 - val_accuracy: 0.8372\n",
            "Epoch 35/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1033 - accuracy: 0.8412 - val_loss: 0.1037 - val_accuracy: 0.8360\n",
            "Epoch 36/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1030 - accuracy: 0.8410 - val_loss: 0.1035 - val_accuracy: 0.8367\n",
            "Epoch 37/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1028 - accuracy: 0.8419 - val_loss: 0.1032 - val_accuracy: 0.8371\n",
            "Epoch 38/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1026 - accuracy: 0.8424 - val_loss: 0.1030 - val_accuracy: 0.8378\n",
            "Epoch 39/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1024 - accuracy: 0.8430 - val_loss: 0.1028 - val_accuracy: 0.8388\n",
            "Epoch 40/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1022 - accuracy: 0.8430 - val_loss: 0.1027 - val_accuracy: 0.8377\n",
            "Epoch 41/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1020 - accuracy: 0.8433 - val_loss: 0.1025 - val_accuracy: 0.8399\n",
            "Epoch 42/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1018 - accuracy: 0.8440 - val_loss: 0.1023 - val_accuracy: 0.8397\n",
            "Epoch 43/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1017 - accuracy: 0.8447 - val_loss: 0.1023 - val_accuracy: 0.8415\n",
            "Epoch 44/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1015 - accuracy: 0.8443 - val_loss: 0.1019 - val_accuracy: 0.8401\n",
            "Epoch 45/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1013 - accuracy: 0.8446 - val_loss: 0.1018 - val_accuracy: 0.8403\n",
            "Epoch 46/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1012 - accuracy: 0.8452 - val_loss: 0.1017 - val_accuracy: 0.8407\n",
            "Epoch 47/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1010 - accuracy: 0.8453 - val_loss: 0.1016 - val_accuracy: 0.8403\n",
            "Epoch 48/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1009 - accuracy: 0.8457 - val_loss: 0.1014 - val_accuracy: 0.8417\n",
            "Epoch 49/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1007 - accuracy: 0.8457 - val_loss: 0.1013 - val_accuracy: 0.8425\n",
            "Epoch 50/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1006 - accuracy: 0.8467 - val_loss: 0.1011 - val_accuracy: 0.8415\n",
            "Epoch 51/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1005 - accuracy: 0.8466 - val_loss: 0.1012 - val_accuracy: 0.8398\n",
            "Epoch 52/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1003 - accuracy: 0.8471 - val_loss: 0.1015 - val_accuracy: 0.8389\n",
            "Epoch 53/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.1002 - accuracy: 0.8475 - val_loss: 0.1008 - val_accuracy: 0.8438\n",
            "Epoch 54/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1001 - accuracy: 0.8472 - val_loss: 0.1008 - val_accuracy: 0.8439\n",
            "Epoch 55/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1000 - accuracy: 0.8477 - val_loss: 0.1006 - val_accuracy: 0.8425\n",
            "Epoch 56/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0999 - accuracy: 0.8475 - val_loss: 0.1005 - val_accuracy: 0.8425\n",
            "Epoch 57/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0998 - accuracy: 0.8479 - val_loss: 0.1006 - val_accuracy: 0.8411\n",
            "Epoch 58/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0997 - accuracy: 0.8484 - val_loss: 0.1003 - val_accuracy: 0.8429\n",
            "Epoch 59/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0995 - accuracy: 0.8490 - val_loss: 0.1003 - val_accuracy: 0.8442\n",
            "Epoch 60/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0995 - accuracy: 0.8485 - val_loss: 0.1000 - val_accuracy: 0.8444\n",
            "Epoch 61/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0993 - accuracy: 0.8490 - val_loss: 0.1000 - val_accuracy: 0.8442\n",
            "Epoch 62/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0993 - accuracy: 0.8493 - val_loss: 0.0998 - val_accuracy: 0.8452\n",
            "Epoch 63/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0992 - accuracy: 0.8501 - val_loss: 0.0998 - val_accuracy: 0.8456\n",
            "Epoch 64/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0991 - accuracy: 0.8497 - val_loss: 0.0997 - val_accuracy: 0.8450\n",
            "Epoch 65/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0990 - accuracy: 0.8498 - val_loss: 0.0996 - val_accuracy: 0.8449\n",
            "Epoch 66/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0989 - accuracy: 0.8500 - val_loss: 0.0998 - val_accuracy: 0.8427\n",
            "Epoch 67/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0988 - accuracy: 0.8503 - val_loss: 0.0994 - val_accuracy: 0.8452\n",
            "Epoch 68/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0987 - accuracy: 0.8503 - val_loss: 0.0994 - val_accuracy: 0.8465\n",
            "Epoch 69/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0987 - accuracy: 0.8504 - val_loss: 0.0995 - val_accuracy: 0.8482\n",
            "Epoch 70/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0986 - accuracy: 0.8508 - val_loss: 0.0992 - val_accuracy: 0.8465\n",
            "Epoch 71/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0985 - accuracy: 0.8508 - val_loss: 0.0993 - val_accuracy: 0.8483\n",
            "Epoch 72/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0984 - accuracy: 0.8509 - val_loss: 0.0991 - val_accuracy: 0.8489\n",
            "Epoch 73/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0983 - accuracy: 0.8513 - val_loss: 0.0990 - val_accuracy: 0.8479\n",
            "Epoch 74/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0983 - accuracy: 0.8518 - val_loss: 0.0989 - val_accuracy: 0.8483\n",
            "Epoch 75/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0982 - accuracy: 0.8518 - val_loss: 0.0989 - val_accuracy: 0.8483\n",
            "Epoch 76/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0981 - accuracy: 0.8520 - val_loss: 0.0988 - val_accuracy: 0.8493\n",
            "Epoch 77/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0981 - accuracy: 0.8519 - val_loss: 0.0991 - val_accuracy: 0.8433\n",
            "Epoch 78/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0980 - accuracy: 0.8516 - val_loss: 0.0987 - val_accuracy: 0.8498\n",
            "Epoch 79/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0979 - accuracy: 0.8525 - val_loss: 0.0986 - val_accuracy: 0.8486\n",
            "Epoch 80/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0979 - accuracy: 0.8523 - val_loss: 0.0989 - val_accuracy: 0.8446\n",
            "Epoch 81/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0978 - accuracy: 0.8531 - val_loss: 0.0984 - val_accuracy: 0.8481\n",
            "Epoch 82/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0977 - accuracy: 0.8529 - val_loss: 0.0985 - val_accuracy: 0.8476\n",
            "Epoch 83/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0977 - accuracy: 0.8524 - val_loss: 0.0983 - val_accuracy: 0.8495\n",
            "Epoch 84/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0976 - accuracy: 0.8527 - val_loss: 0.0984 - val_accuracy: 0.8498\n",
            "Epoch 85/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0975 - accuracy: 0.8528 - val_loss: 0.0985 - val_accuracy: 0.8452\n",
            "Epoch 86/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0975 - accuracy: 0.8530 - val_loss: 0.0982 - val_accuracy: 0.8510\n",
            "Epoch 87/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0974 - accuracy: 0.8538 - val_loss: 0.0981 - val_accuracy: 0.8496\n",
            "Epoch 88/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0974 - accuracy: 0.8536 - val_loss: 0.0980 - val_accuracy: 0.8502\n",
            "Epoch 89/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0973 - accuracy: 0.8541 - val_loss: 0.0980 - val_accuracy: 0.8515\n",
            "Epoch 90/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0973 - accuracy: 0.8534 - val_loss: 0.0979 - val_accuracy: 0.8499\n",
            "Epoch 91/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0972 - accuracy: 0.8536 - val_loss: 0.0980 - val_accuracy: 0.8486\n",
            "Epoch 92/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0971 - accuracy: 0.8544 - val_loss: 0.0978 - val_accuracy: 0.8494\n",
            "Epoch 93/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0970 - accuracy: 0.8537 - val_loss: 0.0978 - val_accuracy: 0.8520\n",
            "Epoch 94/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0970 - accuracy: 0.8539 - val_loss: 0.0978 - val_accuracy: 0.8504\n",
            "Epoch 95/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0969 - accuracy: 0.8545 - val_loss: 0.0976 - val_accuracy: 0.8518\n",
            "Epoch 96/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0969 - accuracy: 0.8541 - val_loss: 0.0977 - val_accuracy: 0.8522\n",
            "Epoch 97/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0968 - accuracy: 0.8545 - val_loss: 0.0975 - val_accuracy: 0.8509\n",
            "Epoch 98/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0968 - accuracy: 0.8547 - val_loss: 0.0975 - val_accuracy: 0.8518\n",
            "Epoch 99/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0967 - accuracy: 0.8547 - val_loss: 0.0975 - val_accuracy: 0.8522\n",
            "Epoch 100/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0967 - accuracy: 0.8548 - val_loss: 0.0974 - val_accuracy: 0.8525\n",
            "Epoch 101/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0966 - accuracy: 0.8550 - val_loss: 0.0973 - val_accuracy: 0.8511\n",
            "Epoch 102/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0966 - accuracy: 0.8550 - val_loss: 0.0972 - val_accuracy: 0.8518\n",
            "Epoch 103/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0965 - accuracy: 0.8548 - val_loss: 0.0972 - val_accuracy: 0.8514\n",
            "Epoch 104/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0965 - accuracy: 0.8558 - val_loss: 0.0971 - val_accuracy: 0.8531\n",
            "Epoch 105/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0964 - accuracy: 0.8549 - val_loss: 0.0972 - val_accuracy: 0.8500\n",
            "Epoch 106/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0964 - accuracy: 0.8551 - val_loss: 0.0971 - val_accuracy: 0.8533\n",
            "Epoch 107/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0963 - accuracy: 0.8556 - val_loss: 0.0971 - val_accuracy: 0.8516\n",
            "Epoch 108/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0963 - accuracy: 0.8557 - val_loss: 0.0969 - val_accuracy: 0.8526\n",
            "Epoch 109/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0962 - accuracy: 0.8557 - val_loss: 0.0969 - val_accuracy: 0.8529\n",
            "Epoch 110/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0962 - accuracy: 0.8557 - val_loss: 0.0969 - val_accuracy: 0.8528\n",
            "Epoch 111/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0961 - accuracy: 0.8558 - val_loss: 0.0970 - val_accuracy: 0.8489\n",
            "Epoch 112/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0960 - accuracy: 0.8555 - val_loss: 0.0968 - val_accuracy: 0.8521\n",
            "Epoch 113/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0960 - accuracy: 0.8565 - val_loss: 0.0968 - val_accuracy: 0.8506\n",
            "Epoch 114/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0960 - accuracy: 0.8560 - val_loss: 0.0967 - val_accuracy: 0.8536\n",
            "Epoch 115/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0959 - accuracy: 0.8563 - val_loss: 0.0967 - val_accuracy: 0.8506\n",
            "Epoch 116/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0959 - accuracy: 0.8558 - val_loss: 0.0968 - val_accuracy: 0.8546\n",
            "Epoch 117/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0958 - accuracy: 0.8559 - val_loss: 0.0966 - val_accuracy: 0.8502\n",
            "Epoch 118/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0958 - accuracy: 0.8562 - val_loss: 0.0966 - val_accuracy: 0.8542\n",
            "Epoch 119/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0957 - accuracy: 0.8565 - val_loss: 0.0967 - val_accuracy: 0.8493\n",
            "Epoch 120/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0957 - accuracy: 0.8567 - val_loss: 0.0963 - val_accuracy: 0.8541\n",
            "Epoch 121/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0956 - accuracy: 0.8568 - val_loss: 0.0964 - val_accuracy: 0.8511\n",
            "Epoch 122/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0956 - accuracy: 0.8562 - val_loss: 0.0964 - val_accuracy: 0.8522\n",
            "Epoch 123/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0956 - accuracy: 0.8569 - val_loss: 0.0964 - val_accuracy: 0.8511\n",
            "Epoch 124/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0955 - accuracy: 0.8568 - val_loss: 0.0962 - val_accuracy: 0.8526\n",
            "Epoch 125/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0955 - accuracy: 0.8571 - val_loss: 0.0961 - val_accuracy: 0.8540\n",
            "Epoch 126/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0954 - accuracy: 0.8573 - val_loss: 0.0962 - val_accuracy: 0.8551\n",
            "Epoch 127/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0954 - accuracy: 0.8567 - val_loss: 0.0961 - val_accuracy: 0.8554\n",
            "Epoch 128/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0953 - accuracy: 0.8570 - val_loss: 0.0961 - val_accuracy: 0.8516\n",
            "Epoch 129/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0953 - accuracy: 0.8570 - val_loss: 0.0960 - val_accuracy: 0.8533\n",
            "Epoch 130/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0952 - accuracy: 0.8568 - val_loss: 0.0960 - val_accuracy: 0.8561\n",
            "Epoch 131/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0952 - accuracy: 0.8579 - val_loss: 0.0958 - val_accuracy: 0.8536\n",
            "Epoch 132/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0951 - accuracy: 0.8572 - val_loss: 0.0958 - val_accuracy: 0.8536\n",
            "Epoch 133/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0951 - accuracy: 0.8575 - val_loss: 0.0958 - val_accuracy: 0.8562\n",
            "Epoch 134/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0950 - accuracy: 0.8575 - val_loss: 0.0957 - val_accuracy: 0.8529\n",
            "Epoch 135/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0950 - accuracy: 0.8574 - val_loss: 0.0956 - val_accuracy: 0.8545\n",
            "Epoch 136/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0949 - accuracy: 0.8577 - val_loss: 0.0956 - val_accuracy: 0.8533\n",
            "Epoch 137/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0949 - accuracy: 0.8575 - val_loss: 0.0959 - val_accuracy: 0.8496\n",
            "Epoch 138/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0949 - accuracy: 0.8577 - val_loss: 0.0955 - val_accuracy: 0.8545\n",
            "Epoch 139/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0948 - accuracy: 0.8579 - val_loss: 0.0955 - val_accuracy: 0.8565\n",
            "Epoch 140/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0948 - accuracy: 0.8575 - val_loss: 0.0955 - val_accuracy: 0.8557\n",
            "Epoch 141/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.8575 - val_loss: 0.0954 - val_accuracy: 0.8539\n",
            "Epoch 142/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.8576 - val_loss: 0.0954 - val_accuracy: 0.8564\n",
            "Epoch 143/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0946 - accuracy: 0.8579 - val_loss: 0.0954 - val_accuracy: 0.8562\n",
            "Epoch 144/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0946 - accuracy: 0.8579 - val_loss: 0.0953 - val_accuracy: 0.8563\n",
            "Epoch 145/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0945 - accuracy: 0.8584 - val_loss: 0.0952 - val_accuracy: 0.8536\n",
            "Epoch 146/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0945 - accuracy: 0.8576 - val_loss: 0.0951 - val_accuracy: 0.8559\n",
            "Epoch 147/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0944 - accuracy: 0.8580 - val_loss: 0.0952 - val_accuracy: 0.8520\n",
            "Epoch 148/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0944 - accuracy: 0.8580 - val_loss: 0.0953 - val_accuracy: 0.8573\n",
            "Epoch 149/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0944 - accuracy: 0.8584 - val_loss: 0.0953 - val_accuracy: 0.8507\n",
            "Epoch 150/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0943 - accuracy: 0.8582 - val_loss: 0.0951 - val_accuracy: 0.8577\n",
            "Epoch 151/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0943 - accuracy: 0.8585 - val_loss: 0.0950 - val_accuracy: 0.8535\n",
            "Epoch 152/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0942 - accuracy: 0.8583 - val_loss: 0.0949 - val_accuracy: 0.8536\n",
            "Epoch 153/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0942 - accuracy: 0.8581 - val_loss: 0.0948 - val_accuracy: 0.8559\n",
            "Epoch 154/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0942 - accuracy: 0.8585 - val_loss: 0.0948 - val_accuracy: 0.8569\n",
            "Epoch 155/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0941 - accuracy: 0.8585 - val_loss: 0.0948 - val_accuracy: 0.8577\n",
            "Epoch 156/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0941 - accuracy: 0.8582 - val_loss: 0.0948 - val_accuracy: 0.8543\n",
            "Epoch 157/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0940 - accuracy: 0.8585 - val_loss: 0.0947 - val_accuracy: 0.8573\n",
            "Epoch 158/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0940 - accuracy: 0.8588 - val_loss: 0.0947 - val_accuracy: 0.8573\n",
            "Epoch 159/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0939 - accuracy: 0.8581 - val_loss: 0.0946 - val_accuracy: 0.8569\n",
            "Epoch 160/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0939 - accuracy: 0.8581 - val_loss: 0.0946 - val_accuracy: 0.8566\n",
            "Epoch 161/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0939 - accuracy: 0.8586 - val_loss: 0.0946 - val_accuracy: 0.8532\n",
            "Epoch 162/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0938 - accuracy: 0.8582 - val_loss: 0.0945 - val_accuracy: 0.8553\n",
            "Epoch 163/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0938 - accuracy: 0.8584 - val_loss: 0.0945 - val_accuracy: 0.8572\n",
            "Epoch 164/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0937 - accuracy: 0.8585 - val_loss: 0.0947 - val_accuracy: 0.8504\n",
            "Epoch 165/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0937 - accuracy: 0.8585 - val_loss: 0.0943 - val_accuracy: 0.8550\n",
            "Epoch 166/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0937 - accuracy: 0.8583 - val_loss: 0.0943 - val_accuracy: 0.8553\n",
            "Epoch 167/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0936 - accuracy: 0.8582 - val_loss: 0.0943 - val_accuracy: 0.8579\n",
            "Epoch 168/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0936 - accuracy: 0.8582 - val_loss: 0.0942 - val_accuracy: 0.8551\n",
            "Epoch 169/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0935 - accuracy: 0.8584 - val_loss: 0.0941 - val_accuracy: 0.8558\n",
            "Epoch 170/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0935 - accuracy: 0.8589 - val_loss: 0.0943 - val_accuracy: 0.8515\n",
            "Epoch 171/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0934 - accuracy: 0.8587 - val_loss: 0.0941 - val_accuracy: 0.8557\n",
            "Epoch 172/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0934 - accuracy: 0.8584 - val_loss: 0.0940 - val_accuracy: 0.8567\n",
            "Epoch 173/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0934 - accuracy: 0.8582 - val_loss: 0.0940 - val_accuracy: 0.8565\n",
            "Epoch 174/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0933 - accuracy: 0.8586 - val_loss: 0.0941 - val_accuracy: 0.8525\n",
            "Epoch 175/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0933 - accuracy: 0.8583 - val_loss: 0.0939 - val_accuracy: 0.8558\n",
            "Epoch 176/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0932 - accuracy: 0.8587 - val_loss: 0.0939 - val_accuracy: 0.8569\n",
            "Epoch 177/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0932 - accuracy: 0.8583 - val_loss: 0.0940 - val_accuracy: 0.8530\n",
            "Epoch 178/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0932 - accuracy: 0.8587 - val_loss: 0.0938 - val_accuracy: 0.8550\n",
            "Epoch 179/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0931 - accuracy: 0.8586 - val_loss: 0.0938 - val_accuracy: 0.8528\n",
            "Epoch 180/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0931 - accuracy: 0.8589 - val_loss: 0.0941 - val_accuracy: 0.8510\n",
            "Epoch 181/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0930 - accuracy: 0.8590 - val_loss: 0.0938 - val_accuracy: 0.8579\n",
            "Epoch 182/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0930 - accuracy: 0.8587 - val_loss: 0.0937 - val_accuracy: 0.8573\n",
            "Epoch 183/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0930 - accuracy: 0.8590 - val_loss: 0.0936 - val_accuracy: 0.8564\n",
            "Epoch 184/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0929 - accuracy: 0.8585 - val_loss: 0.0935 - val_accuracy: 0.8558\n",
            "Epoch 185/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0929 - accuracy: 0.8589 - val_loss: 0.0935 - val_accuracy: 0.8558\n",
            "Epoch 186/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0928 - accuracy: 0.8587 - val_loss: 0.0935 - val_accuracy: 0.8557\n",
            "Epoch 187/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0928 - accuracy: 0.8588 - val_loss: 0.0935 - val_accuracy: 0.8550\n",
            "Epoch 188/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0928 - accuracy: 0.8584 - val_loss: 0.0935 - val_accuracy: 0.8548\n",
            "Epoch 189/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0927 - accuracy: 0.8588 - val_loss: 0.0937 - val_accuracy: 0.8586\n",
            "Epoch 190/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0927 - accuracy: 0.8586 - val_loss: 0.0933 - val_accuracy: 0.8550\n",
            "Epoch 191/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0927 - accuracy: 0.8591 - val_loss: 0.0935 - val_accuracy: 0.8522\n",
            "Epoch 192/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0926 - accuracy: 0.8591 - val_loss: 0.0933 - val_accuracy: 0.8562\n",
            "Epoch 193/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0926 - accuracy: 0.8591 - val_loss: 0.0933 - val_accuracy: 0.8558\n",
            "Epoch 194/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0926 - accuracy: 0.8588 - val_loss: 0.0933 - val_accuracy: 0.8577\n",
            "Epoch 195/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0925 - accuracy: 0.8590 - val_loss: 0.0931 - val_accuracy: 0.8557\n",
            "Epoch 196/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0925 - accuracy: 0.8591 - val_loss: 0.0932 - val_accuracy: 0.8558\n",
            "Epoch 197/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0924 - accuracy: 0.8588 - val_loss: 0.0932 - val_accuracy: 0.8536\n",
            "Epoch 198/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0924 - accuracy: 0.8586 - val_loss: 0.0931 - val_accuracy: 0.8537\n",
            "Epoch 199/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0924 - accuracy: 0.8590 - val_loss: 0.0931 - val_accuracy: 0.8547\n",
            "Epoch 200/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0923 - accuracy: 0.8592 - val_loss: 0.0932 - val_accuracy: 0.8522\n",
            "Epoch 201/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0923 - accuracy: 0.8586 - val_loss: 0.0932 - val_accuracy: 0.8532\n",
            "Epoch 202/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0923 - accuracy: 0.8591 - val_loss: 0.0929 - val_accuracy: 0.8541\n",
            "Epoch 203/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0922 - accuracy: 0.8587 - val_loss: 0.0928 - val_accuracy: 0.8564\n",
            "Epoch 204/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0922 - accuracy: 0.8593 - val_loss: 0.0930 - val_accuracy: 0.8544\n",
            "Epoch 205/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0921 - accuracy: 0.8590 - val_loss: 0.0928 - val_accuracy: 0.8549\n",
            "Epoch 206/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0921 - accuracy: 0.8592 - val_loss: 0.0929 - val_accuracy: 0.8536\n",
            "Epoch 207/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0921 - accuracy: 0.8590 - val_loss: 0.0928 - val_accuracy: 0.8551\n",
            "Epoch 208/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0920 - accuracy: 0.8588 - val_loss: 0.0928 - val_accuracy: 0.8533\n",
            "Epoch 209/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0920 - accuracy: 0.8593 - val_loss: 0.0928 - val_accuracy: 0.8569\n",
            "Epoch 210/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.8594 - val_loss: 0.0927 - val_accuracy: 0.8539\n",
            "Epoch 211/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0919 - accuracy: 0.8593 - val_loss: 0.0926 - val_accuracy: 0.8546\n",
            "Epoch 212/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0919 - accuracy: 0.8586 - val_loss: 0.0925 - val_accuracy: 0.8561\n",
            "Epoch 213/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0918 - accuracy: 0.8596 - val_loss: 0.0927 - val_accuracy: 0.8586\n",
            "Epoch 214/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0918 - accuracy: 0.8592 - val_loss: 0.0926 - val_accuracy: 0.8527\n",
            "Epoch 215/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0918 - accuracy: 0.8591 - val_loss: 0.0926 - val_accuracy: 0.8554\n",
            "Epoch 216/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0917 - accuracy: 0.8587 - val_loss: 0.0925 - val_accuracy: 0.8583\n",
            "Epoch 217/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0917 - accuracy: 0.8585 - val_loss: 0.0929 - val_accuracy: 0.8596\n",
            "Epoch 218/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0917 - accuracy: 0.8587 - val_loss: 0.0923 - val_accuracy: 0.8563\n",
            "Epoch 219/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0916 - accuracy: 0.8590 - val_loss: 0.0924 - val_accuracy: 0.8579\n",
            "Epoch 220/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0916 - accuracy: 0.8590 - val_loss: 0.0922 - val_accuracy: 0.8554\n",
            "Epoch 221/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0916 - accuracy: 0.8590 - val_loss: 0.0924 - val_accuracy: 0.8551\n",
            "Epoch 222/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0915 - accuracy: 0.8590 - val_loss: 0.0922 - val_accuracy: 0.8543\n",
            "Epoch 223/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0915 - accuracy: 0.8593 - val_loss: 0.0922 - val_accuracy: 0.8555\n",
            "Epoch 224/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0915 - accuracy: 0.8591 - val_loss: 0.0922 - val_accuracy: 0.8568\n",
            "Epoch 225/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0914 - accuracy: 0.8591 - val_loss: 0.0921 - val_accuracy: 0.8554\n",
            "Epoch 226/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0914 - accuracy: 0.8591 - val_loss: 0.0920 - val_accuracy: 0.8565\n",
            "Epoch 227/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0914 - accuracy: 0.8597 - val_loss: 0.0922 - val_accuracy: 0.8586\n",
            "Epoch 228/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0913 - accuracy: 0.8594 - val_loss: 0.0920 - val_accuracy: 0.8557\n",
            "Epoch 229/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0913 - accuracy: 0.8591 - val_loss: 0.0920 - val_accuracy: 0.8575\n",
            "Epoch 230/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0913 - accuracy: 0.8595 - val_loss: 0.0920 - val_accuracy: 0.8568\n",
            "Epoch 231/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0912 - accuracy: 0.8590 - val_loss: 0.0920 - val_accuracy: 0.8582\n",
            "Epoch 232/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0912 - accuracy: 0.8589 - val_loss: 0.0919 - val_accuracy: 0.8568\n",
            "Epoch 233/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0912 - accuracy: 0.8592 - val_loss: 0.0918 - val_accuracy: 0.8573\n",
            "Epoch 234/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0911 - accuracy: 0.8598 - val_loss: 0.0919 - val_accuracy: 0.8576\n",
            "Epoch 235/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0911 - accuracy: 0.8594 - val_loss: 0.0918 - val_accuracy: 0.8561\n",
            "Epoch 236/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0911 - accuracy: 0.8596 - val_loss: 0.0918 - val_accuracy: 0.8543\n",
            "Epoch 237/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0910 - accuracy: 0.8594 - val_loss: 0.0918 - val_accuracy: 0.8582\n",
            "Epoch 238/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0910 - accuracy: 0.8591 - val_loss: 0.0918 - val_accuracy: 0.8559\n",
            "Epoch 239/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0909 - accuracy: 0.8594 - val_loss: 0.0917 - val_accuracy: 0.8570\n",
            "Epoch 240/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0909 - accuracy: 0.8594 - val_loss: 0.0916 - val_accuracy: 0.8561\n",
            "Epoch 241/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0909 - accuracy: 0.8591 - val_loss: 0.0917 - val_accuracy: 0.8583\n",
            "Epoch 242/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0909 - accuracy: 0.8597 - val_loss: 0.0915 - val_accuracy: 0.8576\n",
            "Epoch 243/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0908 - accuracy: 0.8596 - val_loss: 0.0915 - val_accuracy: 0.8551\n",
            "Epoch 244/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0908 - accuracy: 0.8592 - val_loss: 0.0915 - val_accuracy: 0.8568\n",
            "Epoch 245/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0908 - accuracy: 0.8595 - val_loss: 0.0915 - val_accuracy: 0.8573\n",
            "Epoch 246/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0907 - accuracy: 0.8599 - val_loss: 0.0915 - val_accuracy: 0.8540\n",
            "Epoch 247/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0907 - accuracy: 0.8593 - val_loss: 0.0915 - val_accuracy: 0.8546\n",
            "Epoch 248/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0907 - accuracy: 0.8594 - val_loss: 0.0914 - val_accuracy: 0.8546\n",
            "Epoch 249/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0907 - accuracy: 0.8595 - val_loss: 0.0914 - val_accuracy: 0.8561\n",
            "Epoch 250/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0906 - accuracy: 0.8594 - val_loss: 0.0913 - val_accuracy: 0.8551\n",
            "Epoch 251/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0906 - accuracy: 0.8601 - val_loss: 0.0913 - val_accuracy: 0.8574\n",
            "Epoch 252/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0905 - accuracy: 0.8597 - val_loss: 0.0912 - val_accuracy: 0.8575\n",
            "Epoch 253/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0905 - accuracy: 0.8597 - val_loss: 0.0915 - val_accuracy: 0.8519\n",
            "Epoch 254/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0905 - accuracy: 0.8597 - val_loss: 0.0916 - val_accuracy: 0.8523\n",
            "Epoch 255/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0905 - accuracy: 0.8595 - val_loss: 0.0912 - val_accuracy: 0.8550\n",
            "Epoch 256/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0904 - accuracy: 0.8598 - val_loss: 0.0911 - val_accuracy: 0.8562\n",
            "Epoch 257/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0904 - accuracy: 0.8599 - val_loss: 0.0912 - val_accuracy: 0.8582\n",
            "Epoch 258/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0904 - accuracy: 0.8595 - val_loss: 0.0913 - val_accuracy: 0.8600\n",
            "Epoch 259/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0904 - accuracy: 0.8600 - val_loss: 0.0911 - val_accuracy: 0.8589\n",
            "Epoch 260/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0903 - accuracy: 0.8601 - val_loss: 0.0910 - val_accuracy: 0.8558\n",
            "Epoch 261/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0903 - accuracy: 0.8597 - val_loss: 0.0909 - val_accuracy: 0.8569\n",
            "Epoch 262/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0903 - accuracy: 0.8594 - val_loss: 0.0916 - val_accuracy: 0.8602\n",
            "Epoch 263/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0902 - accuracy: 0.8601 - val_loss: 0.0909 - val_accuracy: 0.8555\n",
            "Epoch 264/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0902 - accuracy: 0.8590 - val_loss: 0.0912 - val_accuracy: 0.8598\n",
            "Epoch 265/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0902 - accuracy: 0.8599 - val_loss: 0.0909 - val_accuracy: 0.8581\n",
            "Epoch 266/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0901 - accuracy: 0.8599 - val_loss: 0.0908 - val_accuracy: 0.8582\n",
            "Epoch 267/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0901 - accuracy: 0.8606 - val_loss: 0.0908 - val_accuracy: 0.8580\n",
            "Epoch 268/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0901 - accuracy: 0.8600 - val_loss: 0.0908 - val_accuracy: 0.8578\n",
            "Epoch 269/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0900 - accuracy: 0.8602 - val_loss: 0.0908 - val_accuracy: 0.8586\n",
            "Epoch 270/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0900 - accuracy: 0.8605 - val_loss: 0.0908 - val_accuracy: 0.8554\n",
            "Epoch 271/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0900 - accuracy: 0.8601 - val_loss: 0.0907 - val_accuracy: 0.8558\n",
            "Epoch 272/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0900 - accuracy: 0.8598 - val_loss: 0.0907 - val_accuracy: 0.8579\n",
            "Epoch 273/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.8603 - val_loss: 0.0910 - val_accuracy: 0.8601\n",
            "Epoch 274/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.8601 - val_loss: 0.0906 - val_accuracy: 0.8589\n",
            "Epoch 275/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.8605 - val_loss: 0.0906 - val_accuracy: 0.8573\n",
            "Epoch 276/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.8605 - val_loss: 0.0906 - val_accuracy: 0.8582\n",
            "Epoch 277/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.8605 - val_loss: 0.0905 - val_accuracy: 0.8579\n",
            "Epoch 278/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0898 - accuracy: 0.8607 - val_loss: 0.0905 - val_accuracy: 0.8583\n",
            "Epoch 279/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0898 - accuracy: 0.8605 - val_loss: 0.0904 - val_accuracy: 0.8583\n",
            "Epoch 280/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0898 - accuracy: 0.8608 - val_loss: 0.0904 - val_accuracy: 0.8574\n",
            "Epoch 281/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0897 - accuracy: 0.8602 - val_loss: 0.0904 - val_accuracy: 0.8568\n",
            "Epoch 282/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0897 - accuracy: 0.8604 - val_loss: 0.0905 - val_accuracy: 0.8594\n",
            "Epoch 283/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0897 - accuracy: 0.8608 - val_loss: 0.0904 - val_accuracy: 0.8591\n",
            "Epoch 284/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0896 - accuracy: 0.8603 - val_loss: 0.0903 - val_accuracy: 0.8583\n",
            "Epoch 285/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0896 - accuracy: 0.8605 - val_loss: 0.0905 - val_accuracy: 0.8539\n",
            "Epoch 286/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0896 - accuracy: 0.8604 - val_loss: 0.0903 - val_accuracy: 0.8583\n",
            "Epoch 287/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0896 - accuracy: 0.8610 - val_loss: 0.0903 - val_accuracy: 0.8586\n",
            "Epoch 288/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0896 - accuracy: 0.8612 - val_loss: 0.0902 - val_accuracy: 0.8573\n",
            "Epoch 289/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0895 - accuracy: 0.8605 - val_loss: 0.0903 - val_accuracy: 0.8562\n",
            "Epoch 290/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0895 - accuracy: 0.8612 - val_loss: 0.0902 - val_accuracy: 0.8576\n",
            "Epoch 291/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0895 - accuracy: 0.8611 - val_loss: 0.0901 - val_accuracy: 0.8585\n",
            "Epoch 292/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0894 - accuracy: 0.8612 - val_loss: 0.0901 - val_accuracy: 0.8587\n",
            "Epoch 293/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0894 - accuracy: 0.8613 - val_loss: 0.0901 - val_accuracy: 0.8587\n",
            "Epoch 294/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0894 - accuracy: 0.8617 - val_loss: 0.0905 - val_accuracy: 0.8536\n",
            "Epoch 295/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0894 - accuracy: 0.8607 - val_loss: 0.0901 - val_accuracy: 0.8592\n",
            "Epoch 296/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0894 - accuracy: 0.8611 - val_loss: 0.0900 - val_accuracy: 0.8592\n",
            "Epoch 297/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.8615 - val_loss: 0.0901 - val_accuracy: 0.8565\n",
            "Epoch 298/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.8611 - val_loss: 0.0899 - val_accuracy: 0.8572\n",
            "Epoch 299/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.8606 - val_loss: 0.0900 - val_accuracy: 0.8594\n",
            "Epoch 300/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0893 - accuracy: 0.8612 - val_loss: 0.0900 - val_accuracy: 0.8604\n",
            "Epoch 301/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0892 - accuracy: 0.8611 - val_loss: 0.0899 - val_accuracy: 0.8593\n",
            "Epoch 302/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0892 - accuracy: 0.8619 - val_loss: 0.0900 - val_accuracy: 0.8569\n",
            "Epoch 303/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0892 - accuracy: 0.8615 - val_loss: 0.0898 - val_accuracy: 0.8587\n",
            "Epoch 304/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0892 - accuracy: 0.8617 - val_loss: 0.0898 - val_accuracy: 0.8582\n",
            "Epoch 305/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0891 - accuracy: 0.8617 - val_loss: 0.0898 - val_accuracy: 0.8576\n",
            "Epoch 306/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0891 - accuracy: 0.8614 - val_loss: 0.0898 - val_accuracy: 0.8590\n",
            "Epoch 307/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0891 - accuracy: 0.8619 - val_loss: 0.0897 - val_accuracy: 0.8594\n",
            "Epoch 308/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0890 - accuracy: 0.8615 - val_loss: 0.0899 - val_accuracy: 0.8619\n",
            "Epoch 309/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.8616 - val_loss: 0.0898 - val_accuracy: 0.8572\n",
            "Epoch 310/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.8616 - val_loss: 0.0897 - val_accuracy: 0.8605\n",
            "Epoch 311/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.8613 - val_loss: 0.0897 - val_accuracy: 0.8575\n",
            "Epoch 312/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0890 - accuracy: 0.8615 - val_loss: 0.0896 - val_accuracy: 0.8595\n",
            "Epoch 313/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0889 - accuracy: 0.8621 - val_loss: 0.0898 - val_accuracy: 0.8571\n",
            "Epoch 314/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0889 - accuracy: 0.8623 - val_loss: 0.0897 - val_accuracy: 0.8613\n",
            "Epoch 315/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0889 - accuracy: 0.8621 - val_loss: 0.0897 - val_accuracy: 0.8609\n",
            "Epoch 316/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0889 - accuracy: 0.8615 - val_loss: 0.0896 - val_accuracy: 0.8601\n",
            "Epoch 317/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0888 - accuracy: 0.8619 - val_loss: 0.0895 - val_accuracy: 0.8577\n",
            "Epoch 318/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0888 - accuracy: 0.8621 - val_loss: 0.0897 - val_accuracy: 0.8619\n",
            "Epoch 319/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0888 - accuracy: 0.8622 - val_loss: 0.0895 - val_accuracy: 0.8604\n",
            "Epoch 320/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0888 - accuracy: 0.8618 - val_loss: 0.0896 - val_accuracy: 0.8573\n",
            "Epoch 321/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0887 - accuracy: 0.8623 - val_loss: 0.0894 - val_accuracy: 0.8594\n",
            "Epoch 322/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0887 - accuracy: 0.8625 - val_loss: 0.0895 - val_accuracy: 0.8579\n",
            "Epoch 323/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0887 - accuracy: 0.8622 - val_loss: 0.0896 - val_accuracy: 0.8561\n",
            "Epoch 324/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0887 - accuracy: 0.8623 - val_loss: 0.0893 - val_accuracy: 0.8601\n",
            "Epoch 325/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0887 - accuracy: 0.8625 - val_loss: 0.0893 - val_accuracy: 0.8589\n",
            "Epoch 326/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0886 - accuracy: 0.8619 - val_loss: 0.0895 - val_accuracy: 0.8626\n",
            "Epoch 327/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.8625 - val_loss: 0.0893 - val_accuracy: 0.8600\n",
            "Epoch 328/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.8619 - val_loss: 0.0894 - val_accuracy: 0.8573\n",
            "Epoch 329/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.8624 - val_loss: 0.0893 - val_accuracy: 0.8579\n",
            "Epoch 330/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0886 - accuracy: 0.8627 - val_loss: 0.0892 - val_accuracy: 0.8578\n",
            "Epoch 331/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0885 - accuracy: 0.8627 - val_loss: 0.0893 - val_accuracy: 0.8612\n",
            "Epoch 332/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0885 - accuracy: 0.8629 - val_loss: 0.0892 - val_accuracy: 0.8597\n",
            "Epoch 333/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0885 - accuracy: 0.8626 - val_loss: 0.0892 - val_accuracy: 0.8598\n",
            "Epoch 334/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0885 - accuracy: 0.8627 - val_loss: 0.0893 - val_accuracy: 0.8566\n",
            "Epoch 335/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.8624 - val_loss: 0.0891 - val_accuracy: 0.8612\n",
            "Epoch 336/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.8625 - val_loss: 0.0892 - val_accuracy: 0.8600\n",
            "Epoch 337/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.8627 - val_loss: 0.0892 - val_accuracy: 0.8626\n",
            "Epoch 338/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0884 - accuracy: 0.8628 - val_loss: 0.0891 - val_accuracy: 0.8587\n",
            "Epoch 339/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.8632 - val_loss: 0.0891 - val_accuracy: 0.8614\n",
            "Epoch 340/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0883 - accuracy: 0.8627 - val_loss: 0.0891 - val_accuracy: 0.8605\n",
            "Epoch 341/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0883 - accuracy: 0.8626 - val_loss: 0.0891 - val_accuracy: 0.8620\n",
            "Epoch 342/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0883 - accuracy: 0.8629 - val_loss: 0.0890 - val_accuracy: 0.8587\n",
            "Epoch 343/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0883 - accuracy: 0.8631 - val_loss: 0.0889 - val_accuracy: 0.8600\n",
            "Epoch 344/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0882 - accuracy: 0.8627 - val_loss: 0.0889 - val_accuracy: 0.8609\n",
            "Epoch 345/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.8628 - val_loss: 0.0890 - val_accuracy: 0.8592\n",
            "Epoch 346/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.8627 - val_loss: 0.0889 - val_accuracy: 0.8600\n",
            "Epoch 347/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.8636 - val_loss: 0.0890 - val_accuracy: 0.8576\n",
            "Epoch 348/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.8632 - val_loss: 0.0889 - val_accuracy: 0.8620\n",
            "Epoch 349/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0882 - accuracy: 0.8635 - val_loss: 0.0890 - val_accuracy: 0.8621\n",
            "Epoch 350/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0881 - accuracy: 0.8628 - val_loss: 0.0888 - val_accuracy: 0.8608\n",
            "Epoch 351/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.8629 - val_loss: 0.0888 - val_accuracy: 0.8605\n",
            "Epoch 352/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.8633 - val_loss: 0.0888 - val_accuracy: 0.8595\n",
            "Epoch 353/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.8637 - val_loss: 0.0889 - val_accuracy: 0.8630\n",
            "Epoch 354/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.8631 - val_loss: 0.0892 - val_accuracy: 0.8620\n",
            "Epoch 355/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.8633 - val_loss: 0.0887 - val_accuracy: 0.8597\n",
            "Epoch 356/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0880 - accuracy: 0.8636 - val_loss: 0.0887 - val_accuracy: 0.8618\n",
            "Epoch 357/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.8632 - val_loss: 0.0886 - val_accuracy: 0.8609\n",
            "Epoch 358/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.8637 - val_loss: 0.0887 - val_accuracy: 0.8597\n",
            "Epoch 359/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0879 - accuracy: 0.8633 - val_loss: 0.0887 - val_accuracy: 0.8630\n",
            "Epoch 360/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0879 - accuracy: 0.8639 - val_loss: 0.0886 - val_accuracy: 0.8612\n",
            "Epoch 361/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0879 - accuracy: 0.8634 - val_loss: 0.0889 - val_accuracy: 0.8568\n",
            "Epoch 362/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0879 - accuracy: 0.8634 - val_loss: 0.0886 - val_accuracy: 0.8592\n",
            "Epoch 363/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0879 - accuracy: 0.8633 - val_loss: 0.0885 - val_accuracy: 0.8611\n",
            "Epoch 364/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0878 - accuracy: 0.8637 - val_loss: 0.0886 - val_accuracy: 0.8623\n",
            "Epoch 365/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0878 - accuracy: 0.8640 - val_loss: 0.0886 - val_accuracy: 0.8623\n",
            "Epoch 366/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0878 - accuracy: 0.8637 - val_loss: 0.0885 - val_accuracy: 0.8617\n",
            "Epoch 367/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0878 - accuracy: 0.8636 - val_loss: 0.0886 - val_accuracy: 0.8583\n",
            "Epoch 368/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0878 - accuracy: 0.8642 - val_loss: 0.0885 - val_accuracy: 0.8580\n",
            "Epoch 369/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8640 - val_loss: 0.0885 - val_accuracy: 0.8583\n",
            "Epoch 370/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8643 - val_loss: 0.0884 - val_accuracy: 0.8622\n",
            "Epoch 371/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8639 - val_loss: 0.0884 - val_accuracy: 0.8606\n",
            "Epoch 372/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8641 - val_loss: 0.0884 - val_accuracy: 0.8600\n",
            "Epoch 373/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0877 - accuracy: 0.8640 - val_loss: 0.0884 - val_accuracy: 0.8619\n",
            "Epoch 374/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8641 - val_loss: 0.0884 - val_accuracy: 0.8629\n",
            "Epoch 375/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0877 - accuracy: 0.8642 - val_loss: 0.0883 - val_accuracy: 0.8631\n",
            "Epoch 376/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.8645 - val_loss: 0.0883 - val_accuracy: 0.8601\n",
            "Epoch 377/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.8643 - val_loss: 0.0884 - val_accuracy: 0.8633\n",
            "Epoch 378/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.8641 - val_loss: 0.0883 - val_accuracy: 0.8626\n",
            "Epoch 379/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0876 - accuracy: 0.8640 - val_loss: 0.0882 - val_accuracy: 0.8619\n",
            "Epoch 380/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.8643 - val_loss: 0.0882 - val_accuracy: 0.8626\n",
            "Epoch 381/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.8642 - val_loss: 0.0882 - val_accuracy: 0.8620\n",
            "Epoch 382/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.8644 - val_loss: 0.0882 - val_accuracy: 0.8620\n",
            "Epoch 383/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.8640 - val_loss: 0.0881 - val_accuracy: 0.8612\n",
            "Epoch 384/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.8641 - val_loss: 0.0882 - val_accuracy: 0.8623\n",
            "Epoch 385/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0875 - accuracy: 0.8645 - val_loss: 0.0881 - val_accuracy: 0.8623\n",
            "Epoch 386/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0874 - accuracy: 0.8646 - val_loss: 0.0881 - val_accuracy: 0.8626\n",
            "Epoch 387/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0874 - accuracy: 0.8651 - val_loss: 0.0881 - val_accuracy: 0.8606\n",
            "Epoch 388/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0874 - accuracy: 0.8648 - val_loss: 0.0881 - val_accuracy: 0.8609\n",
            "Epoch 389/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0874 - accuracy: 0.8644 - val_loss: 0.0881 - val_accuracy: 0.8615\n",
            "Epoch 390/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0874 - accuracy: 0.8637 - val_loss: 0.0881 - val_accuracy: 0.8637\n",
            "Epoch 391/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0874 - accuracy: 0.8646 - val_loss: 0.0881 - val_accuracy: 0.8601\n",
            "Epoch 392/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0873 - accuracy: 0.8645 - val_loss: 0.0881 - val_accuracy: 0.8607\n",
            "Epoch 393/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0873 - accuracy: 0.8641 - val_loss: 0.0881 - val_accuracy: 0.8638\n",
            "Epoch 394/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0873 - accuracy: 0.8651 - val_loss: 0.0880 - val_accuracy: 0.8634\n",
            "Epoch 395/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0873 - accuracy: 0.8648 - val_loss: 0.0879 - val_accuracy: 0.8623\n",
            "Epoch 396/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0873 - accuracy: 0.8643 - val_loss: 0.0879 - val_accuracy: 0.8619\n",
            "Epoch 397/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0872 - accuracy: 0.8650 - val_loss: 0.0879 - val_accuracy: 0.8613\n",
            "Epoch 398/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0872 - accuracy: 0.8647 - val_loss: 0.0879 - val_accuracy: 0.8635\n",
            "Epoch 399/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0872 - accuracy: 0.8651 - val_loss: 0.0879 - val_accuracy: 0.8613\n",
            "Epoch 400/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0872 - accuracy: 0.8646 - val_loss: 0.0879 - val_accuracy: 0.8612\n",
            "Epoch 401/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0872 - accuracy: 0.8649 - val_loss: 0.0883 - val_accuracy: 0.8654\n",
            "Epoch 402/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0872 - accuracy: 0.8648 - val_loss: 0.0879 - val_accuracy: 0.8618\n",
            "Epoch 403/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0871 - accuracy: 0.8653 - val_loss: 0.0878 - val_accuracy: 0.8618\n",
            "Epoch 404/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.8651 - val_loss: 0.0881 - val_accuracy: 0.8582\n",
            "Epoch 405/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.8652 - val_loss: 0.0879 - val_accuracy: 0.8612\n",
            "Epoch 406/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.8662 - val_loss: 0.0879 - val_accuracy: 0.8591\n",
            "Epoch 407/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.8650 - val_loss: 0.0877 - val_accuracy: 0.8631\n",
            "Epoch 408/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.8646 - val_loss: 0.0880 - val_accuracy: 0.8648\n",
            "Epoch 409/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0870 - accuracy: 0.8654 - val_loss: 0.0877 - val_accuracy: 0.8600\n",
            "Epoch 410/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.8654 - val_loss: 0.0877 - val_accuracy: 0.8627\n",
            "Epoch 411/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.8645 - val_loss: 0.0878 - val_accuracy: 0.8647\n",
            "Epoch 412/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.8655 - val_loss: 0.0877 - val_accuracy: 0.8626\n",
            "Epoch 413/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.8651 - val_loss: 0.0878 - val_accuracy: 0.8587\n",
            "Epoch 414/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0870 - accuracy: 0.8650 - val_loss: 0.0876 - val_accuracy: 0.8619\n",
            "Epoch 415/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0869 - accuracy: 0.8655 - val_loss: 0.0876 - val_accuracy: 0.8615\n",
            "Epoch 416/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.8655 - val_loss: 0.0876 - val_accuracy: 0.8621\n",
            "Epoch 417/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.8655 - val_loss: 0.0875 - val_accuracy: 0.8630\n",
            "Epoch 418/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.8657 - val_loss: 0.0876 - val_accuracy: 0.8633\n",
            "Epoch 419/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.8655 - val_loss: 0.0875 - val_accuracy: 0.8626\n",
            "Epoch 420/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0869 - accuracy: 0.8653 - val_loss: 0.0875 - val_accuracy: 0.8625\n",
            "Epoch 421/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0868 - accuracy: 0.8657 - val_loss: 0.0875 - val_accuracy: 0.8608\n",
            "Epoch 422/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.8657 - val_loss: 0.0876 - val_accuracy: 0.8640\n",
            "Epoch 423/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.8655 - val_loss: 0.0875 - val_accuracy: 0.8626\n",
            "Epoch 424/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.8657 - val_loss: 0.0875 - val_accuracy: 0.8635\n",
            "Epoch 425/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0868 - accuracy: 0.8657 - val_loss: 0.0874 - val_accuracy: 0.8643\n",
            "Epoch 426/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0868 - accuracy: 0.8660 - val_loss: 0.0874 - val_accuracy: 0.8630\n",
            "Epoch 427/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0868 - accuracy: 0.8658 - val_loss: 0.0875 - val_accuracy: 0.8633\n",
            "Epoch 428/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0867 - accuracy: 0.8656 - val_loss: 0.0876 - val_accuracy: 0.8593\n",
            "Epoch 429/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0867 - accuracy: 0.8660 - val_loss: 0.0874 - val_accuracy: 0.8632\n",
            "Epoch 430/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0867 - accuracy: 0.8663 - val_loss: 0.0873 - val_accuracy: 0.8627\n",
            "Epoch 431/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0867 - accuracy: 0.8659 - val_loss: 0.0874 - val_accuracy: 0.8616\n",
            "Epoch 432/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0867 - accuracy: 0.8662 - val_loss: 0.0875 - val_accuracy: 0.8636\n",
            "Epoch 433/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0866 - accuracy: 0.8660 - val_loss: 0.0874 - val_accuracy: 0.8607\n",
            "Epoch 434/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0866 - accuracy: 0.8659 - val_loss: 0.0874 - val_accuracy: 0.8650\n",
            "Epoch 435/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0866 - accuracy: 0.8656 - val_loss: 0.0873 - val_accuracy: 0.8614\n",
            "Epoch 436/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0866 - accuracy: 0.8664 - val_loss: 0.0873 - val_accuracy: 0.8612\n",
            "Epoch 437/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0866 - accuracy: 0.8663 - val_loss: 0.0873 - val_accuracy: 0.8641\n",
            "Epoch 438/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0866 - accuracy: 0.8662 - val_loss: 0.0872 - val_accuracy: 0.8630\n",
            "Epoch 439/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0865 - accuracy: 0.8658 - val_loss: 0.0873 - val_accuracy: 0.8643\n",
            "Epoch 440/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8666 - val_loss: 0.0872 - val_accuracy: 0.8621\n",
            "Epoch 441/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8657 - val_loss: 0.0872 - val_accuracy: 0.8643\n",
            "Epoch 442/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8664 - val_loss: 0.0872 - val_accuracy: 0.8631\n",
            "Epoch 443/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8664 - val_loss: 0.0876 - val_accuracy: 0.8584\n",
            "Epoch 444/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0865 - accuracy: 0.8668 - val_loss: 0.0872 - val_accuracy: 0.8643\n",
            "Epoch 445/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0865 - accuracy: 0.8666 - val_loss: 0.0872 - val_accuracy: 0.8613\n",
            "Epoch 446/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8661 - val_loss: 0.0873 - val_accuracy: 0.8597\n",
            "Epoch 447/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8661 - val_loss: 0.0872 - val_accuracy: 0.8644\n",
            "Epoch 448/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8663 - val_loss: 0.0871 - val_accuracy: 0.8626\n",
            "Epoch 449/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8664 - val_loss: 0.0871 - val_accuracy: 0.8645\n",
            "Epoch 450/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0864 - accuracy: 0.8665 - val_loss: 0.0870 - val_accuracy: 0.8642\n",
            "Epoch 451/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8663 - val_loss: 0.0870 - val_accuracy: 0.8622\n",
            "Epoch 452/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0864 - accuracy: 0.8665 - val_loss: 0.0871 - val_accuracy: 0.8653\n",
            "Epoch 453/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0863 - accuracy: 0.8664 - val_loss: 0.0870 - val_accuracy: 0.8643\n",
            "Epoch 454/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0863 - accuracy: 0.8666 - val_loss: 0.0870 - val_accuracy: 0.8643\n",
            "Epoch 455/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0863 - accuracy: 0.8672 - val_loss: 0.0871 - val_accuracy: 0.8602\n",
            "Epoch 456/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0863 - accuracy: 0.8663 - val_loss: 0.0871 - val_accuracy: 0.8627\n",
            "Epoch 457/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0863 - accuracy: 0.8667 - val_loss: 0.0870 - val_accuracy: 0.8651\n",
            "Epoch 458/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0863 - accuracy: 0.8666 - val_loss: 0.0869 - val_accuracy: 0.8635\n",
            "Epoch 459/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0863 - accuracy: 0.8667 - val_loss: 0.0871 - val_accuracy: 0.8622\n",
            "Epoch 460/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8661 - val_loss: 0.0870 - val_accuracy: 0.8630\n",
            "Epoch 461/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0862 - accuracy: 0.8666 - val_loss: 0.0870 - val_accuracy: 0.8612\n",
            "Epoch 462/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0862 - accuracy: 0.8669 - val_loss: 0.0869 - val_accuracy: 0.8615\n",
            "Epoch 463/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8673 - val_loss: 0.0869 - val_accuracy: 0.8612\n",
            "Epoch 464/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8669 - val_loss: 0.0871 - val_accuracy: 0.8605\n",
            "Epoch 465/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8671 - val_loss: 0.0868 - val_accuracy: 0.8645\n",
            "Epoch 466/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0862 - accuracy: 0.8668 - val_loss: 0.0868 - val_accuracy: 0.8653\n",
            "Epoch 467/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0861 - accuracy: 0.8671 - val_loss: 0.0870 - val_accuracy: 0.8667\n",
            "Epoch 468/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0861 - accuracy: 0.8672 - val_loss: 0.0868 - val_accuracy: 0.8647\n",
            "Epoch 469/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0861 - accuracy: 0.8669 - val_loss: 0.0868 - val_accuracy: 0.8659\n",
            "Epoch 470/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0861 - accuracy: 0.8672 - val_loss: 0.0868 - val_accuracy: 0.8652\n",
            "Epoch 471/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0861 - accuracy: 0.8672 - val_loss: 0.0869 - val_accuracy: 0.8652\n",
            "Epoch 472/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0861 - accuracy: 0.8672 - val_loss: 0.0868 - val_accuracy: 0.8658\n",
            "Epoch 473/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0861 - accuracy: 0.8669 - val_loss: 0.0867 - val_accuracy: 0.8644\n",
            "Epoch 474/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8679 - val_loss: 0.0872 - val_accuracy: 0.8678\n",
            "Epoch 475/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8673 - val_loss: 0.0867 - val_accuracy: 0.8654\n",
            "Epoch 476/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8676 - val_loss: 0.0867 - val_accuracy: 0.8640\n",
            "Epoch 477/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8673 - val_loss: 0.0866 - val_accuracy: 0.8634\n",
            "Epoch 478/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0860 - accuracy: 0.8670 - val_loss: 0.0868 - val_accuracy: 0.8616\n",
            "Epoch 479/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0860 - accuracy: 0.8674 - val_loss: 0.0867 - val_accuracy: 0.8633\n",
            "Epoch 480/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8672 - val_loss: 0.0867 - val_accuracy: 0.8630\n",
            "Epoch 481/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0860 - accuracy: 0.8675 - val_loss: 0.0866 - val_accuracy: 0.8629\n",
            "Epoch 482/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8673 - val_loss: 0.0868 - val_accuracy: 0.8674\n",
            "Epoch 483/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8674 - val_loss: 0.0866 - val_accuracy: 0.8639\n",
            "Epoch 484/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8676 - val_loss: 0.0866 - val_accuracy: 0.8634\n",
            "Epoch 485/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0859 - accuracy: 0.8673 - val_loss: 0.0867 - val_accuracy: 0.8666\n",
            "Epoch 486/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8680 - val_loss: 0.0866 - val_accuracy: 0.8651\n",
            "Epoch 487/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8674 - val_loss: 0.0866 - val_accuracy: 0.8635\n",
            "Epoch 488/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8676 - val_loss: 0.0865 - val_accuracy: 0.8640\n",
            "Epoch 489/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0859 - accuracy: 0.8675 - val_loss: 0.0865 - val_accuracy: 0.8626\n",
            "Epoch 490/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0858 - accuracy: 0.8683 - val_loss: 0.0865 - val_accuracy: 0.8654\n",
            "Epoch 491/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0858 - accuracy: 0.8679 - val_loss: 0.0866 - val_accuracy: 0.8679\n",
            "Epoch 492/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8681 - val_loss: 0.0866 - val_accuracy: 0.8615\n",
            "Epoch 493/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8680 - val_loss: 0.0864 - val_accuracy: 0.8649\n",
            "Epoch 494/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8681 - val_loss: 0.0864 - val_accuracy: 0.8641\n",
            "Epoch 495/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0858 - accuracy: 0.8680 - val_loss: 0.0866 - val_accuracy: 0.8657\n",
            "Epoch 496/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0857 - accuracy: 0.8684 - val_loss: 0.0864 - val_accuracy: 0.8657\n",
            "Epoch 497/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0858 - accuracy: 0.8677 - val_loss: 0.0864 - val_accuracy: 0.8624\n",
            "Epoch 498/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8682 - val_loss: 0.0865 - val_accuracy: 0.8621\n",
            "Epoch 499/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8676 - val_loss: 0.0864 - val_accuracy: 0.8628\n",
            "Epoch 500/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8683 - val_loss: 0.0864 - val_accuracy: 0.8626\n",
            "Epoch 501/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8683 - val_loss: 0.0864 - val_accuracy: 0.8644\n",
            "Epoch 502/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0857 - accuracy: 0.8683 - val_loss: 0.0864 - val_accuracy: 0.8662\n",
            "Epoch 503/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8684 - val_loss: 0.0863 - val_accuracy: 0.8645\n",
            "Epoch 504/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0857 - accuracy: 0.8686 - val_loss: 0.0865 - val_accuracy: 0.8617\n",
            "Epoch 505/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8684 - val_loss: 0.0865 - val_accuracy: 0.8614\n",
            "Epoch 506/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8684 - val_loss: 0.0863 - val_accuracy: 0.8648\n",
            "Epoch 507/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8683 - val_loss: 0.0863 - val_accuracy: 0.8642\n",
            "Epoch 508/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0856 - accuracy: 0.8687 - val_loss: 0.0864 - val_accuracy: 0.8680\n",
            "Epoch 509/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8684 - val_loss: 0.0865 - val_accuracy: 0.8616\n",
            "Epoch 510/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8684 - val_loss: 0.0862 - val_accuracy: 0.8643\n",
            "Epoch 511/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8685 - val_loss: 0.0862 - val_accuracy: 0.8656\n",
            "Epoch 512/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8686 - val_loss: 0.0862 - val_accuracy: 0.8639\n",
            "Epoch 513/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.8688 - val_loss: 0.0864 - val_accuracy: 0.8619\n",
            "Epoch 514/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0855 - accuracy: 0.8684 - val_loss: 0.0862 - val_accuracy: 0.8665\n",
            "Epoch 515/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0855 - accuracy: 0.8686 - val_loss: 0.0861 - val_accuracy: 0.8647\n",
            "Epoch 516/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0855 - accuracy: 0.8684 - val_loss: 0.0864 - val_accuracy: 0.8614\n",
            "Epoch 517/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0855 - accuracy: 0.8684 - val_loss: 0.0864 - val_accuracy: 0.8622\n",
            "Epoch 518/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0855 - accuracy: 0.8684 - val_loss: 0.0862 - val_accuracy: 0.8636\n",
            "Epoch 519/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0855 - accuracy: 0.8685 - val_loss: 0.0862 - val_accuracy: 0.8663\n",
            "Epoch 520/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0854 - accuracy: 0.8688 - val_loss: 0.0862 - val_accuracy: 0.8625\n",
            "Epoch 521/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8690 - val_loss: 0.0865 - val_accuracy: 0.8695\n",
            "Epoch 522/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8686 - val_loss: 0.0862 - val_accuracy: 0.8630\n",
            "Epoch 523/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8689 - val_loss: 0.0862 - val_accuracy: 0.8622\n",
            "Epoch 524/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8686 - val_loss: 0.0863 - val_accuracy: 0.8692\n",
            "Epoch 525/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0854 - accuracy: 0.8686 - val_loss: 0.0861 - val_accuracy: 0.8665\n",
            "Epoch 526/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0854 - accuracy: 0.8687 - val_loss: 0.0862 - val_accuracy: 0.8661\n",
            "Epoch 527/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8690 - val_loss: 0.0861 - val_accuracy: 0.8676\n",
            "Epoch 528/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8688 - val_loss: 0.0860 - val_accuracy: 0.8672\n",
            "Epoch 529/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.8695 - val_loss: 0.0860 - val_accuracy: 0.8655\n",
            "Epoch 530/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.8689 - val_loss: 0.0860 - val_accuracy: 0.8660\n",
            "Epoch 531/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0853 - accuracy: 0.8693 - val_loss: 0.0860 - val_accuracy: 0.8662\n",
            "Epoch 532/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0853 - accuracy: 0.8693 - val_loss: 0.0861 - val_accuracy: 0.8680\n",
            "Epoch 533/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.8687 - val_loss: 0.0859 - val_accuracy: 0.8658\n",
            "Epoch 534/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.8692 - val_loss: 0.0864 - val_accuracy: 0.8593\n",
            "Epoch 535/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.8691 - val_loss: 0.0859 - val_accuracy: 0.8665\n",
            "Epoch 536/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.8689 - val_loss: 0.0860 - val_accuracy: 0.8625\n",
            "Epoch 537/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0853 - accuracy: 0.8691 - val_loss: 0.0859 - val_accuracy: 0.8639\n",
            "Epoch 538/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0853 - accuracy: 0.8690 - val_loss: 0.0859 - val_accuracy: 0.8666\n",
            "Epoch 539/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.8694 - val_loss: 0.0859 - val_accuracy: 0.8654\n",
            "Epoch 540/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0852 - accuracy: 0.8694 - val_loss: 0.0859 - val_accuracy: 0.8663\n",
            "Epoch 541/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.8685 - val_loss: 0.0859 - val_accuracy: 0.8660\n",
            "Epoch 542/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.8693 - val_loss: 0.0859 - val_accuracy: 0.8640\n",
            "Epoch 543/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0852 - accuracy: 0.8696 - val_loss: 0.0858 - val_accuracy: 0.8666\n",
            "Epoch 544/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0852 - accuracy: 0.8698 - val_loss: 0.0858 - val_accuracy: 0.8674\n",
            "Epoch 545/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8690 - val_loss: 0.0858 - val_accuracy: 0.8652\n",
            "Epoch 546/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8694 - val_loss: 0.0860 - val_accuracy: 0.8688\n",
            "Epoch 547/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8695 - val_loss: 0.0858 - val_accuracy: 0.8671\n",
            "Epoch 548/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8693 - val_loss: 0.0858 - val_accuracy: 0.8658\n",
            "Epoch 549/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.8694 - val_loss: 0.0858 - val_accuracy: 0.8653\n",
            "Epoch 550/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8698 - val_loss: 0.0858 - val_accuracy: 0.8661\n",
            "Epoch 551/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.8696 - val_loss: 0.0858 - val_accuracy: 0.8667\n",
            "Epoch 552/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8696 - val_loss: 0.0857 - val_accuracy: 0.8658\n",
            "Epoch 553/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0851 - accuracy: 0.8696 - val_loss: 0.0858 - val_accuracy: 0.8682\n",
            "Epoch 554/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.8696 - val_loss: 0.0857 - val_accuracy: 0.8662\n",
            "Epoch 555/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0851 - accuracy: 0.8694 - val_loss: 0.0858 - val_accuracy: 0.8684\n",
            "Epoch 556/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8697 - val_loss: 0.0857 - val_accuracy: 0.8651\n",
            "Epoch 557/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8702 - val_loss: 0.0857 - val_accuracy: 0.8651\n",
            "Epoch 558/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8694 - val_loss: 0.0860 - val_accuracy: 0.8704\n",
            "Epoch 559/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8697 - val_loss: 0.0856 - val_accuracy: 0.8666\n",
            "Epoch 560/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0850 - accuracy: 0.8700 - val_loss: 0.0856 - val_accuracy: 0.8661\n",
            "Epoch 561/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0850 - accuracy: 0.8695 - val_loss: 0.0857 - val_accuracy: 0.8679\n",
            "Epoch 562/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0850 - accuracy: 0.8701 - val_loss: 0.0857 - val_accuracy: 0.8638\n",
            "Epoch 563/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0850 - accuracy: 0.8697 - val_loss: 0.0856 - val_accuracy: 0.8631\n",
            "Epoch 564/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8701 - val_loss: 0.0857 - val_accuracy: 0.8691\n",
            "Epoch 565/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0849 - accuracy: 0.8697 - val_loss: 0.0856 - val_accuracy: 0.8658\n",
            "Epoch 566/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0849 - accuracy: 0.8698 - val_loss: 0.0856 - val_accuracy: 0.8640\n",
            "Epoch 567/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8702 - val_loss: 0.0856 - val_accuracy: 0.8643\n",
            "Epoch 568/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8698 - val_loss: 0.0856 - val_accuracy: 0.8684\n",
            "Epoch 569/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8700 - val_loss: 0.0856 - val_accuracy: 0.8682\n",
            "Epoch 570/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0849 - accuracy: 0.8702 - val_loss: 0.0855 - val_accuracy: 0.8647\n",
            "Epoch 571/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0849 - accuracy: 0.8701 - val_loss: 0.0856 - val_accuracy: 0.8651\n",
            "Epoch 572/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0849 - accuracy: 0.8700 - val_loss: 0.0855 - val_accuracy: 0.8665\n",
            "Epoch 573/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0849 - accuracy: 0.8701 - val_loss: 0.0856 - val_accuracy: 0.8637\n",
            "Epoch 574/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8706 - val_loss: 0.0856 - val_accuracy: 0.8634\n",
            "Epoch 575/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8706 - val_loss: 0.0855 - val_accuracy: 0.8662\n",
            "Epoch 576/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8703 - val_loss: 0.0857 - val_accuracy: 0.8622\n",
            "Epoch 577/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0848 - accuracy: 0.8703 - val_loss: 0.0855 - val_accuracy: 0.8649\n",
            "Epoch 578/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0848 - accuracy: 0.8701 - val_loss: 0.0858 - val_accuracy: 0.8713\n",
            "Epoch 579/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8704 - val_loss: 0.0854 - val_accuracy: 0.8659\n",
            "Epoch 580/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8704 - val_loss: 0.0855 - val_accuracy: 0.8667\n",
            "Epoch 581/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0848 - accuracy: 0.8707 - val_loss: 0.0855 - val_accuracy: 0.8655\n",
            "Epoch 582/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8705 - val_loss: 0.0854 - val_accuracy: 0.8638\n",
            "Epoch 583/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0848 - accuracy: 0.8704 - val_loss: 0.0854 - val_accuracy: 0.8672\n",
            "Epoch 584/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8705 - val_loss: 0.0855 - val_accuracy: 0.8684\n",
            "Epoch 585/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8703 - val_loss: 0.0854 - val_accuracy: 0.8676\n",
            "Epoch 586/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8705 - val_loss: 0.0854 - val_accuracy: 0.8656\n",
            "Epoch 587/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8706 - val_loss: 0.0854 - val_accuracy: 0.8691\n",
            "Epoch 588/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0847 - accuracy: 0.8709 - val_loss: 0.0854 - val_accuracy: 0.8687\n",
            "Epoch 589/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0847 - accuracy: 0.8705 - val_loss: 0.0854 - val_accuracy: 0.8668\n",
            "Epoch 590/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8703 - val_loss: 0.0856 - val_accuracy: 0.8622\n",
            "Epoch 591/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8708 - val_loss: 0.0853 - val_accuracy: 0.8661\n",
            "Epoch 592/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0847 - accuracy: 0.8709 - val_loss: 0.0853 - val_accuracy: 0.8673\n",
            "Epoch 593/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8704 - val_loss: 0.0853 - val_accuracy: 0.8669\n",
            "Epoch 594/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0846 - accuracy: 0.8709 - val_loss: 0.0854 - val_accuracy: 0.8684\n",
            "Epoch 595/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8704 - val_loss: 0.0853 - val_accuracy: 0.8693\n",
            "Epoch 596/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8705 - val_loss: 0.0854 - val_accuracy: 0.8695\n",
            "Epoch 597/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8707 - val_loss: 0.0853 - val_accuracy: 0.8688\n",
            "Epoch 598/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8712 - val_loss: 0.0853 - val_accuracy: 0.8670\n",
            "Epoch 599/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8710 - val_loss: 0.0854 - val_accuracy: 0.8630\n",
            "Epoch 600/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0846 - accuracy: 0.8716 - val_loss: 0.0853 - val_accuracy: 0.8702\n",
            "Epoch 601/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8709 - val_loss: 0.0857 - val_accuracy: 0.8619\n",
            "Epoch 602/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.8708 - val_loss: 0.0854 - val_accuracy: 0.8707\n",
            "Epoch 603/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8708 - val_loss: 0.0854 - val_accuracy: 0.8631\n",
            "Epoch 604/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8711 - val_loss: 0.0852 - val_accuracy: 0.8653\n",
            "Epoch 605/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8709 - val_loss: 0.0853 - val_accuracy: 0.8655\n",
            "Epoch 606/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0845 - accuracy: 0.8709 - val_loss: 0.0853 - val_accuracy: 0.8677\n",
            "Epoch 607/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8712 - val_loss: 0.0851 - val_accuracy: 0.8675\n",
            "Epoch 608/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8708 - val_loss: 0.0851 - val_accuracy: 0.8669\n",
            "Epoch 609/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8712 - val_loss: 0.0851 - val_accuracy: 0.8665\n",
            "Epoch 610/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0845 - accuracy: 0.8709 - val_loss: 0.0851 - val_accuracy: 0.8666\n",
            "Epoch 611/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0845 - accuracy: 0.8710 - val_loss: 0.0852 - val_accuracy: 0.8674\n",
            "Epoch 612/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0845 - accuracy: 0.8713 - val_loss: 0.0852 - val_accuracy: 0.8698\n",
            "Epoch 613/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8715 - val_loss: 0.0852 - val_accuracy: 0.8690\n",
            "Epoch 614/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8712 - val_loss: 0.0851 - val_accuracy: 0.8672\n",
            "Epoch 615/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8717 - val_loss: 0.0852 - val_accuracy: 0.8708\n",
            "Epoch 616/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8712 - val_loss: 0.0851 - val_accuracy: 0.8678\n",
            "Epoch 617/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0844 - accuracy: 0.8717 - val_loss: 0.0852 - val_accuracy: 0.8641\n",
            "Epoch 618/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8717 - val_loss: 0.0850 - val_accuracy: 0.8677\n",
            "Epoch 619/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8711 - val_loss: 0.0852 - val_accuracy: 0.8645\n",
            "Epoch 620/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8716 - val_loss: 0.0850 - val_accuracy: 0.8695\n",
            "Epoch 621/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8716 - val_loss: 0.0851 - val_accuracy: 0.8667\n",
            "Epoch 622/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.8713 - val_loss: 0.0850 - val_accuracy: 0.8697\n",
            "Epoch 623/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.8716 - val_loss: 0.0851 - val_accuracy: 0.8702\n",
            "Epoch 624/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8712 - val_loss: 0.0851 - val_accuracy: 0.8715\n",
            "Epoch 625/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8717 - val_loss: 0.0852 - val_accuracy: 0.8719\n",
            "Epoch 626/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8714 - val_loss: 0.0850 - val_accuracy: 0.8661\n",
            "Epoch 627/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8716 - val_loss: 0.0850 - val_accuracy: 0.8686\n",
            "Epoch 628/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8716 - val_loss: 0.0851 - val_accuracy: 0.8708\n",
            "Epoch 629/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.8716 - val_loss: 0.0850 - val_accuracy: 0.8699\n",
            "Epoch 630/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0843 - accuracy: 0.8715 - val_loss: 0.0853 - val_accuracy: 0.8634\n",
            "Epoch 631/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8717 - val_loss: 0.0851 - val_accuracy: 0.8645\n",
            "Epoch 632/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8720 - val_loss: 0.0850 - val_accuracy: 0.8670\n",
            "Epoch 633/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8717 - val_loss: 0.0850 - val_accuracy: 0.8702\n",
            "Epoch 634/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0843 - accuracy: 0.8715 - val_loss: 0.0850 - val_accuracy: 0.8697\n",
            "Epoch 635/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.8722 - val_loss: 0.0849 - val_accuracy: 0.8683\n",
            "Epoch 636/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8717 - val_loss: 0.0849 - val_accuracy: 0.8678\n",
            "Epoch 637/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8721 - val_loss: 0.0849 - val_accuracy: 0.8677\n",
            "Epoch 638/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8720 - val_loss: 0.0849 - val_accuracy: 0.8700\n",
            "Epoch 639/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8717 - val_loss: 0.0849 - val_accuracy: 0.8706\n",
            "Epoch 640/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.8724 - val_loss: 0.0849 - val_accuracy: 0.8657\n",
            "Epoch 641/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0842 - accuracy: 0.8721 - val_loss: 0.0848 - val_accuracy: 0.8697\n",
            "Epoch 642/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8719 - val_loss: 0.0849 - val_accuracy: 0.8656\n",
            "Epoch 643/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.8718 - val_loss: 0.0849 - val_accuracy: 0.8676\n",
            "Epoch 644/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8721 - val_loss: 0.0849 - val_accuracy: 0.8653\n",
            "Epoch 645/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8721 - val_loss: 0.0850 - val_accuracy: 0.8646\n",
            "Epoch 646/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.8724 - val_loss: 0.0848 - val_accuracy: 0.8686\n",
            "Epoch 647/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.8723 - val_loss: 0.0848 - val_accuracy: 0.8695\n",
            "Epoch 648/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8717 - val_loss: 0.0848 - val_accuracy: 0.8698\n",
            "Epoch 649/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8721 - val_loss: 0.0847 - val_accuracy: 0.8689\n",
            "Epoch 650/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8720 - val_loss: 0.0849 - val_accuracy: 0.8647\n",
            "Epoch 651/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8721 - val_loss: 0.0849 - val_accuracy: 0.8655\n",
            "Epoch 652/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.8722 - val_loss: 0.0847 - val_accuracy: 0.8687\n",
            "Epoch 653/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0841 - accuracy: 0.8726 - val_loss: 0.0847 - val_accuracy: 0.8700\n",
            "Epoch 654/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.8722 - val_loss: 0.0847 - val_accuracy: 0.8678\n",
            "Epoch 655/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8722 - val_loss: 0.0851 - val_accuracy: 0.8645\n",
            "Epoch 656/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8727 - val_loss: 0.0848 - val_accuracy: 0.8691\n",
            "Epoch 657/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8728 - val_loss: 0.0847 - val_accuracy: 0.8699\n",
            "Epoch 658/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0840 - accuracy: 0.8724 - val_loss: 0.0848 - val_accuracy: 0.8709\n",
            "Epoch 659/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0840 - accuracy: 0.8725 - val_loss: 0.0847 - val_accuracy: 0.8687\n",
            "Epoch 660/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8724 - val_loss: 0.0849 - val_accuracy: 0.8731\n",
            "Epoch 661/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8725 - val_loss: 0.0848 - val_accuracy: 0.8651\n",
            "Epoch 662/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8725 - val_loss: 0.0847 - val_accuracy: 0.8682\n",
            "Epoch 663/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8726 - val_loss: 0.0847 - val_accuracy: 0.8677\n",
            "Epoch 664/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8722 - val_loss: 0.0848 - val_accuracy: 0.8716\n",
            "Epoch 665/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.8730 - val_loss: 0.0847 - val_accuracy: 0.8677\n",
            "Epoch 666/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.8727 - val_loss: 0.0846 - val_accuracy: 0.8705\n",
            "Epoch 667/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8727 - val_loss: 0.0846 - val_accuracy: 0.8688\n",
            "Epoch 668/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8729 - val_loss: 0.0846 - val_accuracy: 0.8698\n",
            "Epoch 669/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8722 - val_loss: 0.0849 - val_accuracy: 0.8733\n",
            "Epoch 670/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.8731 - val_loss: 0.0847 - val_accuracy: 0.8672\n",
            "Epoch 671/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.8727 - val_loss: 0.0845 - val_accuracy: 0.8702\n",
            "Epoch 672/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8730 - val_loss: 0.0846 - val_accuracy: 0.8667\n",
            "Epoch 673/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8726 - val_loss: 0.0846 - val_accuracy: 0.8678\n",
            "Epoch 674/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8727 - val_loss: 0.0847 - val_accuracy: 0.8690\n",
            "Epoch 675/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0839 - accuracy: 0.8722 - val_loss: 0.0847 - val_accuracy: 0.8671\n",
            "Epoch 676/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.8729 - val_loss: 0.0846 - val_accuracy: 0.8669\n",
            "Epoch 677/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.8724 - val_loss: 0.0848 - val_accuracy: 0.8740\n",
            "Epoch 678/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0839 - accuracy: 0.8731 - val_loss: 0.0847 - val_accuracy: 0.8654\n",
            "Epoch 679/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8730 - val_loss: 0.0845 - val_accuracy: 0.8705\n",
            "Epoch 680/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8729 - val_loss: 0.0846 - val_accuracy: 0.8725\n",
            "Epoch 681/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8734 - val_loss: 0.0845 - val_accuracy: 0.8690\n",
            "Epoch 682/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0838 - accuracy: 0.8731 - val_loss: 0.0845 - val_accuracy: 0.8703\n",
            "Epoch 683/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0838 - accuracy: 0.8735 - val_loss: 0.0845 - val_accuracy: 0.8685\n",
            "Epoch 684/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8731 - val_loss: 0.0845 - val_accuracy: 0.8664\n",
            "Epoch 685/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8735 - val_loss: 0.0844 - val_accuracy: 0.8705\n",
            "Epoch 686/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8731 - val_loss: 0.0844 - val_accuracy: 0.8686\n",
            "Epoch 687/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8730 - val_loss: 0.0845 - val_accuracy: 0.8666\n",
            "Epoch 688/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0838 - accuracy: 0.8728 - val_loss: 0.0845 - val_accuracy: 0.8720\n",
            "Epoch 689/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8734 - val_loss: 0.0844 - val_accuracy: 0.8701\n",
            "Epoch 690/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0838 - accuracy: 0.8731 - val_loss: 0.0844 - val_accuracy: 0.8688\n",
            "Epoch 691/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8729 - val_loss: 0.0844 - val_accuracy: 0.8692\n",
            "Epoch 692/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8731 - val_loss: 0.0844 - val_accuracy: 0.8684\n",
            "Epoch 693/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8735 - val_loss: 0.0844 - val_accuracy: 0.8673\n",
            "Epoch 694/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8729 - val_loss: 0.0844 - val_accuracy: 0.8711\n",
            "Epoch 695/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8735 - val_loss: 0.0844 - val_accuracy: 0.8708\n",
            "Epoch 696/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8737 - val_loss: 0.0843 - val_accuracy: 0.8689\n",
            "Epoch 697/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8734 - val_loss: 0.0844 - val_accuracy: 0.8721\n",
            "Epoch 698/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8738 - val_loss: 0.0846 - val_accuracy: 0.8734\n",
            "Epoch 699/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8736 - val_loss: 0.0843 - val_accuracy: 0.8713\n",
            "Epoch 700/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0837 - accuracy: 0.8737 - val_loss: 0.0843 - val_accuracy: 0.8703\n",
            "Epoch 701/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8729 - val_loss: 0.0845 - val_accuracy: 0.8684\n",
            "Epoch 702/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0837 - accuracy: 0.8736 - val_loss: 0.0843 - val_accuracy: 0.8702\n",
            "Epoch 703/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8737 - val_loss: 0.0843 - val_accuracy: 0.8689\n",
            "Epoch 704/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0836 - accuracy: 0.8740 - val_loss: 0.0843 - val_accuracy: 0.8719\n",
            "Epoch 705/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8733 - val_loss: 0.0843 - val_accuracy: 0.8703\n",
            "Epoch 706/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.8732 - val_loss: 0.0843 - val_accuracy: 0.8727\n",
            "Epoch 707/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.8732 - val_loss: 0.0844 - val_accuracy: 0.8668\n",
            "Epoch 708/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8737 - val_loss: 0.0843 - val_accuracy: 0.8681\n",
            "Epoch 709/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.8736 - val_loss: 0.0843 - val_accuracy: 0.8715\n",
            "Epoch 710/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8735 - val_loss: 0.0844 - val_accuracy: 0.8691\n",
            "Epoch 711/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8737 - val_loss: 0.0848 - val_accuracy: 0.8644\n",
            "Epoch 712/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.8740 - val_loss: 0.0843 - val_accuracy: 0.8677\n",
            "Epoch 713/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0836 - accuracy: 0.8735 - val_loss: 0.0842 - val_accuracy: 0.8726\n",
            "Epoch 714/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8736 - val_loss: 0.0843 - val_accuracy: 0.8698\n",
            "Epoch 715/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8737 - val_loss: 0.0842 - val_accuracy: 0.8717\n",
            "Epoch 716/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.8741 - val_loss: 0.0842 - val_accuracy: 0.8711\n",
            "Epoch 717/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8737 - val_loss: 0.0843 - val_accuracy: 0.8727\n",
            "Epoch 718/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.8738 - val_loss: 0.0842 - val_accuracy: 0.8720\n",
            "Epoch 719/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8744 - val_loss: 0.0842 - val_accuracy: 0.8694\n",
            "Epoch 720/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.8740 - val_loss: 0.0842 - val_accuracy: 0.8674\n",
            "Epoch 721/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.8741 - val_loss: 0.0842 - val_accuracy: 0.8719\n",
            "Epoch 722/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8743 - val_loss: 0.0841 - val_accuracy: 0.8713\n",
            "Epoch 723/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.8741 - val_loss: 0.0842 - val_accuracy: 0.8700\n",
            "Epoch 724/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.8739 - val_loss: 0.0842 - val_accuracy: 0.8701\n",
            "Epoch 725/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0835 - accuracy: 0.8744 - val_loss: 0.0842 - val_accuracy: 0.8674\n",
            "Epoch 726/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8739 - val_loss: 0.0843 - val_accuracy: 0.8681\n",
            "Epoch 727/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.8747 - val_loss: 0.0841 - val_accuracy: 0.8723\n",
            "Epoch 728/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8737 - val_loss: 0.0841 - val_accuracy: 0.8712\n",
            "Epoch 729/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.8748 - val_loss: 0.0842 - val_accuracy: 0.8711\n",
            "Epoch 730/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.8746 - val_loss: 0.0841 - val_accuracy: 0.8719\n",
            "Epoch 731/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8742 - val_loss: 0.0841 - val_accuracy: 0.8709\n",
            "Epoch 732/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8744 - val_loss: 0.0841 - val_accuracy: 0.8727\n",
            "Epoch 733/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.8741 - val_loss: 0.0841 - val_accuracy: 0.8712\n",
            "Epoch 734/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.8747 - val_loss: 0.0840 - val_accuracy: 0.8694\n",
            "Epoch 735/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.8743 - val_loss: 0.0840 - val_accuracy: 0.8712\n",
            "Epoch 736/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8742 - val_loss: 0.0842 - val_accuracy: 0.8729\n",
            "Epoch 737/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8744 - val_loss: 0.0841 - val_accuracy: 0.8716\n",
            "Epoch 738/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8742 - val_loss: 0.0841 - val_accuracy: 0.8731\n",
            "Epoch 739/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0834 - accuracy: 0.8744 - val_loss: 0.0841 - val_accuracy: 0.8680\n",
            "Epoch 740/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0834 - accuracy: 0.8747 - val_loss: 0.0841 - val_accuracy: 0.8672\n",
            "Epoch 741/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.8743 - val_loss: 0.0840 - val_accuracy: 0.8713\n",
            "Epoch 742/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8743 - val_loss: 0.0843 - val_accuracy: 0.8749\n",
            "Epoch 743/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8740 - val_loss: 0.0841 - val_accuracy: 0.8743\n",
            "Epoch 744/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8745 - val_loss: 0.0840 - val_accuracy: 0.8730\n",
            "Epoch 745/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.8744 - val_loss: 0.0841 - val_accuracy: 0.8679\n",
            "Epoch 746/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.8743 - val_loss: 0.0839 - val_accuracy: 0.8716\n",
            "Epoch 747/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8749 - val_loss: 0.0840 - val_accuracy: 0.8691\n",
            "Epoch 748/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8744 - val_loss: 0.0842 - val_accuracy: 0.8653\n",
            "Epoch 749/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.8747 - val_loss: 0.0840 - val_accuracy: 0.8717\n",
            "Epoch 750/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8746 - val_loss: 0.0840 - val_accuracy: 0.8686\n",
            "Epoch 751/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.8746 - val_loss: 0.0840 - val_accuracy: 0.8683\n",
            "Epoch 752/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0833 - accuracy: 0.8747 - val_loss: 0.0839 - val_accuracy: 0.8729\n",
            "Epoch 753/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8742 - val_loss: 0.0839 - val_accuracy: 0.8702\n",
            "Epoch 754/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.8748 - val_loss: 0.0840 - val_accuracy: 0.8683\n",
            "Epoch 755/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8746 - val_loss: 0.0840 - val_accuracy: 0.8715\n",
            "Epoch 756/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.0832 - accuracy: 0.8750 - val_loss: 0.0839 - val_accuracy: 0.8730\n",
            "Epoch 757/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0832 - accuracy: 0.8745 - val_loss: 0.0840 - val_accuracy: 0.8749\n",
            "Epoch 758/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8749 - val_loss: 0.0839 - val_accuracy: 0.8714\n",
            "Epoch 759/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0832 - accuracy: 0.8745 - val_loss: 0.0841 - val_accuracy: 0.8754\n",
            "Epoch 760/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0832 - accuracy: 0.8750 - val_loss: 0.0840 - val_accuracy: 0.8740\n",
            "Epoch 761/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8748 - val_loss: 0.0838 - val_accuracy: 0.8709\n",
            "Epoch 762/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0832 - accuracy: 0.8754 - val_loss: 0.0838 - val_accuracy: 0.8705\n",
            "Epoch 763/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0832 - accuracy: 0.8753 - val_loss: 0.0839 - val_accuracy: 0.8684\n",
            "Epoch 764/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8751 - val_loss: 0.0838 - val_accuracy: 0.8699\n",
            "Epoch 765/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8750 - val_loss: 0.0838 - val_accuracy: 0.8720\n",
            "Epoch 766/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8752 - val_loss: 0.0839 - val_accuracy: 0.8733\n",
            "Epoch 767/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.8750 - val_loss: 0.0838 - val_accuracy: 0.8719\n",
            "Epoch 768/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8756 - val_loss: 0.0839 - val_accuracy: 0.8698\n",
            "Epoch 769/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8752 - val_loss: 0.0838 - val_accuracy: 0.8726\n",
            "Epoch 770/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8757 - val_loss: 0.0838 - val_accuracy: 0.8730\n",
            "Epoch 771/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.8759 - val_loss: 0.0838 - val_accuracy: 0.8730\n",
            "Epoch 772/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8751 - val_loss: 0.0839 - val_accuracy: 0.8742\n",
            "Epoch 773/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8751 - val_loss: 0.0838 - val_accuracy: 0.8724\n",
            "Epoch 774/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8755 - val_loss: 0.0838 - val_accuracy: 0.8709\n",
            "Epoch 775/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8750 - val_loss: 0.0838 - val_accuracy: 0.8734\n",
            "Epoch 776/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8753 - val_loss: 0.0838 - val_accuracy: 0.8723\n",
            "Epoch 777/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8752 - val_loss: 0.0839 - val_accuracy: 0.8739\n",
            "Epoch 778/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8750 - val_loss: 0.0838 - val_accuracy: 0.8734\n",
            "Epoch 779/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8754 - val_loss: 0.0838 - val_accuracy: 0.8688\n",
            "Epoch 780/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8751 - val_loss: 0.0837 - val_accuracy: 0.8723\n",
            "Epoch 781/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0830 - accuracy: 0.8754 - val_loss: 0.0838 - val_accuracy: 0.8684\n",
            "Epoch 782/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0831 - accuracy: 0.8749 - val_loss: 0.0838 - val_accuracy: 0.8699\n",
            "Epoch 783/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0830 - accuracy: 0.8753 - val_loss: 0.0838 - val_accuracy: 0.8737\n",
            "Epoch 784/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0830 - accuracy: 0.8761 - val_loss: 0.0839 - val_accuracy: 0.8751\n",
            "Epoch 785/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8754 - val_loss: 0.0838 - val_accuracy: 0.8745\n",
            "Epoch 786/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0830 - accuracy: 0.8756 - val_loss: 0.0838 - val_accuracy: 0.8692\n",
            "Epoch 787/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8751 - val_loss: 0.0840 - val_accuracy: 0.8654\n",
            "Epoch 788/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8755 - val_loss: 0.0837 - val_accuracy: 0.8719\n",
            "Epoch 789/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0830 - accuracy: 0.8760 - val_loss: 0.0836 - val_accuracy: 0.8730\n",
            "Epoch 790/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0830 - accuracy: 0.8754 - val_loss: 0.0838 - val_accuracy: 0.8747\n",
            "Epoch 791/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8757 - val_loss: 0.0839 - val_accuracy: 0.8678\n",
            "Epoch 792/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8759 - val_loss: 0.0837 - val_accuracy: 0.8733\n",
            "Epoch 793/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8753 - val_loss: 0.0838 - val_accuracy: 0.8755\n",
            "Epoch 794/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8755 - val_loss: 0.0837 - val_accuracy: 0.8717\n",
            "Epoch 795/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0830 - accuracy: 0.8758 - val_loss: 0.0836 - val_accuracy: 0.8738\n",
            "Epoch 796/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0830 - accuracy: 0.8762 - val_loss: 0.0836 - val_accuracy: 0.8731\n",
            "Epoch 797/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8759 - val_loss: 0.0838 - val_accuracy: 0.8751\n",
            "Epoch 798/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8760 - val_loss: 0.0836 - val_accuracy: 0.8735\n",
            "Epoch 799/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8756 - val_loss: 0.0837 - val_accuracy: 0.8752\n",
            "Epoch 800/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8756 - val_loss: 0.0836 - val_accuracy: 0.8736\n",
            "Epoch 801/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8762 - val_loss: 0.0836 - val_accuracy: 0.8719\n",
            "Epoch 802/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8756 - val_loss: 0.0836 - val_accuracy: 0.8742\n",
            "Epoch 803/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8759 - val_loss: 0.0837 - val_accuracy: 0.8729\n",
            "Epoch 804/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8758 - val_loss: 0.0837 - val_accuracy: 0.8684\n",
            "Epoch 805/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8760 - val_loss: 0.0836 - val_accuracy: 0.8736\n",
            "Epoch 806/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8763 - val_loss: 0.0836 - val_accuracy: 0.8730\n",
            "Epoch 807/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0829 - accuracy: 0.8761 - val_loss: 0.0836 - val_accuracy: 0.8738\n",
            "Epoch 808/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8764 - val_loss: 0.0835 - val_accuracy: 0.8723\n",
            "Epoch 809/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8761 - val_loss: 0.0836 - val_accuracy: 0.8711\n",
            "Epoch 810/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8763 - val_loss: 0.0836 - val_accuracy: 0.8723\n",
            "Epoch 811/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.8762 - val_loss: 0.0836 - val_accuracy: 0.8748\n",
            "Epoch 812/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8762 - val_loss: 0.0836 - val_accuracy: 0.8709\n",
            "Epoch 813/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8758 - val_loss: 0.0835 - val_accuracy: 0.8722\n",
            "Epoch 814/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8765 - val_loss: 0.0836 - val_accuracy: 0.8722\n",
            "Epoch 815/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8762 - val_loss: 0.0835 - val_accuracy: 0.8729\n",
            "Epoch 816/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8766 - val_loss: 0.0835 - val_accuracy: 0.8733\n",
            "Epoch 817/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8763 - val_loss: 0.0837 - val_accuracy: 0.8674\n",
            "Epoch 818/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8759 - val_loss: 0.0834 - val_accuracy: 0.8737\n",
            "Epoch 819/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8763 - val_loss: 0.0836 - val_accuracy: 0.8693\n",
            "Epoch 820/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8761 - val_loss: 0.0835 - val_accuracy: 0.8748\n",
            "Epoch 821/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8762 - val_loss: 0.0835 - val_accuracy: 0.8743\n",
            "Epoch 822/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8759 - val_loss: 0.0835 - val_accuracy: 0.8716\n",
            "Epoch 823/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8766 - val_loss: 0.0835 - val_accuracy: 0.8728\n",
            "Epoch 824/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0828 - accuracy: 0.8765 - val_loss: 0.0834 - val_accuracy: 0.8730\n",
            "Epoch 825/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8763 - val_loss: 0.0834 - val_accuracy: 0.8724\n",
            "Epoch 826/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0828 - accuracy: 0.8763 - val_loss: 0.0835 - val_accuracy: 0.8722\n",
            "Epoch 827/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0827 - accuracy: 0.8761 - val_loss: 0.0834 - val_accuracy: 0.8714\n",
            "Epoch 828/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8762 - val_loss: 0.0834 - val_accuracy: 0.8745\n",
            "Epoch 829/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8766 - val_loss: 0.0835 - val_accuracy: 0.8694\n",
            "Epoch 830/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8763 - val_loss: 0.0836 - val_accuracy: 0.8726\n",
            "Epoch 831/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8765 - val_loss: 0.0837 - val_accuracy: 0.8662\n",
            "Epoch 832/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8764 - val_loss: 0.0835 - val_accuracy: 0.8708\n",
            "Epoch 833/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8761 - val_loss: 0.0834 - val_accuracy: 0.8724\n",
            "Epoch 834/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8765 - val_loss: 0.0834 - val_accuracy: 0.8731\n",
            "Epoch 835/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8765 - val_loss: 0.0833 - val_accuracy: 0.8731\n",
            "Epoch 836/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0827 - accuracy: 0.8771 - val_loss: 0.0834 - val_accuracy: 0.8748\n",
            "Epoch 837/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8769 - val_loss: 0.0835 - val_accuracy: 0.8725\n",
            "Epoch 838/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8764 - val_loss: 0.0834 - val_accuracy: 0.8712\n",
            "Epoch 839/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8766 - val_loss: 0.0835 - val_accuracy: 0.8755\n",
            "Epoch 840/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8772 - val_loss: 0.0835 - val_accuracy: 0.8767\n",
            "Epoch 841/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8772 - val_loss: 0.0834 - val_accuracy: 0.8709\n",
            "Epoch 842/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8769 - val_loss: 0.0834 - val_accuracy: 0.8753\n",
            "Epoch 843/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0827 - accuracy: 0.8767 - val_loss: 0.0833 - val_accuracy: 0.8734\n",
            "Epoch 844/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8771 - val_loss: 0.0838 - val_accuracy: 0.8661\n",
            "Epoch 845/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8766 - val_loss: 0.0833 - val_accuracy: 0.8742\n",
            "Epoch 846/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8768 - val_loss: 0.0833 - val_accuracy: 0.8734\n",
            "Epoch 847/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8770 - val_loss: 0.0835 - val_accuracy: 0.8700\n",
            "Epoch 848/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8769 - val_loss: 0.0838 - val_accuracy: 0.8670\n",
            "Epoch 849/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8770 - val_loss: 0.0833 - val_accuracy: 0.8749\n",
            "Epoch 850/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8768 - val_loss: 0.0833 - val_accuracy: 0.8741\n",
            "Epoch 851/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8772 - val_loss: 0.0832 - val_accuracy: 0.8747\n",
            "Epoch 852/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8771 - val_loss: 0.0833 - val_accuracy: 0.8751\n",
            "Epoch 853/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8771 - val_loss: 0.0833 - val_accuracy: 0.8751\n",
            "Epoch 854/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0826 - accuracy: 0.8773 - val_loss: 0.0833 - val_accuracy: 0.8751\n",
            "Epoch 855/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8764 - val_loss: 0.0833 - val_accuracy: 0.8741\n",
            "Epoch 856/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8775 - val_loss: 0.0833 - val_accuracy: 0.8728\n",
            "Epoch 857/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8772 - val_loss: 0.0833 - val_accuracy: 0.8731\n",
            "Epoch 858/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0826 - accuracy: 0.8767 - val_loss: 0.0833 - val_accuracy: 0.8762\n",
            "Epoch 859/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.8769 - val_loss: 0.0833 - val_accuracy: 0.8746\n",
            "Epoch 860/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8770 - val_loss: 0.0832 - val_accuracy: 0.8751\n",
            "Epoch 861/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8772 - val_loss: 0.0833 - val_accuracy: 0.8741\n",
            "Epoch 862/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8770 - val_loss: 0.0834 - val_accuracy: 0.8777\n",
            "Epoch 863/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8776 - val_loss: 0.0832 - val_accuracy: 0.8752\n",
            "Epoch 864/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8772 - val_loss: 0.0832 - val_accuracy: 0.8723\n",
            "Epoch 865/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8768 - val_loss: 0.0832 - val_accuracy: 0.8751\n",
            "Epoch 866/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8773 - val_loss: 0.0832 - val_accuracy: 0.8756\n",
            "Epoch 867/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8772 - val_loss: 0.0833 - val_accuracy: 0.8690\n",
            "Epoch 868/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8771 - val_loss: 0.0832 - val_accuracy: 0.8730\n",
            "Epoch 869/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8772 - val_loss: 0.0834 - val_accuracy: 0.8683\n",
            "Epoch 870/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8772 - val_loss: 0.0832 - val_accuracy: 0.8752\n",
            "Epoch 871/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0825 - accuracy: 0.8775 - val_loss: 0.0834 - val_accuracy: 0.8709\n",
            "Epoch 872/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0825 - accuracy: 0.8778 - val_loss: 0.0832 - val_accuracy: 0.8742\n",
            "Epoch 873/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8774 - val_loss: 0.0831 - val_accuracy: 0.8750\n",
            "Epoch 874/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8771 - val_loss: 0.0832 - val_accuracy: 0.8749\n",
            "Epoch 875/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8774 - val_loss: 0.0831 - val_accuracy: 0.8755\n",
            "Epoch 876/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8773 - val_loss: 0.0832 - val_accuracy: 0.8712\n",
            "Epoch 877/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8774 - val_loss: 0.0831 - val_accuracy: 0.8738\n",
            "Epoch 878/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8774 - val_loss: 0.0831 - val_accuracy: 0.8748\n",
            "Epoch 879/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8778 - val_loss: 0.0832 - val_accuracy: 0.8713\n",
            "Epoch 880/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8770 - val_loss: 0.0836 - val_accuracy: 0.8674\n",
            "Epoch 881/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8776 - val_loss: 0.0831 - val_accuracy: 0.8726\n",
            "Epoch 882/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8776 - val_loss: 0.0831 - val_accuracy: 0.8751\n",
            "Epoch 883/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8774 - val_loss: 0.0831 - val_accuracy: 0.8748\n",
            "Epoch 884/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8779 - val_loss: 0.0831 - val_accuracy: 0.8733\n",
            "Epoch 885/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8777 - val_loss: 0.0831 - val_accuracy: 0.8720\n",
            "Epoch 886/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8775 - val_loss: 0.0830 - val_accuracy: 0.8745\n",
            "Epoch 887/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8774 - val_loss: 0.0831 - val_accuracy: 0.8728\n",
            "Epoch 888/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0824 - accuracy: 0.8775 - val_loss: 0.0831 - val_accuracy: 0.8755\n",
            "Epoch 889/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8774 - val_loss: 0.0832 - val_accuracy: 0.8694\n",
            "Epoch 890/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8779 - val_loss: 0.0830 - val_accuracy: 0.8755\n",
            "Epoch 891/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8778 - val_loss: 0.0831 - val_accuracy: 0.8765\n",
            "Epoch 892/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0824 - accuracy: 0.8779 - val_loss: 0.0830 - val_accuracy: 0.8755\n",
            "Epoch 893/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8776 - val_loss: 0.0830 - val_accuracy: 0.8737\n",
            "Epoch 894/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8781 - val_loss: 0.0830 - val_accuracy: 0.8745\n",
            "Epoch 895/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8778 - val_loss: 0.0830 - val_accuracy: 0.8754\n",
            "Epoch 896/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8773 - val_loss: 0.0830 - val_accuracy: 0.8745\n",
            "Epoch 897/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8777 - val_loss: 0.0830 - val_accuracy: 0.8759\n",
            "Epoch 898/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8779 - val_loss: 0.0830 - val_accuracy: 0.8744\n",
            "Epoch 899/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8780 - val_loss: 0.0830 - val_accuracy: 0.8738\n",
            "Epoch 900/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8782 - val_loss: 0.0830 - val_accuracy: 0.8745\n",
            "Epoch 901/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8781 - val_loss: 0.0830 - val_accuracy: 0.8738\n",
            "Epoch 902/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8778 - val_loss: 0.0830 - val_accuracy: 0.8726\n",
            "Epoch 903/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8776 - val_loss: 0.0830 - val_accuracy: 0.8758\n",
            "Epoch 904/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8780 - val_loss: 0.0834 - val_accuracy: 0.8715\n",
            "Epoch 905/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0823 - accuracy: 0.8779 - val_loss: 0.0830 - val_accuracy: 0.8762\n",
            "Epoch 906/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8780 - val_loss: 0.0829 - val_accuracy: 0.8755\n",
            "Epoch 907/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0823 - accuracy: 0.8781 - val_loss: 0.0830 - val_accuracy: 0.8759\n",
            "Epoch 908/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8781 - val_loss: 0.0829 - val_accuracy: 0.8748\n",
            "Epoch 909/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8781 - val_loss: 0.0830 - val_accuracy: 0.8730\n",
            "Epoch 910/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8781 - val_loss: 0.0829 - val_accuracy: 0.8741\n",
            "Epoch 911/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8779 - val_loss: 0.0831 - val_accuracy: 0.8755\n",
            "Epoch 912/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8784 - val_loss: 0.0833 - val_accuracy: 0.8794\n",
            "Epoch 913/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8785 - val_loss: 0.0829 - val_accuracy: 0.8713\n",
            "Epoch 914/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8782 - val_loss: 0.0829 - val_accuracy: 0.8743\n",
            "Epoch 915/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8785 - val_loss: 0.0829 - val_accuracy: 0.8717\n",
            "Epoch 916/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8783 - val_loss: 0.0830 - val_accuracy: 0.8777\n",
            "Epoch 917/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8788 - val_loss: 0.0830 - val_accuracy: 0.8776\n",
            "Epoch 918/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8782 - val_loss: 0.0829 - val_accuracy: 0.8762\n",
            "Epoch 919/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8782 - val_loss: 0.0829 - val_accuracy: 0.8738\n",
            "Epoch 920/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8786 - val_loss: 0.0828 - val_accuracy: 0.8758\n",
            "Epoch 921/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8784 - val_loss: 0.0828 - val_accuracy: 0.8766\n",
            "Epoch 922/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8787 - val_loss: 0.0829 - val_accuracy: 0.8755\n",
            "Epoch 923/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8784 - val_loss: 0.0829 - val_accuracy: 0.8723\n",
            "Epoch 924/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0822 - accuracy: 0.8780 - val_loss: 0.0829 - val_accuracy: 0.8775\n",
            "Epoch 925/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0822 - accuracy: 0.8785 - val_loss: 0.0829 - val_accuracy: 0.8765\n",
            "Epoch 926/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8788 - val_loss: 0.0835 - val_accuracy: 0.8813\n",
            "Epoch 927/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8792 - val_loss: 0.0828 - val_accuracy: 0.8753\n",
            "Epoch 928/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8781 - val_loss: 0.0829 - val_accuracy: 0.8753\n",
            "Epoch 929/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8790 - val_loss: 0.0828 - val_accuracy: 0.8765\n",
            "Epoch 930/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8784 - val_loss: 0.0829 - val_accuracy: 0.8713\n",
            "Epoch 931/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8787 - val_loss: 0.0829 - val_accuracy: 0.8711\n",
            "Epoch 932/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8791 - val_loss: 0.0829 - val_accuracy: 0.8777\n",
            "Epoch 933/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8786 - val_loss: 0.0830 - val_accuracy: 0.8705\n",
            "Epoch 934/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8780 - val_loss: 0.0828 - val_accuracy: 0.8753\n",
            "Epoch 935/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8787 - val_loss: 0.0828 - val_accuracy: 0.8752\n",
            "Epoch 936/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8787 - val_loss: 0.0829 - val_accuracy: 0.8711\n",
            "Epoch 937/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8788 - val_loss: 0.0828 - val_accuracy: 0.8752\n",
            "Epoch 938/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8784 - val_loss: 0.0829 - val_accuracy: 0.8790\n",
            "Epoch 939/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8792 - val_loss: 0.0827 - val_accuracy: 0.8743\n",
            "Epoch 940/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8789 - val_loss: 0.0829 - val_accuracy: 0.8709\n",
            "Epoch 941/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8785 - val_loss: 0.0827 - val_accuracy: 0.8753\n",
            "Epoch 942/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8786 - val_loss: 0.0827 - val_accuracy: 0.8748\n",
            "Epoch 943/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0821 - accuracy: 0.8788 - val_loss: 0.0829 - val_accuracy: 0.8741\n",
            "Epoch 944/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8791 - val_loss: 0.0827 - val_accuracy: 0.8755\n",
            "Epoch 945/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0821 - accuracy: 0.8788 - val_loss: 0.0827 - val_accuracy: 0.8759\n",
            "Epoch 946/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8787 - val_loss: 0.0828 - val_accuracy: 0.8777\n",
            "Epoch 947/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8793 - val_loss: 0.0827 - val_accuracy: 0.8740\n",
            "Epoch 948/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8788 - val_loss: 0.0827 - val_accuracy: 0.8776\n",
            "Epoch 949/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8790 - val_loss: 0.0827 - val_accuracy: 0.8723\n",
            "Epoch 950/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8790 - val_loss: 0.0827 - val_accuracy: 0.8748\n",
            "Epoch 951/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8790 - val_loss: 0.0827 - val_accuracy: 0.8765\n",
            "Epoch 952/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8791 - val_loss: 0.0828 - val_accuracy: 0.8791\n",
            "Epoch 953/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8789 - val_loss: 0.0827 - val_accuracy: 0.8782\n",
            "Epoch 954/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8789 - val_loss: 0.0826 - val_accuracy: 0.8752\n",
            "Epoch 955/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8787 - val_loss: 0.0826 - val_accuracy: 0.8767\n",
            "Epoch 956/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8791 - val_loss: 0.0829 - val_accuracy: 0.8797\n",
            "Epoch 957/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8797 - val_loss: 0.0827 - val_accuracy: 0.8769\n",
            "Epoch 958/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0820 - accuracy: 0.8790 - val_loss: 0.0827 - val_accuracy: 0.8734\n",
            "Epoch 959/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8792 - val_loss: 0.0827 - val_accuracy: 0.8742\n",
            "Epoch 960/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8794 - val_loss: 0.0827 - val_accuracy: 0.8777\n",
            "Epoch 961/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8792 - val_loss: 0.0827 - val_accuracy: 0.8778\n",
            "Epoch 962/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0820 - accuracy: 0.8792 - val_loss: 0.0828 - val_accuracy: 0.8787\n",
            "Epoch 963/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8792 - val_loss: 0.0826 - val_accuracy: 0.8739\n",
            "Epoch 964/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8790 - val_loss: 0.0827 - val_accuracy: 0.8776\n",
            "Epoch 965/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0819 - accuracy: 0.8791 - val_loss: 0.0829 - val_accuracy: 0.8720\n",
            "Epoch 966/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8794 - val_loss: 0.0826 - val_accuracy: 0.8762\n",
            "Epoch 967/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8791 - val_loss: 0.0827 - val_accuracy: 0.8730\n",
            "Epoch 968/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8793 - val_loss: 0.0826 - val_accuracy: 0.8760\n",
            "Epoch 969/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8794 - val_loss: 0.0828 - val_accuracy: 0.8707\n",
            "Epoch 970/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8791 - val_loss: 0.0826 - val_accuracy: 0.8742\n",
            "Epoch 971/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8795 - val_loss: 0.0826 - val_accuracy: 0.8756\n",
            "Epoch 972/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8794 - val_loss: 0.0826 - val_accuracy: 0.8741\n",
            "Epoch 973/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8794 - val_loss: 0.0825 - val_accuracy: 0.8760\n",
            "Epoch 974/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0819 - accuracy: 0.8800 - val_loss: 0.0826 - val_accuracy: 0.8765\n",
            "Epoch 975/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8789 - val_loss: 0.0826 - val_accuracy: 0.8778\n",
            "Epoch 976/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8798 - val_loss: 0.0826 - val_accuracy: 0.8765\n",
            "Epoch 977/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8799 - val_loss: 0.0826 - val_accuracy: 0.8779\n",
            "Epoch 978/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8798 - val_loss: 0.0826 - val_accuracy: 0.8788\n",
            "Epoch 979/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0819 - accuracy: 0.8798 - val_loss: 0.0825 - val_accuracy: 0.8759\n",
            "Epoch 980/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8794 - val_loss: 0.0826 - val_accuracy: 0.8723\n",
            "Epoch 981/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8794 - val_loss: 0.0825 - val_accuracy: 0.8775\n",
            "Epoch 982/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8802 - val_loss: 0.0827 - val_accuracy: 0.8712\n",
            "Epoch 983/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8795 - val_loss: 0.0825 - val_accuracy: 0.8777\n",
            "Epoch 984/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8800 - val_loss: 0.0825 - val_accuracy: 0.8773\n",
            "Epoch 985/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8793 - val_loss: 0.0826 - val_accuracy: 0.8798\n",
            "Epoch 986/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8799 - val_loss: 0.0826 - val_accuracy: 0.8756\n",
            "Epoch 987/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8797 - val_loss: 0.0825 - val_accuracy: 0.8773\n",
            "Epoch 988/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8793 - val_loss: 0.0826 - val_accuracy: 0.8792\n",
            "Epoch 989/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8798 - val_loss: 0.0825 - val_accuracy: 0.8776\n",
            "Epoch 990/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8795 - val_loss: 0.0826 - val_accuracy: 0.8763\n",
            "Epoch 991/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8795 - val_loss: 0.0825 - val_accuracy: 0.8737\n",
            "Epoch 992/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8793 - val_loss: 0.0825 - val_accuracy: 0.8775\n",
            "Epoch 993/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8798 - val_loss: 0.0825 - val_accuracy: 0.8763\n",
            "Epoch 994/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8799 - val_loss: 0.0825 - val_accuracy: 0.8748\n",
            "Epoch 995/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0818 - accuracy: 0.8799 - val_loss: 0.0825 - val_accuracy: 0.8745\n",
            "Epoch 996/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8796 - val_loss: 0.0824 - val_accuracy: 0.8766\n",
            "Epoch 997/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8798 - val_loss: 0.0826 - val_accuracy: 0.8784\n",
            "Epoch 998/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0817 - accuracy: 0.8800 - val_loss: 0.0825 - val_accuracy: 0.8737\n",
            "Epoch 999/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8802 - val_loss: 0.0827 - val_accuracy: 0.8708\n",
            "Epoch 1000/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.0818 - accuracy: 0.8797 - val_loss: 0.0824 - val_accuracy: 0.8794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = network.predict(xtest_std)"
      ],
      "metadata": {
        "id": "RrUIPDfdM5wB",
        "outputId": "ea999f6b-24d7-4d6e-af53-bf00e0c3fa81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat.shape)"
      ],
      "metadata": {
        "id": "GJWR1M7LN6rv",
        "outputId": "5f8146d9-0bde-41dc-a97e-eecba9547ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytest.shape)"
      ],
      "metadata": {
        "id": "pFXuFm6HPG0g",
        "outputId": "93e19a31-1636-4c40-efa0-fdfb06db038c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat =np.argmax(yhat, axis = -1)\n",
        "ytest = np.argmax(ytest, axis= -1)"
      ],
      "metadata": {
        "id": "V162us36U6Ij"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = accuracy_score(ytest,yhat)\n",
        "cm = confusion_matrix(ytest,yhat)\n",
        "print(f\"El grado de precisión de los datos son los siguientes {100*precision}\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "yXPBisYxORs_",
        "outputId": "b1e549b3-2470-4d9c-9696-9db90064cc76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El grado de precisión de los datos son los siguientes 87.94\n",
            "[[11104   346   439]\n",
            " [  392  3377    23]\n",
            " [ 1210     2  3107]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función logarítimica\n",
        "\n",
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "plt.title(\"Grafica de aprendizaje del modelo Softmax\")\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"accuracy\"])\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_accuracy\"])\n",
        "\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "JbkIxANdZHMB",
        "outputId": "5d95589b-505c-43f6-a8bf-fc914438ceb9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"loss\"])\n",
        "\n",
        "\n",
        "plt.title(\"Grafica de aprendizaje del modelo Softmax\")\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_loss\"])\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "VD_qykwMajLa",
        "outputId": "6228a0ee-01e7-4a1c-ea7a-8ac7f6040789"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir un mapa de calor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "sns.heatmap(xtrain_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Entrenamiento\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n"
      ],
      "metadata": {
        "id": "lE0LmmEE1LMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un mapa de calor para los datos de prueba\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "sns.heatmap(xtest_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Prueba\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Py3_zIxs4elw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}