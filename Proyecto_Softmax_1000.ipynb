{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8nkvMSARhor5UOSYN4WrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosQuark/Machine-Learning-Astrophysics/blob/main/Proyecto_Softmax_1000.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# PROYECTO DE MACHINE LEARNING\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GxvURBlWmT07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZV03xjlnj-NB"
      },
      "outputs": [],
      "source": [
        "#librerias Comunes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#liberias de PCA\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import eig\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder #Change the class to str for another type the int.\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "#librerias de sklearn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#librerias de Keras y Redes Neuronales\n",
        "\n",
        "\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = pd.read_csv(\"star_classification.csv\")\n",
        "data_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "OQ6pTIb2mimr",
        "outputId": "3e10e0a8-8068-4d46-90e8-2ad4d07cc5cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237660e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237660e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237660e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237660e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543780e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176010e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030110e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891860e+18   \n",
              "\n",
              "   redshift  plate    MJD  fiber_ID   class  \n",
              "0  0.634794   5812  56354       171  GALAXY  \n",
              "1  0.779136  10445  58158       427  GALAXY  \n",
              "2  0.644195   4576  55592       299  GALAXY  \n",
              "3  0.932346   9149  58039       775  GALAXY  \n",
              "4  0.116123   6121  56187       842  GALAXY  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87b7df07-cb77-443b-aaab-cb63a5948fbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543780e+18</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176010e+19</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237660e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030110e+19</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891860e+18</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "      <td>GALAXY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b7df07-cb77-443b-aaab-cb63a5948fbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87b7df07-cb77-443b-aaab-cb63a5948fbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87b7df07-cb77-443b-aaab-cb63a5948fbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9c19507-52cd-4455-a9af-e69a1a3016bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9c19507-52cd-4455-a9af-e69a1a3016bf')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9c19507-52cd-4455-a9af-e69a1a3016bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_set.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nlql6Qz1Znk",
        "outputId": "25c35a38-bed9-4508-8973-246463072e15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 18 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   obj_ID       100000 non-null  float64\n",
            " 1   alpha        100000 non-null  float64\n",
            " 2   delta        100000 non-null  float64\n",
            " 3   u            100000 non-null  float64\n",
            " 4   g            100000 non-null  float64\n",
            " 5   r            100000 non-null  float64\n",
            " 6   i            100000 non-null  float64\n",
            " 7   z            100000 non-null  float64\n",
            " 8   run_ID       100000 non-null  int64  \n",
            " 9   rerun_ID     100000 non-null  int64  \n",
            " 10  cam_col      100000 non-null  int64  \n",
            " 11  field_ID     100000 non-null  int64  \n",
            " 12  spec_obj_ID  100000 non-null  float64\n",
            " 13  redshift     100000 non-null  float64\n",
            " 14  plate        100000 non-null  int64  \n",
            " 15  MJD          100000 non-null  int64  \n",
            " 16  fiber_ID     100000 non-null  int64  \n",
            " 17  class        100000 non-null  object \n",
            "dtypes: float64(10), int64(7), object(1)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enconder = LabelEncoder()\n",
        "\n",
        "data_set[\"class\"] = enconder.fit_transform(data_set[\"class\"])"
      ],
      "metadata": {
        "id": "lVhT4P72weJt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separar los datos\n",
        "\n",
        "Y = np.array(data_set[\"class\"])\n",
        "\n",
        "df_new = data_set.drop([\"class\"], axis =1)\n",
        "\n",
        "X = np.array(df_new)\n"
      ],
      "metadata": {
        "id": "5VSRDHJhn75L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components= 17)\n",
        "PCA_objeto.fit(X)"
      ],
      "metadata": {
        "id": "Akeqp3SySWYi",
        "outputId": "7662b86d-f611-4128-cf20-fb6d2592910e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=17)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=17)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PCA_objeto.explained_variance_)"
      ],
      "metadata": {
        "id": "3jmLTxmoSp0Q",
        "outputId": "8b2452e6-a188-4051-9520-7992f8761636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.10491489e+37 5.34345995e+28 3.63783147e+06 1.90094686e+05\n",
            " 6.89069641e+04 2.22875371e+04 8.93542373e+03 3.01724592e+03\n",
            " 3.23491013e+02 6.79740439e+00 3.42870277e+00 2.46778931e+00\n",
            " 1.93784010e+00 4.09255753e-01 3.26988977e-01 4.66492584e-02\n",
            " 3.72772496e-34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PCA_objeto = PCA(n_components = 17)\n",
        "Z = PCA_objeto.fit_transform(X)"
      ],
      "metadata": {
        "id": "0dytpcETSr5A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento de los datos\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Z,Y, test_size = 0.2, stratify=Y)"
      ],
      "metadata": {
        "id": "MXeQdyFvxQQ6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estandarizar los datos\n",
        "\n",
        "scaler = MinMaxScaler().fit(xtrain)\n",
        "\n",
        "xtrain_std = scaler.transform(xtrain)\n",
        "\n",
        "xtest_std = scaler.transform(xtest)\n"
      ],
      "metadata": {
        "id": "i6dJHiUQxpVc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Este apartado se utilizar para poder dar inicio el entrenamiento a una red\n",
        "neuronal\n",
        "\n",
        "   Todo esto viene dentro de la página oficial de Keras.\n",
        "\n",
        "   Dense es una capa de neurona que está conectada con todas las anteriores\n",
        "\n",
        "   Sequential es utilizado para crear secuencias en redes neuronales.\n",
        "\n",
        "   Optimizador: Adam.\n",
        "\n",
        "   units es la candtidad de clases que tienes.\n",
        "\n",
        "   activation: \"Qué tipo de función de activación almacenas\".\n",
        "\n",
        "   input_dim = la dimensionalidad.\n",
        "\n",
        "\"\"\"\n",
        "network = Sequential([\n",
        "\n",
        "    Dense(units=3, activation= \"softmax\" , input_dim = 17)\n",
        "])\n",
        "\n",
        "#Que copilador voy a utilizar, Adam, puede hacer eso.\n",
        "\n",
        "Adam(learning_rate=0.0001) #Taza de aprendizaje pequeña\n",
        "\n",
        "network.compile()\n",
        "\n",
        "#Función de perdida que se utilizará en la sala de entrenamient como su métrica.\n",
        "\n",
        "network.compile(loss= \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "QbP87Xplx-fX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"La libreria de keras para to_categorical\n",
        "\n",
        "   se utiliza para poder experesar problemas de clasificación de multiclase.\n",
        "   Para convertir nuestras etiquetas númericas en tipo one-hot.\n",
        "\n",
        "   Supongamso que tienes 3 clases (etiqeutas númericas 0,1,2)\n",
        "\n",
        "   En la primera linea convierte la una matriz en one-hot\n",
        "\n",
        "   Cada fila corresponde a un etiqueta, y cada columna, representa una clase.\n",
        "\n",
        "   AQUÍ INICIAMOS LA ETAPA DE ENTRENAMIENTO DE LA RED\n",
        "\n",
        "   El profe explica que es el batch_size, es para reducir el costo\n",
        "   computacional,\n",
        "   crea grupos para filas de hasta 100,000 dimensiones.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#network.fit(xtrain_std, ytrain, epochs=50, batch_size=128 )\n",
        "\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "epoch_accuracy =network.fit(xtrain_std, ytrain, epochs=1000, batch_size=80,\n",
        "                             validation_data=(xtest_std,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJMrjFO3yNnb",
        "outputId": "8c66b6a5-351f-4357-81a8-d567263d54c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1000/1000 [==============================] - 6s 5ms/step - loss: 0.9428 - accuracy: 0.5842 - val_loss: 0.9140 - val_accuracy: 0.5950\n",
            "Epoch 2/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8957 - accuracy: 0.5966 - val_loss: 0.8825 - val_accuracy: 0.5997\n",
            "Epoch 3/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8681 - accuracy: 0.6037 - val_loss: 0.8583 - val_accuracy: 0.6085\n",
            "Epoch 4/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8463 - accuracy: 0.6119 - val_loss: 0.8386 - val_accuracy: 0.6157\n",
            "Epoch 5/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8277 - accuracy: 0.6188 - val_loss: 0.8211 - val_accuracy: 0.6187\n",
            "Epoch 6/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8112 - accuracy: 0.6260 - val_loss: 0.8054 - val_accuracy: 0.6254\n",
            "Epoch 7/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7961 - accuracy: 0.6345 - val_loss: 0.7908 - val_accuracy: 0.6370\n",
            "Epoch 8/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7825 - accuracy: 0.6455 - val_loss: 0.7774 - val_accuracy: 0.6517\n",
            "Epoch 9/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7695 - accuracy: 0.6565 - val_loss: 0.7644 - val_accuracy: 0.6575\n",
            "Epoch 10/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7573 - accuracy: 0.6680 - val_loss: 0.7527 - val_accuracy: 0.6667\n",
            "Epoch 11/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7461 - accuracy: 0.6787 - val_loss: 0.7419 - val_accuracy: 0.6910\n",
            "Epoch 12/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7358 - accuracy: 0.6887 - val_loss: 0.7317 - val_accuracy: 0.6903\n",
            "Epoch 13/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7261 - accuracy: 0.6980 - val_loss: 0.7219 - val_accuracy: 0.7000\n",
            "Epoch 14/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7169 - accuracy: 0.7078 - val_loss: 0.7132 - val_accuracy: 0.7055\n",
            "Epoch 15/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7085 - accuracy: 0.7162 - val_loss: 0.7049 - val_accuracy: 0.7208\n",
            "Epoch 16/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7006 - accuracy: 0.7253 - val_loss: 0.6970 - val_accuracy: 0.7337\n",
            "Epoch 17/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.7329 - val_loss: 0.6906 - val_accuracy: 0.7209\n",
            "Epoch 18/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6860 - accuracy: 0.7394 - val_loss: 0.6830 - val_accuracy: 0.7523\n",
            "Epoch 19/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6793 - accuracy: 0.7463 - val_loss: 0.6764 - val_accuracy: 0.7521\n",
            "Epoch 20/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6729 - accuracy: 0.7525 - val_loss: 0.6694 - val_accuracy: 0.7526\n",
            "Epoch 21/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6667 - accuracy: 0.7567 - val_loss: 0.6633 - val_accuracy: 0.7631\n",
            "Epoch 22/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6609 - accuracy: 0.7623 - val_loss: 0.6576 - val_accuracy: 0.7690\n",
            "Epoch 23/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6554 - accuracy: 0.7659 - val_loss: 0.6525 - val_accuracy: 0.7764\n",
            "Epoch 24/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6500 - accuracy: 0.7704 - val_loss: 0.6472 - val_accuracy: 0.7747\n",
            "Epoch 25/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6450 - accuracy: 0.7745 - val_loss: 0.6419 - val_accuracy: 0.7760\n",
            "Epoch 26/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6403 - accuracy: 0.7777 - val_loss: 0.6374 - val_accuracy: 0.7878\n",
            "Epoch 27/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6357 - accuracy: 0.7811 - val_loss: 0.6326 - val_accuracy: 0.7843\n",
            "Epoch 28/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6313 - accuracy: 0.7839 - val_loss: 0.6283 - val_accuracy: 0.7867\n",
            "Epoch 29/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6272 - accuracy: 0.7866 - val_loss: 0.6241 - val_accuracy: 0.7894\n",
            "Epoch 30/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6230 - accuracy: 0.7900 - val_loss: 0.6203 - val_accuracy: 0.7984\n",
            "Epoch 31/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6192 - accuracy: 0.7922 - val_loss: 0.6166 - val_accuracy: 0.8015\n",
            "Epoch 32/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6156 - accuracy: 0.7947 - val_loss: 0.6126 - val_accuracy: 0.7990\n",
            "Epoch 33/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6121 - accuracy: 0.7969 - val_loss: 0.6093 - val_accuracy: 0.7990\n",
            "Epoch 34/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6087 - accuracy: 0.7994 - val_loss: 0.6059 - val_accuracy: 0.8030\n",
            "Epoch 35/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6054 - accuracy: 0.8008 - val_loss: 0.6025 - val_accuracy: 0.8067\n",
            "Epoch 36/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6023 - accuracy: 0.8030 - val_loss: 0.5993 - val_accuracy: 0.8076\n",
            "Epoch 37/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5992 - accuracy: 0.8048 - val_loss: 0.5964 - val_accuracy: 0.8093\n",
            "Epoch 38/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5963 - accuracy: 0.8060 - val_loss: 0.5934 - val_accuracy: 0.8134\n",
            "Epoch 39/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5934 - accuracy: 0.8081 - val_loss: 0.5907 - val_accuracy: 0.8159\n",
            "Epoch 40/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5907 - accuracy: 0.8097 - val_loss: 0.5878 - val_accuracy: 0.8133\n",
            "Epoch 41/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5880 - accuracy: 0.8108 - val_loss: 0.5853 - val_accuracy: 0.8139\n",
            "Epoch 42/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5855 - accuracy: 0.8124 - val_loss: 0.5827 - val_accuracy: 0.8169\n",
            "Epoch 43/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5830 - accuracy: 0.8133 - val_loss: 0.5804 - val_accuracy: 0.8203\n",
            "Epoch 44/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5806 - accuracy: 0.8147 - val_loss: 0.5778 - val_accuracy: 0.8195\n",
            "Epoch 45/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5783 - accuracy: 0.8158 - val_loss: 0.5757 - val_accuracy: 0.8180\n",
            "Epoch 46/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5761 - accuracy: 0.8169 - val_loss: 0.5733 - val_accuracy: 0.8201\n",
            "Epoch 47/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5739 - accuracy: 0.8182 - val_loss: 0.5714 - val_accuracy: 0.8185\n",
            "Epoch 48/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5717 - accuracy: 0.8184 - val_loss: 0.5692 - val_accuracy: 0.8226\n",
            "Epoch 49/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5696 - accuracy: 0.8199 - val_loss: 0.5669 - val_accuracy: 0.8243\n",
            "Epoch 50/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5677 - accuracy: 0.8209 - val_loss: 0.5653 - val_accuracy: 0.8280\n",
            "Epoch 51/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5657 - accuracy: 0.8211 - val_loss: 0.5631 - val_accuracy: 0.8278\n",
            "Epoch 52/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5638 - accuracy: 0.8219 - val_loss: 0.5617 - val_accuracy: 0.8300\n",
            "Epoch 53/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5620 - accuracy: 0.8229 - val_loss: 0.5593 - val_accuracy: 0.8276\n",
            "Epoch 54/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5603 - accuracy: 0.8237 - val_loss: 0.5576 - val_accuracy: 0.8281\n",
            "Epoch 55/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5585 - accuracy: 0.8241 - val_loss: 0.5559 - val_accuracy: 0.8295\n",
            "Epoch 56/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5569 - accuracy: 0.8250 - val_loss: 0.5543 - val_accuracy: 0.8300\n",
            "Epoch 57/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5552 - accuracy: 0.8253 - val_loss: 0.5526 - val_accuracy: 0.8303\n",
            "Epoch 58/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5536 - accuracy: 0.8264 - val_loss: 0.5510 - val_accuracy: 0.8303\n",
            "Epoch 59/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5520 - accuracy: 0.8269 - val_loss: 0.5493 - val_accuracy: 0.8324\n",
            "Epoch 60/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5504 - accuracy: 0.8274 - val_loss: 0.5478 - val_accuracy: 0.8326\n",
            "Epoch 61/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5488 - accuracy: 0.8280 - val_loss: 0.5466 - val_accuracy: 0.8293\n",
            "Epoch 62/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5474 - accuracy: 0.8284 - val_loss: 0.5453 - val_accuracy: 0.8344\n",
            "Epoch 63/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5460 - accuracy: 0.8292 - val_loss: 0.5434 - val_accuracy: 0.8340\n",
            "Epoch 64/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5445 - accuracy: 0.8295 - val_loss: 0.5421 - val_accuracy: 0.8321\n",
            "Epoch 65/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5430 - accuracy: 0.8298 - val_loss: 0.5411 - val_accuracy: 0.8364\n",
            "Epoch 66/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5418 - accuracy: 0.8311 - val_loss: 0.5396 - val_accuracy: 0.8309\n",
            "Epoch 67/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5404 - accuracy: 0.8309 - val_loss: 0.5380 - val_accuracy: 0.8334\n",
            "Epoch 68/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5391 - accuracy: 0.8314 - val_loss: 0.5365 - val_accuracy: 0.8346\n",
            "Epoch 69/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5378 - accuracy: 0.8322 - val_loss: 0.5353 - val_accuracy: 0.8347\n",
            "Epoch 70/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5366 - accuracy: 0.8330 - val_loss: 0.5341 - val_accuracy: 0.8370\n",
            "Epoch 71/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5353 - accuracy: 0.8328 - val_loss: 0.5334 - val_accuracy: 0.8393\n",
            "Epoch 72/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5342 - accuracy: 0.8336 - val_loss: 0.5321 - val_accuracy: 0.8396\n",
            "Epoch 73/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5329 - accuracy: 0.8337 - val_loss: 0.5307 - val_accuracy: 0.8383\n",
            "Epoch 74/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5318 - accuracy: 0.8343 - val_loss: 0.5293 - val_accuracy: 0.8369\n",
            "Epoch 75/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5307 - accuracy: 0.8349 - val_loss: 0.5281 - val_accuracy: 0.8379\n",
            "Epoch 76/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5295 - accuracy: 0.8350 - val_loss: 0.5273 - val_accuracy: 0.8362\n",
            "Epoch 77/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5284 - accuracy: 0.8356 - val_loss: 0.5259 - val_accuracy: 0.8395\n",
            "Epoch 78/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5273 - accuracy: 0.8361 - val_loss: 0.5248 - val_accuracy: 0.8384\n",
            "Epoch 79/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5263 - accuracy: 0.8359 - val_loss: 0.5237 - val_accuracy: 0.8393\n",
            "Epoch 80/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5252 - accuracy: 0.8364 - val_loss: 0.5227 - val_accuracy: 0.8401\n",
            "Epoch 81/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5241 - accuracy: 0.8374 - val_loss: 0.5217 - val_accuracy: 0.8403\n",
            "Epoch 82/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5231 - accuracy: 0.8369 - val_loss: 0.5207 - val_accuracy: 0.8400\n",
            "Epoch 83/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5223 - accuracy: 0.8376 - val_loss: 0.5199 - val_accuracy: 0.8426\n",
            "Epoch 84/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5212 - accuracy: 0.8374 - val_loss: 0.5189 - val_accuracy: 0.8429\n",
            "Epoch 85/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5203 - accuracy: 0.8378 - val_loss: 0.5179 - val_accuracy: 0.8406\n",
            "Epoch 86/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5193 - accuracy: 0.8378 - val_loss: 0.5168 - val_accuracy: 0.8418\n",
            "Epoch 87/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5184 - accuracy: 0.8385 - val_loss: 0.5159 - val_accuracy: 0.8415\n",
            "Epoch 88/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5175 - accuracy: 0.8390 - val_loss: 0.5150 - val_accuracy: 0.8429\n",
            "Epoch 89/1000\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5166 - accuracy: 0.8392 - val_loss: 0.5149 - val_accuracy: 0.8382\n",
            "Epoch 90/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5157 - accuracy: 0.8393 - val_loss: 0.5135 - val_accuracy: 0.8413\n",
            "Epoch 91/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5148 - accuracy: 0.8396 - val_loss: 0.5130 - val_accuracy: 0.8449\n",
            "Epoch 92/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5140 - accuracy: 0.8396 - val_loss: 0.5116 - val_accuracy: 0.8449\n",
            "Epoch 93/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5131 - accuracy: 0.8400 - val_loss: 0.5106 - val_accuracy: 0.8432\n",
            "Epoch 94/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5122 - accuracy: 0.8405 - val_loss: 0.5097 - val_accuracy: 0.8440\n",
            "Epoch 95/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5114 - accuracy: 0.8406 - val_loss: 0.5092 - val_accuracy: 0.8419\n",
            "Epoch 96/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5105 - accuracy: 0.8410 - val_loss: 0.5080 - val_accuracy: 0.8444\n",
            "Epoch 97/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5097 - accuracy: 0.8415 - val_loss: 0.5075 - val_accuracy: 0.8429\n",
            "Epoch 98/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5089 - accuracy: 0.8414 - val_loss: 0.5066 - val_accuracy: 0.8462\n",
            "Epoch 99/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5081 - accuracy: 0.8416 - val_loss: 0.5058 - val_accuracy: 0.8450\n",
            "Epoch 100/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5074 - accuracy: 0.8420 - val_loss: 0.5052 - val_accuracy: 0.8464\n",
            "Epoch 101/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5066 - accuracy: 0.8424 - val_loss: 0.5042 - val_accuracy: 0.8449\n",
            "Epoch 102/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5058 - accuracy: 0.8423 - val_loss: 0.5034 - val_accuracy: 0.8454\n",
            "Epoch 103/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5050 - accuracy: 0.8424 - val_loss: 0.5027 - val_accuracy: 0.8466\n",
            "Epoch 104/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5043 - accuracy: 0.8430 - val_loss: 0.5023 - val_accuracy: 0.8433\n",
            "Epoch 105/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5036 - accuracy: 0.8427 - val_loss: 0.5012 - val_accuracy: 0.8464\n",
            "Epoch 106/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5028 - accuracy: 0.8427 - val_loss: 0.5004 - val_accuracy: 0.8468\n",
            "Epoch 107/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5021 - accuracy: 0.8439 - val_loss: 0.4997 - val_accuracy: 0.8468\n",
            "Epoch 108/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5014 - accuracy: 0.8434 - val_loss: 0.4991 - val_accuracy: 0.8465\n",
            "Epoch 109/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5007 - accuracy: 0.8438 - val_loss: 0.4986 - val_accuracy: 0.8486\n",
            "Epoch 110/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.5000 - accuracy: 0.8438 - val_loss: 0.4977 - val_accuracy: 0.8484\n",
            "Epoch 111/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4993 - accuracy: 0.8442 - val_loss: 0.4970 - val_accuracy: 0.8472\n",
            "Epoch 112/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4987 - accuracy: 0.8444 - val_loss: 0.4963 - val_accuracy: 0.8485\n",
            "Epoch 113/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4980 - accuracy: 0.8445 - val_loss: 0.4958 - val_accuracy: 0.8485\n",
            "Epoch 114/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.8448 - val_loss: 0.4950 - val_accuracy: 0.8475\n",
            "Epoch 115/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4967 - accuracy: 0.8448 - val_loss: 0.4945 - val_accuracy: 0.8461\n",
            "Epoch 116/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4960 - accuracy: 0.8449 - val_loss: 0.4943 - val_accuracy: 0.8494\n",
            "Epoch 117/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4954 - accuracy: 0.8450 - val_loss: 0.4930 - val_accuracy: 0.8490\n",
            "Epoch 118/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4948 - accuracy: 0.8457 - val_loss: 0.4925 - val_accuracy: 0.8476\n",
            "Epoch 119/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4941 - accuracy: 0.8455 - val_loss: 0.4917 - val_accuracy: 0.8493\n",
            "Epoch 120/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4935 - accuracy: 0.8460 - val_loss: 0.4914 - val_accuracy: 0.8484\n",
            "Epoch 121/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4929 - accuracy: 0.8459 - val_loss: 0.4907 - val_accuracy: 0.8478\n",
            "Epoch 122/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4923 - accuracy: 0.8459 - val_loss: 0.4900 - val_accuracy: 0.8482\n",
            "Epoch 123/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4916 - accuracy: 0.8462 - val_loss: 0.4895 - val_accuracy: 0.8499\n",
            "Epoch 124/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4911 - accuracy: 0.8463 - val_loss: 0.4891 - val_accuracy: 0.8466\n",
            "Epoch 125/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4905 - accuracy: 0.8465 - val_loss: 0.4881 - val_accuracy: 0.8495\n",
            "Epoch 126/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4898 - accuracy: 0.8469 - val_loss: 0.4875 - val_accuracy: 0.8501\n",
            "Epoch 127/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4892 - accuracy: 0.8469 - val_loss: 0.4870 - val_accuracy: 0.8493\n",
            "Epoch 128/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4887 - accuracy: 0.8470 - val_loss: 0.4865 - val_accuracy: 0.8502\n",
            "Epoch 129/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4882 - accuracy: 0.8469 - val_loss: 0.4858 - val_accuracy: 0.8503\n",
            "Epoch 130/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4875 - accuracy: 0.8478 - val_loss: 0.4855 - val_accuracy: 0.8474\n",
            "Epoch 131/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4870 - accuracy: 0.8474 - val_loss: 0.4849 - val_accuracy: 0.8505\n",
            "Epoch 132/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4865 - accuracy: 0.8478 - val_loss: 0.4842 - val_accuracy: 0.8508\n",
            "Epoch 133/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4859 - accuracy: 0.8475 - val_loss: 0.4845 - val_accuracy: 0.8513\n",
            "Epoch 134/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4854 - accuracy: 0.8481 - val_loss: 0.4832 - val_accuracy: 0.8512\n",
            "Epoch 135/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.8479 - val_loss: 0.4825 - val_accuracy: 0.8504\n",
            "Epoch 136/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4843 - accuracy: 0.8479 - val_loss: 0.4820 - val_accuracy: 0.8512\n",
            "Epoch 137/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4838 - accuracy: 0.8482 - val_loss: 0.4816 - val_accuracy: 0.8514\n",
            "Epoch 138/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4832 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.8512\n",
            "Epoch 139/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4826 - accuracy: 0.8485 - val_loss: 0.4803 - val_accuracy: 0.8511\n",
            "Epoch 140/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4821 - accuracy: 0.8486 - val_loss: 0.4798 - val_accuracy: 0.8513\n",
            "Epoch 141/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4816 - accuracy: 0.8489 - val_loss: 0.4793 - val_accuracy: 0.8509\n",
            "Epoch 142/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4811 - accuracy: 0.8488 - val_loss: 0.4788 - val_accuracy: 0.8511\n",
            "Epoch 143/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4806 - accuracy: 0.8490 - val_loss: 0.4783 - val_accuracy: 0.8513\n",
            "Epoch 144/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4801 - accuracy: 0.8488 - val_loss: 0.4780 - val_accuracy: 0.8515\n",
            "Epoch 145/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4796 - accuracy: 0.8490 - val_loss: 0.4773 - val_accuracy: 0.8509\n",
            "Epoch 146/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4791 - accuracy: 0.8497 - val_loss: 0.4768 - val_accuracy: 0.8519\n",
            "Epoch 147/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4786 - accuracy: 0.8497 - val_loss: 0.4765 - val_accuracy: 0.8522\n",
            "Epoch 148/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4781 - accuracy: 0.8500 - val_loss: 0.4758 - val_accuracy: 0.8519\n",
            "Epoch 149/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4775 - accuracy: 0.8502 - val_loss: 0.4755 - val_accuracy: 0.8504\n",
            "Epoch 150/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4770 - accuracy: 0.8499 - val_loss: 0.4754 - val_accuracy: 0.8486\n",
            "Epoch 151/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4766 - accuracy: 0.8503 - val_loss: 0.4746 - val_accuracy: 0.8500\n",
            "Epoch 152/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4761 - accuracy: 0.8503 - val_loss: 0.4738 - val_accuracy: 0.8523\n",
            "Epoch 153/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4757 - accuracy: 0.8502 - val_loss: 0.4736 - val_accuracy: 0.8508\n",
            "Epoch 154/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4751 - accuracy: 0.8506 - val_loss: 0.4730 - val_accuracy: 0.8532\n",
            "Epoch 155/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4747 - accuracy: 0.8509 - val_loss: 0.4726 - val_accuracy: 0.8533\n",
            "Epoch 156/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4743 - accuracy: 0.8511 - val_loss: 0.4722 - val_accuracy: 0.8532\n",
            "Epoch 157/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4737 - accuracy: 0.8510 - val_loss: 0.4716 - val_accuracy: 0.8529\n",
            "Epoch 158/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4733 - accuracy: 0.8509 - val_loss: 0.4710 - val_accuracy: 0.8528\n",
            "Epoch 159/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4729 - accuracy: 0.8508 - val_loss: 0.4706 - val_accuracy: 0.8529\n",
            "Epoch 160/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4724 - accuracy: 0.8511 - val_loss: 0.4702 - val_accuracy: 0.8535\n",
            "Epoch 161/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4720 - accuracy: 0.8516 - val_loss: 0.4698 - val_accuracy: 0.8527\n",
            "Epoch 162/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4715 - accuracy: 0.8512 - val_loss: 0.4693 - val_accuracy: 0.8532\n",
            "Epoch 163/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4711 - accuracy: 0.8512 - val_loss: 0.4695 - val_accuracy: 0.8550\n",
            "Epoch 164/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.4706 - accuracy: 0.8516 - val_loss: 0.4693 - val_accuracy: 0.8492\n",
            "Epoch 165/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4701 - accuracy: 0.8516 - val_loss: 0.4681 - val_accuracy: 0.8541\n",
            "Epoch 166/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4697 - accuracy: 0.8516 - val_loss: 0.4675 - val_accuracy: 0.8533\n",
            "Epoch 167/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4693 - accuracy: 0.8517 - val_loss: 0.4672 - val_accuracy: 0.8543\n",
            "Epoch 168/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4688 - accuracy: 0.8520 - val_loss: 0.4666 - val_accuracy: 0.8539\n",
            "Epoch 169/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4684 - accuracy: 0.8520 - val_loss: 0.4662 - val_accuracy: 0.8543\n",
            "Epoch 170/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4680 - accuracy: 0.8524 - val_loss: 0.4657 - val_accuracy: 0.8544\n",
            "Epoch 171/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4676 - accuracy: 0.8522 - val_loss: 0.4653 - val_accuracy: 0.8540\n",
            "Epoch 172/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.8521 - val_loss: 0.4649 - val_accuracy: 0.8540\n",
            "Epoch 173/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4668 - accuracy: 0.8526 - val_loss: 0.4647 - val_accuracy: 0.8550\n",
            "Epoch 174/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4663 - accuracy: 0.8520 - val_loss: 0.4643 - val_accuracy: 0.8551\n",
            "Epoch 175/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4660 - accuracy: 0.8525 - val_loss: 0.4638 - val_accuracy: 0.8532\n",
            "Epoch 176/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4654 - accuracy: 0.8525 - val_loss: 0.4633 - val_accuracy: 0.8543\n",
            "Epoch 177/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4651 - accuracy: 0.8526 - val_loss: 0.4628 - val_accuracy: 0.8544\n",
            "Epoch 178/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4647 - accuracy: 0.8529 - val_loss: 0.4624 - val_accuracy: 0.8542\n",
            "Epoch 179/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4642 - accuracy: 0.8532 - val_loss: 0.4622 - val_accuracy: 0.8527\n",
            "Epoch 180/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4639 - accuracy: 0.8529 - val_loss: 0.4616 - val_accuracy: 0.8549\n",
            "Epoch 181/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4635 - accuracy: 0.8532 - val_loss: 0.4618 - val_accuracy: 0.8526\n",
            "Epoch 182/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4630 - accuracy: 0.8536 - val_loss: 0.4608 - val_accuracy: 0.8551\n",
            "Epoch 183/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4626 - accuracy: 0.8534 - val_loss: 0.4603 - val_accuracy: 0.8551\n",
            "Epoch 184/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4622 - accuracy: 0.8534 - val_loss: 0.4600 - val_accuracy: 0.8555\n",
            "Epoch 185/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4618 - accuracy: 0.8535 - val_loss: 0.4603 - val_accuracy: 0.8572\n",
            "Epoch 186/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4615 - accuracy: 0.8538 - val_loss: 0.4592 - val_accuracy: 0.8561\n",
            "Epoch 187/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4611 - accuracy: 0.8540 - val_loss: 0.4588 - val_accuracy: 0.8563\n",
            "Epoch 188/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4607 - accuracy: 0.8540 - val_loss: 0.4586 - val_accuracy: 0.8557\n",
            "Epoch 189/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4603 - accuracy: 0.8539 - val_loss: 0.4581 - val_accuracy: 0.8548\n",
            "Epoch 190/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4599 - accuracy: 0.8542 - val_loss: 0.4580 - val_accuracy: 0.8539\n",
            "Epoch 191/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4596 - accuracy: 0.8539 - val_loss: 0.4575 - val_accuracy: 0.8570\n",
            "Epoch 192/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4592 - accuracy: 0.8539 - val_loss: 0.4571 - val_accuracy: 0.8568\n",
            "Epoch 193/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4587 - accuracy: 0.8545 - val_loss: 0.4565 - val_accuracy: 0.8563\n",
            "Epoch 194/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4584 - accuracy: 0.8545 - val_loss: 0.4561 - val_accuracy: 0.8565\n",
            "Epoch 195/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4581 - accuracy: 0.8547 - val_loss: 0.4559 - val_accuracy: 0.8566\n",
            "Epoch 196/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4576 - accuracy: 0.8543 - val_loss: 0.4557 - val_accuracy: 0.8572\n",
            "Epoch 197/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4573 - accuracy: 0.8548 - val_loss: 0.4550 - val_accuracy: 0.8564\n",
            "Epoch 198/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4570 - accuracy: 0.8551 - val_loss: 0.4546 - val_accuracy: 0.8568\n",
            "Epoch 199/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.8548 - val_loss: 0.4543 - val_accuracy: 0.8564\n",
            "Epoch 200/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4562 - accuracy: 0.8549 - val_loss: 0.4541 - val_accuracy: 0.8573\n",
            "Epoch 201/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4558 - accuracy: 0.8549 - val_loss: 0.4539 - val_accuracy: 0.8541\n",
            "Epoch 202/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4555 - accuracy: 0.8552 - val_loss: 0.4534 - val_accuracy: 0.8550\n",
            "Epoch 203/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4551 - accuracy: 0.8547 - val_loss: 0.4529 - val_accuracy: 0.8560\n",
            "Epoch 204/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4548 - accuracy: 0.8549 - val_loss: 0.4525 - val_accuracy: 0.8573\n",
            "Epoch 205/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4544 - accuracy: 0.8549 - val_loss: 0.4525 - val_accuracy: 0.8579\n",
            "Epoch 206/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4540 - accuracy: 0.8553 - val_loss: 0.4520 - val_accuracy: 0.8560\n",
            "Epoch 207/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4537 - accuracy: 0.8549 - val_loss: 0.4515 - val_accuracy: 0.8576\n",
            "Epoch 208/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4533 - accuracy: 0.8553 - val_loss: 0.4511 - val_accuracy: 0.8576\n",
            "Epoch 209/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4530 - accuracy: 0.8550 - val_loss: 0.4507 - val_accuracy: 0.8579\n",
            "Epoch 210/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4527 - accuracy: 0.8554 - val_loss: 0.4505 - val_accuracy: 0.8559\n",
            "Epoch 211/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.8555 - val_loss: 0.4505 - val_accuracy: 0.8584\n",
            "Epoch 212/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4519 - accuracy: 0.8558 - val_loss: 0.4498 - val_accuracy: 0.8561\n",
            "Epoch 213/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4516 - accuracy: 0.8554 - val_loss: 0.4493 - val_accuracy: 0.8574\n",
            "Epoch 214/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4512 - accuracy: 0.8555 - val_loss: 0.4490 - val_accuracy: 0.8581\n",
            "Epoch 215/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4509 - accuracy: 0.8560 - val_loss: 0.4486 - val_accuracy: 0.8581\n",
            "Epoch 216/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.8555 - val_loss: 0.4502 - val_accuracy: 0.8595\n",
            "Epoch 217/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4502 - accuracy: 0.8562 - val_loss: 0.4480 - val_accuracy: 0.8579\n",
            "Epoch 218/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4498 - accuracy: 0.8559 - val_loss: 0.4476 - val_accuracy: 0.8582\n",
            "Epoch 219/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4496 - accuracy: 0.8555 - val_loss: 0.4474 - val_accuracy: 0.8572\n",
            "Epoch 220/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4492 - accuracy: 0.8561 - val_loss: 0.4472 - val_accuracy: 0.8590\n",
            "Epoch 221/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4489 - accuracy: 0.8565 - val_loss: 0.4466 - val_accuracy: 0.8580\n",
            "Epoch 222/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4486 - accuracy: 0.8559 - val_loss: 0.4463 - val_accuracy: 0.8583\n",
            "Epoch 223/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4483 - accuracy: 0.8561 - val_loss: 0.4461 - val_accuracy: 0.8582\n",
            "Epoch 224/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4480 - accuracy: 0.8565 - val_loss: 0.4457 - val_accuracy: 0.8586\n",
            "Epoch 225/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4477 - accuracy: 0.8565 - val_loss: 0.4456 - val_accuracy: 0.8594\n",
            "Epoch 226/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4472 - accuracy: 0.8563 - val_loss: 0.4458 - val_accuracy: 0.8600\n",
            "Epoch 227/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4470 - accuracy: 0.8567 - val_loss: 0.4447 - val_accuracy: 0.8584\n",
            "Epoch 228/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4467 - accuracy: 0.8570 - val_loss: 0.4444 - val_accuracy: 0.8589\n",
            "Epoch 229/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4464 - accuracy: 0.8566 - val_loss: 0.4442 - val_accuracy: 0.8587\n",
            "Epoch 230/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4460 - accuracy: 0.8571 - val_loss: 0.4438 - val_accuracy: 0.8591\n",
            "Epoch 231/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4457 - accuracy: 0.8569 - val_loss: 0.4435 - val_accuracy: 0.8586\n",
            "Epoch 232/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4454 - accuracy: 0.8569 - val_loss: 0.4432 - val_accuracy: 0.8590\n",
            "Epoch 233/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4451 - accuracy: 0.8569 - val_loss: 0.4429 - val_accuracy: 0.8591\n",
            "Epoch 234/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4447 - accuracy: 0.8571 - val_loss: 0.4427 - val_accuracy: 0.8600\n",
            "Epoch 235/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4445 - accuracy: 0.8569 - val_loss: 0.4422 - val_accuracy: 0.8584\n",
            "Epoch 236/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4441 - accuracy: 0.8569 - val_loss: 0.4421 - val_accuracy: 0.8569\n",
            "Epoch 237/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4437 - accuracy: 0.8574 - val_loss: 0.4418 - val_accuracy: 0.8576\n",
            "Epoch 238/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4435 - accuracy: 0.8568 - val_loss: 0.4413 - val_accuracy: 0.8581\n",
            "Epoch 239/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4432 - accuracy: 0.8575 - val_loss: 0.4410 - val_accuracy: 0.8594\n",
            "Epoch 240/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4429 - accuracy: 0.8571 - val_loss: 0.4413 - val_accuracy: 0.8607\n",
            "Epoch 241/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4426 - accuracy: 0.8571 - val_loss: 0.4410 - val_accuracy: 0.8562\n",
            "Epoch 242/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4423 - accuracy: 0.8575 - val_loss: 0.4400 - val_accuracy: 0.8595\n",
            "Epoch 243/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4419 - accuracy: 0.8573 - val_loss: 0.4401 - val_accuracy: 0.8608\n",
            "Epoch 244/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4416 - accuracy: 0.8577 - val_loss: 0.4395 - val_accuracy: 0.8594\n",
            "Epoch 245/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4414 - accuracy: 0.8576 - val_loss: 0.4392 - val_accuracy: 0.8599\n",
            "Epoch 246/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4410 - accuracy: 0.8581 - val_loss: 0.4388 - val_accuracy: 0.8598\n",
            "Epoch 247/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4408 - accuracy: 0.8578 - val_loss: 0.4388 - val_accuracy: 0.8593\n",
            "Epoch 248/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4404 - accuracy: 0.8577 - val_loss: 0.4382 - val_accuracy: 0.8591\n",
            "Epoch 249/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4401 - accuracy: 0.8581 - val_loss: 0.4379 - val_accuracy: 0.8603\n",
            "Epoch 250/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4398 - accuracy: 0.8576 - val_loss: 0.4380 - val_accuracy: 0.8610\n",
            "Epoch 251/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4396 - accuracy: 0.8577 - val_loss: 0.4373 - val_accuracy: 0.8603\n",
            "Epoch 252/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4393 - accuracy: 0.8579 - val_loss: 0.4372 - val_accuracy: 0.8601\n",
            "Epoch 253/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4390 - accuracy: 0.8579 - val_loss: 0.4371 - val_accuracy: 0.8575\n",
            "Epoch 254/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4387 - accuracy: 0.8581 - val_loss: 0.4367 - val_accuracy: 0.8610\n",
            "Epoch 255/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4383 - accuracy: 0.8584 - val_loss: 0.4362 - val_accuracy: 0.8596\n",
            "Epoch 256/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4381 - accuracy: 0.8582 - val_loss: 0.4359 - val_accuracy: 0.8601\n",
            "Epoch 257/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4379 - accuracy: 0.8583 - val_loss: 0.4356 - val_accuracy: 0.8595\n",
            "Epoch 258/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4375 - accuracy: 0.8582 - val_loss: 0.4353 - val_accuracy: 0.8611\n",
            "Epoch 259/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4372 - accuracy: 0.8580 - val_loss: 0.4353 - val_accuracy: 0.8615\n",
            "Epoch 260/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4370 - accuracy: 0.8585 - val_loss: 0.4348 - val_accuracy: 0.8609\n",
            "Epoch 261/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4367 - accuracy: 0.8586 - val_loss: 0.4344 - val_accuracy: 0.8610\n",
            "Epoch 262/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4364 - accuracy: 0.8582 - val_loss: 0.4344 - val_accuracy: 0.8605\n",
            "Epoch 263/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4361 - accuracy: 0.8585 - val_loss: 0.4339 - val_accuracy: 0.8606\n",
            "Epoch 264/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4358 - accuracy: 0.8587 - val_loss: 0.4335 - val_accuracy: 0.8606\n",
            "Epoch 265/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.8586 - val_loss: 0.4335 - val_accuracy: 0.8603\n",
            "Epoch 266/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4353 - accuracy: 0.8583 - val_loss: 0.4332 - val_accuracy: 0.8594\n",
            "Epoch 267/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4350 - accuracy: 0.8587 - val_loss: 0.4329 - val_accuracy: 0.8592\n",
            "Epoch 268/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4347 - accuracy: 0.8590 - val_loss: 0.4325 - val_accuracy: 0.8612\n",
            "Epoch 269/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4344 - accuracy: 0.8590 - val_loss: 0.4323 - val_accuracy: 0.8597\n",
            "Epoch 270/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4341 - accuracy: 0.8589 - val_loss: 0.4319 - val_accuracy: 0.8612\n",
            "Epoch 271/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4339 - accuracy: 0.8591 - val_loss: 0.4319 - val_accuracy: 0.8587\n",
            "Epoch 272/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4336 - accuracy: 0.8593 - val_loss: 0.4317 - val_accuracy: 0.8584\n",
            "Epoch 273/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4333 - accuracy: 0.8592 - val_loss: 0.4312 - val_accuracy: 0.8594\n",
            "Epoch 274/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4330 - accuracy: 0.8590 - val_loss: 0.4310 - val_accuracy: 0.8601\n",
            "Epoch 275/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4328 - accuracy: 0.8597 - val_loss: 0.4305 - val_accuracy: 0.8613\n",
            "Epoch 276/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4325 - accuracy: 0.8588 - val_loss: 0.4302 - val_accuracy: 0.8622\n",
            "Epoch 277/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4322 - accuracy: 0.8591 - val_loss: 0.4300 - val_accuracy: 0.8612\n",
            "Epoch 278/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4320 - accuracy: 0.8596 - val_loss: 0.4299 - val_accuracy: 0.8589\n",
            "Epoch 279/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4317 - accuracy: 0.8593 - val_loss: 0.4295 - val_accuracy: 0.8619\n",
            "Epoch 280/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4315 - accuracy: 0.8594 - val_loss: 0.4292 - val_accuracy: 0.8623\n",
            "Epoch 281/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4312 - accuracy: 0.8596 - val_loss: 0.4289 - val_accuracy: 0.8603\n",
            "Epoch 282/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4309 - accuracy: 0.8595 - val_loss: 0.4291 - val_accuracy: 0.8589\n",
            "Epoch 283/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4306 - accuracy: 0.8597 - val_loss: 0.4283 - val_accuracy: 0.8622\n",
            "Epoch 284/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4304 - accuracy: 0.8595 - val_loss: 0.4282 - val_accuracy: 0.8622\n",
            "Epoch 285/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4302 - accuracy: 0.8599 - val_loss: 0.4279 - val_accuracy: 0.8603\n",
            "Epoch 286/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4298 - accuracy: 0.8598 - val_loss: 0.4277 - val_accuracy: 0.8598\n",
            "Epoch 287/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4295 - accuracy: 0.8596 - val_loss: 0.4279 - val_accuracy: 0.8627\n",
            "Epoch 288/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4293 - accuracy: 0.8598 - val_loss: 0.4271 - val_accuracy: 0.8605\n",
            "Epoch 289/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4291 - accuracy: 0.8598 - val_loss: 0.4271 - val_accuracy: 0.8626\n",
            "Epoch 290/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4288 - accuracy: 0.8602 - val_loss: 0.4267 - val_accuracy: 0.8601\n",
            "Epoch 291/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4285 - accuracy: 0.8600 - val_loss: 0.4266 - val_accuracy: 0.8630\n",
            "Epoch 292/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4283 - accuracy: 0.8601 - val_loss: 0.4262 - val_accuracy: 0.8634\n",
            "Epoch 293/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4280 - accuracy: 0.8596 - val_loss: 0.4257 - val_accuracy: 0.8630\n",
            "Epoch 294/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4278 - accuracy: 0.8604 - val_loss: 0.4256 - val_accuracy: 0.8609\n",
            "Epoch 295/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4275 - accuracy: 0.8602 - val_loss: 0.4253 - val_accuracy: 0.8629\n",
            "Epoch 296/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4272 - accuracy: 0.8603 - val_loss: 0.4250 - val_accuracy: 0.8626\n",
            "Epoch 297/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4269 - accuracy: 0.8605 - val_loss: 0.4251 - val_accuracy: 0.8608\n",
            "Epoch 298/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4267 - accuracy: 0.8605 - val_loss: 0.4245 - val_accuracy: 0.8630\n",
            "Epoch 299/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4265 - accuracy: 0.8603 - val_loss: 0.4247 - val_accuracy: 0.8590\n",
            "Epoch 300/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4262 - accuracy: 0.8603 - val_loss: 0.4240 - val_accuracy: 0.8629\n",
            "Epoch 301/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4260 - accuracy: 0.8601 - val_loss: 0.4238 - val_accuracy: 0.8612\n",
            "Epoch 302/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4257 - accuracy: 0.8608 - val_loss: 0.4237 - val_accuracy: 0.8637\n",
            "Epoch 303/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4255 - accuracy: 0.8604 - val_loss: 0.4232 - val_accuracy: 0.8623\n",
            "Epoch 304/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4252 - accuracy: 0.8609 - val_loss: 0.4230 - val_accuracy: 0.8624\n",
            "Epoch 305/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4250 - accuracy: 0.8607 - val_loss: 0.4229 - val_accuracy: 0.8636\n",
            "Epoch 306/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4247 - accuracy: 0.8608 - val_loss: 0.4225 - val_accuracy: 0.8633\n",
            "Epoch 307/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4245 - accuracy: 0.8609 - val_loss: 0.4223 - val_accuracy: 0.8640\n",
            "Epoch 308/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4242 - accuracy: 0.8608 - val_loss: 0.4221 - val_accuracy: 0.8616\n",
            "Epoch 309/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4240 - accuracy: 0.8608 - val_loss: 0.4219 - val_accuracy: 0.8644\n",
            "Epoch 310/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4237 - accuracy: 0.8611 - val_loss: 0.4215 - val_accuracy: 0.8619\n",
            "Epoch 311/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4234 - accuracy: 0.8609 - val_loss: 0.4214 - val_accuracy: 0.8618\n",
            "Epoch 312/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4232 - accuracy: 0.8606 - val_loss: 0.4214 - val_accuracy: 0.8640\n",
            "Epoch 313/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4230 - accuracy: 0.8611 - val_loss: 0.4209 - val_accuracy: 0.8640\n",
            "Epoch 314/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4228 - accuracy: 0.8608 - val_loss: 0.4205 - val_accuracy: 0.8638\n",
            "Epoch 315/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4225 - accuracy: 0.8607 - val_loss: 0.4205 - val_accuracy: 0.8612\n",
            "Epoch 316/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4222 - accuracy: 0.8609 - val_loss: 0.4202 - val_accuracy: 0.8640\n",
            "Epoch 317/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4220 - accuracy: 0.8610 - val_loss: 0.4198 - val_accuracy: 0.8623\n",
            "Epoch 318/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4218 - accuracy: 0.8613 - val_loss: 0.4199 - val_accuracy: 0.8601\n",
            "Epoch 319/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4216 - accuracy: 0.8612 - val_loss: 0.4196 - val_accuracy: 0.8612\n",
            "Epoch 320/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4213 - accuracy: 0.8611 - val_loss: 0.4191 - val_accuracy: 0.8639\n",
            "Epoch 321/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4211 - accuracy: 0.8614 - val_loss: 0.4190 - val_accuracy: 0.8624\n",
            "Epoch 322/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4209 - accuracy: 0.8614 - val_loss: 0.4187 - val_accuracy: 0.8622\n",
            "Epoch 323/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4206 - accuracy: 0.8618 - val_loss: 0.4187 - val_accuracy: 0.8647\n",
            "Epoch 324/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4204 - accuracy: 0.8616 - val_loss: 0.4182 - val_accuracy: 0.8631\n",
            "Epoch 325/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4201 - accuracy: 0.8613 - val_loss: 0.4181 - val_accuracy: 0.8628\n",
            "Epoch 326/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4199 - accuracy: 0.8618 - val_loss: 0.4178 - val_accuracy: 0.8645\n",
            "Epoch 327/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4197 - accuracy: 0.8616 - val_loss: 0.4174 - val_accuracy: 0.8632\n",
            "Epoch 328/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4195 - accuracy: 0.8612 - val_loss: 0.4176 - val_accuracy: 0.8627\n",
            "Epoch 329/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4192 - accuracy: 0.8618 - val_loss: 0.4169 - val_accuracy: 0.8633\n",
            "Epoch 330/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4190 - accuracy: 0.8617 - val_loss: 0.4168 - val_accuracy: 0.8635\n",
            "Epoch 331/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4187 - accuracy: 0.8620 - val_loss: 0.4167 - val_accuracy: 0.8622\n",
            "Epoch 332/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4185 - accuracy: 0.8619 - val_loss: 0.4163 - val_accuracy: 0.8641\n",
            "Epoch 333/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4183 - accuracy: 0.8615 - val_loss: 0.4161 - val_accuracy: 0.8640\n",
            "Epoch 334/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4181 - accuracy: 0.8616 - val_loss: 0.4160 - val_accuracy: 0.8622\n",
            "Epoch 335/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4178 - accuracy: 0.8615 - val_loss: 0.4157 - val_accuracy: 0.8644\n",
            "Epoch 336/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4176 - accuracy: 0.8618 - val_loss: 0.4162 - val_accuracy: 0.8659\n",
            "Epoch 337/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4174 - accuracy: 0.8621 - val_loss: 0.4153 - val_accuracy: 0.8624\n",
            "Epoch 338/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4171 - accuracy: 0.8620 - val_loss: 0.4150 - val_accuracy: 0.8638\n",
            "Epoch 339/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4169 - accuracy: 0.8620 - val_loss: 0.4148 - val_accuracy: 0.8646\n",
            "Epoch 340/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4167 - accuracy: 0.8621 - val_loss: 0.4146 - val_accuracy: 0.8640\n",
            "Epoch 341/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4165 - accuracy: 0.8622 - val_loss: 0.4143 - val_accuracy: 0.8637\n",
            "Epoch 342/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4163 - accuracy: 0.8623 - val_loss: 0.4144 - val_accuracy: 0.8650\n",
            "Epoch 343/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4160 - accuracy: 0.8620 - val_loss: 0.4140 - val_accuracy: 0.8659\n",
            "Epoch 344/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4159 - accuracy: 0.8621 - val_loss: 0.4140 - val_accuracy: 0.8616\n",
            "Epoch 345/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4156 - accuracy: 0.8623 - val_loss: 0.4136 - val_accuracy: 0.8656\n",
            "Epoch 346/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4153 - accuracy: 0.8624 - val_loss: 0.4131 - val_accuracy: 0.8643\n",
            "Epoch 347/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4151 - accuracy: 0.8623 - val_loss: 0.4129 - val_accuracy: 0.8649\n",
            "Epoch 348/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4149 - accuracy: 0.8625 - val_loss: 0.4133 - val_accuracy: 0.8607\n",
            "Epoch 349/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4147 - accuracy: 0.8622 - val_loss: 0.4125 - val_accuracy: 0.8646\n",
            "Epoch 350/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4145 - accuracy: 0.8629 - val_loss: 0.4123 - val_accuracy: 0.8637\n",
            "Epoch 351/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4142 - accuracy: 0.8622 - val_loss: 0.4123 - val_accuracy: 0.8627\n",
            "Epoch 352/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4140 - accuracy: 0.8624 - val_loss: 0.4120 - val_accuracy: 0.8633\n",
            "Epoch 353/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4138 - accuracy: 0.8629 - val_loss: 0.4117 - val_accuracy: 0.8661\n",
            "Epoch 354/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4135 - accuracy: 0.8628 - val_loss: 0.4115 - val_accuracy: 0.8637\n",
            "Epoch 355/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4134 - accuracy: 0.8625 - val_loss: 0.4112 - val_accuracy: 0.8641\n",
            "Epoch 356/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4132 - accuracy: 0.8625 - val_loss: 0.4110 - val_accuracy: 0.8651\n",
            "Epoch 357/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4129 - accuracy: 0.8628 - val_loss: 0.4111 - val_accuracy: 0.8659\n",
            "Epoch 358/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4126 - accuracy: 0.8627 - val_loss: 0.4106 - val_accuracy: 0.8637\n",
            "Epoch 359/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4125 - accuracy: 0.8627 - val_loss: 0.4104 - val_accuracy: 0.8661\n",
            "Epoch 360/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4123 - accuracy: 0.8630 - val_loss: 0.4101 - val_accuracy: 0.8650\n",
            "Epoch 361/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4120 - accuracy: 0.8631 - val_loss: 0.4105 - val_accuracy: 0.8665\n",
            "Epoch 362/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4119 - accuracy: 0.8627 - val_loss: 0.4097 - val_accuracy: 0.8651\n",
            "Epoch 363/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4117 - accuracy: 0.8629 - val_loss: 0.4097 - val_accuracy: 0.8626\n",
            "Epoch 364/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4115 - accuracy: 0.8631 - val_loss: 0.4094 - val_accuracy: 0.8654\n",
            "Epoch 365/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4112 - accuracy: 0.8629 - val_loss: 0.4092 - val_accuracy: 0.8663\n",
            "Epoch 366/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4110 - accuracy: 0.8632 - val_loss: 0.4094 - val_accuracy: 0.8668\n",
            "Epoch 367/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4108 - accuracy: 0.8636 - val_loss: 0.4086 - val_accuracy: 0.8655\n",
            "Epoch 368/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4106 - accuracy: 0.8635 - val_loss: 0.4088 - val_accuracy: 0.8641\n",
            "Epoch 369/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4104 - accuracy: 0.8634 - val_loss: 0.4083 - val_accuracy: 0.8635\n",
            "Epoch 370/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4102 - accuracy: 0.8632 - val_loss: 0.4082 - val_accuracy: 0.8662\n",
            "Epoch 371/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4100 - accuracy: 0.8634 - val_loss: 0.4079 - val_accuracy: 0.8647\n",
            "Epoch 372/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4098 - accuracy: 0.8632 - val_loss: 0.4077 - val_accuracy: 0.8666\n",
            "Epoch 373/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4096 - accuracy: 0.8630 - val_loss: 0.4074 - val_accuracy: 0.8652\n",
            "Epoch 374/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4094 - accuracy: 0.8633 - val_loss: 0.4073 - val_accuracy: 0.8651\n",
            "Epoch 375/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4092 - accuracy: 0.8642 - val_loss: 0.4070 - val_accuracy: 0.8643\n",
            "Epoch 376/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4089 - accuracy: 0.8636 - val_loss: 0.4071 - val_accuracy: 0.8669\n",
            "Epoch 377/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4088 - accuracy: 0.8633 - val_loss: 0.4066 - val_accuracy: 0.8649\n",
            "Epoch 378/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4085 - accuracy: 0.8632 - val_loss: 0.4069 - val_accuracy: 0.8615\n",
            "Epoch 379/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4084 - accuracy: 0.8638 - val_loss: 0.4063 - val_accuracy: 0.8661\n",
            "Epoch 380/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4082 - accuracy: 0.8641 - val_loss: 0.4062 - val_accuracy: 0.8669\n",
            "Epoch 381/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4080 - accuracy: 0.8638 - val_loss: 0.4060 - val_accuracy: 0.8668\n",
            "Epoch 382/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4078 - accuracy: 0.8639 - val_loss: 0.4056 - val_accuracy: 0.8652\n",
            "Epoch 383/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4076 - accuracy: 0.8641 - val_loss: 0.4055 - val_accuracy: 0.8644\n",
            "Epoch 384/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4074 - accuracy: 0.8638 - val_loss: 0.4054 - val_accuracy: 0.8672\n",
            "Epoch 385/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4072 - accuracy: 0.8640 - val_loss: 0.4050 - val_accuracy: 0.8653\n",
            "Epoch 386/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4070 - accuracy: 0.8641 - val_loss: 0.4050 - val_accuracy: 0.8644\n",
            "Epoch 387/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4068 - accuracy: 0.8639 - val_loss: 0.4046 - val_accuracy: 0.8654\n",
            "Epoch 388/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4065 - accuracy: 0.8643 - val_loss: 0.4053 - val_accuracy: 0.8678\n",
            "Epoch 389/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4063 - accuracy: 0.8640 - val_loss: 0.4042 - val_accuracy: 0.8662\n",
            "Epoch 390/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4062 - accuracy: 0.8641 - val_loss: 0.4042 - val_accuracy: 0.8673\n",
            "Epoch 391/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4060 - accuracy: 0.8643 - val_loss: 0.4038 - val_accuracy: 0.8657\n",
            "Epoch 392/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4058 - accuracy: 0.8643 - val_loss: 0.4037 - val_accuracy: 0.8669\n",
            "Epoch 393/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4056 - accuracy: 0.8645 - val_loss: 0.4034 - val_accuracy: 0.8663\n",
            "Epoch 394/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4053 - accuracy: 0.8645 - val_loss: 0.4032 - val_accuracy: 0.8656\n",
            "Epoch 395/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4052 - accuracy: 0.8646 - val_loss: 0.4031 - val_accuracy: 0.8664\n",
            "Epoch 396/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4050 - accuracy: 0.8645 - val_loss: 0.4029 - val_accuracy: 0.8664\n",
            "Epoch 397/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4048 - accuracy: 0.8644 - val_loss: 0.4028 - val_accuracy: 0.8674\n",
            "Epoch 398/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4046 - accuracy: 0.8645 - val_loss: 0.4028 - val_accuracy: 0.8676\n",
            "Epoch 399/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4044 - accuracy: 0.8642 - val_loss: 0.4026 - val_accuracy: 0.8622\n",
            "Epoch 400/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4042 - accuracy: 0.8646 - val_loss: 0.4023 - val_accuracy: 0.8633\n",
            "Epoch 401/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4041 - accuracy: 0.8641 - val_loss: 0.4023 - val_accuracy: 0.8674\n",
            "Epoch 402/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4038 - accuracy: 0.8643 - val_loss: 0.4018 - val_accuracy: 0.8672\n",
            "Epoch 403/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4036 - accuracy: 0.8648 - val_loss: 0.4015 - val_accuracy: 0.8667\n",
            "Epoch 404/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4034 - accuracy: 0.8644 - val_loss: 0.4014 - val_accuracy: 0.8674\n",
            "Epoch 405/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4033 - accuracy: 0.8647 - val_loss: 0.4011 - val_accuracy: 0.8666\n",
            "Epoch 406/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4030 - accuracy: 0.8650 - val_loss: 0.4010 - val_accuracy: 0.8650\n",
            "Epoch 407/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.8646 - val_loss: 0.4007 - val_accuracy: 0.8666\n",
            "Epoch 408/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4027 - accuracy: 0.8651 - val_loss: 0.4008 - val_accuracy: 0.8655\n",
            "Epoch 409/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4025 - accuracy: 0.8647 - val_loss: 0.4004 - val_accuracy: 0.8666\n",
            "Epoch 410/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4023 - accuracy: 0.8647 - val_loss: 0.4002 - val_accuracy: 0.8661\n",
            "Epoch 411/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4021 - accuracy: 0.8651 - val_loss: 0.4000 - val_accuracy: 0.8666\n",
            "Epoch 412/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4019 - accuracy: 0.8652 - val_loss: 0.4000 - val_accuracy: 0.8673\n",
            "Epoch 413/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4018 - accuracy: 0.8649 - val_loss: 0.3997 - val_accuracy: 0.8673\n",
            "Epoch 414/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4016 - accuracy: 0.8652 - val_loss: 0.3995 - val_accuracy: 0.8668\n",
            "Epoch 415/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4014 - accuracy: 0.8653 - val_loss: 0.3993 - val_accuracy: 0.8668\n",
            "Epoch 416/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4012 - accuracy: 0.8649 - val_loss: 0.3993 - val_accuracy: 0.8637\n",
            "Epoch 417/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4010 - accuracy: 0.8651 - val_loss: 0.3989 - val_accuracy: 0.8668\n",
            "Epoch 418/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4008 - accuracy: 0.8650 - val_loss: 0.3988 - val_accuracy: 0.8645\n",
            "Epoch 419/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4006 - accuracy: 0.8648 - val_loss: 0.3990 - val_accuracy: 0.8680\n",
            "Epoch 420/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4004 - accuracy: 0.8658 - val_loss: 0.3985 - val_accuracy: 0.8676\n",
            "Epoch 421/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4003 - accuracy: 0.8652 - val_loss: 0.3983 - val_accuracy: 0.8681\n",
            "Epoch 422/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4001 - accuracy: 0.8654 - val_loss: 0.3980 - val_accuracy: 0.8670\n",
            "Epoch 423/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.4000 - accuracy: 0.8656 - val_loss: 0.3978 - val_accuracy: 0.8669\n",
            "Epoch 424/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3997 - accuracy: 0.8656 - val_loss: 0.3976 - val_accuracy: 0.8673\n",
            "Epoch 425/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3995 - accuracy: 0.8655 - val_loss: 0.3978 - val_accuracy: 0.8684\n",
            "Epoch 426/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3994 - accuracy: 0.8652 - val_loss: 0.3973 - val_accuracy: 0.8675\n",
            "Epoch 427/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3992 - accuracy: 0.8655 - val_loss: 0.3971 - val_accuracy: 0.8673\n",
            "Epoch 428/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3990 - accuracy: 0.8655 - val_loss: 0.3970 - val_accuracy: 0.8676\n",
            "Epoch 429/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3988 - accuracy: 0.8661 - val_loss: 0.3971 - val_accuracy: 0.8633\n",
            "Epoch 430/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3986 - accuracy: 0.8660 - val_loss: 0.3967 - val_accuracy: 0.8680\n",
            "Epoch 431/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3985 - accuracy: 0.8661 - val_loss: 0.3966 - val_accuracy: 0.8687\n",
            "Epoch 432/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3983 - accuracy: 0.8661 - val_loss: 0.3966 - val_accuracy: 0.8648\n",
            "Epoch 433/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3981 - accuracy: 0.8658 - val_loss: 0.3962 - val_accuracy: 0.8682\n",
            "Epoch 434/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3979 - accuracy: 0.8657 - val_loss: 0.3958 - val_accuracy: 0.8671\n",
            "Epoch 435/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3978 - accuracy: 0.8661 - val_loss: 0.3957 - val_accuracy: 0.8667\n",
            "Epoch 436/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3976 - accuracy: 0.8655 - val_loss: 0.3955 - val_accuracy: 0.8674\n",
            "Epoch 437/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3974 - accuracy: 0.8657 - val_loss: 0.3953 - val_accuracy: 0.8673\n",
            "Epoch 438/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3972 - accuracy: 0.8660 - val_loss: 0.3951 - val_accuracy: 0.8673\n",
            "Epoch 439/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3971 - accuracy: 0.8660 - val_loss: 0.3950 - val_accuracy: 0.8672\n",
            "Epoch 440/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3969 - accuracy: 0.8662 - val_loss: 0.3951 - val_accuracy: 0.8690\n",
            "Epoch 441/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3967 - accuracy: 0.8659 - val_loss: 0.3947 - val_accuracy: 0.8676\n",
            "Epoch 442/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3965 - accuracy: 0.8662 - val_loss: 0.3945 - val_accuracy: 0.8673\n",
            "Epoch 443/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3963 - accuracy: 0.8659 - val_loss: 0.3943 - val_accuracy: 0.8679\n",
            "Epoch 444/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3961 - accuracy: 0.8661 - val_loss: 0.3942 - val_accuracy: 0.8666\n",
            "Epoch 445/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3960 - accuracy: 0.8661 - val_loss: 0.3940 - val_accuracy: 0.8674\n",
            "Epoch 446/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3958 - accuracy: 0.8668 - val_loss: 0.3938 - val_accuracy: 0.8660\n",
            "Epoch 447/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3956 - accuracy: 0.8667 - val_loss: 0.3943 - val_accuracy: 0.8665\n",
            "Epoch 448/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3955 - accuracy: 0.8664 - val_loss: 0.3936 - val_accuracy: 0.8665\n",
            "Epoch 449/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3953 - accuracy: 0.8666 - val_loss: 0.3934 - val_accuracy: 0.8688\n",
            "Epoch 450/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3952 - accuracy: 0.8666 - val_loss: 0.3931 - val_accuracy: 0.8687\n",
            "Epoch 451/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3950 - accuracy: 0.8664 - val_loss: 0.3931 - val_accuracy: 0.8658\n",
            "Epoch 452/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3948 - accuracy: 0.8666 - val_loss: 0.3930 - val_accuracy: 0.8690\n",
            "Epoch 453/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8667 - val_loss: 0.3926 - val_accuracy: 0.8674\n",
            "Epoch 454/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3945 - accuracy: 0.8668 - val_loss: 0.3925 - val_accuracy: 0.8686\n",
            "Epoch 455/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3942 - accuracy: 0.8670 - val_loss: 0.3931 - val_accuracy: 0.8705\n",
            "Epoch 456/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3941 - accuracy: 0.8668 - val_loss: 0.3923 - val_accuracy: 0.8672\n",
            "Epoch 457/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3939 - accuracy: 0.8665 - val_loss: 0.3921 - val_accuracy: 0.8689\n",
            "Epoch 458/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3938 - accuracy: 0.8669 - val_loss: 0.3918 - val_accuracy: 0.8661\n",
            "Epoch 459/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3936 - accuracy: 0.8667 - val_loss: 0.3919 - val_accuracy: 0.8652\n",
            "Epoch 460/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3935 - accuracy: 0.8669 - val_loss: 0.3914 - val_accuracy: 0.8672\n",
            "Epoch 461/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3933 - accuracy: 0.8668 - val_loss: 0.3912 - val_accuracy: 0.8677\n",
            "Epoch 462/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3931 - accuracy: 0.8669 - val_loss: 0.3911 - val_accuracy: 0.8667\n",
            "Epoch 463/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3929 - accuracy: 0.8666 - val_loss: 0.3911 - val_accuracy: 0.8654\n",
            "Epoch 464/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3928 - accuracy: 0.8670 - val_loss: 0.3908 - val_accuracy: 0.8674\n",
            "Epoch 465/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3926 - accuracy: 0.8670 - val_loss: 0.3906 - val_accuracy: 0.8683\n",
            "Epoch 466/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3925 - accuracy: 0.8670 - val_loss: 0.3905 - val_accuracy: 0.8677\n",
            "Epoch 467/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3923 - accuracy: 0.8666 - val_loss: 0.3906 - val_accuracy: 0.8695\n",
            "Epoch 468/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3921 - accuracy: 0.8670 - val_loss: 0.3902 - val_accuracy: 0.8696\n",
            "Epoch 469/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3920 - accuracy: 0.8670 - val_loss: 0.3900 - val_accuracy: 0.8690\n",
            "Epoch 470/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3918 - accuracy: 0.8670 - val_loss: 0.3902 - val_accuracy: 0.8662\n",
            "Epoch 471/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3917 - accuracy: 0.8672 - val_loss: 0.3896 - val_accuracy: 0.8699\n",
            "Epoch 472/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3914 - accuracy: 0.8670 - val_loss: 0.3896 - val_accuracy: 0.8695\n",
            "Epoch 473/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3913 - accuracy: 0.8673 - val_loss: 0.3893 - val_accuracy: 0.8686\n",
            "Epoch 474/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3911 - accuracy: 0.8678 - val_loss: 0.3892 - val_accuracy: 0.8667\n",
            "Epoch 475/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3909 - accuracy: 0.8673 - val_loss: 0.3895 - val_accuracy: 0.8648\n",
            "Epoch 476/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3908 - accuracy: 0.8673 - val_loss: 0.3888 - val_accuracy: 0.8695\n",
            "Epoch 477/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3907 - accuracy: 0.8677 - val_loss: 0.3886 - val_accuracy: 0.8686\n",
            "Epoch 478/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3904 - accuracy: 0.8677 - val_loss: 0.3887 - val_accuracy: 0.8699\n",
            "Epoch 479/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3904 - accuracy: 0.8675 - val_loss: 0.3883 - val_accuracy: 0.8698\n",
            "Epoch 480/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3901 - accuracy: 0.8677 - val_loss: 0.3882 - val_accuracy: 0.8678\n",
            "Epoch 481/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3900 - accuracy: 0.8681 - val_loss: 0.3881 - val_accuracy: 0.8673\n",
            "Epoch 482/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3898 - accuracy: 0.8673 - val_loss: 0.3879 - val_accuracy: 0.8700\n",
            "Epoch 483/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3897 - accuracy: 0.8679 - val_loss: 0.3878 - val_accuracy: 0.8700\n",
            "Epoch 484/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3895 - accuracy: 0.8676 - val_loss: 0.3875 - val_accuracy: 0.8701\n",
            "Epoch 485/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3893 - accuracy: 0.8679 - val_loss: 0.3874 - val_accuracy: 0.8701\n",
            "Epoch 486/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3892 - accuracy: 0.8677 - val_loss: 0.3873 - val_accuracy: 0.8680\n",
            "Epoch 487/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3891 - accuracy: 0.8683 - val_loss: 0.3871 - val_accuracy: 0.8691\n",
            "Epoch 488/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3889 - accuracy: 0.8681 - val_loss: 0.3873 - val_accuracy: 0.8658\n",
            "Epoch 489/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3887 - accuracy: 0.8676 - val_loss: 0.3873 - val_accuracy: 0.8706\n",
            "Epoch 490/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3886 - accuracy: 0.8679 - val_loss: 0.3866 - val_accuracy: 0.8698\n",
            "Epoch 491/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3884 - accuracy: 0.8684 - val_loss: 0.3865 - val_accuracy: 0.8709\n",
            "Epoch 492/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3882 - accuracy: 0.8683 - val_loss: 0.3864 - val_accuracy: 0.8710\n",
            "Epoch 493/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3881 - accuracy: 0.8680 - val_loss: 0.3864 - val_accuracy: 0.8706\n",
            "Epoch 494/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3878 - accuracy: 0.8683 - val_loss: 0.3867 - val_accuracy: 0.8712\n",
            "Epoch 495/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3878 - accuracy: 0.8684 - val_loss: 0.3860 - val_accuracy: 0.8703\n",
            "Epoch 496/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3876 - accuracy: 0.8683 - val_loss: 0.3858 - val_accuracy: 0.8700\n",
            "Epoch 497/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3874 - accuracy: 0.8690 - val_loss: 0.3858 - val_accuracy: 0.8712\n",
            "Epoch 498/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3873 - accuracy: 0.8685 - val_loss: 0.3856 - val_accuracy: 0.8712\n",
            "Epoch 499/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3872 - accuracy: 0.8684 - val_loss: 0.3855 - val_accuracy: 0.8710\n",
            "Epoch 500/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3870 - accuracy: 0.8684 - val_loss: 0.3852 - val_accuracy: 0.8710\n",
            "Epoch 501/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3869 - accuracy: 0.8686 - val_loss: 0.3849 - val_accuracy: 0.8709\n",
            "Epoch 502/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3867 - accuracy: 0.8684 - val_loss: 0.3847 - val_accuracy: 0.8702\n",
            "Epoch 503/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3866 - accuracy: 0.8686 - val_loss: 0.3847 - val_accuracy: 0.8679\n",
            "Epoch 504/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3864 - accuracy: 0.8687 - val_loss: 0.3846 - val_accuracy: 0.8709\n",
            "Epoch 505/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3863 - accuracy: 0.8685 - val_loss: 0.3844 - val_accuracy: 0.8702\n",
            "Epoch 506/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3861 - accuracy: 0.8684 - val_loss: 0.3843 - val_accuracy: 0.8712\n",
            "Epoch 507/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3859 - accuracy: 0.8691 - val_loss: 0.3840 - val_accuracy: 0.8704\n",
            "Epoch 508/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3858 - accuracy: 0.8688 - val_loss: 0.3840 - val_accuracy: 0.8710\n",
            "Epoch 509/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3856 - accuracy: 0.8690 - val_loss: 0.3839 - val_accuracy: 0.8681\n",
            "Epoch 510/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3855 - accuracy: 0.8689 - val_loss: 0.3835 - val_accuracy: 0.8698\n",
            "Epoch 511/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3853 - accuracy: 0.8693 - val_loss: 0.3835 - val_accuracy: 0.8694\n",
            "Epoch 512/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3852 - accuracy: 0.8691 - val_loss: 0.3834 - val_accuracy: 0.8708\n",
            "Epoch 513/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3850 - accuracy: 0.8690 - val_loss: 0.3833 - val_accuracy: 0.8692\n",
            "Epoch 514/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3849 - accuracy: 0.8690 - val_loss: 0.3832 - val_accuracy: 0.8717\n",
            "Epoch 515/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3848 - accuracy: 0.8695 - val_loss: 0.3829 - val_accuracy: 0.8695\n",
            "Epoch 516/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3846 - accuracy: 0.8690 - val_loss: 0.3828 - val_accuracy: 0.8716\n",
            "Epoch 517/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3845 - accuracy: 0.8690 - val_loss: 0.3828 - val_accuracy: 0.8717\n",
            "Epoch 518/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3843 - accuracy: 0.8694 - val_loss: 0.3824 - val_accuracy: 0.8713\n",
            "Epoch 519/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3842 - accuracy: 0.8696 - val_loss: 0.3822 - val_accuracy: 0.8710\n",
            "Epoch 520/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3840 - accuracy: 0.8693 - val_loss: 0.3822 - val_accuracy: 0.8717\n",
            "Epoch 521/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3838 - accuracy: 0.8698 - val_loss: 0.3821 - val_accuracy: 0.8694\n",
            "Epoch 522/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3837 - accuracy: 0.8696 - val_loss: 0.3821 - val_accuracy: 0.8679\n",
            "Epoch 523/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3836 - accuracy: 0.8692 - val_loss: 0.3818 - val_accuracy: 0.8703\n",
            "Epoch 524/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3834 - accuracy: 0.8696 - val_loss: 0.3816 - val_accuracy: 0.8699\n",
            "Epoch 525/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3832 - accuracy: 0.8695 - val_loss: 0.3817 - val_accuracy: 0.8724\n",
            "Epoch 526/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3831 - accuracy: 0.8697 - val_loss: 0.3814 - val_accuracy: 0.8701\n",
            "Epoch 527/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3830 - accuracy: 0.8698 - val_loss: 0.3811 - val_accuracy: 0.8716\n",
            "Epoch 528/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3828 - accuracy: 0.8697 - val_loss: 0.3810 - val_accuracy: 0.8712\n",
            "Epoch 529/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3826 - accuracy: 0.8699 - val_loss: 0.3811 - val_accuracy: 0.8717\n",
            "Epoch 530/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3826 - accuracy: 0.8700 - val_loss: 0.3807 - val_accuracy: 0.8720\n",
            "Epoch 531/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3823 - accuracy: 0.8700 - val_loss: 0.3806 - val_accuracy: 0.8711\n",
            "Epoch 532/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3822 - accuracy: 0.8698 - val_loss: 0.3811 - val_accuracy: 0.8728\n",
            "Epoch 533/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3821 - accuracy: 0.8701 - val_loss: 0.3802 - val_accuracy: 0.8719\n",
            "Epoch 534/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3820 - accuracy: 0.8702 - val_loss: 0.3801 - val_accuracy: 0.8717\n",
            "Epoch 535/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3818 - accuracy: 0.8702 - val_loss: 0.3802 - val_accuracy: 0.8684\n",
            "Epoch 536/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3816 - accuracy: 0.8699 - val_loss: 0.3798 - val_accuracy: 0.8717\n",
            "Epoch 537/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3815 - accuracy: 0.8700 - val_loss: 0.3796 - val_accuracy: 0.8711\n",
            "Epoch 538/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3814 - accuracy: 0.8707 - val_loss: 0.3795 - val_accuracy: 0.8712\n",
            "Epoch 539/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3812 - accuracy: 0.8701 - val_loss: 0.3794 - val_accuracy: 0.8708\n",
            "Epoch 540/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3811 - accuracy: 0.8702 - val_loss: 0.3792 - val_accuracy: 0.8719\n",
            "Epoch 541/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3810 - accuracy: 0.8705 - val_loss: 0.3792 - val_accuracy: 0.8720\n",
            "Epoch 542/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3808 - accuracy: 0.8702 - val_loss: 0.3793 - val_accuracy: 0.8706\n",
            "Epoch 543/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3807 - accuracy: 0.8703 - val_loss: 0.3789 - val_accuracy: 0.8725\n",
            "Epoch 544/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3805 - accuracy: 0.8709 - val_loss: 0.3789 - val_accuracy: 0.8722\n",
            "Epoch 545/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3804 - accuracy: 0.8702 - val_loss: 0.3786 - val_accuracy: 0.8723\n",
            "Epoch 546/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3803 - accuracy: 0.8708 - val_loss: 0.3790 - val_accuracy: 0.8680\n",
            "Epoch 547/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3801 - accuracy: 0.8705 - val_loss: 0.3783 - val_accuracy: 0.8723\n",
            "Epoch 548/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3800 - accuracy: 0.8705 - val_loss: 0.3782 - val_accuracy: 0.8702\n",
            "Epoch 549/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3798 - accuracy: 0.8706 - val_loss: 0.3780 - val_accuracy: 0.8716\n",
            "Epoch 550/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3797 - accuracy: 0.8702 - val_loss: 0.3784 - val_accuracy: 0.8734\n",
            "Epoch 551/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3796 - accuracy: 0.8706 - val_loss: 0.3779 - val_accuracy: 0.8734\n",
            "Epoch 552/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3794 - accuracy: 0.8707 - val_loss: 0.3776 - val_accuracy: 0.8712\n",
            "Epoch 553/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3792 - accuracy: 0.8708 - val_loss: 0.3777 - val_accuracy: 0.8732\n",
            "Epoch 554/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3792 - accuracy: 0.8707 - val_loss: 0.3774 - val_accuracy: 0.8730\n",
            "Epoch 555/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3790 - accuracy: 0.8709 - val_loss: 0.3774 - val_accuracy: 0.8711\n",
            "Epoch 556/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3789 - accuracy: 0.8710 - val_loss: 0.3771 - val_accuracy: 0.8716\n",
            "Epoch 557/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3788 - accuracy: 0.8708 - val_loss: 0.3769 - val_accuracy: 0.8727\n",
            "Epoch 558/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3786 - accuracy: 0.8709 - val_loss: 0.3775 - val_accuracy: 0.8734\n",
            "Epoch 559/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3785 - accuracy: 0.8709 - val_loss: 0.3766 - val_accuracy: 0.8727\n",
            "Epoch 560/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3783 - accuracy: 0.8714 - val_loss: 0.3765 - val_accuracy: 0.8719\n",
            "Epoch 561/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3782 - accuracy: 0.8711 - val_loss: 0.3763 - val_accuracy: 0.8727\n",
            "Epoch 562/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3780 - accuracy: 0.8715 - val_loss: 0.3764 - val_accuracy: 0.8738\n",
            "Epoch 563/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8715 - val_loss: 0.3765 - val_accuracy: 0.8698\n",
            "Epoch 564/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3778 - accuracy: 0.8713 - val_loss: 0.3760 - val_accuracy: 0.8737\n",
            "Epoch 565/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3776 - accuracy: 0.8712 - val_loss: 0.3758 - val_accuracy: 0.8726\n",
            "Epoch 566/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3775 - accuracy: 0.8710 - val_loss: 0.3759 - val_accuracy: 0.8734\n",
            "Epoch 567/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3774 - accuracy: 0.8714 - val_loss: 0.3761 - val_accuracy: 0.8737\n",
            "Epoch 568/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3772 - accuracy: 0.8717 - val_loss: 0.3755 - val_accuracy: 0.8730\n",
            "Epoch 569/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8717 - val_loss: 0.3753 - val_accuracy: 0.8734\n",
            "Epoch 570/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3769 - accuracy: 0.8716 - val_loss: 0.3764 - val_accuracy: 0.8676\n",
            "Epoch 571/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3769 - accuracy: 0.8720 - val_loss: 0.3750 - val_accuracy: 0.8735\n",
            "Epoch 572/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3767 - accuracy: 0.8716 - val_loss: 0.3752 - val_accuracy: 0.8734\n",
            "Epoch 573/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3766 - accuracy: 0.8718 - val_loss: 0.3748 - val_accuracy: 0.8722\n",
            "Epoch 574/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3764 - accuracy: 0.8717 - val_loss: 0.3751 - val_accuracy: 0.8739\n",
            "Epoch 575/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3763 - accuracy: 0.8719 - val_loss: 0.3746 - val_accuracy: 0.8706\n",
            "Epoch 576/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3761 - accuracy: 0.8717 - val_loss: 0.3748 - val_accuracy: 0.8744\n",
            "Epoch 577/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3760 - accuracy: 0.8716 - val_loss: 0.3745 - val_accuracy: 0.8737\n",
            "Epoch 578/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3759 - accuracy: 0.8716 - val_loss: 0.3743 - val_accuracy: 0.8726\n",
            "Epoch 579/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3757 - accuracy: 0.8721 - val_loss: 0.3741 - val_accuracy: 0.8710\n",
            "Epoch 580/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3756 - accuracy: 0.8716 - val_loss: 0.3739 - val_accuracy: 0.8737\n",
            "Epoch 581/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3755 - accuracy: 0.8723 - val_loss: 0.3748 - val_accuracy: 0.8747\n",
            "Epoch 582/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3754 - accuracy: 0.8719 - val_loss: 0.3738 - val_accuracy: 0.8742\n",
            "Epoch 583/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3753 - accuracy: 0.8715 - val_loss: 0.3736 - val_accuracy: 0.8738\n",
            "Epoch 584/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8721 - val_loss: 0.3733 - val_accuracy: 0.8742\n",
            "Epoch 585/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3750 - accuracy: 0.8725 - val_loss: 0.3733 - val_accuracy: 0.8719\n",
            "Epoch 586/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3749 - accuracy: 0.8722 - val_loss: 0.3732 - val_accuracy: 0.8739\n",
            "Epoch 587/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3747 - accuracy: 0.8724 - val_loss: 0.3731 - val_accuracy: 0.8747\n",
            "Epoch 588/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3746 - accuracy: 0.8719 - val_loss: 0.3731 - val_accuracy: 0.8745\n",
            "Epoch 589/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3745 - accuracy: 0.8724 - val_loss: 0.3728 - val_accuracy: 0.8742\n",
            "Epoch 590/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3744 - accuracy: 0.8719 - val_loss: 0.3728 - val_accuracy: 0.8746\n",
            "Epoch 591/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3742 - accuracy: 0.8725 - val_loss: 0.3728 - val_accuracy: 0.8722\n",
            "Epoch 592/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3741 - accuracy: 0.8722 - val_loss: 0.3724 - val_accuracy: 0.8713\n",
            "Epoch 593/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3739 - accuracy: 0.8727 - val_loss: 0.3726 - val_accuracy: 0.8738\n",
            "Epoch 594/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.8730 - val_loss: 0.3721 - val_accuracy: 0.8745\n",
            "Epoch 595/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.8724 - val_loss: 0.3722 - val_accuracy: 0.8751\n",
            "Epoch 596/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3736 - accuracy: 0.8728 - val_loss: 0.3718 - val_accuracy: 0.8740\n",
            "Epoch 597/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3734 - accuracy: 0.8728 - val_loss: 0.3717 - val_accuracy: 0.8737\n",
            "Epoch 598/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3733 - accuracy: 0.8729 - val_loss: 0.3718 - val_accuracy: 0.8717\n",
            "Epoch 599/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3732 - accuracy: 0.8728 - val_loss: 0.3714 - val_accuracy: 0.8730\n",
            "Epoch 600/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3730 - accuracy: 0.8727 - val_loss: 0.3713 - val_accuracy: 0.8742\n",
            "Epoch 601/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3729 - accuracy: 0.8734 - val_loss: 0.3713 - val_accuracy: 0.8741\n",
            "Epoch 602/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3728 - accuracy: 0.8733 - val_loss: 0.3710 - val_accuracy: 0.8736\n",
            "Epoch 603/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3726 - accuracy: 0.8729 - val_loss: 0.3709 - val_accuracy: 0.8731\n",
            "Epoch 604/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3726 - accuracy: 0.8732 - val_loss: 0.3708 - val_accuracy: 0.8745\n",
            "Epoch 605/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3725 - accuracy: 0.8730 - val_loss: 0.3707 - val_accuracy: 0.8743\n",
            "Epoch 606/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3723 - accuracy: 0.8733 - val_loss: 0.3706 - val_accuracy: 0.8730\n",
            "Epoch 607/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3722 - accuracy: 0.8730 - val_loss: 0.3705 - val_accuracy: 0.8734\n",
            "Epoch 608/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3720 - accuracy: 0.8730 - val_loss: 0.3706 - val_accuracy: 0.8742\n",
            "Epoch 609/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3719 - accuracy: 0.8731 - val_loss: 0.3703 - val_accuracy: 0.8749\n",
            "Epoch 610/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3718 - accuracy: 0.8729 - val_loss: 0.3707 - val_accuracy: 0.8758\n",
            "Epoch 611/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3717 - accuracy: 0.8735 - val_loss: 0.3700 - val_accuracy: 0.8725\n",
            "Epoch 612/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3716 - accuracy: 0.8732 - val_loss: 0.3699 - val_accuracy: 0.8727\n",
            "Epoch 613/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3714 - accuracy: 0.8733 - val_loss: 0.3698 - val_accuracy: 0.8752\n",
            "Epoch 614/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3713 - accuracy: 0.8735 - val_loss: 0.3696 - val_accuracy: 0.8727\n",
            "Epoch 615/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3712 - accuracy: 0.8729 - val_loss: 0.3696 - val_accuracy: 0.8750\n",
            "Epoch 616/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3711 - accuracy: 0.8740 - val_loss: 0.3694 - val_accuracy: 0.8734\n",
            "Epoch 617/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3709 - accuracy: 0.8735 - val_loss: 0.3694 - val_accuracy: 0.8756\n",
            "Epoch 618/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3708 - accuracy: 0.8736 - val_loss: 0.3692 - val_accuracy: 0.8745\n",
            "Epoch 619/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3707 - accuracy: 0.8735 - val_loss: 0.3690 - val_accuracy: 0.8752\n",
            "Epoch 620/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3705 - accuracy: 0.8735 - val_loss: 0.3696 - val_accuracy: 0.8763\n",
            "Epoch 621/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3705 - accuracy: 0.8737 - val_loss: 0.3688 - val_accuracy: 0.8744\n",
            "Epoch 622/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3703 - accuracy: 0.8738 - val_loss: 0.3692 - val_accuracy: 0.8756\n",
            "Epoch 623/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3702 - accuracy: 0.8738 - val_loss: 0.3687 - val_accuracy: 0.8724\n",
            "Epoch 624/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3701 - accuracy: 0.8737 - val_loss: 0.3685 - val_accuracy: 0.8758\n",
            "Epoch 625/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3700 - accuracy: 0.8741 - val_loss: 0.3683 - val_accuracy: 0.8756\n",
            "Epoch 626/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3699 - accuracy: 0.8740 - val_loss: 0.3682 - val_accuracy: 0.8760\n",
            "Epoch 627/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3697 - accuracy: 0.8739 - val_loss: 0.3681 - val_accuracy: 0.8761\n",
            "Epoch 628/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3696 - accuracy: 0.8741 - val_loss: 0.3679 - val_accuracy: 0.8752\n",
            "Epoch 629/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3695 - accuracy: 0.8739 - val_loss: 0.3681 - val_accuracy: 0.8764\n",
            "Epoch 630/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3694 - accuracy: 0.8740 - val_loss: 0.3678 - val_accuracy: 0.8759\n",
            "Epoch 631/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3693 - accuracy: 0.8744 - val_loss: 0.3678 - val_accuracy: 0.8731\n",
            "Epoch 632/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3691 - accuracy: 0.8744 - val_loss: 0.3676 - val_accuracy: 0.8759\n",
            "Epoch 633/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3690 - accuracy: 0.8743 - val_loss: 0.3676 - val_accuracy: 0.8765\n",
            "Epoch 634/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3689 - accuracy: 0.8740 - val_loss: 0.3675 - val_accuracy: 0.8756\n",
            "Epoch 635/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3688 - accuracy: 0.8746 - val_loss: 0.3671 - val_accuracy: 0.8745\n",
            "Epoch 636/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3687 - accuracy: 0.8746 - val_loss: 0.3671 - val_accuracy: 0.8742\n",
            "Epoch 637/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3686 - accuracy: 0.8743 - val_loss: 0.3668 - val_accuracy: 0.8752\n",
            "Epoch 638/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3684 - accuracy: 0.8743 - val_loss: 0.3670 - val_accuracy: 0.8764\n",
            "Epoch 639/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3683 - accuracy: 0.8746 - val_loss: 0.3669 - val_accuracy: 0.8727\n",
            "Epoch 640/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3682 - accuracy: 0.8745 - val_loss: 0.3666 - val_accuracy: 0.8748\n",
            "Epoch 641/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3681 - accuracy: 0.8747 - val_loss: 0.3668 - val_accuracy: 0.8727\n",
            "Epoch 642/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3679 - accuracy: 0.8744 - val_loss: 0.3665 - val_accuracy: 0.8766\n",
            "Epoch 643/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3679 - accuracy: 0.8748 - val_loss: 0.3663 - val_accuracy: 0.8748\n",
            "Epoch 644/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3677 - accuracy: 0.8750 - val_loss: 0.3661 - val_accuracy: 0.8762\n",
            "Epoch 645/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3676 - accuracy: 0.8748 - val_loss: 0.3660 - val_accuracy: 0.8753\n",
            "Epoch 646/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3675 - accuracy: 0.8750 - val_loss: 0.3659 - val_accuracy: 0.8763\n",
            "Epoch 647/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3673 - accuracy: 0.8750 - val_loss: 0.3657 - val_accuracy: 0.8749\n",
            "Epoch 648/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3672 - accuracy: 0.8748 - val_loss: 0.3656 - val_accuracy: 0.8742\n",
            "Epoch 649/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3672 - accuracy: 0.8751 - val_loss: 0.3657 - val_accuracy: 0.8763\n",
            "Epoch 650/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3670 - accuracy: 0.8748 - val_loss: 0.3654 - val_accuracy: 0.8763\n",
            "Epoch 651/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3669 - accuracy: 0.8751 - val_loss: 0.3657 - val_accuracy: 0.8777\n",
            "Epoch 652/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3668 - accuracy: 0.8749 - val_loss: 0.3652 - val_accuracy: 0.8762\n",
            "Epoch 653/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3667 - accuracy: 0.8751 - val_loss: 0.3650 - val_accuracy: 0.8754\n",
            "Epoch 654/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3665 - accuracy: 0.8752 - val_loss: 0.3652 - val_accuracy: 0.8771\n",
            "Epoch 655/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3665 - accuracy: 0.8751 - val_loss: 0.3651 - val_accuracy: 0.8777\n",
            "Epoch 656/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3663 - accuracy: 0.8757 - val_loss: 0.3647 - val_accuracy: 0.8752\n",
            "Epoch 657/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3663 - accuracy: 0.8752 - val_loss: 0.3646 - val_accuracy: 0.8746\n",
            "Epoch 658/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3661 - accuracy: 0.8752 - val_loss: 0.3657 - val_accuracy: 0.8711\n",
            "Epoch 659/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3660 - accuracy: 0.8756 - val_loss: 0.3645 - val_accuracy: 0.8773\n",
            "Epoch 660/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3659 - accuracy: 0.8753 - val_loss: 0.3643 - val_accuracy: 0.8746\n",
            "Epoch 661/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3658 - accuracy: 0.8756 - val_loss: 0.3643 - val_accuracy: 0.8773\n",
            "Epoch 662/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3657 - accuracy: 0.8757 - val_loss: 0.3640 - val_accuracy: 0.8766\n",
            "Epoch 663/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3655 - accuracy: 0.8753 - val_loss: 0.3642 - val_accuracy: 0.8777\n",
            "Epoch 664/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3654 - accuracy: 0.8753 - val_loss: 0.3638 - val_accuracy: 0.8752\n",
            "Epoch 665/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3653 - accuracy: 0.8755 - val_loss: 0.3637 - val_accuracy: 0.8765\n",
            "Epoch 666/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3652 - accuracy: 0.8757 - val_loss: 0.3638 - val_accuracy: 0.8741\n",
            "Epoch 667/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3651 - accuracy: 0.8756 - val_loss: 0.3640 - val_accuracy: 0.8784\n",
            "Epoch 668/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3650 - accuracy: 0.8759 - val_loss: 0.3634 - val_accuracy: 0.8774\n",
            "Epoch 669/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3649 - accuracy: 0.8758 - val_loss: 0.3633 - val_accuracy: 0.8771\n",
            "Epoch 670/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3648 - accuracy: 0.8757 - val_loss: 0.3633 - val_accuracy: 0.8749\n",
            "Epoch 671/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3647 - accuracy: 0.8759 - val_loss: 0.3630 - val_accuracy: 0.8755\n",
            "Epoch 672/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3645 - accuracy: 0.8763 - val_loss: 0.3629 - val_accuracy: 0.8766\n",
            "Epoch 673/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3644 - accuracy: 0.8759 - val_loss: 0.3631 - val_accuracy: 0.8783\n",
            "Epoch 674/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3643 - accuracy: 0.8762 - val_loss: 0.3628 - val_accuracy: 0.8778\n",
            "Epoch 675/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3642 - accuracy: 0.8760 - val_loss: 0.3627 - val_accuracy: 0.8780\n",
            "Epoch 676/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3641 - accuracy: 0.8765 - val_loss: 0.3626 - val_accuracy: 0.8779\n",
            "Epoch 677/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3640 - accuracy: 0.8759 - val_loss: 0.3628 - val_accuracy: 0.8788\n",
            "Epoch 678/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3638 - accuracy: 0.8762 - val_loss: 0.3624 - val_accuracy: 0.8778\n",
            "Epoch 679/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3637 - accuracy: 0.8764 - val_loss: 0.3626 - val_accuracy: 0.8737\n",
            "Epoch 680/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3637 - accuracy: 0.8764 - val_loss: 0.3622 - val_accuracy: 0.8748\n",
            "Epoch 681/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3635 - accuracy: 0.8760 - val_loss: 0.3622 - val_accuracy: 0.8778\n",
            "Epoch 682/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3634 - accuracy: 0.8765 - val_loss: 0.3619 - val_accuracy: 0.8752\n",
            "Epoch 683/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3633 - accuracy: 0.8764 - val_loss: 0.3618 - val_accuracy: 0.8755\n",
            "Epoch 684/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3632 - accuracy: 0.8761 - val_loss: 0.3616 - val_accuracy: 0.8771\n",
            "Epoch 685/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3630 - accuracy: 0.8764 - val_loss: 0.3616 - val_accuracy: 0.8776\n",
            "Epoch 686/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3630 - accuracy: 0.8767 - val_loss: 0.3615 - val_accuracy: 0.8784\n",
            "Epoch 687/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3629 - accuracy: 0.8765 - val_loss: 0.3615 - val_accuracy: 0.8788\n",
            "Epoch 688/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3628 - accuracy: 0.8765 - val_loss: 0.3612 - val_accuracy: 0.8758\n",
            "Epoch 689/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3627 - accuracy: 0.8764 - val_loss: 0.3611 - val_accuracy: 0.8780\n",
            "Epoch 690/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3626 - accuracy: 0.8768 - val_loss: 0.3610 - val_accuracy: 0.8783\n",
            "Epoch 691/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3625 - accuracy: 0.8767 - val_loss: 0.3609 - val_accuracy: 0.8784\n",
            "Epoch 692/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3623 - accuracy: 0.8769 - val_loss: 0.3608 - val_accuracy: 0.8768\n",
            "Epoch 693/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3623 - accuracy: 0.8769 - val_loss: 0.3608 - val_accuracy: 0.8773\n",
            "Epoch 694/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3622 - accuracy: 0.8770 - val_loss: 0.3606 - val_accuracy: 0.8772\n",
            "Epoch 695/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3621 - accuracy: 0.8769 - val_loss: 0.3605 - val_accuracy: 0.8777\n",
            "Epoch 696/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3619 - accuracy: 0.8769 - val_loss: 0.3603 - val_accuracy: 0.8778\n",
            "Epoch 697/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3619 - accuracy: 0.8771 - val_loss: 0.3606 - val_accuracy: 0.8798\n",
            "Epoch 698/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3618 - accuracy: 0.8770 - val_loss: 0.3602 - val_accuracy: 0.8785\n",
            "Epoch 699/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3616 - accuracy: 0.8770 - val_loss: 0.3601 - val_accuracy: 0.8789\n",
            "Epoch 700/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3615 - accuracy: 0.8770 - val_loss: 0.3599 - val_accuracy: 0.8786\n",
            "Epoch 701/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3615 - accuracy: 0.8773 - val_loss: 0.3598 - val_accuracy: 0.8781\n",
            "Epoch 702/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3613 - accuracy: 0.8772 - val_loss: 0.3597 - val_accuracy: 0.8787\n",
            "Epoch 703/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3612 - accuracy: 0.8773 - val_loss: 0.3599 - val_accuracy: 0.8796\n",
            "Epoch 704/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3611 - accuracy: 0.8773 - val_loss: 0.3595 - val_accuracy: 0.8784\n",
            "Epoch 705/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3610 - accuracy: 0.8775 - val_loss: 0.3594 - val_accuracy: 0.8786\n",
            "Epoch 706/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3609 - accuracy: 0.8772 - val_loss: 0.3596 - val_accuracy: 0.8791\n",
            "Epoch 707/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3608 - accuracy: 0.8774 - val_loss: 0.3592 - val_accuracy: 0.8771\n",
            "Epoch 708/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3607 - accuracy: 0.8774 - val_loss: 0.3595 - val_accuracy: 0.8780\n",
            "Epoch 709/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3606 - accuracy: 0.8777 - val_loss: 0.3591 - val_accuracy: 0.8795\n",
            "Epoch 710/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3604 - accuracy: 0.8779 - val_loss: 0.3590 - val_accuracy: 0.8789\n",
            "Epoch 711/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3603 - accuracy: 0.8776 - val_loss: 0.3595 - val_accuracy: 0.8810\n",
            "Epoch 712/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3603 - accuracy: 0.8776 - val_loss: 0.3589 - val_accuracy: 0.8799\n",
            "Epoch 713/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3602 - accuracy: 0.8777 - val_loss: 0.3587 - val_accuracy: 0.8791\n",
            "Epoch 714/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3601 - accuracy: 0.8779 - val_loss: 0.3585 - val_accuracy: 0.8787\n",
            "Epoch 715/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3599 - accuracy: 0.8775 - val_loss: 0.3585 - val_accuracy: 0.8791\n",
            "Epoch 716/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3598 - accuracy: 0.8781 - val_loss: 0.3585 - val_accuracy: 0.8786\n",
            "Epoch 717/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3598 - accuracy: 0.8781 - val_loss: 0.3582 - val_accuracy: 0.8788\n",
            "Epoch 718/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3597 - accuracy: 0.8782 - val_loss: 0.3581 - val_accuracy: 0.8785\n",
            "Epoch 719/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3595 - accuracy: 0.8782 - val_loss: 0.3580 - val_accuracy: 0.8786\n",
            "Epoch 720/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3595 - accuracy: 0.8782 - val_loss: 0.3583 - val_accuracy: 0.8809\n",
            "Epoch 721/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3594 - accuracy: 0.8779 - val_loss: 0.3578 - val_accuracy: 0.8792\n",
            "Epoch 722/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3592 - accuracy: 0.8780 - val_loss: 0.3579 - val_accuracy: 0.8805\n",
            "Epoch 723/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3591 - accuracy: 0.8780 - val_loss: 0.3576 - val_accuracy: 0.8788\n",
            "Epoch 724/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3591 - accuracy: 0.8780 - val_loss: 0.3575 - val_accuracy: 0.8789\n",
            "Epoch 725/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3589 - accuracy: 0.8779 - val_loss: 0.3575 - val_accuracy: 0.8802\n",
            "Epoch 726/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3589 - accuracy: 0.8785 - val_loss: 0.3576 - val_accuracy: 0.8812\n",
            "Epoch 727/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3587 - accuracy: 0.8781 - val_loss: 0.3572 - val_accuracy: 0.8788\n",
            "Epoch 728/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3587 - accuracy: 0.8786 - val_loss: 0.3572 - val_accuracy: 0.8771\n",
            "Epoch 729/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3585 - accuracy: 0.8782 - val_loss: 0.3574 - val_accuracy: 0.8767\n",
            "Epoch 730/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3584 - accuracy: 0.8787 - val_loss: 0.3570 - val_accuracy: 0.8802\n",
            "Epoch 731/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3584 - accuracy: 0.8784 - val_loss: 0.3571 - val_accuracy: 0.8814\n",
            "Epoch 732/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3583 - accuracy: 0.8783 - val_loss: 0.3567 - val_accuracy: 0.8795\n",
            "Epoch 733/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3582 - accuracy: 0.8789 - val_loss: 0.3569 - val_accuracy: 0.8767\n",
            "Epoch 734/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3581 - accuracy: 0.8787 - val_loss: 0.3565 - val_accuracy: 0.8791\n",
            "Epoch 735/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3579 - accuracy: 0.8788 - val_loss: 0.3567 - val_accuracy: 0.8811\n",
            "Epoch 736/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3578 - accuracy: 0.8788 - val_loss: 0.3564 - val_accuracy: 0.8808\n",
            "Epoch 737/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3578 - accuracy: 0.8788 - val_loss: 0.3564 - val_accuracy: 0.8803\n",
            "Epoch 738/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3577 - accuracy: 0.8785 - val_loss: 0.3561 - val_accuracy: 0.8788\n",
            "Epoch 739/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3576 - accuracy: 0.8788 - val_loss: 0.3565 - val_accuracy: 0.8805\n",
            "Epoch 740/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3574 - accuracy: 0.8791 - val_loss: 0.3560 - val_accuracy: 0.8812\n",
            "Epoch 741/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3574 - accuracy: 0.8793 - val_loss: 0.3559 - val_accuracy: 0.8778\n",
            "Epoch 742/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3573 - accuracy: 0.8790 - val_loss: 0.3558 - val_accuracy: 0.8804\n",
            "Epoch 743/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3571 - accuracy: 0.8792 - val_loss: 0.3559 - val_accuracy: 0.8778\n",
            "Epoch 744/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3570 - accuracy: 0.8792 - val_loss: 0.3557 - val_accuracy: 0.8770\n",
            "Epoch 745/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3570 - accuracy: 0.8789 - val_loss: 0.3555 - val_accuracy: 0.8808\n",
            "Epoch 746/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3569 - accuracy: 0.8795 - val_loss: 0.3554 - val_accuracy: 0.8802\n",
            "Epoch 747/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3568 - accuracy: 0.8794 - val_loss: 0.3553 - val_accuracy: 0.8795\n",
            "Epoch 748/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3567 - accuracy: 0.8792 - val_loss: 0.3554 - val_accuracy: 0.8775\n",
            "Epoch 749/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3566 - accuracy: 0.8792 - val_loss: 0.3551 - val_accuracy: 0.8791\n",
            "Epoch 750/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3565 - accuracy: 0.8794 - val_loss: 0.3550 - val_accuracy: 0.8810\n",
            "Epoch 751/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3564 - accuracy: 0.8795 - val_loss: 0.3551 - val_accuracy: 0.8813\n",
            "Epoch 752/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3563 - accuracy: 0.8793 - val_loss: 0.3551 - val_accuracy: 0.8820\n",
            "Epoch 753/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3561 - accuracy: 0.8793 - val_loss: 0.3548 - val_accuracy: 0.8813\n",
            "Epoch 754/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3561 - accuracy: 0.8795 - val_loss: 0.3546 - val_accuracy: 0.8798\n",
            "Epoch 755/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3560 - accuracy: 0.8796 - val_loss: 0.3547 - val_accuracy: 0.8808\n",
            "Epoch 756/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3559 - accuracy: 0.8798 - val_loss: 0.3549 - val_accuracy: 0.8773\n",
            "Epoch 757/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3558 - accuracy: 0.8793 - val_loss: 0.3543 - val_accuracy: 0.8809\n",
            "Epoch 758/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3557 - accuracy: 0.8795 - val_loss: 0.3543 - val_accuracy: 0.8806\n",
            "Epoch 759/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3556 - accuracy: 0.8801 - val_loss: 0.3543 - val_accuracy: 0.8819\n",
            "Epoch 760/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3555 - accuracy: 0.8803 - val_loss: 0.3540 - val_accuracy: 0.8804\n",
            "Epoch 761/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3554 - accuracy: 0.8803 - val_loss: 0.3540 - val_accuracy: 0.8808\n",
            "Epoch 762/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3553 - accuracy: 0.8797 - val_loss: 0.3540 - val_accuracy: 0.8781\n",
            "Epoch 763/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3553 - accuracy: 0.8796 - val_loss: 0.3538 - val_accuracy: 0.8813\n",
            "Epoch 764/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3551 - accuracy: 0.8806 - val_loss: 0.3538 - val_accuracy: 0.8805\n",
            "Epoch 765/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3551 - accuracy: 0.8800 - val_loss: 0.3537 - val_accuracy: 0.8808\n",
            "Epoch 766/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3550 - accuracy: 0.8804 - val_loss: 0.3535 - val_accuracy: 0.8811\n",
            "Epoch 767/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3548 - accuracy: 0.8799 - val_loss: 0.3536 - val_accuracy: 0.8824\n",
            "Epoch 768/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3547 - accuracy: 0.8799 - val_loss: 0.3536 - val_accuracy: 0.8827\n",
            "Epoch 769/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3546 - accuracy: 0.8803 - val_loss: 0.3538 - val_accuracy: 0.8776\n",
            "Epoch 770/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3546 - accuracy: 0.8802 - val_loss: 0.3532 - val_accuracy: 0.8811\n",
            "Epoch 771/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3545 - accuracy: 0.8800 - val_loss: 0.3530 - val_accuracy: 0.8820\n",
            "Epoch 772/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3544 - accuracy: 0.8799 - val_loss: 0.3530 - val_accuracy: 0.8816\n",
            "Epoch 773/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3543 - accuracy: 0.8805 - val_loss: 0.3529 - val_accuracy: 0.8822\n",
            "Epoch 774/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3542 - accuracy: 0.8804 - val_loss: 0.3528 - val_accuracy: 0.8799\n",
            "Epoch 775/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3541 - accuracy: 0.8803 - val_loss: 0.3527 - val_accuracy: 0.8814\n",
            "Epoch 776/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3540 - accuracy: 0.8809 - val_loss: 0.3526 - val_accuracy: 0.8816\n",
            "Epoch 777/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3539 - accuracy: 0.8807 - val_loss: 0.3526 - val_accuracy: 0.8821\n",
            "Epoch 778/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3538 - accuracy: 0.8806 - val_loss: 0.3524 - val_accuracy: 0.8810\n",
            "Epoch 779/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3537 - accuracy: 0.8808 - val_loss: 0.3524 - val_accuracy: 0.8809\n",
            "Epoch 780/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3536 - accuracy: 0.8809 - val_loss: 0.3522 - val_accuracy: 0.8803\n",
            "Epoch 781/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8809 - val_loss: 0.3521 - val_accuracy: 0.8820\n",
            "Epoch 782/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3535 - accuracy: 0.8808 - val_loss: 0.3520 - val_accuracy: 0.8823\n",
            "Epoch 783/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3533 - accuracy: 0.8808 - val_loss: 0.3519 - val_accuracy: 0.8820\n",
            "Epoch 784/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3533 - accuracy: 0.8802 - val_loss: 0.3520 - val_accuracy: 0.8824\n",
            "Epoch 785/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3532 - accuracy: 0.8807 - val_loss: 0.3518 - val_accuracy: 0.8820\n",
            "Epoch 786/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3531 - accuracy: 0.8808 - val_loss: 0.3517 - val_accuracy: 0.8826\n",
            "Epoch 787/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3530 - accuracy: 0.8811 - val_loss: 0.3516 - val_accuracy: 0.8823\n",
            "Epoch 788/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3529 - accuracy: 0.8811 - val_loss: 0.3515 - val_accuracy: 0.8819\n",
            "Epoch 789/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3528 - accuracy: 0.8807 - val_loss: 0.3515 - val_accuracy: 0.8817\n",
            "Epoch 790/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3527 - accuracy: 0.8810 - val_loss: 0.3516 - val_accuracy: 0.8789\n",
            "Epoch 791/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3526 - accuracy: 0.8810 - val_loss: 0.3515 - val_accuracy: 0.8798\n",
            "Epoch 792/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3525 - accuracy: 0.8813 - val_loss: 0.3514 - val_accuracy: 0.8785\n",
            "Epoch 793/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3524 - accuracy: 0.8807 - val_loss: 0.3510 - val_accuracy: 0.8823\n",
            "Epoch 794/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3524 - accuracy: 0.8813 - val_loss: 0.3512 - val_accuracy: 0.8790\n",
            "Epoch 795/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3522 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8826\n",
            "Epoch 796/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3522 - accuracy: 0.8813 - val_loss: 0.3509 - val_accuracy: 0.8834\n",
            "Epoch 797/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3520 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8835\n",
            "Epoch 798/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3520 - accuracy: 0.8814 - val_loss: 0.3509 - val_accuracy: 0.8835\n",
            "Epoch 799/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3519 - accuracy: 0.8814 - val_loss: 0.3506 - val_accuracy: 0.8819\n",
            "Epoch 800/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3518 - accuracy: 0.8812 - val_loss: 0.3510 - val_accuracy: 0.8786\n",
            "Epoch 801/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3517 - accuracy: 0.8818 - val_loss: 0.3506 - val_accuracy: 0.8827\n",
            "Epoch 802/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3517 - accuracy: 0.8816 - val_loss: 0.3503 - val_accuracy: 0.8828\n",
            "Epoch 803/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3516 - accuracy: 0.8817 - val_loss: 0.3503 - val_accuracy: 0.8834\n",
            "Epoch 804/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3514 - accuracy: 0.8819 - val_loss: 0.3502 - val_accuracy: 0.8811\n",
            "Epoch 805/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3514 - accuracy: 0.8816 - val_loss: 0.3501 - val_accuracy: 0.8830\n",
            "Epoch 806/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3513 - accuracy: 0.8816 - val_loss: 0.3502 - val_accuracy: 0.8817\n",
            "Epoch 807/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3512 - accuracy: 0.8819 - val_loss: 0.3498 - val_accuracy: 0.8829\n",
            "Epoch 808/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.8816 - val_loss: 0.3500 - val_accuracy: 0.8831\n",
            "Epoch 809/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.8821 - val_loss: 0.3496 - val_accuracy: 0.8821\n",
            "Epoch 810/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3509 - accuracy: 0.8820 - val_loss: 0.3496 - val_accuracy: 0.8820\n",
            "Epoch 811/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3508 - accuracy: 0.8818 - val_loss: 0.3498 - val_accuracy: 0.8836\n",
            "Epoch 812/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3508 - accuracy: 0.8820 - val_loss: 0.3494 - val_accuracy: 0.8822\n",
            "Epoch 813/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3507 - accuracy: 0.8822 - val_loss: 0.3493 - val_accuracy: 0.8837\n",
            "Epoch 814/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3505 - accuracy: 0.8822 - val_loss: 0.3492 - val_accuracy: 0.8826\n",
            "Epoch 815/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3505 - accuracy: 0.8821 - val_loss: 0.3493 - val_accuracy: 0.8841\n",
            "Epoch 816/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3504 - accuracy: 0.8821 - val_loss: 0.3490 - val_accuracy: 0.8834\n",
            "Epoch 817/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3503 - accuracy: 0.8822 - val_loss: 0.3494 - val_accuracy: 0.8845\n",
            "Epoch 818/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3502 - accuracy: 0.8823 - val_loss: 0.3490 - val_accuracy: 0.8839\n",
            "Epoch 819/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3501 - accuracy: 0.8819 - val_loss: 0.3488 - val_accuracy: 0.8842\n",
            "Epoch 820/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3501 - accuracy: 0.8822 - val_loss: 0.3489 - val_accuracy: 0.8815\n",
            "Epoch 821/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3500 - accuracy: 0.8824 - val_loss: 0.3488 - val_accuracy: 0.8842\n",
            "Epoch 822/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3499 - accuracy: 0.8824 - val_loss: 0.3485 - val_accuracy: 0.8826\n",
            "Epoch 823/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3498 - accuracy: 0.8823 - val_loss: 0.3485 - val_accuracy: 0.8835\n",
            "Epoch 824/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3497 - accuracy: 0.8826 - val_loss: 0.3483 - val_accuracy: 0.8824\n",
            "Epoch 825/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8826 - val_loss: 0.3483 - val_accuracy: 0.8841\n",
            "Epoch 826/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3496 - accuracy: 0.8828 - val_loss: 0.3482 - val_accuracy: 0.8836\n",
            "Epoch 827/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3495 - accuracy: 0.8829 - val_loss: 0.3483 - val_accuracy: 0.8846\n",
            "Epoch 828/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3494 - accuracy: 0.8826 - val_loss: 0.3480 - val_accuracy: 0.8841\n",
            "Epoch 829/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3493 - accuracy: 0.8824 - val_loss: 0.3480 - val_accuracy: 0.8840\n",
            "Epoch 830/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3492 - accuracy: 0.8824 - val_loss: 0.3481 - val_accuracy: 0.8844\n",
            "Epoch 831/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3491 - accuracy: 0.8828 - val_loss: 0.3481 - val_accuracy: 0.8807\n",
            "Epoch 832/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3490 - accuracy: 0.8831 - val_loss: 0.3478 - val_accuracy: 0.8845\n",
            "Epoch 833/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3489 - accuracy: 0.8826 - val_loss: 0.3477 - val_accuracy: 0.8828\n",
            "Epoch 834/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3488 - accuracy: 0.8826 - val_loss: 0.3476 - val_accuracy: 0.8840\n",
            "Epoch 835/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3488 - accuracy: 0.8830 - val_loss: 0.3474 - val_accuracy: 0.8838\n",
            "Epoch 836/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3487 - accuracy: 0.8832 - val_loss: 0.3473 - val_accuracy: 0.8844\n",
            "Epoch 837/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3486 - accuracy: 0.8828 - val_loss: 0.3476 - val_accuracy: 0.8828\n",
            "Epoch 838/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3485 - accuracy: 0.8828 - val_loss: 0.3472 - val_accuracy: 0.8848\n",
            "Epoch 839/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3484 - accuracy: 0.8830 - val_loss: 0.3471 - val_accuracy: 0.8832\n",
            "Epoch 840/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3483 - accuracy: 0.8832 - val_loss: 0.3472 - val_accuracy: 0.8849\n",
            "Epoch 841/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3483 - accuracy: 0.8832 - val_loss: 0.3469 - val_accuracy: 0.8839\n",
            "Epoch 842/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3482 - accuracy: 0.8833 - val_loss: 0.3470 - val_accuracy: 0.8856\n",
            "Epoch 843/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3481 - accuracy: 0.8827 - val_loss: 0.3469 - val_accuracy: 0.8839\n",
            "Epoch 844/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3480 - accuracy: 0.8834 - val_loss: 0.3468 - val_accuracy: 0.8817\n",
            "Epoch 845/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3479 - accuracy: 0.8831 - val_loss: 0.3468 - val_accuracy: 0.8844\n",
            "Epoch 846/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3478 - accuracy: 0.8834 - val_loss: 0.3466 - val_accuracy: 0.8838\n",
            "Epoch 847/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3477 - accuracy: 0.8834 - val_loss: 0.3465 - val_accuracy: 0.8828\n",
            "Epoch 848/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3477 - accuracy: 0.8834 - val_loss: 0.3465 - val_accuracy: 0.8854\n",
            "Epoch 849/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3476 - accuracy: 0.8833 - val_loss: 0.3463 - val_accuracy: 0.8841\n",
            "Epoch 850/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3474 - accuracy: 0.8835 - val_loss: 0.3469 - val_accuracy: 0.8861\n",
            "Epoch 851/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3474 - accuracy: 0.8831 - val_loss: 0.3469 - val_accuracy: 0.8791\n",
            "Epoch 852/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3473 - accuracy: 0.8837 - val_loss: 0.3460 - val_accuracy: 0.8850\n",
            "Epoch 853/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3472 - accuracy: 0.8837 - val_loss: 0.3460 - val_accuracy: 0.8849\n",
            "Epoch 854/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3472 - accuracy: 0.8840 - val_loss: 0.3458 - val_accuracy: 0.8842\n",
            "Epoch 855/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3471 - accuracy: 0.8835 - val_loss: 0.3458 - val_accuracy: 0.8852\n",
            "Epoch 856/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3470 - accuracy: 0.8832 - val_loss: 0.3458 - val_accuracy: 0.8839\n",
            "Epoch 857/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3470 - accuracy: 0.8841 - val_loss: 0.3456 - val_accuracy: 0.8846\n",
            "Epoch 858/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3468 - accuracy: 0.8836 - val_loss: 0.3456 - val_accuracy: 0.8839\n",
            "Epoch 859/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3468 - accuracy: 0.8837 - val_loss: 0.3457 - val_accuracy: 0.8831\n",
            "Epoch 860/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3466 - accuracy: 0.8838 - val_loss: 0.3455 - val_accuracy: 0.8823\n",
            "Epoch 861/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3466 - accuracy: 0.8839 - val_loss: 0.3458 - val_accuracy: 0.8806\n",
            "Epoch 862/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3465 - accuracy: 0.8835 - val_loss: 0.3452 - val_accuracy: 0.8854\n",
            "Epoch 863/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3464 - accuracy: 0.8838 - val_loss: 0.3452 - val_accuracy: 0.8852\n",
            "Epoch 864/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3464 - accuracy: 0.8840 - val_loss: 0.3451 - val_accuracy: 0.8846\n",
            "Epoch 865/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3462 - accuracy: 0.8839 - val_loss: 0.3453 - val_accuracy: 0.8856\n",
            "Epoch 866/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3462 - accuracy: 0.8840 - val_loss: 0.3448 - val_accuracy: 0.8851\n",
            "Epoch 867/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3461 - accuracy: 0.8840 - val_loss: 0.3452 - val_accuracy: 0.8856\n",
            "Epoch 868/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3461 - accuracy: 0.8842 - val_loss: 0.3448 - val_accuracy: 0.8840\n",
            "Epoch 869/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3459 - accuracy: 0.8840 - val_loss: 0.3447 - val_accuracy: 0.8856\n",
            "Epoch 870/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3458 - accuracy: 0.8843 - val_loss: 0.3453 - val_accuracy: 0.8816\n",
            "Epoch 871/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3458 - accuracy: 0.8838 - val_loss: 0.3446 - val_accuracy: 0.8845\n",
            "Epoch 872/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3457 - accuracy: 0.8838 - val_loss: 0.3444 - val_accuracy: 0.8853\n",
            "Epoch 873/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3456 - accuracy: 0.8846 - val_loss: 0.3443 - val_accuracy: 0.8849\n",
            "Epoch 874/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3455 - accuracy: 0.8840 - val_loss: 0.3443 - val_accuracy: 0.8854\n",
            "Epoch 875/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3455 - accuracy: 0.8845 - val_loss: 0.3443 - val_accuracy: 0.8860\n",
            "Epoch 876/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3454 - accuracy: 0.8843 - val_loss: 0.3445 - val_accuracy: 0.8867\n",
            "Epoch 877/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3453 - accuracy: 0.8843 - val_loss: 0.3441 - val_accuracy: 0.8852\n",
            "Epoch 878/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3452 - accuracy: 0.8843 - val_loss: 0.3440 - val_accuracy: 0.8859\n",
            "Epoch 879/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3452 - accuracy: 0.8847 - val_loss: 0.3439 - val_accuracy: 0.8859\n",
            "Epoch 880/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3451 - accuracy: 0.8847 - val_loss: 0.3439 - val_accuracy: 0.8861\n",
            "Epoch 881/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3450 - accuracy: 0.8847 - val_loss: 0.3438 - val_accuracy: 0.8859\n",
            "Epoch 882/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3449 - accuracy: 0.8848 - val_loss: 0.3436 - val_accuracy: 0.8853\n",
            "Epoch 883/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3449 - accuracy: 0.8846 - val_loss: 0.3435 - val_accuracy: 0.8854\n",
            "Epoch 884/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3447 - accuracy: 0.8845 - val_loss: 0.3436 - val_accuracy: 0.8832\n",
            "Epoch 885/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3447 - accuracy: 0.8845 - val_loss: 0.3435 - val_accuracy: 0.8863\n",
            "Epoch 886/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3446 - accuracy: 0.8848 - val_loss: 0.3434 - val_accuracy: 0.8841\n",
            "Epoch 887/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3445 - accuracy: 0.8851 - val_loss: 0.3433 - val_accuracy: 0.8860\n",
            "Epoch 888/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3444 - accuracy: 0.8848 - val_loss: 0.3432 - val_accuracy: 0.8862\n",
            "Epoch 889/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3443 - accuracy: 0.8845 - val_loss: 0.3439 - val_accuracy: 0.8881\n",
            "Epoch 890/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3443 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8849\n",
            "Epoch 891/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3442 - accuracy: 0.8850 - val_loss: 0.3429 - val_accuracy: 0.8864\n",
            "Epoch 892/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3441 - accuracy: 0.8849 - val_loss: 0.3428 - val_accuracy: 0.8865\n",
            "Epoch 893/1000\n",
            "1000/1000 [==============================] - 3s 2ms/step - loss: 0.3440 - accuracy: 0.8850 - val_loss: 0.3430 - val_accuracy: 0.8868\n",
            "Epoch 894/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3440 - accuracy: 0.8847 - val_loss: 0.3430 - val_accuracy: 0.8870\n",
            "Epoch 895/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3439 - accuracy: 0.8856 - val_loss: 0.3426 - val_accuracy: 0.8863\n",
            "Epoch 896/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3438 - accuracy: 0.8856 - val_loss: 0.3426 - val_accuracy: 0.8861\n",
            "Epoch 897/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3437 - accuracy: 0.8854 - val_loss: 0.3426 - val_accuracy: 0.8856\n",
            "Epoch 898/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3437 - accuracy: 0.8853 - val_loss: 0.3424 - val_accuracy: 0.8865\n",
            "Epoch 899/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3436 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8866\n",
            "Epoch 900/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3435 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8867\n",
            "Epoch 901/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3434 - accuracy: 0.8854 - val_loss: 0.3421 - val_accuracy: 0.8857\n",
            "Epoch 902/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3433 - accuracy: 0.8853 - val_loss: 0.3424 - val_accuracy: 0.8871\n",
            "Epoch 903/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3432 - accuracy: 0.8853 - val_loss: 0.3423 - val_accuracy: 0.8844\n",
            "Epoch 904/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3432 - accuracy: 0.8848 - val_loss: 0.3420 - val_accuracy: 0.8867\n",
            "Epoch 905/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8856 - val_loss: 0.3418 - val_accuracy: 0.8863\n",
            "Epoch 906/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8853 - val_loss: 0.3422 - val_accuracy: 0.8880\n",
            "Epoch 907/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3430 - accuracy: 0.8853 - val_loss: 0.3417 - val_accuracy: 0.8860\n",
            "Epoch 908/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3428 - accuracy: 0.8856 - val_loss: 0.3417 - val_accuracy: 0.8859\n",
            "Epoch 909/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3428 - accuracy: 0.8856 - val_loss: 0.3417 - val_accuracy: 0.8859\n",
            "Epoch 910/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3427 - accuracy: 0.8858 - val_loss: 0.3415 - val_accuracy: 0.8862\n",
            "Epoch 911/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3427 - accuracy: 0.8855 - val_loss: 0.3414 - val_accuracy: 0.8867\n",
            "Epoch 912/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3426 - accuracy: 0.8860 - val_loss: 0.3416 - val_accuracy: 0.8866\n",
            "Epoch 913/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3424 - accuracy: 0.8855 - val_loss: 0.3413 - val_accuracy: 0.8863\n",
            "Epoch 914/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3424 - accuracy: 0.8853 - val_loss: 0.3412 - val_accuracy: 0.8867\n",
            "Epoch 915/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3424 - accuracy: 0.8859 - val_loss: 0.3411 - val_accuracy: 0.8864\n",
            "Epoch 916/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3423 - accuracy: 0.8859 - val_loss: 0.3410 - val_accuracy: 0.8860\n",
            "Epoch 917/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3422 - accuracy: 0.8857 - val_loss: 0.3414 - val_accuracy: 0.8843\n",
            "Epoch 918/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3421 - accuracy: 0.8858 - val_loss: 0.3411 - val_accuracy: 0.8849\n",
            "Epoch 919/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3421 - accuracy: 0.8858 - val_loss: 0.3408 - val_accuracy: 0.8859\n",
            "Epoch 920/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3420 - accuracy: 0.8861 - val_loss: 0.3410 - val_accuracy: 0.8878\n",
            "Epoch 921/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3419 - accuracy: 0.8861 - val_loss: 0.3410 - val_accuracy: 0.8856\n",
            "Epoch 922/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3418 - accuracy: 0.8858 - val_loss: 0.3408 - val_accuracy: 0.8844\n",
            "Epoch 923/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3418 - accuracy: 0.8860 - val_loss: 0.3405 - val_accuracy: 0.8868\n",
            "Epoch 924/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3417 - accuracy: 0.8860 - val_loss: 0.3404 - val_accuracy: 0.8867\n",
            "Epoch 925/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3416 - accuracy: 0.8861 - val_loss: 0.3405 - val_accuracy: 0.8856\n",
            "Epoch 926/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3415 - accuracy: 0.8860 - val_loss: 0.3405 - val_accuracy: 0.8853\n",
            "Epoch 927/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3415 - accuracy: 0.8861 - val_loss: 0.3403 - val_accuracy: 0.8860\n",
            "Epoch 928/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3414 - accuracy: 0.8858 - val_loss: 0.3402 - val_accuracy: 0.8864\n",
            "Epoch 929/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3413 - accuracy: 0.8860 - val_loss: 0.3402 - val_accuracy: 0.8881\n",
            "Epoch 930/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3413 - accuracy: 0.8864 - val_loss: 0.3401 - val_accuracy: 0.8878\n",
            "Epoch 931/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3412 - accuracy: 0.8863 - val_loss: 0.3403 - val_accuracy: 0.8842\n",
            "Epoch 932/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3411 - accuracy: 0.8860 - val_loss: 0.3401 - val_accuracy: 0.8850\n",
            "Epoch 933/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3410 - accuracy: 0.8863 - val_loss: 0.3398 - val_accuracy: 0.8871\n",
            "Epoch 934/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8860 - val_loss: 0.3397 - val_accuracy: 0.8868\n",
            "Epoch 935/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8861 - val_loss: 0.3397 - val_accuracy: 0.8873\n",
            "Epoch 936/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3408 - accuracy: 0.8862 - val_loss: 0.3399 - val_accuracy: 0.8878\n",
            "Epoch 937/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3407 - accuracy: 0.8862 - val_loss: 0.3396 - val_accuracy: 0.8881\n",
            "Epoch 938/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3407 - accuracy: 0.8868 - val_loss: 0.3395 - val_accuracy: 0.8866\n",
            "Epoch 939/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3406 - accuracy: 0.8864 - val_loss: 0.3395 - val_accuracy: 0.8878\n",
            "Epoch 940/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8866 - val_loss: 0.3394 - val_accuracy: 0.8887\n",
            "Epoch 941/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8870 - val_loss: 0.3395 - val_accuracy: 0.8885\n",
            "Epoch 942/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3404 - accuracy: 0.8862 - val_loss: 0.3398 - val_accuracy: 0.8892\n",
            "Epoch 943/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3403 - accuracy: 0.8869 - val_loss: 0.3391 - val_accuracy: 0.8864\n",
            "Epoch 944/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3402 - accuracy: 0.8864 - val_loss: 0.3395 - val_accuracy: 0.8881\n",
            "Epoch 945/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3401 - accuracy: 0.8863 - val_loss: 0.3393 - val_accuracy: 0.8870\n",
            "Epoch 946/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8869 - val_loss: 0.3389 - val_accuracy: 0.8868\n",
            "Epoch 947/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3400 - accuracy: 0.8868 - val_loss: 0.3388 - val_accuracy: 0.8868\n",
            "Epoch 948/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3399 - accuracy: 0.8865 - val_loss: 0.3388 - val_accuracy: 0.8884\n",
            "Epoch 949/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3399 - accuracy: 0.8864 - val_loss: 0.3389 - val_accuracy: 0.8892\n",
            "Epoch 950/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8866 - val_loss: 0.3386 - val_accuracy: 0.8863\n",
            "Epoch 951/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8868 - val_loss: 0.3386 - val_accuracy: 0.8877\n",
            "Epoch 952/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3397 - accuracy: 0.8867 - val_loss: 0.3385 - val_accuracy: 0.8881\n",
            "Epoch 953/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3396 - accuracy: 0.8869 - val_loss: 0.3384 - val_accuracy: 0.8887\n",
            "Epoch 954/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3395 - accuracy: 0.8871 - val_loss: 0.3384 - val_accuracy: 0.8876\n",
            "Epoch 955/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3394 - accuracy: 0.8867 - val_loss: 0.3383 - val_accuracy: 0.8888\n",
            "Epoch 956/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3394 - accuracy: 0.8869 - val_loss: 0.3381 - val_accuracy: 0.8878\n",
            "Epoch 957/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3393 - accuracy: 0.8870 - val_loss: 0.3382 - val_accuracy: 0.8888\n",
            "Epoch 958/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3392 - accuracy: 0.8875 - val_loss: 0.3384 - val_accuracy: 0.8852\n",
            "Epoch 959/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3391 - accuracy: 0.8869 - val_loss: 0.3380 - val_accuracy: 0.8870\n",
            "Epoch 960/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3390 - accuracy: 0.8868 - val_loss: 0.3379 - val_accuracy: 0.8892\n",
            "Epoch 961/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3390 - accuracy: 0.8874 - val_loss: 0.3379 - val_accuracy: 0.8878\n",
            "Epoch 962/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8871 - val_loss: 0.3377 - val_accuracy: 0.8884\n",
            "Epoch 963/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8871 - val_loss: 0.3378 - val_accuracy: 0.8866\n",
            "Epoch 964/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3388 - accuracy: 0.8868 - val_loss: 0.3377 - val_accuracy: 0.8870\n",
            "Epoch 965/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3387 - accuracy: 0.8872 - val_loss: 0.3376 - val_accuracy: 0.8877\n",
            "Epoch 966/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8871\n",
            "Epoch 967/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8892\n",
            "Epoch 968/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3385 - accuracy: 0.8875 - val_loss: 0.3374 - val_accuracy: 0.8867\n",
            "Epoch 969/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3385 - accuracy: 0.8872 - val_loss: 0.3373 - val_accuracy: 0.8878\n",
            "Epoch 970/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3384 - accuracy: 0.8874 - val_loss: 0.3375 - val_accuracy: 0.8902\n",
            "Epoch 971/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3383 - accuracy: 0.8878 - val_loss: 0.3372 - val_accuracy: 0.8874\n",
            "Epoch 972/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3382 - accuracy: 0.8873 - val_loss: 0.3371 - val_accuracy: 0.8883\n",
            "Epoch 973/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8873 - val_loss: 0.3372 - val_accuracy: 0.8866\n",
            "Epoch 974/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8875 - val_loss: 0.3369 - val_accuracy: 0.8878\n",
            "Epoch 975/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.8875 - val_loss: 0.3370 - val_accuracy: 0.8898\n",
            "Epoch 976/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3380 - accuracy: 0.8872 - val_loss: 0.3369 - val_accuracy: 0.8891\n",
            "Epoch 977/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3379 - accuracy: 0.8874 - val_loss: 0.3368 - val_accuracy: 0.8892\n",
            "Epoch 978/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3378 - accuracy: 0.8872 - val_loss: 0.3366 - val_accuracy: 0.8888\n",
            "Epoch 979/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3377 - accuracy: 0.8876 - val_loss: 0.3371 - val_accuracy: 0.8906\n",
            "Epoch 980/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8882 - val_loss: 0.3366 - val_accuracy: 0.8900\n",
            "Epoch 981/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3376 - accuracy: 0.8875 - val_loss: 0.3368 - val_accuracy: 0.8907\n",
            "Epoch 982/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3376 - accuracy: 0.8877 - val_loss: 0.3365 - val_accuracy: 0.8868\n",
            "Epoch 983/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3375 - accuracy: 0.8879 - val_loss: 0.3364 - val_accuracy: 0.8875\n",
            "Epoch 984/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3374 - accuracy: 0.8875 - val_loss: 0.3362 - val_accuracy: 0.8892\n",
            "Epoch 985/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3373 - accuracy: 0.8877 - val_loss: 0.3370 - val_accuracy: 0.8860\n",
            "Epoch 986/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3372 - accuracy: 0.8878 - val_loss: 0.3362 - val_accuracy: 0.8891\n",
            "Epoch 987/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3372 - accuracy: 0.8880 - val_loss: 0.3361 - val_accuracy: 0.8893\n",
            "Epoch 988/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3371 - accuracy: 0.8877 - val_loss: 0.3361 - val_accuracy: 0.8885\n",
            "Epoch 989/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3371 - accuracy: 0.8881 - val_loss: 0.3360 - val_accuracy: 0.8873\n",
            "Epoch 990/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3370 - accuracy: 0.8879 - val_loss: 0.3359 - val_accuracy: 0.8883\n",
            "Epoch 991/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3369 - accuracy: 0.8879 - val_loss: 0.3361 - val_accuracy: 0.8903\n",
            "Epoch 992/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3368 - accuracy: 0.8881 - val_loss: 0.3358 - val_accuracy: 0.8879\n",
            "Epoch 993/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3368 - accuracy: 0.8881 - val_loss: 0.3358 - val_accuracy: 0.8910\n",
            "Epoch 994/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3367 - accuracy: 0.8884 - val_loss: 0.3356 - val_accuracy: 0.8881\n",
            "Epoch 995/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3367 - accuracy: 0.8881 - val_loss: 0.3355 - val_accuracy: 0.8893\n",
            "Epoch 996/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3366 - accuracy: 0.8877 - val_loss: 0.3355 - val_accuracy: 0.8906\n",
            "Epoch 997/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3365 - accuracy: 0.8880 - val_loss: 0.3356 - val_accuracy: 0.8886\n",
            "Epoch 998/1000\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.3364 - accuracy: 0.8883 - val_loss: 0.3354 - val_accuracy: 0.8891\n",
            "Epoch 999/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3364 - accuracy: 0.8883 - val_loss: 0.3353 - val_accuracy: 0.8895\n",
            "Epoch 1000/1000\n",
            "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3363 - accuracy: 0.8885 - val_loss: 0.3360 - val_accuracy: 0.8863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = network.predict(xtest_std)"
      ],
      "metadata": {
        "id": "RrUIPDfdM5wB",
        "outputId": "bd8b8e1e-94d9-4327-e98e-fdb1fc7d4769",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 1s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(yhat.shape)"
      ],
      "metadata": {
        "id": "GJWR1M7LN6rv",
        "outputId": "8f8fe9a0-e945-4254-fd21-31ad53ecbf2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ytest.shape)"
      ],
      "metadata": {
        "id": "pFXuFm6HPG0g",
        "outputId": "4a9b76b0-68d2-4483-ab9e-1ce15043d7f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat =np.argmax(yhat, axis = -1)\n",
        "ytest = np.argmax(ytest, axis= -1)"
      ],
      "metadata": {
        "id": "V162us36U6Ij"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = accuracy_score(ytest,yhat)\n",
        "cm = confusion_matrix(ytest,yhat)\n",
        "print(f\"El grado de precisión de los datos son los siguientes {100*precision}\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "yXPBisYxORs_",
        "outputId": "bc960abf-acc8-4605-932f-a99705634373",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El grado de precisión de los datos son los siguientes 88.625\n",
            "[[11302   160   427]\n",
            " [  520  3240    32]\n",
            " [ 1134     2  3183]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Función logarítimica\n",
        "\n",
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "plt.title(\"Grafica de aprendizaje del modelo Softmax\")\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"accuracy\"])\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_accuracy\"])\n",
        "\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "JbkIxANdZHMB",
        "outputId": "541ca858-4318-42bd-ae38-f1271c2e34d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epocas = list(range(1,1001,1))\n",
        "\n",
        "plt.figure(1)\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"loss\"])\n",
        "\n",
        "\n",
        "plt.title(\"Grafica de aprendizaje del modelo Softmax\")\n",
        "\n",
        "\n",
        "plt.plot(epocas, epoch_accuracy.history[\"val_loss\"])\n",
        "\n",
        "plt.grid()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "\n",
        "plt.ylabel(\"Accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "VD_qykwMajLa",
        "outputId": "e2264863-c83e-40d1-a51c-d46c8dec67e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definir un mapa de calor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "sns.heatmap(xtrain_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Entrenamiento\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n"
      ],
      "metadata": {
        "id": "lE0LmmEE1LMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un mapa de calor para los datos de prueba\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Ajusta el tamaño de la figura según tus preferencias\n",
        "\n",
        "sns.heatmap(xtest_std, cmap=\"YlGnBu\", annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "plt.title(\"Mapa de calor para Datos de Prueba\")\n",
        "plt.xlabel(\"Características\")\n",
        "plt.ylabel(\"Muestras\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Py3_zIxs4elw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}